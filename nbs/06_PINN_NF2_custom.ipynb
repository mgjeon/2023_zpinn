{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3d60fc8c-60d3-421d-90cd-682bdc18a79f",
   "metadata": {},
   "source": [
    "# PINN NF2 (custom)\n",
    "> https://github.com/RobertJaro/NF2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "733794bb-89c1-4b26-86f2-613277bd357f",
   "metadata": {},
   "source": [
    "## Low-Lou (19990) NLFFF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0304d011-b7ee-458e-b2c3-12078a4f1946",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from zpinn.lowloumag import LowLouMag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fc9faf5c-fb6b-40c7-8b75-2434733377d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### Low and Lou (1990) NLFFF\n",
       "bounds = [-1, 1, -1, 1, 0, 2]<br>\n",
       "resolutions = [32, 64, 100]<br>\n",
       "n = 1<br>\n",
       "m = 1<br>\n",
       "l = 0.3<br>\n",
       "Phi = 1.5707963267948966<br>\n"
      ],
      "text/plain": [
       "<zpinn.lowloumag.LowLouMag at 0x7fb7101d8b20>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = LowLouMag(resolutions=[32, 64, 100])\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ce3c9518-a06d-4c11-bf7b-88a8fd5cb66b",
   "metadata": {},
   "outputs": [],
   "source": [
    "b.calculate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d200978c-7f0b-4f59-ae30-2d512ecd1861",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table><tr><th>Header</th><th>Data Arrays</th></tr><tr><td>\n",
       "<table>\n",
       "<tr><th>UniformGrid</th><th>Information</th></tr>\n",
       "<tr><td>N Cells</td><td>193347</td></tr>\n",
       "<tr><td>N Points</td><td>204800</td></tr>\n",
       "<tr><td>X Bounds</td><td>-1.000e+00, 1.000e+00</td></tr>\n",
       "<tr><td>Y Bounds</td><td>-1.000e+00, 1.000e+00</td></tr>\n",
       "<tr><td>Z Bounds</td><td>0.000e+00, 2.000e+00</td></tr>\n",
       "<tr><td>Dimensions</td><td>32, 64, 100</td></tr>\n",
       "<tr><td>Spacing</td><td>6.452e-02, 3.175e-02, 2.020e-02</td></tr>\n",
       "<tr><td>N Arrays</td><td>3</td></tr>\n",
       "</table>\n",
       "\n",
       "</td><td>\n",
       "<table>\n",
       "<tr><th>Name</th><th>Field</th><th>Type</th><th>N Comp</th><th>Min</th><th>Max</th></tr>\n",
       "<tr><td>B</td><td>Points</td><td>float64</td><td>3</td><td>-1.343e+02</td><td>2.231e+02</td></tr>\n",
       "<tr><td><b>mag</b></td><td>Points</td><td>float64</td><td>1</td><td>3.360e-01</td><td>2.258e+02</td></tr>\n",
       "<tr><td>alpha</td><td>Points</td><td>float64</td><td>1</td><td>-9.682e+00</td><td>9.682e+00</td></tr>\n",
       "</table>\n",
       "\n",
       "</td></tr> </table>"
      ],
      "text/plain": [
       "UniformGrid (0x7fb7101c3160)\n",
       "  N Cells:      193347\n",
       "  N Points:     204800\n",
       "  X Bounds:     -1.000e+00, 1.000e+00\n",
       "  Y Bounds:     -1.000e+00, 1.000e+00\n",
       "  Z Bounds:     0.000e+00, 2.000e+00\n",
       "  Dimensions:   32, 64, 100\n",
       "  Spacing:      6.452e-02, 3.175e-02, 2.020e-02\n",
       "  N Arrays:     3"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a95e1558-1601-47e2-8d92-4498784387a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 64)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Nx, Ny, _ =  b.grid.dimensions\n",
    "Nx, Ny"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2be5c281-a511-4f5a-8039-e7e2cd69489c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 31, 0, 63, 0, 0)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bottom_subset = (0, Nx-1, 0, Ny-1, 0, 0)\n",
    "bottom_subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3280043b-46a0-4453-bb95-64b9678b6966",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table><tr><th>Header</th><th>Data Arrays</th></tr><tr><td>\n",
       "<table>\n",
       "<tr><th>PolyData</th><th>Information</th></tr>\n",
       "<tr><td>N Cells</td><td>1953</td></tr>\n",
       "<tr><td>N Points</td><td>2048</td></tr>\n",
       "<tr><td>N Strips</td><td>0</td></tr>\n",
       "<tr><td>X Bounds</td><td>-1.000e+00, 1.000e+00</td></tr>\n",
       "<tr><td>Y Bounds</td><td>-1.000e+00, 1.000e+00</td></tr>\n",
       "<tr><td>Z Bounds</td><td>0.000e+00, 0.000e+00</td></tr>\n",
       "<tr><td>N Arrays</td><td>5</td></tr>\n",
       "</table>\n",
       "\n",
       "</td><td>\n",
       "<table>\n",
       "<tr><th>Name</th><th>Field</th><th>Type</th><th>N Comp</th><th>Min</th><th>Max</th></tr>\n",
       "<tr><td><b>B</b></td><td>Points</td><td>float64</td><td>3</td><td>-1.343e+02</td><td>2.231e+02</td></tr>\n",
       "<tr><td>mag</td><td>Points</td><td>float64</td><td>1</td><td>2.433e+00</td><td>2.258e+02</td></tr>\n",
       "<tr><td>alpha</td><td>Points</td><td>float64</td><td>1</td><td>-9.682e+00</td><td>9.682e+00</td></tr>\n",
       "<tr><td>vtkOriginalPointIds</td><td>Points</td><td>int64</td><td>1</td><td>0.000e+00</td><td>2.047e+03</td></tr>\n",
       "<tr><td>vtkOriginalCellIds</td><td>Cells</td><td>int64</td><td>1</td><td>0.000e+00</td><td>1.952e+03</td></tr>\n",
       "</table>\n",
       "\n",
       "</td></tr> </table>"
      ],
      "text/plain": [
       "PolyData (0x7fb71026e260)\n",
       "  N Cells:    1953\n",
       "  N Points:   2048\n",
       "  N Strips:   0\n",
       "  X Bounds:   -1.000e+00, 1.000e+00\n",
       "  Y Bounds:   -1.000e+00, 1.000e+00\n",
       "  Z Bounds:   0.000e+00, 0.000e+00\n",
       "  N Arrays:   5"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bottom = b.grid.extract_subset(bottom_subset).extract_surface()\n",
    "bottom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f02e7b2b-47c7-40cb-b882-daae6d679145",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 64, 3)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b_bottom = bottom['B'].reshape(Nx, Ny, 3)\n",
    "b_bottom = np.array(b_bottom)\n",
    "b_bottom.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72c66b53-cf67-4cac-a4a1-95ab778ae4cb",
   "metadata": {},
   "source": [
    "## PINN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebc9b824-92cd-4dd7-a4a0-60de74708a66",
   "metadata": {},
   "source": [
    "$$\n",
    "\\mathbf{B}(z=0)\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "627ea741-94db-4342-aac6-c6a82fc7f887",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 64, 3)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b_bottom.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3520183e-a435-4b0b-a96a-9d512f54e71a",
   "metadata": {},
   "source": [
    "$$\n",
    "\\mathcal{L}_\\text{ff}(\\boldsymbol{\\theta}; \\mathcal{T}_f) = \\frac{1}{|\\mathcal{T}_f|} \\sum_{\\boldsymbol{x}\\in \\mathcal{T}_f} \\frac{|(\\nabla \\times \\mathbf{\\hat{B}})\\times \\mathbf{\\hat{B}}|^2}{|\\mathbf{\\hat{B}}|^2}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\mathcal{L}_\\text{div}(\\boldsymbol{\\theta}; \\mathcal{T}_f) = \\frac{1}{|\\mathcal{T}_f|} \\sum_{\\boldsymbol{x}\\in \\mathcal{T}_f} |\\nabla \\cdot \\mathbf{\\hat{B}}|^2\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\mathcal{L}_\\text{bc}(\\boldsymbol{\\theta};\\mathcal{T}_b)=\\frac{1}{|\\mathcal{T}_b|}\\sum_{\\boldsymbol{x}\\in\\mathcal{T}_b}{|\\mathbf{\\hat{B}}-\\mathbf{B}|^2}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\mathcal{L} = w_{\\text{ff}}\\mathcal{L}_\\text{ff} + w_{\\text{div}}\\mathcal{L}_\\text{div} +  w_{\\text{bc}}\\mathcal{L}_{\\text{bc}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dc0ffac4-3520-476a-a0c5-596658cfe8bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.cuda import get_device_name\n",
    "from torch.optim.lr_scheduler import ExponentialLR\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset, RandomSampler\n",
    "\n",
    "import os\n",
    "import json\n",
    "import logging\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "53ec35c5-a8d5-4391-bf5e-066101108b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]= \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "58fea061-eb11-4095-a5fd-c6e509de74bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_coordinates(bounds):\n",
    "    xbounds = (bounds[0], bounds[1])\n",
    "    ybounds = (bounds[2], bounds[3])\n",
    "    zbounds = (bounds[4], bounds[5])\n",
    "    meshgrid = np.mgrid[xbounds[0]:xbounds[1]+1, ybounds[0]:ybounds[1]+1, zbounds[0]:zbounds[1]+1]\n",
    "    return np.stack(meshgrid, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "54581b84-153b-43db-9c98-789dab97e0bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sine(nn.Module):\n",
    "    def __init__(self, w0=1.):\n",
    "        super().__init__()\n",
    "        self.w0 = w0\n",
    "\n",
    "    def forward(self, x):\n",
    "        return torch.sin(self.w0 * x)\n",
    "    \n",
    "class PositionalEncoding(nn.Module):\n",
    "    \"\"\"\n",
    "    Positional Encoding of the input coordinates.\n",
    "\n",
    "    encodes x to (..., sin(2^k x), cos(2^k x), ...)\n",
    "    k takes \"num_freqs\" number of values equally spaced between [0, max_freq]\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, max_freq, num_freqs):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            max_freq (int): maximum frequency in the positional encoding.\n",
    "            num_freqs (int): number of frequencies between [0, max_freq]\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        freqs = 2 ** torch.linspace(0, max_freq, num_freqs)\n",
    "        self.register_buffer(\"freqs\", freqs)  # (num_freqs)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Inputs:\n",
    "            x: (batch, num_samples, in_features)\n",
    "        Outputs:\n",
    "            out: (batch, num_samples, 2*num_freqs*in_features)\n",
    "        \"\"\"\n",
    "        x_proj = x.unsqueeze(dim=-2) * self.freqs.unsqueeze(dim=-1)  # (num_rays, num_samples, num_freqs, in_features)\n",
    "        x_proj = x_proj.reshape(*x.shape[:-1], -1)  # (num_rays, num_samples, num_freqs*in_features)\n",
    "        out = torch.cat([torch.sin(x_proj), torch.cos(x_proj)],\n",
    "                        dim=-1)  # (num_rays, num_samples, 2*num_freqs*in_features)\n",
    "        return out\n",
    "\n",
    "class BModel(nn.Module):\n",
    "\n",
    "    def __init__(self, in_coords, out_values, dim, pos_encoding=False):\n",
    "        super().__init__()\n",
    "        if pos_encoding:\n",
    "            posenc = PositionalEncoding(8, 20)\n",
    "            d_in = nn.Linear(in_coords * 40, dim)\n",
    "            self.d_in = nn.Sequential(posenc, d_in)\n",
    "        else:\n",
    "            self.d_in = nn.Linear(in_coords, dim)\n",
    "        lin = [nn.Linear(dim, dim) for _ in range(8)]\n",
    "        self.linear_layers = nn.ModuleList(lin)\n",
    "        self.d_out = nn.Linear(dim, out_values)\n",
    "        self.activation = Sine()  # torch.tanh\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.activation(self.d_in(x))\n",
    "        for l in self.linear_layers:\n",
    "            x = self.activation(l(x))\n",
    "        x = self.d_out(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "97aae5a6-0dac-4f2b-a484-666229c315a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BoundaryDataset(Dataset):\n",
    "\n",
    "    def __init__(self, batches_path):\n",
    "        self.batches_path = batches_path\n",
    "\n",
    "    def __len__(self):\n",
    "        return np.load(self.batches_path, mmap_mode='r').shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # lazy load data\n",
    "        d = np.load(self.batches_path, mmap_mode='r')[idx]\n",
    "        d = np.copy(d)\n",
    "        coord, field = d[:, 0],  d[:, 1]\n",
    "        return coord, field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d0b1761c-b6cc-4a6c-b7fc-61016aac981a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PotentialModel(nn.Module):\n",
    "\n",
    "    def __init__(self, b_n, r_p):\n",
    "        super().__init__()\n",
    "        self.register_buffer('b_n', b_n)\n",
    "        self.register_buffer('r_p', r_p)\n",
    "        c = np.array([[0, 0, 1/np.sqrt(2*np.pi)]])\n",
    "        c = torch.tensor(c, dtype=torch.float64)\n",
    "        self.register_buffer('c', c)\n",
    "\n",
    "    def forward(self, r):\n",
    "        numerator = self.b_n[:, None]\n",
    "        denominator = torch.sqrt(torch.sum((r[None, :] - self.r_p[:, None] + self.c[None])**2, -1))\n",
    "        potential = torch.sum(numerator/denominator, 0) / (2*np.pi)\n",
    "        return potential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8e462333-ff5a-4d35-9fd9-04270f34c613",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_bc_data(device, b_bottom, height, b_norm, spatial_norm):\n",
    "    Nx, Ny, _ = b_bottom.shape\n",
    "    Nz = height\n",
    "\n",
    "    bottom_values = b_bottom.reshape(-1, 3)\n",
    "    bottom_values = np.double(bottom_values)\n",
    "    bottom_coords = create_coordinates((0, Nx-1, 0, Ny-1, 0, 0)).reshape(-1, 3)\n",
    "    bottom_coords = np.double(bottom_coords)\n",
    "\n",
    "    top_lateral_coordinates = [create_coordinates((0, Nx-1, 0, Ny-1, Nz-1, Nz-1)).reshape(-1, 3),\n",
    "                        create_coordinates((0, 0, 0, Ny-1, 0, Nz-1)).reshape(-1, 3),\n",
    "                        create_coordinates((Nx-1, Nx-1, 0, Ny-1, 0, Nz-1)).reshape(-1, 3),\n",
    "                        create_coordinates((0, Nx-1, 0, 0, 0, Nz-1)).reshape(-1, 3),\n",
    "                        create_coordinates((0, Nx-1, Ny-1, Ny-1, 0, Nz-1)).reshape(-1, 3)]\n",
    "\n",
    "    b_n = torch.tensor(bottom_values[:, 2], dtype=torch.float64)\n",
    "    r_p = torch.tensor(bottom_coords, dtype=torch.float64)\n",
    "\n",
    "    model = nn.DataParallel(PotentialModel(b_n, r_p)).to(device)\n",
    "\n",
    "    pf_fields = []\n",
    "    pf_coords = []\n",
    "    for r_coords in top_lateral_coordinates:\n",
    "        r_coords = torch.tensor(r_coords, dtype=torch.float64)\n",
    "        pf_batch_size = int(np.prod(r_coords.shape[:-1]) // 10)\n",
    "\n",
    "        fields = []\n",
    "        for r, in tqdm(DataLoader(TensorDataset(r_coords), batch_size=pf_batch_size, num_workers=2),\n",
    "                            desc='Potential Boundary'):\n",
    "            r = r.to(device).requires_grad_(True)\n",
    "            p_batch = model(r)\n",
    "            b_p = -1 * torch.autograd.grad(p_batch, r, torch.ones_like(p_batch), retain_graph=True, create_graph=True)[0]\n",
    "            fields += [b_p.clone().detach().cpu().numpy()]\n",
    "        pf_fields += [np.concatenate(fields)]\n",
    "        pf_coords += [r_coords.clone().detach().cpu().numpy()]\n",
    "\n",
    "    top_lateral_values = np.concatenate(pf_fields) \n",
    "    top_lateral_coords = np.concatenate(pf_coords)\n",
    "\n",
    "    boundary_values = np.concatenate([top_lateral_values, bottom_values])\n",
    "    boundary_coords = np.concatenate([top_lateral_coords, bottom_coords])\n",
    "\n",
    "    normalized_boundary_values = boundary_values / b_norm\n",
    "    normalized_boundary_coords = boundary_coords / spatial_norm\n",
    "\n",
    "    boundary_data = np.stack([normalized_boundary_coords, normalized_boundary_values], 1)\n",
    "\n",
    "    return boundary_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f7fceb4c-7fcf-4931-a4d7-c74b9b6ac701",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_boundary_batches(boundary_data, batch_size, total_iterations, num_workers):\n",
    "        # shuffle data\n",
    "        r = np.random.permutation(boundary_data.shape[0])\n",
    "        boundary_data = boundary_data[r]\n",
    "    \n",
    "        # adjust to batch size\n",
    "        pad = batch_size - boundary_data.shape[0] % batch_size\n",
    "        boundary_data = np.concatenate([boundary_data, boundary_data[:pad]])\n",
    "    \n",
    "        # split data into batches\n",
    "        n_batches = boundary_data.shape[0] // batch_size\n",
    "        boundary_batches = np.array(np.split(boundary_data, n_batches), dtype=np.float32)\n",
    "    \n",
    "        # store batches to disk\n",
    "        boundary_batches_path = 'boundary_batches.npy'\n",
    "        np.save(boundary_batches_path, boundary_batches)\n",
    "        # create data loaders\n",
    "        boundary_dataset = BoundaryDataset(boundary_batches_path)\n",
    "        # create loader\n",
    "        boundary_data_loader = DataLoader(boundary_dataset, batch_size=None, num_workers=num_workers, pin_memory=True,\n",
    "                                 sampler=RandomSampler(boundary_dataset, replacement=True, num_samples=total_iterations))\n",
    "        return boundary_data_loader, boundary_batches_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "40b547d0-78ad-4c3e-bd0c-b218efb084af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_b_bottom(b_bottom):\n",
    "    plt.close()\n",
    "    fig, axes = plt.subplots(nrows=1, ncols=3)\n",
    "    axes[0].contour(b_bottom[:, :, 2].transpose(), origin='lower', cmap='plasma')\n",
    "    axes[0].set_xlabel('x')\n",
    "    axes[0].set_ylabel('y')\n",
    "    axes[0].set_title(r\"$B_z(z=0)$\")\n",
    "    axes[0].set_aspect('equal')\n",
    "    \n",
    "    axes[1].contourf(b_bottom[:, :, 2].transpose(), origin='lower', cmap='plasma')\n",
    "    axes[1].set_xlabel('x')\n",
    "    axes[1].set_ylabel('y')\n",
    "    axes[1].set_title(r\"$B_z(z=0)$\")\n",
    "    axes[1].set_aspect('equal')\n",
    "    \n",
    "    CS = axes[2].imshow(b_bottom[:, :, 2].transpose(), origin='lower', cmap='plasma')\n",
    "    axes[2].set_xlabel('x')\n",
    "    axes[2].set_ylabel('y')\n",
    "    axes[2].set_title(r\"$B_z(z=0)$\")\n",
    "    axes[2].set_aspect('equal')\n",
    "    \n",
    "    fig.colorbar(CS, ax=axes, orientation='horizontal', pad=0.2)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dd0acaf7-35c4-4dd6-9ae7-2dd3f43bdfe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NF2Trainer:\n",
    "    def __init__(self, device, batch_size, b_bottom, height, b_norm=150, spatial_norm=150, decay_iterations=25000, total_iterations=50000):\n",
    "        self.device = device\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "        self.b_bottom = b_bottom\n",
    "        self.height = height\n",
    "        self.Nx, self.Ny, _ = self.b_bottom.shape\n",
    "        self.Nz = height\n",
    "        self.cube_shape = (self.Nx, self.Ny, self.Nz)\n",
    "        \n",
    "        self.b_norm = b_norm\n",
    "        self.spatial_norm = spatial_norm\n",
    "        self.total_iterations = total_iterations\n",
    "\n",
    "        self.boundary_data = prepare_bc_data(self.device, self.b_bottom, self.height, self.b_norm, self.spatial_norm)\n",
    "\n",
    "        collocation_coords = create_coordinates((0, self.Nx-1, 0, self.Ny-1, 0, self.Nz-1)).reshape(-1, 3)\n",
    "        normalized_collocation_coords = collocation_coords / self.spatial_norm\n",
    "        self.normalized_collocation_coords = torch.tensor(normalized_collocation_coords)\n",
    "\n",
    "        self.Bmodel = nn.DataParallel(BModel(3, 3, 256)).to(device)\n",
    "        self.opt = torch.optim.Adam(self.Bmodel.parameters(), lr=5e-4)\n",
    "        self.scheduler = ExponentialLR(self.opt, gamma=(5e-5 / 5e-4) ** (1 / total_iterations))\n",
    "\n",
    "        self.w_ff = 1\n",
    "        self.w_div = 1\n",
    "        self.w_bc = 1000\n",
    "        self.w_bc_decay = (1 / 1000) ** (1 / decay_iterations) \n",
    "        \n",
    "    def train(self):\n",
    "        num_workers = os.cpu_count()\n",
    "        boundary_data_loader, boundary_batches_path = create_boundary_batches(self.boundary_data, self.batch_size, num_workers, self.total_iterations)\n",
    "        \n",
    "        model = self.Bmodel\n",
    "        opt = self.opt\n",
    "        device = self.device\n",
    "        w_div, w_ff = self.w_div, self.w_ff\n",
    "\n",
    "        for iter, (boundary_coords, boundary_b) in tqdm(enumerate(boundary_data_loader, start=0),\n",
    "                                                                   total=len(data_loader), desc='Training'):\n",
    "            print(iter)\n",
    "    \n",
    "            boundary_coords, boundary_b= boundary_coords.to(device), boundary_b.to(device)\n",
    "    \n",
    "            perm = torch.randperm(self.normalized_collocation_coords.shape[0])\n",
    "            idx = perm[:batch_size]\n",
    "            co_coords = self.normalized_collocation_coords[idx].to(device)\n",
    "    \n",
    "            # concatenate boundary and random points\n",
    "            # n_boundary_coords = boundary_coords.shape[0]\n",
    "            # r = torch.cat([boundary_coords, co_coords], 0)\n",
    "            r = co_coords\n",
    "            r.requires_grad = True\n",
    "    \n",
    "            # forward step\n",
    "            B = model(r)\n",
    "    \n",
    "            # if iter == 0:\n",
    "            #     model.eval()\n",
    "            #     torch.save({'model': self.model,\n",
    "            #         'cube_shape': self.cube_shape,\n",
    "            #         'b_norm': self.b_norm,\n",
    "            #         'spatial_norm': self.spatial_norm,\n",
    "            #         'meta_info': self.meta_info}, os.path.join(self.base_path, 'fields_%06d.nf2' % iter))\n",
    "            #     self.plot_sample(iter-1, batch_size=batch_size)\n",
    "            #     model.train()\n",
    "    \n",
    "            # compute boundary loss\n",
    "            # boundary_B = B[:n_boundary_coords]\n",
    "            boundary_B = model(boundary_coords)\n",
    "            # bc_loss = torch.abs(boundary_B - boundary_b)\n",
    "            # bc_loss = torch.mean(bc_loss.pow(2).sum(-1))\n",
    "    \n",
    "            bc_loss = torch.sum((boundary_B - boundary_b)**2, dim=-1)\n",
    "            bc_loss = torch.mean(bc_loss)\n",
    "            # compute div and ff loss\n",
    "            # divergence_loss, force_free_loss = calculate_loss(b, coords)\n",
    "    \n",
    "            dBx_dr = torch.autograd.grad(B[:, 0], r, torch.ones_like(B[:, 0]), retain_graph=True, create_graph=True)[0]\n",
    "            dBy_dr = torch.autograd.grad(B[:, 1], r, torch.ones_like(B[:, 1]), retain_graph=True, create_graph=True)[0]\n",
    "            dBz_dr = torch.autograd.grad(B[:, 2], r, torch.ones_like(B[:, 2]), retain_graph=True, create_graph=True)[0]\n",
    "    \n",
    "            dBx_dx = dBx_dr[:, 0]\n",
    "            dBx_dy = dBx_dr[:, 1]\n",
    "            dBx_dz = dBx_dr[:, 2]\n",
    "    \n",
    "            dBy_dx = dBy_dr[:, 0]\n",
    "            dBy_dy = dBy_dr[:, 1]\n",
    "            dBy_dz = dBy_dr[:, 2]\n",
    "    \n",
    "            dBz_dx = dBz_dr[:, 0]\n",
    "            dBz_dy = dBz_dr[:, 1]\n",
    "            dBz_dz = dBz_dr[:, 2]\n",
    "    \n",
    "            rot_x = dBz_dy - dBy_dz\n",
    "            rot_y = dBx_dz - dBz_dx\n",
    "            rot_z = dBy_dx - dBx_dy\n",
    "    \n",
    "            J = torch.stack([rot_x, rot_y, rot_z], -1)\n",
    "            JxB = torch.cross(J, B, dim=-1)\n",
    "    \n",
    "            divB = dBx_dx + dBy_dy + dBz_dz\n",
    "    \n",
    "            force_free_loss = torch.sum(JxB**2, dim=-1) / (torch.sum(B**2, dim=-1) + 1e-7)\n",
    "            force_free_loss = torch.mean(force_free_loss)\n",
    "            divergence_loss = torch.sum((divB)**2, dim=-1)\n",
    "            divergence_loss = torch.mean(divergence_loss)\n",
    "    \n",
    "            loss = self.w_bc*bc_loss + w_ff*force_free_loss + w_div*divergence_loss\n",
    "    \n",
    "            if iter == 0:\n",
    "                self.log.info('[Iteration %06d/%06d] [loss: %.08f] [bc_loss: %.08f; div_loss: %.08f; ff_loss: %.08f] [w_bc: %f, LR: %f] [%s]' %\n",
    "                        (iter + 1, total_iterations,\n",
    "                        loss,\n",
    "                        self.w_bc*bc_loss,\n",
    "                        w_ff*force_free_loss,\n",
    "                        w_div*divergence_loss,\n",
    "                        self.w_bc,\n",
    "                        scheduler.get_last_lr()[0],\n",
    "                        datetime.now() - start_time))\n",
    "                \n",
    "                torch.save({'BC_loss': bc_loss.detach().cpu().numpy(),\n",
    "                    'w_bc': self.w_bc,\n",
    "                    'divergence_loss': divergence_loss.mean().detach().cpu().numpy(),\n",
    "                    'w_div': w_div,\n",
    "                    'force_loss': force_free_loss.mean().detach().cpu().numpy(),\n",
    "                    'w_ff': w_ff,}, os.path.join(self.base_path, 'loss_%06d.nf2' % iter))\n",
    "                torch.save({'model': self.model,\n",
    "                    'cube_shape': self.cube_shape,\n",
    "                    'b_norm': self.b_norm,\n",
    "                    'spatial_norm': self.spatial_norm,\n",
    "                    'meta_info': self.meta_info}, os.path.join(self.base_path, 'fields_%06d.nf2' % iter))\n",
    "    \n",
    "            opt.zero_grad()\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 0.1)\n",
    "            opt.step()\n",
    "    \n",
    "            if (log_interval > 0 and (iter + 1) % log_interval == 0):\n",
    "                # log loss\n",
    "                self.log.info('[Iteration %06d/%06d] [loss: %.08f] [bc_loss: %.08f; div_loss: %.08f; ff_loss: %.08f] [w_bc: %f, LR: %f] [%s]' %\n",
    "                        (iter + 1, total_iterations,\n",
    "                        loss,\n",
    "                        self.w_bc*bc_loss,\n",
    "                        w_ff*force_free_loss,\n",
    "                        w_div*divergence_loss,\n",
    "                        self.w_bc,\n",
    "                        scheduler.get_last_lr()[0],\n",
    "                        datetime.now() - start_time))\n",
    "                \n",
    "                torch.save({'BC_loss': bc_loss.detach().cpu().numpy(),\n",
    "                            'lambda_BC': self.w_bc,\n",
    "                            'divergence_loss': divergence_loss.detach().cpu().numpy(),\n",
    "                            'lambda_div': w_div,\n",
    "                            'force_loss': force_free_loss.detach().cpu().numpy(),\n",
    "                            'lambda_ff': w_ff,\n",
    "                            'LR':scheduler.get_last_lr()[0]}, \n",
    "                            os.path.join(base_path, 'loss_%06d.nf2' % iter))\n",
    "                torch.save({'model': model,\n",
    "                            'cube_shape': self.cube_shape,\n",
    "                            'b_norm': b_norm,\n",
    "                            'spatial_norm': spatial_norm,\n",
    "                            'meta_info': meta_info}, \n",
    "                            os.path.join(base_path, 'fields_%06d.nf2' % iter))\n",
    "    \n",
    "            # update training parameters\n",
    "            if self.w_bc > 1:\n",
    "                self.w_bc *= self.w_bc_decay\n",
    "                if self.w_bc <= 1:\n",
    "                    self.w_bc = 1\n",
    "            if scheduler.get_last_lr()[0] > 5e-5:\n",
    "                scheduler.step()\n",
    "    \n",
    "        # save final model state\n",
    "        torch.save({'BC_loss': bc_loss.detach().cpu().numpy(),\n",
    "                    'w_bc': self.w_bc,\n",
    "                    'divergence_loss': divergence_loss.detach().cpu().numpy(),\n",
    "                    'w_div': w_div,\n",
    "                    'force_loss': force_free_loss.detach().cpu().numpy(),\n",
    "                    'w_ff': w_ff,\n",
    "                    'LR':scheduler.get_last_lr()[0]}, \n",
    "                    os.path.join(base_path, 'loss_final.nf2'))\n",
    "        torch.save({'model': model,\n",
    "                    'cube_shape': self.cube_shape,\n",
    "                    'b_norm': b_norm,\n",
    "                    'spatial_norm': spatial_norm,\n",
    "                    'meta_info': meta_info}, \n",
    "                    os.path.join(base_path, 'fields_final.nf2'))\n",
    "        torch.save({'m': model.state_dict(),\n",
    "                    'o': opt.state_dict(), },\n",
    "                    os.path.join(base_path, 'model_final.pt'))\n",
    "        # cleanup\n",
    "        os.remove(batches_path)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0910927b-ad29-44ef-a7d3-75947e96f186",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "batch_size = 10000\n",
    "height = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "37b2156a-a3ea-442b-931c-97e0dd310e16",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Potential Boundary: 100%|█████████████| 11/11 [00:00<00:00, 97.23it/s]\n",
      "Potential Boundary: 100%|█████████████| 10/10 [00:00<00:00, 90.31it/s]\n",
      "Potential Boundary: 100%|█████████████| 10/10 [00:00<00:00, 97.85it/s]\n",
      "Potential Boundary: 100%|████████████| 10/10 [00:00<00:00, 105.74it/s]\n",
      "Potential Boundary: 100%|████████████| 10/10 [00:00<00:00, 112.86it/s]\n"
     ]
    }
   ],
   "source": [
    "trainer = NF2Trainer(device, batch_size, b_bottom, height)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b57b60b-25be-47f7-b233-d1059fb759df",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tensor/mambaforge/envs/zpinn/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 50000 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66d1ea2e-7eb5-4276-ab4c-ed3bf572f622",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "zpinn",
   "language": "python",
   "name": "zpinn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
