{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PINN (series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from setproctitle import setproctitle\n",
    "setproctitle(\"PINN (series)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]= \"2\"\n",
    "\n",
    "import time\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b_bottom_paths = os.path.expanduser('~/workspace/_data/NOAA12673/b_bottom')\n",
    "Nz = 160\n",
    "spatial_norm = 160\n",
    "b_norm = 2500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_iterations = 50000\n",
    "log_interval = 1000\n",
    "\n",
    "series_iteration = 2000\n",
    "series_log_interval = 100\n",
    "\n",
    "num_neurons = 256\n",
    "num_layers = 8\n",
    "\n",
    "w_ff = 1\n",
    "w_div = 1\n",
    "# w_bc_init = 1000\n",
    "decay_iterations = 25000\n",
    "\n",
    "# lr_init = 5e-4\n",
    "# lr_final = 5e-5\n",
    "# lr_decay_iterations = 50000\n",
    "\n",
    "batch_size = 10000\n",
    "num_worker = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cmspinn.pinn_nf2_old import NF2Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration:\n",
      "dim: 256, w_div: 1.000000, w_ff: 1.000000, decay_iterations: 25000, potential: True, vector_potential: False, \n",
      "Using device: cuda (gpus 1) ['NVIDIA RTX A6000']\n",
      "Potential Boundary: 100%|██████████| 1/1 [00:01<00:00,  1.30s/it]\n",
      "Training:   0%|          | 0/50000 [00:00<?, ?it/s][Iteration 000000/050000] [loss: 29.98109436] [loss_bc: 29.98107910; loss_div: 0.00001250; loss_ff: 0.00000281] [w_bc: 1000.000000, LR: 0.000500]\n",
      "Training:   2%|▏         | 999/50000 [01:13<59:10, 13.80it/s]  [Iteration 001000/050000] [loss: 6.27711678] [loss_bc: 5.88370609; loss_div: 0.25200206; loss_ff: 0.14140853] [w_bc: 758.787207, LR: 0.000478]\n",
      "Training:   4%|▍         | 1999/50000 [02:26<57:54, 13.82it/s]  [Iteration 002000/050000] [loss: 3.82460690] [loss_bc: 3.61501765; loss_div: 0.14968877; loss_ff: 0.05990048] [w_bc: 575.598959, LR: 0.000456]\n",
      "Training:   6%|▌         | 2999/50000 [03:38<57:04, 13.72it/s]  [Iteration 003000/050000] [loss: 2.30608153] [loss_bc: 2.01824665; loss_div: 0.19885935; loss_ff: 0.08897533] [w_bc: 436.636463, LR: 0.000436]\n",
      "Training:   8%|▊         | 3999/50000 [04:51<55:42, 13.76it/s]  [Iteration 004000/050000] [loss: 1.23827636] [loss_bc: 1.13903141; loss_div: 0.06435177; loss_ff: 0.03489317] [w_bc: 331.222629, LR: 0.000416]\n",
      "Training:  10%|▉         | 4999/50000 [06:04<54:33, 13.75it/s][Iteration 005000/050000] [loss: 0.88111007] [loss_bc: 0.80489385; loss_div: 0.04822965; loss_ff: 0.02798658] [w_bc: 251.258059, LR: 0.000397]\n",
      "Training:  12%|█▏        | 5999/50000 [07:17<53:19, 13.75it/s][Iteration 006000/050000] [loss: 0.61447710] [loss_bc: 0.55933553; loss_div: 0.03624348; loss_ff: 0.01889809] [w_bc: 190.598729, LR: 0.000379]\n",
      "Training:  14%|█▍        | 6999/50000 [08:30<52:19, 13.70it/s][Iteration 007000/050000] [loss: 0.42899722] [loss_bc: 0.39272720; loss_div: 0.02336920; loss_ff: 0.01290082] [w_bc: 144.583922, LR: 0.000362]\n",
      "Training:  16%|█▌        | 7999/50000 [09:43<50:55, 13.75it/s][Iteration 008000/050000] [loss: 0.27236098] [loss_bc: 0.23482007; loss_div: 0.02305298; loss_ff: 0.01448793] [w_bc: 109.678121, LR: 0.000346]\n",
      "Training:  18%|█▊        | 8999/50000 [10:56<49:42, 13.75it/s][Iteration 009000/050000] [loss: 0.21606772] [loss_bc: 0.18886811; loss_div: 0.01677536; loss_ff: 0.01042426] [w_bc: 83.199363, LR: 0.000330]\n",
      "Training:  20%|█▉        | 9999/50000 [12:08<48:27, 13.76it/s][Iteration 010000/050000] [loss: 0.15865663] [loss_bc: 0.14112894; loss_div: 0.01208563; loss_ff: 0.00544205] [w_bc: 63.113171, LR: 0.000315]\n",
      "Training:  22%|██▏       | 10999/50000 [13:21<46:53, 13.86it/s][Iteration 011000/050000] [loss: 0.11882458] [loss_bc: 0.10364455; loss_div: 0.00994525; loss_ff: 0.00523478] [w_bc: 47.876236, LR: 0.000301]\n",
      "Training:  24%|██▍       | 11999/50000 [14:34<46:12, 13.70it/s][Iteration 012000/050000] [loss: 0.09201219] [loss_bc: 0.07856748; loss_div: 0.00916871; loss_ff: 0.00427601] [w_bc: 36.317839, LR: 0.000288]\n",
      "Training:  26%|██▌       | 12999/50000 [15:47<44:49, 13.76it/s][Iteration 013000/050000] [loss: 0.07073423] [loss_bc: 0.05997747; loss_div: 0.00715429; loss_ff: 0.00360247] [w_bc: 27.549898, LR: 0.000275]\n",
      "Training:  28%|██▊       | 13999/50000 [17:00<43:49, 13.69it/s][Iteration 014000/050000] [loss: 0.05303431] [loss_bc: 0.04615937; loss_div: 0.00426863; loss_ff: 0.00260631] [w_bc: 20.898735, LR: 0.000262]\n",
      "Training:  30%|██▉       | 14999/50000 [18:13<42:36, 13.69it/s][Iteration 015000/050000] [loss: 0.04347598] [loss_bc: 0.03633435; loss_div: 0.00443322; loss_ff: 0.00270841] [w_bc: 15.853312, LR: 0.000251]\n",
      "Training:  32%|███▏      | 15999/50000 [19:26<41:15, 13.73it/s][Iteration 016000/050000] [loss: 0.03349613] [loss_bc: 0.02752403; loss_div: 0.00329102; loss_ff: 0.00268108] [w_bc: 12.025967, LR: 0.000239]\n",
      "Training:  34%|███▍      | 16999/50000 [20:39<39:57, 13.76it/s][Iteration 017000/050000] [loss: 0.02416827] [loss_bc: 0.01998284; loss_div: 0.00239875; loss_ff: 0.00178667] [w_bc: 9.122629, LR: 0.000229]\n",
      "Training:  36%|███▌      | 17999/50000 [21:51<38:49, 13.74it/s][Iteration 018000/050000] [loss: 0.02124412] [loss_bc: 0.01627332; loss_div: 0.00287604; loss_ff: 0.00209476] [w_bc: 6.920222, LR: 0.000218]\n",
      "Training:  38%|███▊      | 18999/50000 [23:04<38:23, 13.46it/s][Iteration 019000/050000] [loss: 0.01396798] [loss_bc: 0.01201227; loss_div: 0.00136715; loss_ff: 0.00058856] [w_bc: 5.249525, LR: 0.000208]\n",
      "Training:  40%|███▉      | 19999/50000 [24:17<36:24, 13.73it/s][Iteration 020000/050000] [loss: 0.01197226] [loss_bc: 0.00938909; loss_div: 0.00151245; loss_ff: 0.00107072] [w_bc: 3.982172, LR: 0.000199]\n",
      "Training:  42%|████▏     | 20999/50000 [25:30<35:10, 13.74it/s][Iteration 021000/050000] [loss: 0.00994081] [loss_bc: 0.00755843; loss_div: 0.00166458; loss_ff: 0.00071780] [w_bc: 3.020786, LR: 0.000190]\n",
      "Training:  44%|████▍     | 21999/50000 [26:43<33:51, 13.78it/s][Iteration 022000/050000] [loss: 0.00742463] [loss_bc: 0.00582319; loss_div: 0.00087550; loss_ff: 0.00072594] [w_bc: 2.291501, LR: 0.000182]\n",
      "Training:  46%|████▌     | 22999/50000 [27:56<32:46, 13.73it/s][Iteration 023000/050000] [loss: 0.00626380] [loss_bc: 0.00446374; loss_div: 0.00103240; loss_ff: 0.00076765] [w_bc: 1.738281, LR: 0.000173]\n",
      "Training:  48%|████▊     | 23999/50000 [29:09<31:31, 13.75it/s][Iteration 024000/050000] [loss: 0.00499669] [loss_bc: 0.00344292; loss_div: 0.00077012; loss_ff: 0.00078366] [w_bc: 1.318621, LR: 0.000166]\n",
      "Training:  50%|████▉     | 24999/50000 [30:22<30:23, 13.71it/s][Iteration 025000/050000] [loss: 0.00359866] [loss_bc: 0.00268927; loss_div: 0.00046414; loss_ff: 0.00044525] [w_bc: 1.000276, LR: 0.000158]\n",
      "Training:  52%|█████▏    | 25999/50000 [31:34<29:05, 13.75it/s][Iteration 026000/050000] [loss: 0.00319492] [loss_bc: 0.00250239; loss_div: 0.00042844; loss_ff: 0.00026408] [w_bc: 1.000000, LR: 0.000151]\n",
      "Training:  54%|█████▍    | 26999/50000 [32:47<27:56, 13.72it/s][Iteration 027000/050000] [loss: 0.00345269] [loss_bc: 0.00273254; loss_div: 0.00042922; loss_ff: 0.00029094] [w_bc: 1.000000, LR: 0.000144]\n",
      "Training:  56%|█████▌    | 27999/50000 [34:00<26:44, 13.71it/s][Iteration 028000/050000] [loss: 0.00349506] [loss_bc: 0.00275572; loss_div: 0.00037058; loss_ff: 0.00036876] [w_bc: 1.000000, LR: 0.000138]\n",
      "Training:  58%|█████▊    | 28999/50000 [35:13<25:24, 13.77it/s][Iteration 029000/050000] [loss: 0.00367625] [loss_bc: 0.00275927; loss_div: 0.00054893; loss_ff: 0.00036806] [w_bc: 1.000000, LR: 0.000132]\n",
      "Training:  60%|█████▉    | 29999/50000 [36:26<24:16, 13.73it/s][Iteration 030000/050000] [loss: 0.00329268] [loss_bc: 0.00263388; loss_div: 0.00041010; loss_ff: 0.00024871] [w_bc: 1.000000, LR: 0.000126]\n",
      "Training:  62%|██████▏   | 30999/50000 [37:39<23:05, 13.71it/s][Iteration 031000/050000] [loss: 0.00351388] [loss_bc: 0.00268717; loss_div: 0.00046629; loss_ff: 0.00036042] [w_bc: 1.000000, LR: 0.000120]\n",
      "Training:  64%|██████▍   | 31999/50000 [38:52<21:54, 13.69it/s][Iteration 032000/050000] [loss: 0.00298453] [loss_bc: 0.00245087; loss_div: 0.00030512; loss_ff: 0.00022854] [w_bc: 1.000000, LR: 0.000115]\n",
      "Training:  66%|██████▌   | 32999/50000 [40:05<20:35, 13.76it/s][Iteration 033000/050000] [loss: 0.00320209] [loss_bc: 0.00271865; loss_div: 0.00028143; loss_ff: 0.00020200] [w_bc: 1.000000, LR: 0.000109]\n",
      "Training:  68%|██████▊   | 33999/50000 [41:18<19:35, 13.62it/s][Iteration 034000/050000] [loss: 0.00293623] [loss_bc: 0.00240723; loss_div: 0.00029807; loss_ff: 0.00023093] [w_bc: 1.000000, LR: 0.000104]\n",
      "Training:  70%|██████▉   | 34999/50000 [42:31<18:15, 13.70it/s][Iteration 035000/050000] [loss: 0.00298889] [loss_bc: 0.00253313; loss_div: 0.00027861; loss_ff: 0.00017716] [w_bc: 1.000000, LR: 0.000100]\n",
      "Training:  72%|███████▏  | 35999/50000 [43:44<17:05, 13.66it/s][Iteration 036000/050000] [loss: 0.00296427] [loss_bc: 0.00247849; loss_div: 0.00030694; loss_ff: 0.00017884] [w_bc: 1.000000, LR: 0.000095]\n",
      "Training:  74%|███████▍  | 36999/50000 [44:57<15:49, 13.69it/s][Iteration 037000/050000] [loss: 0.00305495] [loss_bc: 0.00261820; loss_div: 0.00029529; loss_ff: 0.00014146] [w_bc: 1.000000, LR: 0.000091]\n",
      "Training:  76%|███████▌  | 37999/50000 [46:10<14:35, 13.71it/s][Iteration 038000/050000] [loss: 0.00298966] [loss_bc: 0.00254391; loss_div: 0.00027808; loss_ff: 0.00016768] [w_bc: 1.000000, LR: 0.000087]\n",
      "Training:  78%|███████▊  | 38999/50000 [47:23<13:24, 13.67it/s][Iteration 039000/050000] [loss: 0.00298710] [loss_bc: 0.00259191; loss_div: 0.00022990; loss_ff: 0.00016529] [w_bc: 1.000000, LR: 0.000083]\n",
      "Training:  80%|███████▉  | 39999/50000 [48:36<12:10, 13.69it/s][Iteration 040000/050000] [loss: 0.00298812] [loss_bc: 0.00259076; loss_div: 0.00024621; loss_ff: 0.00015116] [w_bc: 1.000000, LR: 0.000079]\n",
      "Training:  82%|████████▏ | 40999/50000 [49:49<10:56, 13.71it/s][Iteration 041000/050000] [loss: 0.00284821] [loss_bc: 0.00248220; loss_div: 0.00022704; loss_ff: 0.00013897] [w_bc: 1.000000, LR: 0.000076]\n",
      "Training:  84%|████████▍ | 41999/50000 [51:02<09:41, 13.75it/s][Iteration 042000/050000] [loss: 0.00296120] [loss_bc: 0.00262142; loss_div: 0.00022005; loss_ff: 0.00011973] [w_bc: 1.000000, LR: 0.000072]\n",
      "Training:  86%|████████▌ | 42999/50000 [52:15<08:18, 14.04it/s][Iteration 043000/050000] [loss: 0.00279172] [loss_bc: 0.00249282; loss_div: 0.00018391; loss_ff: 0.00011499] [w_bc: 1.000000, LR: 0.000069]\n",
      "Training:  88%|████████▊ | 43999/50000 [53:28<07:16, 13.74it/s][Iteration 044000/050000] [loss: 0.00290455] [loss_bc: 0.00257374; loss_div: 0.00021792; loss_ff: 0.00011289] [w_bc: 1.000000, LR: 0.000066]\n",
      "Training:  90%|████████▉ | 44999/50000 [54:41<06:05, 13.67it/s][Iteration 045000/050000] [loss: 0.00289477] [loss_bc: 0.00254797; loss_div: 0.00022195; loss_ff: 0.00012485] [w_bc: 1.000000, LR: 0.000063]\n",
      "Training:  92%|█████████▏| 45999/50000 [55:54<04:51, 13.73it/s][Iteration 046000/050000] [loss: 0.00290155] [loss_bc: 0.00258029; loss_div: 0.00021063; loss_ff: 0.00011063] [w_bc: 1.000000, LR: 0.000060]\n",
      "Training:  94%|█████████▍| 46999/50000 [57:07<03:38, 13.75it/s][Iteration 047000/050000] [loss: 0.00256005] [loss_bc: 0.00228005; loss_div: 0.00018815; loss_ff: 0.00009185] [w_bc: 1.000000, LR: 0.000057]\n",
      "Training:  96%|█████████▌| 47999/50000 [58:20<02:25, 13.71it/s][Iteration 048000/050000] [loss: 0.00284094] [loss_bc: 0.00254665; loss_div: 0.00020238; loss_ff: 0.00009190] [w_bc: 1.000000, LR: 0.000055]\n",
      "Training:  98%|█████████▊| 48999/50000 [59:33<01:13, 13.67it/s][Iteration 049000/050000] [loss: 0.00280250] [loss_bc: 0.00253256; loss_div: 0.00018893; loss_ff: 0.00008101] [w_bc: 1.000000, LR: 0.000052]\n",
      "Training: 100%|█████████▉| 49999/50000 [1:00:46<00:00, 13.72it/s][Iteration 050000/050000] [loss: 0.00272831] [loss_bc: 0.00245585; loss_div: 0.00018991; loss_ff: 0.00008255] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training: 100%|██████████| 50000/50000 [1:00:46<00:00, 13.71it/s]\n",
      "[Iteration 050000/050000] [loss: 0.00272831] [loss_bc: 0.00245585; loss_div: 0.00018991; loss_ff: 0.00008255] [w_bc: 1.000000, LR: 0.000050]\n",
      "Runtime --> total: 3646.87sec (72.94ms/iter.)\n",
      "Configuration:\n",
      "dim: 256, w_div: 1.000000, w_ff: 1.000000, decay_iterations: None, potential: True, vector_potential: False, \n",
      "Using device: cuda (gpus 1) ['NVIDIA RTX A6000']\n",
      "Potential Boundary: 100%|██████████| 1/1 [00:00<00:00,  1.28it/s]\n",
      "Loaded meta state: /userhome/jeon_mg/workspace/_data/NOAA12673/PINN/20170904_000000/model_final.pt\n",
      "Training:   0%|          | 0/2000 [00:00<?, ?it/s][Iteration 000000/002000] [loss: 0.00277159] [loss_bc: 0.00247692; loss_div: 0.00021673; loss_ff: 0.00007793] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:   5%|▍         | 98/2000 [00:07<02:18, 13.76it/s][Iteration 000100/002000] [loss: 0.00276427] [loss_bc: 0.00247538; loss_div: 0.00020417; loss_ff: 0.00008472] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  10%|▉         | 198/2000 [00:14<02:11, 13.67it/s][Iteration 000200/002000] [loss: 0.00273090] [loss_bc: 0.00248642; loss_div: 0.00017095; loss_ff: 0.00007353] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  15%|█▍        | 298/2000 [00:21<02:03, 13.76it/s][Iteration 000300/002000] [loss: 0.00275178] [loss_bc: 0.00248654; loss_div: 0.00018323; loss_ff: 0.00008201] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  20%|█▉        | 398/2000 [00:29<01:56, 13.71it/s][Iteration 000400/002000] [loss: 0.00276001] [loss_bc: 0.00246200; loss_div: 0.00017896; loss_ff: 0.00011905] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  25%|██▍       | 498/2000 [00:36<01:49, 13.75it/s][Iteration 000500/002000] [loss: 0.00273431] [loss_bc: 0.00246398; loss_div: 0.00018117; loss_ff: 0.00008916] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  30%|██▉       | 598/2000 [00:43<01:43, 13.49it/s][Iteration 000600/002000] [loss: 0.00284149] [loss_bc: 0.00251745; loss_div: 0.00022814; loss_ff: 0.00009590] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  35%|███▍      | 698/2000 [00:51<01:33, 13.88it/s][Iteration 000700/002000] [loss: 0.00270949] [loss_bc: 0.00245137; loss_div: 0.00018951; loss_ff: 0.00006861] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  40%|███▉      | 798/2000 [00:58<01:26, 13.83it/s][Iteration 000800/002000] [loss: 0.00293426] [loss_bc: 0.00260318; loss_div: 0.00020802; loss_ff: 0.00012306] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  45%|████▍     | 898/2000 [01:05<01:20, 13.75it/s][Iteration 000900/002000] [loss: 0.00274751] [loss_bc: 0.00246971; loss_div: 0.00019002; loss_ff: 0.00008779] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  50%|████▉     | 998/2000 [01:13<01:13, 13.71it/s][Iteration 001000/002000] [loss: 0.00259732] [loss_bc: 0.00236828; loss_div: 0.00016154; loss_ff: 0.00006750] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  55%|█████▍    | 1098/2000 [01:20<01:05, 13.73it/s][Iteration 001100/002000] [loss: 0.00279429] [loss_bc: 0.00250255; loss_div: 0.00018865; loss_ff: 0.00010309] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  60%|█████▉    | 1198/2000 [01:27<00:58, 13.72it/s][Iteration 001200/002000] [loss: 0.00281197] [loss_bc: 0.00252696; loss_div: 0.00018139; loss_ff: 0.00010362] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  65%|██████▍   | 1298/2000 [01:34<00:51, 13.67it/s][Iteration 001300/002000] [loss: 0.00266627] [loss_bc: 0.00236834; loss_div: 0.00020608; loss_ff: 0.00009185] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  70%|██████▉   | 1398/2000 [01:42<00:43, 13.74it/s][Iteration 001400/002000] [loss: 0.00273063] [loss_bc: 0.00247414; loss_div: 0.00018000; loss_ff: 0.00007649] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  75%|███████▍  | 1498/2000 [01:49<00:36, 13.67it/s][Iteration 001500/002000] [loss: 0.00276553] [loss_bc: 0.00246887; loss_div: 0.00019149; loss_ff: 0.00010517] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  80%|███████▉  | 1598/2000 [01:56<00:29, 13.68it/s][Iteration 001600/002000] [loss: 0.00275155] [loss_bc: 0.00246598; loss_div: 0.00019928; loss_ff: 0.00008628] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  85%|████████▍ | 1698/2000 [02:04<00:22, 13.71it/s][Iteration 001700/002000] [loss: 0.00272211] [loss_bc: 0.00246659; loss_div: 0.00017583; loss_ff: 0.00007969] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  90%|████████▉ | 1798/2000 [02:11<00:14, 13.70it/s][Iteration 001800/002000] [loss: 0.00276644] [loss_bc: 0.00249588; loss_div: 0.00018354; loss_ff: 0.00008703] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  95%|█████████▍| 1898/2000 [02:18<00:07, 13.69it/s][Iteration 001900/002000] [loss: 0.00267551] [loss_bc: 0.00244467; loss_div: 0.00015872; loss_ff: 0.00007213] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training: 100%|█████████▉| 1998/2000 [02:26<00:00, 13.71it/s][Iteration 002000/002000] [loss: 0.00274458] [loss_bc: 0.00245301; loss_div: 0.00020966; loss_ff: 0.00008191] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training: 100%|██████████| 2000/2000 [02:26<00:00, 13.66it/s]\n",
      "[Iteration 002000/002000] [loss: 0.00274458] [loss_bc: 0.00245301; loss_div: 0.00020966; loss_ff: 0.00008191] [w_bc: 1.000000, LR: 0.000050]\n",
      "Runtime --> total: 146.62sec (2.93ms/iter.)\n",
      "Configuration:\n",
      "dim: 256, w_div: 1.000000, w_ff: 1.000000, decay_iterations: None, potential: True, vector_potential: False, \n",
      "Using device: cuda (gpus 1) ['NVIDIA RTX A6000']\n",
      "Potential Boundary: 100%|██████████| 1/1 [00:00<00:00,  1.24it/s]\n",
      "Loaded meta state: /userhome/jeon_mg/workspace/_data/NOAA12673/PINN/20170904_001200/model_final.pt\n",
      "Training:   0%|          | 0/2000 [00:00<?, ?it/s][Iteration 000000/002000] [loss: 0.00288892] [loss_bc: 0.00263642; loss_div: 0.00018146; loss_ff: 0.00007104] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:   5%|▍         | 98/2000 [00:07<02:18, 13.72it/s][Iteration 000100/002000] [loss: 0.00284387] [loss_bc: 0.00259281; loss_div: 0.00017352; loss_ff: 0.00007754] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  10%|▉         | 198/2000 [00:14<02:11, 13.70it/s][Iteration 000200/002000] [loss: 0.00285157] [loss_bc: 0.00254702; loss_div: 0.00020040; loss_ff: 0.00010414] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  15%|█▍        | 298/2000 [00:21<02:03, 13.75it/s][Iteration 000300/002000] [loss: 0.00280176] [loss_bc: 0.00255228; loss_div: 0.00018946; loss_ff: 0.00006002] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  20%|█▉        | 398/2000 [00:29<01:56, 13.73it/s][Iteration 000400/002000] [loss: 0.00274773] [loss_bc: 0.00243876; loss_div: 0.00021109; loss_ff: 0.00009788] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  25%|██▍       | 498/2000 [00:36<01:49, 13.72it/s][Iteration 000500/002000] [loss: 0.00280196] [loss_bc: 0.00254236; loss_div: 0.00018734; loss_ff: 0.00007226] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  30%|██▉       | 598/2000 [00:43<01:42, 13.67it/s][Iteration 000600/002000] [loss: 0.00284741] [loss_bc: 0.00258610; loss_div: 0.00017606; loss_ff: 0.00008525] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  35%|███▍      | 698/2000 [00:51<01:35, 13.68it/s][Iteration 000700/002000] [loss: 0.00293177] [loss_bc: 0.00261123; loss_div: 0.00022652; loss_ff: 0.00009402] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  40%|███▉      | 798/2000 [00:58<01:27, 13.71it/s][Iteration 000800/002000] [loss: 0.00287312] [loss_bc: 0.00261867; loss_div: 0.00017819; loss_ff: 0.00007626] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  45%|████▍     | 898/2000 [01:05<01:20, 13.75it/s][Iteration 000900/002000] [loss: 0.00287424] [loss_bc: 0.00258377; loss_div: 0.00020987; loss_ff: 0.00008060] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  50%|████▉     | 998/2000 [01:12<01:13, 13.66it/s][Iteration 001000/002000] [loss: 0.00283267] [loss_bc: 0.00255417; loss_div: 0.00019672; loss_ff: 0.00008177] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  55%|█████▍    | 1098/2000 [01:20<01:05, 13.69it/s][Iteration 001100/002000] [loss: 0.00284374] [loss_bc: 0.00256832; loss_div: 0.00018829; loss_ff: 0.00008714] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  60%|█████▉    | 1198/2000 [01:27<00:58, 13.68it/s][Iteration 001200/002000] [loss: 0.00271281] [loss_bc: 0.00241951; loss_div: 0.00021968; loss_ff: 0.00007361] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  65%|██████▍   | 1298/2000 [01:34<00:51, 13.68it/s][Iteration 001300/002000] [loss: 0.00281492] [loss_bc: 0.00258685; loss_div: 0.00016379; loss_ff: 0.00006428] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  70%|██████▉   | 1398/2000 [01:42<00:43, 13.75it/s][Iteration 001400/002000] [loss: 0.00273268] [loss_bc: 0.00248684; loss_div: 0.00017378; loss_ff: 0.00007206] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  75%|███████▍  | 1498/2000 [01:49<00:36, 13.77it/s][Iteration 001500/002000] [loss: 0.00285314] [loss_bc: 0.00258721; loss_div: 0.00016035; loss_ff: 0.00010558] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  80%|███████▉  | 1598/2000 [01:56<00:29, 13.65it/s][Iteration 001600/002000] [loss: 0.00289133] [loss_bc: 0.00258744; loss_div: 0.00022442; loss_ff: 0.00007947] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  85%|████████▍ | 1698/2000 [02:04<00:22, 13.67it/s][Iteration 001700/002000] [loss: 0.00284679] [loss_bc: 0.00255040; loss_div: 0.00020269; loss_ff: 0.00009370] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  90%|████████▉ | 1798/2000 [02:11<00:14, 13.71it/s][Iteration 001800/002000] [loss: 0.00269284] [loss_bc: 0.00242450; loss_div: 0.00018778; loss_ff: 0.00008056] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  95%|█████████▍| 1898/2000 [02:18<00:07, 13.72it/s][Iteration 001900/002000] [loss: 0.00279966] [loss_bc: 0.00253230; loss_div: 0.00019779; loss_ff: 0.00006957] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training: 100%|█████████▉| 1998/2000 [02:26<00:00, 13.74it/s][Iteration 002000/002000] [loss: 0.00281350] [loss_bc: 0.00252898; loss_div: 0.00019617; loss_ff: 0.00008836] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training: 100%|██████████| 2000/2000 [02:26<00:00, 13.66it/s]\n",
      "[Iteration 002000/002000] [loss: 0.00281350] [loss_bc: 0.00252898; loss_div: 0.00019617; loss_ff: 0.00008836] [w_bc: 1.000000, LR: 0.000050]\n",
      "Runtime --> total: 146.62sec (2.93ms/iter.)\n",
      "Configuration:\n",
      "dim: 256, w_div: 1.000000, w_ff: 1.000000, decay_iterations: None, potential: True, vector_potential: False, \n",
      "Using device: cuda (gpus 1) ['NVIDIA RTX A6000']\n",
      "Potential Boundary: 100%|██████████| 1/1 [00:00<00:00,  1.14it/s]\n",
      "Loaded meta state: /userhome/jeon_mg/workspace/_data/NOAA12673/PINN/20170904_002400/model_final.pt\n",
      "Training:   0%|          | 0/2000 [00:00<?, ?it/s][Iteration 000000/002000] [loss: 0.00276306] [loss_bc: 0.00247350; loss_div: 0.00019312; loss_ff: 0.00009644] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:   5%|▍         | 98/2000 [00:07<02:18, 13.73it/s][Iteration 000100/002000] [loss: 0.00282197] [loss_bc: 0.00259176; loss_div: 0.00016271; loss_ff: 0.00006750] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  10%|▉         | 198/2000 [00:14<02:12, 13.62it/s][Iteration 000200/002000] [loss: 0.00285189] [loss_bc: 0.00258897; loss_div: 0.00017668; loss_ff: 0.00008624] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  15%|█▍        | 298/2000 [00:21<02:04, 13.67it/s][Iteration 000300/002000] [loss: 0.00283505] [loss_bc: 0.00258129; loss_div: 0.00017670; loss_ff: 0.00007706] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  20%|█▉        | 398/2000 [00:29<01:56, 13.70it/s][Iteration 000400/002000] [loss: 0.00271946] [loss_bc: 0.00244236; loss_div: 0.00018360; loss_ff: 0.00009350] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  25%|██▍       | 498/2000 [00:36<01:49, 13.69it/s][Iteration 000500/002000] [loss: 0.00286499] [loss_bc: 0.00257936; loss_div: 0.00019276; loss_ff: 0.00009288] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  30%|██▉       | 598/2000 [00:43<01:42, 13.74it/s][Iteration 000600/002000] [loss: 0.00289409] [loss_bc: 0.00261325; loss_div: 0.00020654; loss_ff: 0.00007430] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  35%|███▍      | 698/2000 [00:51<01:35, 13.69it/s][Iteration 000700/002000] [loss: 0.00284899] [loss_bc: 0.00256819; loss_div: 0.00019458; loss_ff: 0.00008623] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  40%|███▉      | 798/2000 [00:58<01:27, 13.68it/s][Iteration 000800/002000] [loss: 0.00274531] [loss_bc: 0.00245589; loss_div: 0.00019123; loss_ff: 0.00009820] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  45%|████▍     | 898/2000 [01:05<01:20, 13.72it/s][Iteration 000900/002000] [loss: 0.00296958] [loss_bc: 0.00271577; loss_div: 0.00017786; loss_ff: 0.00007595] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  50%|████▉     | 998/2000 [01:13<01:12, 13.73it/s][Iteration 001000/002000] [loss: 0.00302284] [loss_bc: 0.00272285; loss_div: 0.00020069; loss_ff: 0.00009930] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  55%|█████▍    | 1098/2000 [01:20<01:05, 13.68it/s][Iteration 001100/002000] [loss: 0.00293057] [loss_bc: 0.00263788; loss_div: 0.00020305; loss_ff: 0.00008963] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  60%|█████▉    | 1198/2000 [01:27<00:58, 13.68it/s][Iteration 001200/002000] [loss: 0.00298400] [loss_bc: 0.00271818; loss_div: 0.00018106; loss_ff: 0.00008476] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  65%|██████▍   | 1298/2000 [01:34<00:51, 13.72it/s][Iteration 001300/002000] [loss: 0.00270416] [loss_bc: 0.00245376; loss_div: 0.00017214; loss_ff: 0.00007826] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  70%|██████▉   | 1398/2000 [01:42<00:43, 13.71it/s][Iteration 001400/002000] [loss: 0.00299180] [loss_bc: 0.00271168; loss_div: 0.00018372; loss_ff: 0.00009640] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  75%|███████▍  | 1498/2000 [01:49<00:36, 13.70it/s][Iteration 001500/002000] [loss: 0.00283845] [loss_bc: 0.00257414; loss_div: 0.00018463; loss_ff: 0.00007969] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  80%|███████▉  | 1598/2000 [01:56<00:29, 13.67it/s][Iteration 001600/002000] [loss: 0.00287729] [loss_bc: 0.00260272; loss_div: 0.00018765; loss_ff: 0.00008692] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  85%|████████▍ | 1698/2000 [02:04<00:22, 13.67it/s][Iteration 001700/002000] [loss: 0.00291949] [loss_bc: 0.00263853; loss_div: 0.00017298; loss_ff: 0.00010798] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  90%|████████▉ | 1798/2000 [02:11<00:14, 13.69it/s][Iteration 001800/002000] [loss: 0.00264086] [loss_bc: 0.00237289; loss_div: 0.00019623; loss_ff: 0.00007174] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  95%|█████████▍| 1898/2000 [02:18<00:07, 13.70it/s][Iteration 001900/002000] [loss: 0.00282254] [loss_bc: 0.00255643; loss_div: 0.00018807; loss_ff: 0.00007805] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training: 100%|█████████▉| 1998/2000 [02:26<00:00, 13.70it/s][Iteration 002000/002000] [loss: 0.00270850] [loss_bc: 0.00242343; loss_div: 0.00020243; loss_ff: 0.00008263] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training: 100%|██████████| 2000/2000 [02:26<00:00, 13.65it/s]\n",
      "[Iteration 002000/002000] [loss: 0.00270850] [loss_bc: 0.00242343; loss_div: 0.00020243; loss_ff: 0.00008263] [w_bc: 1.000000, LR: 0.000050]\n",
      "Runtime --> total: 146.64sec (2.93ms/iter.)\n",
      "Configuration:\n",
      "dim: 256, w_div: 1.000000, w_ff: 1.000000, decay_iterations: None, potential: True, vector_potential: False, \n",
      "Using device: cuda (gpus 1) ['NVIDIA RTX A6000']\n",
      "Potential Boundary: 100%|██████████| 1/1 [00:00<00:00,  1.13it/s]\n",
      "Loaded meta state: /userhome/jeon_mg/workspace/_data/NOAA12673/PINN/20170904_003600/model_final.pt\n",
      "Training:   0%|          | 0/2000 [00:00<?, ?it/s][Iteration 000000/002000] [loss: 0.00293402] [loss_bc: 0.00263261; loss_div: 0.00021281; loss_ff: 0.00008860] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:   5%|▍         | 98/2000 [00:07<02:18, 13.72it/s][Iteration 000100/002000] [loss: 0.00297046] [loss_bc: 0.00270028; loss_div: 0.00017884; loss_ff: 0.00009134] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  10%|▉         | 198/2000 [00:14<02:11, 13.66it/s][Iteration 000200/002000] [loss: 0.00288938] [loss_bc: 0.00261045; loss_div: 0.00019852; loss_ff: 0.00008041] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  15%|█▍        | 298/2000 [00:21<02:04, 13.67it/s][Iteration 000300/002000] [loss: 0.00301241] [loss_bc: 0.00268746; loss_div: 0.00020333; loss_ff: 0.00012162] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  20%|█▉        | 398/2000 [00:29<01:57, 13.68it/s][Iteration 000400/002000] [loss: 0.00300991] [loss_bc: 0.00268042; loss_div: 0.00023153; loss_ff: 0.00009796] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  25%|██▍       | 498/2000 [00:36<01:49, 13.71it/s][Iteration 000500/002000] [loss: 0.00275611] [loss_bc: 0.00244089; loss_div: 0.00020766; loss_ff: 0.00010755] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  30%|██▉       | 598/2000 [00:43<01:42, 13.69it/s][Iteration 000600/002000] [loss: 0.00289059] [loss_bc: 0.00261571; loss_div: 0.00019471; loss_ff: 0.00008018] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  35%|███▍      | 698/2000 [00:51<01:35, 13.68it/s][Iteration 000700/002000] [loss: 0.00300047] [loss_bc: 0.00270174; loss_div: 0.00019226; loss_ff: 0.00010647] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  40%|███▉      | 798/2000 [00:58<01:27, 13.73it/s][Iteration 000800/002000] [loss: 0.00272524] [loss_bc: 0.00243579; loss_div: 0.00020460; loss_ff: 0.00008485] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  45%|████▍     | 898/2000 [01:05<01:20, 13.73it/s][Iteration 000900/002000] [loss: 0.00272447] [loss_bc: 0.00244420; loss_div: 0.00019512; loss_ff: 0.00008515] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  50%|████▉     | 998/2000 [01:13<01:12, 13.76it/s][Iteration 001000/002000] [loss: 0.00298374] [loss_bc: 0.00269896; loss_div: 0.00020115; loss_ff: 0.00008362] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  55%|█████▍    | 1098/2000 [01:20<01:05, 13.69it/s][Iteration 001100/002000] [loss: 0.00290129] [loss_bc: 0.00259732; loss_div: 0.00021323; loss_ff: 0.00009074] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  60%|█████▉    | 1198/2000 [01:27<00:58, 13.65it/s][Iteration 001200/002000] [loss: 0.00297570] [loss_bc: 0.00269208; loss_div: 0.00018600; loss_ff: 0.00009761] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  65%|██████▍   | 1298/2000 [01:35<00:51, 13.67it/s][Iteration 001300/002000] [loss: 0.00286723] [loss_bc: 0.00260466; loss_div: 0.00018611; loss_ff: 0.00007646] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  70%|██████▉   | 1398/2000 [01:42<00:44, 13.67it/s][Iteration 001400/002000] [loss: 0.00287187] [loss_bc: 0.00254275; loss_div: 0.00024420; loss_ff: 0.00008492] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  75%|███████▍  | 1498/2000 [01:49<00:36, 13.70it/s][Iteration 001500/002000] [loss: 0.00280474] [loss_bc: 0.00253650; loss_div: 0.00018651; loss_ff: 0.00008173] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  80%|███████▉  | 1598/2000 [01:56<00:29, 13.73it/s][Iteration 001600/002000] [loss: 0.00284754] [loss_bc: 0.00253915; loss_div: 0.00020190; loss_ff: 0.00010649] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  85%|████████▍ | 1698/2000 [02:04<00:22, 13.72it/s][Iteration 001700/002000] [loss: 0.00275085] [loss_bc: 0.00242297; loss_div: 0.00022904; loss_ff: 0.00009884] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  90%|████████▉ | 1798/2000 [02:11<00:14, 13.69it/s][Iteration 001800/002000] [loss: 0.00286112] [loss_bc: 0.00259910; loss_div: 0.00018137; loss_ff: 0.00008065] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  95%|█████████▍| 1898/2000 [02:18<00:07, 13.74it/s][Iteration 001900/002000] [loss: 0.00297106] [loss_bc: 0.00266410; loss_div: 0.00020488; loss_ff: 0.00010208] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training: 100%|█████████▉| 1998/2000 [02:26<00:00, 13.70it/s][Iteration 002000/002000] [loss: 0.00284510] [loss_bc: 0.00253634; loss_div: 0.00021643; loss_ff: 0.00009233] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training: 100%|██████████| 2000/2000 [02:26<00:00, 13.64it/s]\n",
      "[Iteration 002000/002000] [loss: 0.00284510] [loss_bc: 0.00253634; loss_div: 0.00021643; loss_ff: 0.00009233] [w_bc: 1.000000, LR: 0.000050]\n",
      "Runtime --> total: 146.81sec (2.94ms/iter.)\n",
      "Configuration:\n",
      "dim: 256, w_div: 1.000000, w_ff: 1.000000, decay_iterations: None, potential: True, vector_potential: False, \n",
      "Using device: cuda (gpus 1) ['NVIDIA RTX A6000']\n",
      "Potential Boundary: 100%|██████████| 1/1 [00:00<00:00,  1.18it/s]\n",
      "Loaded meta state: /userhome/jeon_mg/workspace/_data/NOAA12673/PINN/20170904_004800/model_final.pt\n",
      "Training:   0%|          | 0/2000 [00:00<?, ?it/s][Iteration 000000/002000] [loss: 0.00309607] [loss_bc: 0.00280312; loss_div: 0.00019341; loss_ff: 0.00009955] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:   5%|▍         | 98/2000 [00:07<02:19, 13.65it/s][Iteration 000100/002000] [loss: 0.00284960] [loss_bc: 0.00257133; loss_div: 0.00018366; loss_ff: 0.00009461] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  10%|▉         | 198/2000 [00:14<02:11, 13.73it/s][Iteration 000200/002000] [loss: 0.00278998] [loss_bc: 0.00249724; loss_div: 0.00020131; loss_ff: 0.00009142] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  15%|█▍        | 298/2000 [00:21<02:04, 13.68it/s][Iteration 000300/002000] [loss: 0.00271997] [loss_bc: 0.00244861; loss_div: 0.00019081; loss_ff: 0.00008055] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  20%|█▉        | 398/2000 [00:29<01:56, 13.71it/s][Iteration 000400/002000] [loss: 0.00309080] [loss_bc: 0.00279438; loss_div: 0.00020131; loss_ff: 0.00009511] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  25%|██▍       | 498/2000 [00:36<01:49, 13.71it/s][Iteration 000500/002000] [loss: 0.00286307] [loss_bc: 0.00261170; loss_div: 0.00016938; loss_ff: 0.00008199] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  30%|██▉       | 598/2000 [00:43<01:42, 13.72it/s][Iteration 000600/002000] [loss: 0.00269949] [loss_bc: 0.00240600; loss_div: 0.00021650; loss_ff: 0.00007699] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  35%|███▍      | 698/2000 [00:51<01:34, 13.73it/s][Iteration 000700/002000] [loss: 0.00281344] [loss_bc: 0.00257130; loss_div: 0.00017085; loss_ff: 0.00007129] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  40%|███▉      | 798/2000 [00:58<01:27, 13.70it/s][Iteration 000800/002000] [loss: 0.00282777] [loss_bc: 0.00255866; loss_div: 0.00018986; loss_ff: 0.00007925] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  45%|████▍     | 898/2000 [01:06<01:20, 13.61it/s][Iteration 000900/002000] [loss: 0.00291096] [loss_bc: 0.00254850; loss_div: 0.00022956; loss_ff: 0.00013290] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  50%|████▉     | 998/2000 [01:13<01:12, 13.88it/s][Iteration 001000/002000] [loss: 0.00278490] [loss_bc: 0.00244160; loss_div: 0.00022695; loss_ff: 0.00011635] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  55%|█████▍    | 1098/2000 [01:20<01:06, 13.62it/s][Iteration 001100/002000] [loss: 0.00311852] [loss_bc: 0.00279546; loss_div: 0.00022688; loss_ff: 0.00009618] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  60%|█████▉    | 1198/2000 [01:28<00:58, 13.61it/s][Iteration 001200/002000] [loss: 0.00282048] [loss_bc: 0.00254892; loss_div: 0.00018395; loss_ff: 0.00008761] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  65%|██████▍   | 1298/2000 [01:35<00:51, 13.67it/s][Iteration 001300/002000] [loss: 0.00265831] [loss_bc: 0.00240288; loss_div: 0.00017454; loss_ff: 0.00008089] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  70%|██████▉   | 1398/2000 [01:42<00:44, 13.62it/s][Iteration 001400/002000] [loss: 0.00292814] [loss_bc: 0.00262979; loss_div: 0.00020784; loss_ff: 0.00009051] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  75%|███████▍  | 1498/2000 [01:50<00:36, 13.68it/s][Iteration 001500/002000] [loss: 0.00264700] [loss_bc: 0.00240095; loss_div: 0.00017376; loss_ff: 0.00007229] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  80%|███████▉  | 1598/2000 [01:57<00:29, 13.65it/s][Iteration 001600/002000] [loss: 0.00273001] [loss_bc: 0.00244066; loss_div: 0.00019162; loss_ff: 0.00009773] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  85%|████████▍ | 1698/2000 [02:04<00:22, 13.59it/s][Iteration 001700/002000] [loss: 0.00266777] [loss_bc: 0.00239919; loss_div: 0.00018174; loss_ff: 0.00008683] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  90%|████████▉ | 1798/2000 [02:12<00:14, 13.64it/s][Iteration 001800/002000] [loss: 0.00291332] [loss_bc: 0.00260683; loss_div: 0.00021380; loss_ff: 0.00009270] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  95%|█████████▍| 1898/2000 [02:19<00:07, 13.97it/s][Iteration 001900/002000] [loss: 0.00283194] [loss_bc: 0.00253589; loss_div: 0.00020348; loss_ff: 0.00009256] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training: 100%|█████████▉| 1998/2000 [02:26<00:00, 13.63it/s][Iteration 002000/002000] [loss: 0.00270995] [loss_bc: 0.00243150; loss_div: 0.00017441; loss_ff: 0.00010405] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training: 100%|██████████| 2000/2000 [02:27<00:00, 13.60it/s]\n",
      "[Iteration 002000/002000] [loss: 0.00270995] [loss_bc: 0.00243150; loss_div: 0.00017441; loss_ff: 0.00010405] [w_bc: 1.000000, LR: 0.000050]\n",
      "Runtime --> total: 147.29sec (2.95ms/iter.)\n",
      "Configuration:\n",
      "dim: 256, w_div: 1.000000, w_ff: 1.000000, decay_iterations: None, potential: True, vector_potential: False, \n",
      "Using device: cuda (gpus 1) ['NVIDIA RTX A6000']\n",
      "Potential Boundary: 100%|██████████| 1/1 [00:00<00:00,  1.27it/s]\n",
      "Loaded meta state: /userhome/jeon_mg/workspace/_data/NOAA12673/PINN/20170904_010000/model_final.pt\n",
      "Training:   0%|          | 0/2000 [00:00<?, ?it/s][Iteration 000000/002000] [loss: 0.00284303] [loss_bc: 0.00251533; loss_div: 0.00022107; loss_ff: 0.00010664] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:   5%|▍         | 98/2000 [00:07<02:18, 13.74it/s][Iteration 000100/002000] [loss: 0.00305388] [loss_bc: 0.00276378; loss_div: 0.00021217; loss_ff: 0.00007793] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  10%|▉         | 198/2000 [00:14<02:12, 13.61it/s][Iteration 000200/002000] [loss: 0.00280573] [loss_bc: 0.00253329; loss_div: 0.00019736; loss_ff: 0.00007507] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  15%|█▍        | 298/2000 [00:21<02:04, 13.68it/s][Iteration 000300/002000] [loss: 0.00284813] [loss_bc: 0.00261100; loss_div: 0.00017414; loss_ff: 0.00006299] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  20%|█▉        | 398/2000 [00:29<01:56, 13.70it/s][Iteration 000400/002000] [loss: 0.00282303] [loss_bc: 0.00250278; loss_div: 0.00018828; loss_ff: 0.00013197] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  25%|██▍       | 498/2000 [00:36<01:50, 13.62it/s][Iteration 000500/002000] [loss: 0.00279757] [loss_bc: 0.00253057; loss_div: 0.00019220; loss_ff: 0.00007481] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  30%|██▉       | 598/2000 [00:43<01:42, 13.66it/s][Iteration 000600/002000] [loss: 0.00269195] [loss_bc: 0.00242835; loss_div: 0.00017951; loss_ff: 0.00008409] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  35%|███▍      | 698/2000 [00:51<01:34, 13.84it/s][Iteration 000700/002000] [loss: 0.00295094] [loss_bc: 0.00270774; loss_div: 0.00017107; loss_ff: 0.00007213] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  40%|███▉      | 798/2000 [00:58<01:28, 13.63it/s][Iteration 000800/002000] [loss: 0.00294863] [loss_bc: 0.00270159; loss_div: 0.00017240; loss_ff: 0.00007463] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  45%|████▍     | 898/2000 [01:05<01:20, 13.68it/s][Iteration 000900/002000] [loss: 0.00261080] [loss_bc: 0.00238432; loss_div: 0.00016286; loss_ff: 0.00006363] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  50%|████▉     | 998/2000 [01:13<01:13, 13.68it/s][Iteration 001000/002000] [loss: 0.00271926] [loss_bc: 0.00242747; loss_div: 0.00019691; loss_ff: 0.00009488] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  55%|█████▍    | 1098/2000 [01:20<01:06, 13.64it/s][Iteration 001100/002000] [loss: 0.00285976] [loss_bc: 0.00259336; loss_div: 0.00018246; loss_ff: 0.00008394] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  60%|█████▉    | 1198/2000 [01:27<00:58, 13.70it/s][Iteration 001200/002000] [loss: 0.00293495] [loss_bc: 0.00263916; loss_div: 0.00020186; loss_ff: 0.00009393] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  65%|██████▍   | 1298/2000 [01:35<00:51, 13.63it/s][Iteration 001300/002000] [loss: 0.00297056] [loss_bc: 0.00269434; loss_div: 0.00018562; loss_ff: 0.00009061] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  70%|██████▉   | 1398/2000 [01:42<00:44, 13.62it/s][Iteration 001400/002000] [loss: 0.00298866] [loss_bc: 0.00264072; loss_div: 0.00023057; loss_ff: 0.00011736] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  75%|███████▍  | 1498/2000 [01:49<00:36, 13.62it/s][Iteration 001500/002000] [loss: 0.00301340] [loss_bc: 0.00273644; loss_div: 0.00018790; loss_ff: 0.00008906] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  80%|███████▉  | 1598/2000 [01:57<00:29, 13.68it/s][Iteration 001600/002000] [loss: 0.00303500] [loss_bc: 0.00271910; loss_div: 0.00020428; loss_ff: 0.00011162] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  85%|████████▍ | 1698/2000 [02:04<00:22, 13.64it/s][Iteration 001700/002000] [loss: 0.00290486] [loss_bc: 0.00258322; loss_div: 0.00022477; loss_ff: 0.00009687] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  90%|████████▉ | 1798/2000 [02:12<00:14, 13.62it/s][Iteration 001800/002000] [loss: 0.00281861] [loss_bc: 0.00251417; loss_div: 0.00019556; loss_ff: 0.00010888] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  95%|█████████▍| 1898/2000 [02:19<00:07, 13.63it/s][Iteration 001900/002000] [loss: 0.00300266] [loss_bc: 0.00268558; loss_div: 0.00022294; loss_ff: 0.00009414] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training: 100%|█████████▉| 1998/2000 [02:26<00:00, 13.59it/s][Iteration 002000/002000] [loss: 0.00296011] [loss_bc: 0.00263769; loss_div: 0.00020450; loss_ff: 0.00011793] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training: 100%|██████████| 2000/2000 [02:27<00:00, 13.60it/s]\n",
      "[Iteration 002000/002000] [loss: 0.00296011] [loss_bc: 0.00263769; loss_div: 0.00020450; loss_ff: 0.00011793] [w_bc: 1.000000, LR: 0.000050]\n",
      "Runtime --> total: 147.19sec (2.94ms/iter.)\n",
      "Configuration:\n",
      "dim: 256, w_div: 1.000000, w_ff: 1.000000, decay_iterations: None, potential: True, vector_potential: False, \n",
      "Using device: cuda (gpus 1) ['NVIDIA RTX A6000']\n",
      "Potential Boundary: 100%|██████████| 1/1 [00:00<00:00,  1.18it/s]\n",
      "Loaded meta state: /userhome/jeon_mg/workspace/_data/NOAA12673/PINN/20170904_011200/model_final.pt\n",
      "Training:   0%|          | 0/2000 [00:00<?, ?it/s][Iteration 000000/002000] [loss: 0.00275839] [loss_bc: 0.00243381; loss_div: 0.00020248; loss_ff: 0.00012210] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:   5%|▍         | 98/2000 [00:07<02:16, 13.89it/s][Iteration 000100/002000] [loss: 0.00283722] [loss_bc: 0.00253234; loss_div: 0.00022827; loss_ff: 0.00007661] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  10%|▉         | 198/2000 [00:14<02:11, 13.75it/s][Iteration 000200/002000] [loss: 0.00279580] [loss_bc: 0.00253356; loss_div: 0.00019292; loss_ff: 0.00006932] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  15%|█▍        | 298/2000 [00:21<02:04, 13.64it/s][Iteration 000300/002000] [loss: 0.00275617] [loss_bc: 0.00248838; loss_div: 0.00017733; loss_ff: 0.00009046] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  20%|█▉        | 398/2000 [00:29<01:59, 13.46it/s][Iteration 000400/002000] [loss: 0.00305446] [loss_bc: 0.00279832; loss_div: 0.00018786; loss_ff: 0.00006828] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  25%|██▍       | 498/2000 [00:36<01:49, 13.68it/s][Iteration 000500/002000] [loss: 0.00295485] [loss_bc: 0.00270820; loss_div: 0.00017168; loss_ff: 0.00007496] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  30%|██▉       | 598/2000 [00:43<01:42, 13.67it/s][Iteration 000600/002000] [loss: 0.00278650] [loss_bc: 0.00247734; loss_div: 0.00021244; loss_ff: 0.00009671] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  35%|███▍      | 698/2000 [00:51<01:35, 13.68it/s][Iteration 000700/002000] [loss: 0.00275957] [loss_bc: 0.00247805; loss_div: 0.00019495; loss_ff: 0.00008657] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  40%|███▉      | 798/2000 [00:58<01:27, 13.66it/s][Iteration 000800/002000] [loss: 0.00285820] [loss_bc: 0.00258551; loss_div: 0.00018670; loss_ff: 0.00008599] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  45%|████▍     | 898/2000 [01:05<01:20, 13.68it/s][Iteration 000900/002000] [loss: 0.00299682] [loss_bc: 0.00270424; loss_div: 0.00018439; loss_ff: 0.00010820] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  50%|████▉     | 998/2000 [01:13<01:13, 13.63it/s][Iteration 001000/002000] [loss: 0.00292489] [loss_bc: 0.00262796; loss_div: 0.00018819; loss_ff: 0.00010874] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  55%|█████▍    | 1098/2000 [01:20<01:05, 13.73it/s][Iteration 001100/002000] [loss: 0.00299549] [loss_bc: 0.00272509; loss_div: 0.00016381; loss_ff: 0.00010659] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  60%|█████▉    | 1198/2000 [01:27<00:58, 13.65it/s][Iteration 001200/002000] [loss: 0.00279729] [loss_bc: 0.00252279; loss_div: 0.00018937; loss_ff: 0.00008513] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  65%|██████▍   | 1298/2000 [01:35<00:51, 13.56it/s][Iteration 001300/002000] [loss: 0.00272276] [loss_bc: 0.00246741; loss_div: 0.00017587; loss_ff: 0.00007948] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  70%|██████▉   | 1398/2000 [01:42<00:44, 13.63it/s][Iteration 001400/002000] [loss: 0.00276286] [loss_bc: 0.00247595; loss_div: 0.00019320; loss_ff: 0.00009371] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  75%|███████▍  | 1498/2000 [01:50<00:36, 13.65it/s][Iteration 001500/002000] [loss: 0.00288768] [loss_bc: 0.00261976; loss_div: 0.00018357; loss_ff: 0.00008436] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  80%|███████▉  | 1598/2000 [01:57<00:29, 13.71it/s][Iteration 001600/002000] [loss: 0.00268093] [loss_bc: 0.00241542; loss_div: 0.00018378; loss_ff: 0.00008173] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  85%|████████▍ | 1698/2000 [02:04<00:22, 13.60it/s][Iteration 001700/002000] [loss: 0.00289450] [loss_bc: 0.00261870; loss_div: 0.00019186; loss_ff: 0.00008394] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  90%|████████▉ | 1798/2000 [02:12<00:14, 13.69it/s][Iteration 001800/002000] [loss: 0.00279547] [loss_bc: 0.00251260; loss_div: 0.00018308; loss_ff: 0.00009979] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  95%|█████████▍| 1898/2000 [02:19<00:07, 13.67it/s][Iteration 001900/002000] [loss: 0.00275206] [loss_bc: 0.00251576; loss_div: 0.00017452; loss_ff: 0.00006179] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training: 100%|█████████▉| 1998/2000 [02:26<00:00, 13.62it/s][Iteration 002000/002000] [loss: 0.00286171] [loss_bc: 0.00257149; loss_div: 0.00020593; loss_ff: 0.00008429] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training: 100%|██████████| 2000/2000 [02:27<00:00, 13.59it/s]\n",
      "[Iteration 002000/002000] [loss: 0.00286171] [loss_bc: 0.00257149; loss_div: 0.00020593; loss_ff: 0.00008429] [w_bc: 1.000000, LR: 0.000050]\n",
      "Runtime --> total: 147.32sec (2.95ms/iter.)\n",
      "Configuration:\n",
      "dim: 256, w_div: 1.000000, w_ff: 1.000000, decay_iterations: None, potential: True, vector_potential: False, \n",
      "Using device: cuda (gpus 1) ['NVIDIA RTX A6000']\n",
      "Potential Boundary: 100%|██████████| 1/1 [00:00<00:00,  1.35it/s]\n",
      "Loaded meta state: /userhome/jeon_mg/workspace/_data/NOAA12673/PINN/20170904_012400/model_final.pt\n",
      "Training:   0%|          | 0/2000 [00:00<?, ?it/s][Iteration 000000/002000] [loss: 0.00314911] [loss_bc: 0.00289437; loss_div: 0.00017407; loss_ff: 0.00008067] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:   5%|▍         | 98/2000 [00:07<02:19, 13.66it/s][Iteration 000100/002000] [loss: 0.00314547] [loss_bc: 0.00281783; loss_div: 0.00021850; loss_ff: 0.00010914] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  10%|▉         | 198/2000 [00:14<02:11, 13.71it/s][Iteration 000200/002000] [loss: 0.00287051] [loss_bc: 0.00259972; loss_div: 0.00019104; loss_ff: 0.00007975] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  15%|█▍        | 298/2000 [00:21<02:04, 13.70it/s][Iteration 000300/002000] [loss: 0.00310366] [loss_bc: 0.00281207; loss_div: 0.00020865; loss_ff: 0.00008294] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  20%|█▉        | 398/2000 [00:29<01:57, 13.66it/s][Iteration 000400/002000] [loss: 0.00280999] [loss_bc: 0.00256051; loss_div: 0.00018253; loss_ff: 0.00006695] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  25%|██▍       | 498/2000 [00:36<01:49, 13.67it/s][Iteration 000500/002000] [loss: 0.00314871] [loss_bc: 0.00286275; loss_div: 0.00018587; loss_ff: 0.00010009] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  30%|██▉       | 598/2000 [00:43<01:42, 13.72it/s][Iteration 000600/002000] [loss: 0.00289965] [loss_bc: 0.00259747; loss_div: 0.00022220; loss_ff: 0.00007999] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  35%|███▍      | 698/2000 [00:51<01:33, 14.00it/s][Iteration 000700/002000] [loss: 0.00286268] [loss_bc: 0.00259540; loss_div: 0.00018981; loss_ff: 0.00007746] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  40%|███▉      | 798/2000 [00:58<01:28, 13.54it/s][Iteration 000800/002000] [loss: 0.00301052] [loss_bc: 0.00270106; loss_div: 0.00019655; loss_ff: 0.00011291] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  45%|████▍     | 898/2000 [01:05<01:20, 13.67it/s][Iteration 000900/002000] [loss: 0.00294282] [loss_bc: 0.00269920; loss_div: 0.00017662; loss_ff: 0.00006700] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  50%|████▉     | 998/2000 [01:13<01:13, 13.66it/s][Iteration 001000/002000] [loss: 0.00285529] [loss_bc: 0.00259107; loss_div: 0.00016885; loss_ff: 0.00009537] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  55%|█████▍    | 1098/2000 [01:20<01:05, 13.68it/s][Iteration 001100/002000] [loss: 0.00283574] [loss_bc: 0.00255330; loss_div: 0.00019228; loss_ff: 0.00009016] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  60%|█████▉    | 1198/2000 [01:27<00:58, 13.61it/s][Iteration 001200/002000] [loss: 0.00289014] [loss_bc: 0.00259635; loss_div: 0.00020604; loss_ff: 0.00008775] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  65%|██████▍   | 1298/2000 [01:35<00:51, 13.67it/s][Iteration 001300/002000] [loss: 0.00285715] [loss_bc: 0.00254216; loss_div: 0.00021627; loss_ff: 0.00009873] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  70%|██████▉   | 1398/2000 [01:42<00:43, 13.74it/s][Iteration 001400/002000] [loss: 0.00304924] [loss_bc: 0.00273378; loss_div: 0.00021425; loss_ff: 0.00010120] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  75%|███████▍  | 1498/2000 [01:49<00:36, 13.60it/s][Iteration 001500/002000] [loss: 0.00283911] [loss_bc: 0.00254882; loss_div: 0.00020725; loss_ff: 0.00008304] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  80%|███████▉  | 1598/2000 [01:57<00:29, 13.64it/s][Iteration 001600/002000] [loss: 0.00280986] [loss_bc: 0.00254439; loss_div: 0.00019024; loss_ff: 0.00007524] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  85%|████████▍ | 1698/2000 [02:04<00:22, 13.69it/s][Iteration 001700/002000] [loss: 0.00284530] [loss_bc: 0.00258140; loss_div: 0.00018234; loss_ff: 0.00008156] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  90%|████████▉ | 1798/2000 [02:11<00:14, 13.62it/s][Iteration 001800/002000] [loss: 0.00300911] [loss_bc: 0.00273056; loss_div: 0.00017195; loss_ff: 0.00010660] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  95%|█████████▍| 1898/2000 [02:19<00:07, 13.64it/s][Iteration 001900/002000] [loss: 0.00288742] [loss_bc: 0.00258923; loss_div: 0.00021704; loss_ff: 0.00008114] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training: 100%|█████████▉| 1998/2000 [02:26<00:00, 13.70it/s][Iteration 002000/002000] [loss: 0.00286287] [loss_bc: 0.00254158; loss_div: 0.00022128; loss_ff: 0.00010000] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training: 100%|██████████| 2000/2000 [02:26<00:00, 13.61it/s]\n",
      "[Iteration 002000/002000] [loss: 0.00286287] [loss_bc: 0.00254158; loss_div: 0.00022128; loss_ff: 0.00010000] [w_bc: 1.000000, LR: 0.000050]\n",
      "Runtime --> total: 147.11sec (2.94ms/iter.)\n",
      "Configuration:\n",
      "dim: 256, w_div: 1.000000, w_ff: 1.000000, decay_iterations: None, potential: True, vector_potential: False, \n",
      "Using device: cuda (gpus 1) ['NVIDIA RTX A6000']\n",
      "Potential Boundary: 100%|██████████| 1/1 [00:00<00:00,  1.42it/s]\n",
      "Loaded meta state: /userhome/jeon_mg/workspace/_data/NOAA12673/PINN/20170904_013600/model_final.pt\n",
      "Training:   0%|          | 0/2000 [00:00<?, ?it/s][Iteration 000000/002000] [loss: 0.00282146] [loss_bc: 0.00249687; loss_div: 0.00022906; loss_ff: 0.00009553] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:   5%|▍         | 98/2000 [00:07<02:18, 13.69it/s][Iteration 000100/002000] [loss: 0.00298644] [loss_bc: 0.00270057; loss_div: 0.00018515; loss_ff: 0.00010071] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  10%|▉         | 198/2000 [00:14<02:12, 13.61it/s][Iteration 000200/002000] [loss: 0.00291689] [loss_bc: 0.00270107; loss_div: 0.00015224; loss_ff: 0.00006358] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  15%|█▍        | 298/2000 [00:21<02:04, 13.63it/s][Iteration 000300/002000] [loss: 0.00297448] [loss_bc: 0.00272589; loss_div: 0.00016898; loss_ff: 0.00007961] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  20%|█▉        | 398/2000 [00:29<01:56, 13.70it/s][Iteration 000400/002000] [loss: 0.00317061] [loss_bc: 0.00285225; loss_div: 0.00020619; loss_ff: 0.00011217] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  25%|██▍       | 498/2000 [00:36<01:50, 13.65it/s][Iteration 000500/002000] [loss: 0.00295558] [loss_bc: 0.00269228; loss_div: 0.00018448; loss_ff: 0.00007882] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  30%|██▉       | 598/2000 [00:43<01:42, 13.66it/s][Iteration 000600/002000] [loss: 0.00272014] [loss_bc: 0.00247190; loss_div: 0.00017536; loss_ff: 0.00007289] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  35%|███▍      | 698/2000 [00:51<01:35, 13.63it/s][Iteration 000700/002000] [loss: 0.00306097] [loss_bc: 0.00274835; loss_div: 0.00022674; loss_ff: 0.00008587] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  40%|███▉      | 798/2000 [00:58<01:27, 13.71it/s][Iteration 000800/002000] [loss: 0.00294927] [loss_bc: 0.00260859; loss_div: 0.00021673; loss_ff: 0.00012394] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  45%|████▍     | 898/2000 [01:05<01:20, 13.64it/s][Iteration 000900/002000] [loss: 0.00295533] [loss_bc: 0.00271599; loss_div: 0.00017222; loss_ff: 0.00006712] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  50%|████▉     | 998/2000 [01:13<01:13, 13.68it/s][Iteration 001000/002000] [loss: 0.00294868] [loss_bc: 0.00268314; loss_div: 0.00017937; loss_ff: 0.00008617] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  55%|█████▍    | 1098/2000 [01:20<01:05, 13.67it/s][Iteration 001100/002000] [loss: 0.00284804] [loss_bc: 0.00260101; loss_div: 0.00017494; loss_ff: 0.00007209] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  60%|█████▉    | 1198/2000 [01:28<00:58, 13.64it/s][Iteration 001200/002000] [loss: 0.00299974] [loss_bc: 0.00274917; loss_div: 0.00018149; loss_ff: 0.00006908] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  65%|██████▍   | 1298/2000 [01:35<00:51, 13.64it/s][Iteration 001300/002000] [loss: 0.00270651] [loss_bc: 0.00245705; loss_div: 0.00017191; loss_ff: 0.00007755] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  70%|██████▉   | 1398/2000 [01:42<00:44, 13.68it/s][Iteration 001400/002000] [loss: 0.00303123] [loss_bc: 0.00274874; loss_div: 0.00021056; loss_ff: 0.00007193] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  75%|███████▍  | 1498/2000 [01:50<00:36, 13.61it/s][Iteration 001500/002000] [loss: 0.00295639] [loss_bc: 0.00270030; loss_div: 0.00018556; loss_ff: 0.00007052] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  80%|███████▉  | 1598/2000 [01:57<00:29, 13.67it/s][Iteration 001600/002000] [loss: 0.00289772] [loss_bc: 0.00266245; loss_div: 0.00016935; loss_ff: 0.00006592] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  85%|████████▍ | 1698/2000 [02:04<00:22, 13.68it/s][Iteration 001700/002000] [loss: 0.00290610] [loss_bc: 0.00265654; loss_div: 0.00017410; loss_ff: 0.00007546] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  90%|████████▉ | 1798/2000 [02:12<00:14, 13.68it/s][Iteration 001800/002000] [loss: 0.00295068] [loss_bc: 0.00267776; loss_div: 0.00018083; loss_ff: 0.00009209] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  95%|█████████▍| 1898/2000 [02:19<00:07, 13.70it/s][Iteration 001900/002000] [loss: 0.00303123] [loss_bc: 0.00273943; loss_div: 0.00020571; loss_ff: 0.00008609] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training: 100%|█████████▉| 1998/2000 [02:26<00:00, 13.66it/s][Iteration 002000/002000] [loss: 0.00283835] [loss_bc: 0.00258927; loss_div: 0.00017154; loss_ff: 0.00007755] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training: 100%|██████████| 2000/2000 [02:27<00:00, 13.60it/s]\n",
      "[Iteration 002000/002000] [loss: 0.00283835] [loss_bc: 0.00258927; loss_div: 0.00017154; loss_ff: 0.00007755] [w_bc: 1.000000, LR: 0.000050]\n",
      "Runtime --> total: 147.17sec (2.94ms/iter.)\n",
      "Configuration:\n",
      "dim: 256, w_div: 1.000000, w_ff: 1.000000, decay_iterations: None, potential: True, vector_potential: False, \n",
      "Using device: cuda (gpus 1) ['NVIDIA RTX A6000']\n",
      "Potential Boundary: 100%|██████████| 1/1 [00:00<00:00,  1.35it/s]\n",
      "Loaded meta state: /userhome/jeon_mg/workspace/_data/NOAA12673/PINN/20170904_014800/model_final.pt\n",
      "Training:   0%|          | 0/2000 [00:00<?, ?it/s][Iteration 000000/002000] [loss: 0.00285672] [loss_bc: 0.00258097; loss_div: 0.00018707; loss_ff: 0.00008868] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:   5%|▍         | 98/2000 [00:07<02:19, 13.66it/s][Iteration 000100/002000] [loss: 0.00314267] [loss_bc: 0.00286802; loss_div: 0.00019948; loss_ff: 0.00007517] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  10%|▉         | 198/2000 [00:14<02:11, 13.66it/s][Iteration 000200/002000] [loss: 0.00311072] [loss_bc: 0.00283873; loss_div: 0.00019795; loss_ff: 0.00007403] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  15%|█▍        | 298/2000 [00:21<02:04, 13.65it/s][Iteration 000300/002000] [loss: 0.00276473] [loss_bc: 0.00247713; loss_div: 0.00019813; loss_ff: 0.00008946] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  20%|█▉        | 398/2000 [00:29<01:57, 13.60it/s][Iteration 000400/002000] [loss: 0.00276935] [loss_bc: 0.00245372; loss_div: 0.00019725; loss_ff: 0.00011837] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  25%|██▍       | 498/2000 [00:36<01:49, 13.69it/s][Iteration 000500/002000] [loss: 0.00288930] [loss_bc: 0.00263663; loss_div: 0.00018363; loss_ff: 0.00006903] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  30%|██▉       | 598/2000 [00:43<01:42, 13.72it/s][Iteration 000600/002000] [loss: 0.00270893] [loss_bc: 0.00245060; loss_div: 0.00018850; loss_ff: 0.00006982] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  35%|███▍      | 698/2000 [00:51<01:32, 14.05it/s][Iteration 000700/002000] [loss: 0.00315297] [loss_bc: 0.00283220; loss_div: 0.00021037; loss_ff: 0.00011040] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  40%|███▉      | 798/2000 [00:58<01:26, 13.97it/s][Iteration 000800/002000] [loss: 0.00306287] [loss_bc: 0.00278629; loss_div: 0.00018794; loss_ff: 0.00008864] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  45%|████▍     | 898/2000 [01:05<01:18, 13.98it/s][Iteration 000900/002000] [loss: 0.00271928] [loss_bc: 0.00246909; loss_div: 0.00017395; loss_ff: 0.00007624] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  50%|████▉     | 998/2000 [01:12<01:13, 13.70it/s][Iteration 001000/002000] [loss: 0.00290494] [loss_bc: 0.00263158; loss_div: 0.00018208; loss_ff: 0.00009128] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  55%|█████▍    | 1098/2000 [01:20<01:05, 13.68it/s][Iteration 001100/002000] [loss: 0.00316357] [loss_bc: 0.00286110; loss_div: 0.00020861; loss_ff: 0.00009386] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  60%|█████▉    | 1198/2000 [01:27<00:58, 13.70it/s][Iteration 001200/002000] [loss: 0.00289131] [loss_bc: 0.00262360; loss_div: 0.00017555; loss_ff: 0.00009217] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  65%|██████▍   | 1298/2000 [01:34<00:51, 13.68it/s][Iteration 001300/002000] [loss: 0.00274498] [loss_bc: 0.00246329; loss_div: 0.00018545; loss_ff: 0.00009624] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  70%|██████▉   | 1398/2000 [01:42<00:44, 13.67it/s][Iteration 001400/002000] [loss: 0.00307456] [loss_bc: 0.00278250; loss_div: 0.00019032; loss_ff: 0.00010174] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  75%|███████▍  | 1498/2000 [01:49<00:36, 13.67it/s][Iteration 001500/002000] [loss: 0.00290034] [loss_bc: 0.00254761; loss_div: 0.00024820; loss_ff: 0.00010453] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  80%|███████▉  | 1598/2000 [01:56<00:29, 13.61it/s][Iteration 001600/002000] [loss: 0.00282436] [loss_bc: 0.00254787; loss_div: 0.00018561; loss_ff: 0.00009088] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  85%|████████▍ | 1698/2000 [02:04<00:22, 13.62it/s][Iteration 001700/002000] [loss: 0.00276995] [loss_bc: 0.00245746; loss_div: 0.00020442; loss_ff: 0.00010807] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  90%|████████▉ | 1798/2000 [02:11<00:14, 13.92it/s][Iteration 001800/002000] [loss: 0.00301498] [loss_bc: 0.00277894; loss_div: 0.00017174; loss_ff: 0.00006430] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  95%|█████████▍| 1898/2000 [02:18<00:07, 13.72it/s][Iteration 001900/002000] [loss: 0.00287641] [loss_bc: 0.00261375; loss_div: 0.00018206; loss_ff: 0.00008061] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training: 100%|█████████▉| 1998/2000 [02:26<00:00, 13.65it/s][Iteration 002000/002000] [loss: 0.00305748] [loss_bc: 0.00277463; loss_div: 0.00020204; loss_ff: 0.00008082] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training: 100%|██████████| 2000/2000 [02:26<00:00, 13.67it/s]\n",
      "[Iteration 002000/002000] [loss: 0.00305748] [loss_bc: 0.00277463; loss_div: 0.00020204; loss_ff: 0.00008082] [w_bc: 1.000000, LR: 0.000050]\n",
      "Runtime --> total: 146.51sec (2.93ms/iter.)\n",
      "Configuration:\n",
      "dim: 256, w_div: 1.000000, w_ff: 1.000000, decay_iterations: None, potential: True, vector_potential: False, \n",
      "Using device: cuda (gpus 1) ['NVIDIA RTX A6000']\n",
      "Potential Boundary: 100%|██████████| 1/1 [00:00<00:00,  1.39it/s]\n",
      "Loaded meta state: /userhome/jeon_mg/workspace/_data/NOAA12673/PINN/20170904_020000/model_final.pt\n",
      "Training:   0%|          | 0/2000 [00:00<?, ?it/s][Iteration 000000/002000] [loss: 0.00282674] [loss_bc: 0.00255592; loss_div: 0.00018847; loss_ff: 0.00008235] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:   5%|▍         | 98/2000 [00:07<02:20, 13.57it/s][Iteration 000100/002000] [loss: 0.00308286] [loss_bc: 0.00282123; loss_div: 0.00017277; loss_ff: 0.00008886] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  10%|▉         | 198/2000 [00:14<02:11, 13.72it/s][Iteration 000200/002000] [loss: 0.00329526] [loss_bc: 0.00299077; loss_div: 0.00019341; loss_ff: 0.00011108] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  15%|█▍        | 298/2000 [00:21<02:04, 13.64it/s][Iteration 000300/002000] [loss: 0.00295278] [loss_bc: 0.00268403; loss_div: 0.00019563; loss_ff: 0.00007312] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  20%|█▉        | 398/2000 [00:29<01:57, 13.64it/s][Iteration 000400/002000] [loss: 0.00269250] [loss_bc: 0.00242534; loss_div: 0.00020041; loss_ff: 0.00006675] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  25%|██▍       | 498/2000 [00:36<01:49, 13.67it/s][Iteration 000500/002000] [loss: 0.00310457] [loss_bc: 0.00278818; loss_div: 0.00022440; loss_ff: 0.00009199] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  30%|██▉       | 598/2000 [00:43<01:42, 13.64it/s][Iteration 000600/002000] [loss: 0.00324891] [loss_bc: 0.00298209; loss_div: 0.00019308; loss_ff: 0.00007375] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  35%|███▍      | 698/2000 [00:51<01:35, 13.65it/s][Iteration 000700/002000] [loss: 0.00322984] [loss_bc: 0.00297947; loss_div: 0.00017238; loss_ff: 0.00007800] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  40%|███▉      | 798/2000 [00:58<01:28, 13.55it/s][Iteration 000800/002000] [loss: 0.00267715] [loss_bc: 0.00241939; loss_div: 0.00018447; loss_ff: 0.00007330] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  45%|████▍     | 898/2000 [01:05<01:20, 13.71it/s][Iteration 000900/002000] [loss: 0.00316285] [loss_bc: 0.00284848; loss_div: 0.00021118; loss_ff: 0.00010319] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  50%|████▉     | 998/2000 [01:13<01:13, 13.64it/s][Iteration 001000/002000] [loss: 0.00301272] [loss_bc: 0.00272577; loss_div: 0.00019061; loss_ff: 0.00009634] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  55%|█████▍    | 1098/2000 [01:20<01:06, 13.65it/s][Iteration 001100/002000] [loss: 0.00327366] [loss_bc: 0.00297600; loss_div: 0.00020601; loss_ff: 0.00009165] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  60%|█████▉    | 1198/2000 [01:27<00:58, 13.66it/s][Iteration 001200/002000] [loss: 0.00312312] [loss_bc: 0.00284804; loss_div: 0.00017877; loss_ff: 0.00009631] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  65%|██████▍   | 1298/2000 [01:35<00:50, 13.92it/s][Iteration 001300/002000] [loss: 0.00283635] [loss_bc: 0.00253084; loss_div: 0.00020608; loss_ff: 0.00009943] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  70%|██████▉   | 1398/2000 [01:42<00:43, 13.68it/s][Iteration 001400/002000] [loss: 0.00304049] [loss_bc: 0.00277520; loss_div: 0.00018415; loss_ff: 0.00008114] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  75%|███████▍  | 1498/2000 [01:49<00:36, 13.58it/s][Iteration 001500/002000] [loss: 0.00278151] [loss_bc: 0.00253036; loss_div: 0.00017914; loss_ff: 0.00007201] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  80%|███████▉  | 1598/2000 [01:57<00:29, 13.65it/s][Iteration 001600/002000] [loss: 0.00308941] [loss_bc: 0.00279023; loss_div: 0.00018743; loss_ff: 0.00011175] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  85%|████████▍ | 1698/2000 [02:04<00:22, 13.67it/s][Iteration 001700/002000] [loss: 0.00324219] [loss_bc: 0.00297064; loss_div: 0.00018871; loss_ff: 0.00008284] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  90%|████████▉ | 1798/2000 [02:11<00:14, 13.68it/s][Iteration 001800/002000] [loss: 0.00304898] [loss_bc: 0.00276890; loss_div: 0.00020871; loss_ff: 0.00007138] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  95%|█████████▍| 1898/2000 [02:19<00:07, 13.70it/s][Iteration 001900/002000] [loss: 0.00277344] [loss_bc: 0.00252377; loss_div: 0.00017439; loss_ff: 0.00007528] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training: 100%|█████████▉| 1998/2000 [02:26<00:00, 13.64it/s][Iteration 002000/002000] [loss: 0.00297366] [loss_bc: 0.00274634; loss_div: 0.00015801; loss_ff: 0.00006931] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training: 100%|██████████| 2000/2000 [02:26<00:00, 13.62it/s]\n",
      "[Iteration 002000/002000] [loss: 0.00297366] [loss_bc: 0.00274634; loss_div: 0.00015801; loss_ff: 0.00006931] [w_bc: 1.000000, LR: 0.000050]\n",
      "Runtime --> total: 147.03sec (2.94ms/iter.)\n",
      "Configuration:\n",
      "dim: 256, w_div: 1.000000, w_ff: 1.000000, decay_iterations: None, potential: True, vector_potential: False, \n",
      "Using device: cuda (gpus 1) ['NVIDIA RTX A6000']\n",
      "Potential Boundary: 100%|██████████| 1/1 [00:00<00:00,  1.16it/s]\n",
      "Loaded meta state: /userhome/jeon_mg/workspace/_data/NOAA12673/PINN/20170904_021200/model_final.pt\n",
      "Training:   0%|          | 0/2000 [00:00<?, ?it/s][Iteration 000000/002000] [loss: 0.00290579] [loss_bc: 0.00265373; loss_div: 0.00018581; loss_ff: 0.00006624] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:   5%|▍         | 98/2000 [00:07<02:18, 13.69it/s][Iteration 000100/002000] [loss: 0.00283764] [loss_bc: 0.00258403; loss_div: 0.00018047; loss_ff: 0.00007314] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  10%|▉         | 198/2000 [00:14<02:10, 13.76it/s][Iteration 000200/002000] [loss: 0.00293041] [loss_bc: 0.00264086; loss_div: 0.00018835; loss_ff: 0.00010121] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  15%|█▍        | 298/2000 [00:21<02:04, 13.68it/s][Iteration 000300/002000] [loss: 0.00290925] [loss_bc: 0.00264868; loss_div: 0.00018459; loss_ff: 0.00007597] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  20%|█▉        | 398/2000 [00:29<01:57, 13.67it/s][Iteration 000400/002000] [loss: 0.00290884] [loss_bc: 0.00265186; loss_div: 0.00017633; loss_ff: 0.00008065] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  25%|██▍       | 498/2000 [00:36<01:49, 13.68it/s][Iteration 000500/002000] [loss: 0.00302481] [loss_bc: 0.00267462; loss_div: 0.00021343; loss_ff: 0.00013676] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  30%|██▉       | 598/2000 [00:43<01:42, 13.67it/s][Iteration 000600/002000] [loss: 0.00284200] [loss_bc: 0.00256871; loss_div: 0.00019737; loss_ff: 0.00007592] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  35%|███▍      | 698/2000 [00:51<01:35, 13.66it/s][Iteration 000700/002000] [loss: 0.00293258] [loss_bc: 0.00267066; loss_div: 0.00018531; loss_ff: 0.00007661] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  40%|███▉      | 798/2000 [00:58<01:29, 13.50it/s][Iteration 000800/002000] [loss: 0.00288366] [loss_bc: 0.00262546; loss_div: 0.00017308; loss_ff: 0.00008512] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  45%|████▍     | 898/2000 [01:05<01:20, 13.62it/s][Iteration 000900/002000] [loss: 0.00302896] [loss_bc: 0.00279016; loss_div: 0.00015991; loss_ff: 0.00007889] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  50%|████▉     | 998/2000 [01:13<01:13, 13.67it/s][Iteration 001000/002000] [loss: 0.00286018] [loss_bc: 0.00263708; loss_div: 0.00016243; loss_ff: 0.00006068] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  55%|█████▍    | 1098/2000 [01:20<01:05, 13.69it/s][Iteration 001100/002000] [loss: 0.00290416] [loss_bc: 0.00261962; loss_div: 0.00021102; loss_ff: 0.00007352] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  60%|█████▉    | 1198/2000 [01:27<00:58, 13.65it/s][Iteration 001200/002000] [loss: 0.00291587] [loss_bc: 0.00263762; loss_div: 0.00019897; loss_ff: 0.00007928] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  65%|██████▍   | 1298/2000 [01:35<00:51, 13.65it/s][Iteration 001300/002000] [loss: 0.00292180] [loss_bc: 0.00262124; loss_div: 0.00018718; loss_ff: 0.00011338] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  70%|██████▉   | 1398/2000 [01:42<00:43, 13.70it/s][Iteration 001400/002000] [loss: 0.00321274] [loss_bc: 0.00284005; loss_div: 0.00022309; loss_ff: 0.00014960] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  75%|███████▍  | 1498/2000 [01:49<00:36, 13.72it/s][Iteration 001500/002000] [loss: 0.00293923] [loss_bc: 0.00263534; loss_div: 0.00021021; loss_ff: 0.00009367] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  80%|███████▉  | 1598/2000 [01:57<00:29, 13.59it/s][Iteration 001600/002000] [loss: 0.00287493] [loss_bc: 0.00260765; loss_div: 0.00018534; loss_ff: 0.00008193] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  85%|████████▍ | 1698/2000 [02:04<00:22, 13.65it/s][Iteration 001700/002000] [loss: 0.00306115] [loss_bc: 0.00277800; loss_div: 0.00018625; loss_ff: 0.00009689] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  90%|████████▉ | 1798/2000 [02:11<00:14, 13.63it/s][Iteration 001800/002000] [loss: 0.00292394] [loss_bc: 0.00261941; loss_div: 0.00020493; loss_ff: 0.00009961] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  95%|█████████▍| 1898/2000 [02:19<00:07, 13.59it/s][Iteration 001900/002000] [loss: 0.00285793] [loss_bc: 0.00262887; loss_div: 0.00016179; loss_ff: 0.00006727] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training: 100%|█████████▉| 1998/2000 [02:26<00:00, 13.65it/s][Iteration 002000/002000] [loss: 0.00283131] [loss_bc: 0.00255078; loss_div: 0.00019916; loss_ff: 0.00008137] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training: 100%|██████████| 2000/2000 [02:26<00:00, 13.62it/s]\n",
      "[Iteration 002000/002000] [loss: 0.00283131] [loss_bc: 0.00255078; loss_div: 0.00019916; loss_ff: 0.00008137] [w_bc: 1.000000, LR: 0.000050]\n",
      "Runtime --> total: 147.00sec (2.94ms/iter.)\n",
      "Configuration:\n",
      "dim: 256, w_div: 1.000000, w_ff: 1.000000, decay_iterations: None, potential: True, vector_potential: False, \n",
      "Using device: cuda (gpus 1) ['NVIDIA RTX A6000']\n",
      "Potential Boundary: 100%|██████████| 1/1 [00:01<00:00,  1.07s/it]\n",
      "Loaded meta state: /userhome/jeon_mg/workspace/_data/NOAA12673/PINN/20170904_022400/model_final.pt\n",
      "Training:   0%|          | 0/2000 [00:00<?, ?it/s][Iteration 000000/002000] [loss: 0.00305357] [loss_bc: 0.00276641; loss_div: 0.00020877; loss_ff: 0.00007839] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:   5%|▍         | 98/2000 [00:07<02:19, 13.66it/s][Iteration 000100/002000] [loss: 0.00311293] [loss_bc: 0.00282122; loss_div: 0.00020377; loss_ff: 0.00008794] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  10%|▉         | 198/2000 [00:14<02:11, 13.66it/s][Iteration 000200/002000] [loss: 0.00285424] [loss_bc: 0.00263591; loss_div: 0.00015587; loss_ff: 0.00006245] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  15%|█▍        | 298/2000 [00:21<02:04, 13.70it/s][Iteration 000300/002000] [loss: 0.00291987] [loss_bc: 0.00265143; loss_div: 0.00017778; loss_ff: 0.00009066] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  20%|█▉        | 398/2000 [00:29<01:56, 13.70it/s][Iteration 000400/002000] [loss: 0.00298326] [loss_bc: 0.00272251; loss_div: 0.00018436; loss_ff: 0.00007638] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  25%|██▍       | 498/2000 [00:36<01:49, 13.69it/s][Iteration 000500/002000] [loss: 0.00306273] [loss_bc: 0.00272190; loss_div: 0.00022109; loss_ff: 0.00011974] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  30%|██▉       | 598/2000 [00:43<01:43, 13.57it/s][Iteration 000600/002000] [loss: 0.00308443] [loss_bc: 0.00281862; loss_div: 0.00019090; loss_ff: 0.00007492] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  35%|███▍      | 698/2000 [00:51<01:35, 13.63it/s][Iteration 000700/002000] [loss: 0.00287277] [loss_bc: 0.00259572; loss_div: 0.00018100; loss_ff: 0.00009605] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  40%|███▉      | 798/2000 [00:58<01:28, 13.65it/s][Iteration 000800/002000] [loss: 0.00312899] [loss_bc: 0.00288723; loss_div: 0.00018066; loss_ff: 0.00006110] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  45%|████▍     | 898/2000 [01:06<01:20, 13.66it/s][Iteration 000900/002000] [loss: 0.00302517] [loss_bc: 0.00273998; loss_div: 0.00019167; loss_ff: 0.00009353] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  50%|████▉     | 998/2000 [01:13<01:13, 13.68it/s][Iteration 001000/002000] [loss: 0.00302907] [loss_bc: 0.00273887; loss_div: 0.00019684; loss_ff: 0.00009336] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  55%|█████▍    | 1098/2000 [01:20<01:06, 13.66it/s][Iteration 001100/002000] [loss: 0.00307860] [loss_bc: 0.00281379; loss_div: 0.00017883; loss_ff: 0.00008598] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  60%|█████▉    | 1198/2000 [01:28<00:58, 13.70it/s][Iteration 001200/002000] [loss: 0.00291514] [loss_bc: 0.00263244; loss_div: 0.00019176; loss_ff: 0.00009094] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  65%|██████▍   | 1298/2000 [01:35<00:51, 13.56it/s][Iteration 001300/002000] [loss: 0.00299754] [loss_bc: 0.00274152; loss_div: 0.00017764; loss_ff: 0.00007837] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  70%|██████▉   | 1398/2000 [01:42<00:43, 13.70it/s][Iteration 001400/002000] [loss: 0.00313169] [loss_bc: 0.00288236; loss_div: 0.00017845; loss_ff: 0.00007088] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  75%|███████▍  | 1498/2000 [01:50<00:36, 13.66it/s][Iteration 001500/002000] [loss: 0.00296879] [loss_bc: 0.00271267; loss_div: 0.00017589; loss_ff: 0.00008022] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  80%|███████▉  | 1598/2000 [01:57<00:29, 13.74it/s][Iteration 001600/002000] [loss: 0.00308520] [loss_bc: 0.00280759; loss_div: 0.00020315; loss_ff: 0.00007446] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  85%|████████▍ | 1698/2000 [02:04<00:22, 13.65it/s][Iteration 001700/002000] [loss: 0.00282337] [loss_bc: 0.00256361; loss_div: 0.00018612; loss_ff: 0.00007364] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  90%|████████▉ | 1798/2000 [02:12<00:14, 13.71it/s][Iteration 001800/002000] [loss: 0.00297665] [loss_bc: 0.00272689; loss_div: 0.00017950; loss_ff: 0.00007027] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  95%|█████████▍| 1898/2000 [02:19<00:07, 13.67it/s][Iteration 001900/002000] [loss: 0.00296695] [loss_bc: 0.00270799; loss_div: 0.00017760; loss_ff: 0.00008135] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training: 100%|█████████▉| 1998/2000 [02:26<00:00, 13.84it/s][Iteration 002000/002000] [loss: 0.00300565] [loss_bc: 0.00273186; loss_div: 0.00018105; loss_ff: 0.00009273] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training: 100%|██████████| 2000/2000 [02:27<00:00, 13.58it/s]\n",
      "[Iteration 002000/002000] [loss: 0.00300565] [loss_bc: 0.00273186; loss_div: 0.00018105; loss_ff: 0.00009273] [w_bc: 1.000000, LR: 0.000050]\n",
      "Runtime --> total: 147.42sec (2.95ms/iter.)\n",
      "Configuration:\n",
      "dim: 256, w_div: 1.000000, w_ff: 1.000000, decay_iterations: None, potential: True, vector_potential: False, \n",
      "Using device: cuda (gpus 1) ['NVIDIA RTX A6000']\n",
      "Potential Boundary: 100%|██████████| 1/1 [00:00<00:00,  1.08it/s]\n",
      "Loaded meta state: /userhome/jeon_mg/workspace/_data/NOAA12673/PINN/20170904_023600/model_final.pt\n",
      "Training:   0%|          | 0/2000 [00:00<?, ?it/s][Iteration 000000/002000] [loss: 0.00279307] [loss_bc: 0.00252904; loss_div: 0.00019703; loss_ff: 0.00006700] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:   5%|▍         | 98/2000 [00:07<02:20, 13.58it/s][Iteration 000100/002000] [loss: 0.00278085] [loss_bc: 0.00253206; loss_div: 0.00016883; loss_ff: 0.00007997] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  10%|▉         | 198/2000 [00:14<02:11, 13.68it/s][Iteration 000200/002000] [loss: 0.00298520] [loss_bc: 0.00272006; loss_div: 0.00018534; loss_ff: 0.00007980] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  15%|█▍        | 298/2000 [00:21<02:02, 13.90it/s][Iteration 000300/002000] [loss: 0.00310253] [loss_bc: 0.00286589; loss_div: 0.00017125; loss_ff: 0.00006539] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  20%|█▉        | 398/2000 [00:28<01:56, 13.80it/s][Iteration 000400/002000] [loss: 0.00278898] [loss_bc: 0.00251606; loss_div: 0.00018266; loss_ff: 0.00009026] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  25%|██▍       | 498/2000 [00:36<01:49, 13.67it/s][Iteration 000500/002000] [loss: 0.00301821] [loss_bc: 0.00271648; loss_div: 0.00020429; loss_ff: 0.00009744] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  30%|██▉       | 598/2000 [00:43<01:42, 13.72it/s][Iteration 000600/002000] [loss: 0.00297320] [loss_bc: 0.00269046; loss_div: 0.00020154; loss_ff: 0.00008120] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  35%|███▍      | 698/2000 [00:50<01:34, 13.84it/s][Iteration 000700/002000] [loss: 0.00295421] [loss_bc: 0.00269623; loss_div: 0.00018050; loss_ff: 0.00007747] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  40%|███▉      | 798/2000 [00:58<01:26, 13.89it/s][Iteration 000800/002000] [loss: 0.00276601] [loss_bc: 0.00251604; loss_div: 0.00016631; loss_ff: 0.00008366] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  45%|████▍     | 898/2000 [01:05<01:19, 13.94it/s][Iteration 000900/002000] [loss: 0.00296495] [loss_bc: 0.00269001; loss_div: 0.00018027; loss_ff: 0.00009466] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  50%|████▉     | 998/2000 [01:12<01:11, 13.94it/s][Iteration 001000/002000] [loss: 0.00288323] [loss_bc: 0.00261798; loss_div: 0.00017797; loss_ff: 0.00008728] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  55%|█████▍    | 1098/2000 [01:19<01:05, 13.85it/s][Iteration 001100/002000] [loss: 0.00305422] [loss_bc: 0.00277680; loss_div: 0.00018794; loss_ff: 0.00008949] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  60%|█████▉    | 1198/2000 [01:27<00:57, 13.88it/s][Iteration 001200/002000] [loss: 0.00287711] [loss_bc: 0.00261461; loss_div: 0.00018231; loss_ff: 0.00008019] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  65%|██████▍   | 1298/2000 [01:34<00:51, 13.67it/s][Iteration 001300/002000] [loss: 0.00296158] [loss_bc: 0.00271370; loss_div: 0.00017846; loss_ff: 0.00006942] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  70%|██████▉   | 1398/2000 [01:41<00:44, 13.56it/s][Iteration 001400/002000] [loss: 0.00302903] [loss_bc: 0.00275775; loss_div: 0.00017462; loss_ff: 0.00009666] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  75%|███████▍  | 1498/2000 [01:49<00:36, 13.71it/s][Iteration 001500/002000] [loss: 0.00295692] [loss_bc: 0.00270258; loss_div: 0.00017350; loss_ff: 0.00008085] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  80%|███████▉  | 1598/2000 [01:56<00:29, 13.64it/s][Iteration 001600/002000] [loss: 0.00278863] [loss_bc: 0.00250227; loss_div: 0.00020451; loss_ff: 0.00008184] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  85%|████████▍ | 1698/2000 [02:03<00:22, 13.27it/s][Iteration 001700/002000] [loss: 0.00302614] [loss_bc: 0.00274969; loss_div: 0.00017196; loss_ff: 0.00010449] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  90%|████████▉ | 1798/2000 [02:11<00:14, 13.68it/s][Iteration 001800/002000] [loss: 0.00296758] [loss_bc: 0.00271076; loss_div: 0.00018396; loss_ff: 0.00007285] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  95%|█████████▍| 1898/2000 [02:18<00:07, 13.90it/s][Iteration 001900/002000] [loss: 0.00296241] [loss_bc: 0.00267637; loss_div: 0.00018677; loss_ff: 0.00009927] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training: 100%|█████████▉| 1998/2000 [02:25<00:00, 13.83it/s][Iteration 002000/002000] [loss: 0.00285106] [loss_bc: 0.00260423; loss_div: 0.00017659; loss_ff: 0.00007024] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training: 100%|██████████| 2000/2000 [02:26<00:00, 13.67it/s]\n",
      "[Iteration 002000/002000] [loss: 0.00285106] [loss_bc: 0.00260423; loss_div: 0.00017659; loss_ff: 0.00007024] [w_bc: 1.000000, LR: 0.000050]\n",
      "Runtime --> total: 146.49sec (2.93ms/iter.)\n",
      "Configuration:\n",
      "dim: 256, w_div: 1.000000, w_ff: 1.000000, decay_iterations: None, potential: True, vector_potential: False, \n",
      "Using device: cuda (gpus 1) ['NVIDIA RTX A6000']\n",
      "Potential Boundary: 100%|██████████| 1/1 [00:00<00:00,  1.18it/s]\n",
      "Loaded meta state: /userhome/jeon_mg/workspace/_data/NOAA12673/PINN/20170904_024800/model_final.pt\n",
      "Training:   0%|          | 0/2000 [00:00<?, ?it/s][Iteration 000000/002000] [loss: 0.00288409] [loss_bc: 0.00261927; loss_div: 0.00018800; loss_ff: 0.00007682] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:   5%|▍         | 98/2000 [00:07<02:18, 13.70it/s][Iteration 000100/002000] [loss: 0.00295526] [loss_bc: 0.00267598; loss_div: 0.00017939; loss_ff: 0.00009990] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  10%|▉         | 198/2000 [00:14<02:10, 13.77it/s][Iteration 000200/002000] [loss: 0.00314733] [loss_bc: 0.00288389; loss_div: 0.00017709; loss_ff: 0.00008634] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  15%|█▍        | 298/2000 [00:21<02:04, 13.65it/s][Iteration 000300/002000] [loss: 0.00292715] [loss_bc: 0.00266840; loss_div: 0.00018432; loss_ff: 0.00007443] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  20%|█▉        | 398/2000 [00:28<01:58, 13.54it/s][Iteration 000400/002000] [loss: 0.00288618] [loss_bc: 0.00264017; loss_div: 0.00017564; loss_ff: 0.00007036] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  25%|██▍       | 498/2000 [00:36<01:51, 13.50it/s][Iteration 000500/002000] [loss: 0.00314094] [loss_bc: 0.00287254; loss_div: 0.00017954; loss_ff: 0.00008887] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  30%|██▉       | 598/2000 [00:43<01:43, 13.52it/s][Iteration 000600/002000] [loss: 0.00289782] [loss_bc: 0.00265955; loss_div: 0.00017372; loss_ff: 0.00006456] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  35%|███▍      | 698/2000 [00:50<01:33, 13.88it/s][Iteration 000700/002000] [loss: 0.00298035] [loss_bc: 0.00271354; loss_div: 0.00017150; loss_ff: 0.00009531] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  40%|███▉      | 798/2000 [00:58<01:28, 13.54it/s][Iteration 000800/002000] [loss: 0.00294952] [loss_bc: 0.00271230; loss_div: 0.00016687; loss_ff: 0.00007035] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  45%|████▍     | 898/2000 [01:05<01:20, 13.75it/s][Iteration 000900/002000] [loss: 0.00291014] [loss_bc: 0.00265529; loss_div: 0.00018142; loss_ff: 0.00007343] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  50%|████▉     | 998/2000 [01:12<01:12, 13.87it/s][Iteration 001000/002000] [loss: 0.00294987] [loss_bc: 0.00265366; loss_div: 0.00019011; loss_ff: 0.00010610] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  55%|█████▍    | 1098/2000 [01:20<01:06, 13.63it/s][Iteration 001100/002000] [loss: 0.00302936] [loss_bc: 0.00270799; loss_div: 0.00021274; loss_ff: 0.00010862] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  60%|█████▉    | 1198/2000 [01:27<00:57, 13.85it/s][Iteration 001200/002000] [loss: 0.00290335] [loss_bc: 0.00265508; loss_div: 0.00016850; loss_ff: 0.00007978] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  65%|██████▍   | 1298/2000 [01:34<00:51, 13.63it/s][Iteration 001300/002000] [loss: 0.00294254] [loss_bc: 0.00270899; loss_div: 0.00016958; loss_ff: 0.00006397] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  70%|██████▉   | 1398/2000 [01:41<00:43, 13.76it/s][Iteration 001400/002000] [loss: 0.00289574] [loss_bc: 0.00263574; loss_div: 0.00017719; loss_ff: 0.00008281] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  75%|███████▍  | 1498/2000 [01:49<00:36, 13.83it/s][Iteration 001500/002000] [loss: 0.00293395] [loss_bc: 0.00265500; loss_div: 0.00020185; loss_ff: 0.00007710] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  80%|███████▉  | 1598/2000 [01:56<00:29, 13.74it/s][Iteration 001600/002000] [loss: 0.00285096] [loss_bc: 0.00259574; loss_div: 0.00016407; loss_ff: 0.00009115] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  85%|████████▍ | 1698/2000 [02:03<00:21, 13.80it/s][Iteration 001700/002000] [loss: 0.00290272] [loss_bc: 0.00265152; loss_div: 0.00017689; loss_ff: 0.00007432] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  90%|████████▉ | 1798/2000 [02:11<00:14, 13.83it/s][Iteration 001800/002000] [loss: 0.00286862] [loss_bc: 0.00259925; loss_div: 0.00018896; loss_ff: 0.00008041] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  95%|█████████▍| 1898/2000 [02:18<00:07, 13.72it/s][Iteration 001900/002000] [loss: 0.00312531] [loss_bc: 0.00285515; loss_div: 0.00018583; loss_ff: 0.00008433] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training: 100%|█████████▉| 1998/2000 [02:25<00:00, 13.80it/s][Iteration 002000/002000] [loss: 0.00290484] [loss_bc: 0.00268155; loss_div: 0.00016285; loss_ff: 0.00006045] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training: 100%|██████████| 2000/2000 [02:26<00:00, 13.70it/s]\n",
      "[Iteration 002000/002000] [loss: 0.00290484] [loss_bc: 0.00268155; loss_div: 0.00016285; loss_ff: 0.00006045] [w_bc: 1.000000, LR: 0.000050]\n",
      "Runtime --> total: 146.24sec (2.92ms/iter.)\n",
      "Configuration:\n",
      "dim: 256, w_div: 1.000000, w_ff: 1.000000, decay_iterations: None, potential: True, vector_potential: False, \n",
      "Using device: cuda (gpus 1) ['NVIDIA RTX A6000']\n",
      "Potential Boundary: 100%|██████████| 1/1 [00:00<00:00,  1.08it/s]\n",
      "Loaded meta state: /userhome/jeon_mg/workspace/_data/NOAA12673/PINN/20170904_030000/model_final.pt\n",
      "Training:   0%|          | 0/2000 [00:00<?, ?it/s][Iteration 000000/002000] [loss: 0.00301587] [loss_bc: 0.00274585; loss_div: 0.00018116; loss_ff: 0.00008886] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:   5%|▍         | 98/2000 [00:07<02:18, 13.77it/s][Iteration 000100/002000] [loss: 0.00310133] [loss_bc: 0.00287817; loss_div: 0.00015390; loss_ff: 0.00006926] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  10%|▉         | 198/2000 [00:14<02:12, 13.63it/s][Iteration 000200/002000] [loss: 0.00311490] [loss_bc: 0.00284718; loss_div: 0.00019034; loss_ff: 0.00007738] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  15%|█▍        | 298/2000 [00:21<02:03, 13.74it/s][Iteration 000300/002000] [loss: 0.00311032] [loss_bc: 0.00287024; loss_div: 0.00016885; loss_ff: 0.00007123] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  20%|█▉        | 398/2000 [00:29<01:57, 13.60it/s][Iteration 000400/002000] [loss: 0.00275518] [loss_bc: 0.00248838; loss_div: 0.00018570; loss_ff: 0.00008110] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  25%|██▍       | 498/2000 [00:36<01:48, 13.81it/s][Iteration 000500/002000] [loss: 0.00294483] [loss_bc: 0.00263698; loss_div: 0.00021116; loss_ff: 0.00009669] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  30%|██▉       | 598/2000 [00:43<01:41, 13.84it/s][Iteration 000600/002000] [loss: 0.00315974] [loss_bc: 0.00289991; loss_div: 0.00018165; loss_ff: 0.00007818] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  35%|███▍      | 698/2000 [00:50<01:34, 13.74it/s][Iteration 000700/002000] [loss: 0.00285707] [loss_bc: 0.00257311; loss_div: 0.00019271; loss_ff: 0.00009125] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  40%|███▉      | 798/2000 [00:58<01:27, 13.79it/s][Iteration 000800/002000] [loss: 0.00290614] [loss_bc: 0.00264037; loss_div: 0.00016961; loss_ff: 0.00009616] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  45%|████▍     | 898/2000 [01:05<01:19, 13.80it/s][Iteration 000900/002000] [loss: 0.00280657] [loss_bc: 0.00257040; loss_div: 0.00017022; loss_ff: 0.00006595] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  50%|████▉     | 998/2000 [01:12<01:12, 13.87it/s][Iteration 001000/002000] [loss: 0.00287907] [loss_bc: 0.00262975; loss_div: 0.00018134; loss_ff: 0.00006799] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  55%|█████▍    | 1098/2000 [01:20<01:06, 13.54it/s][Iteration 001100/002000] [loss: 0.00307043] [loss_bc: 0.00286341; loss_div: 0.00014851; loss_ff: 0.00005851] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  60%|█████▉    | 1198/2000 [01:27<00:58, 13.75it/s][Iteration 001200/002000] [loss: 0.00291808] [loss_bc: 0.00263110; loss_div: 0.00020853; loss_ff: 0.00007845] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  65%|██████▍   | 1298/2000 [01:34<00:51, 13.73it/s][Iteration 001300/002000] [loss: 0.00285331] [loss_bc: 0.00256883; loss_div: 0.00020317; loss_ff: 0.00008130] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  70%|██████▉   | 1398/2000 [01:42<00:44, 13.66it/s][Iteration 001400/002000] [loss: 0.00314781] [loss_bc: 0.00283296; loss_div: 0.00020629; loss_ff: 0.00010855] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  75%|███████▍  | 1498/2000 [01:49<00:36, 13.82it/s][Iteration 001500/002000] [loss: 0.00315564] [loss_bc: 0.00288766; loss_div: 0.00019862; loss_ff: 0.00006937] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  80%|███████▉  | 1598/2000 [01:56<00:29, 13.82it/s][Iteration 001600/002000] [loss: 0.00309034] [loss_bc: 0.00285989; loss_div: 0.00016327; loss_ff: 0.00006718] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  85%|████████▍ | 1698/2000 [02:03<00:21, 13.81it/s][Iteration 001700/002000] [loss: 0.00277964] [loss_bc: 0.00254577; loss_div: 0.00016840; loss_ff: 0.00006547] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  90%|████████▉ | 1798/2000 [02:11<00:14, 13.79it/s][Iteration 001800/002000] [loss: 0.00284802] [loss_bc: 0.00262403; loss_div: 0.00015484; loss_ff: 0.00006915] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  95%|█████████▍| 1898/2000 [02:18<00:07, 13.57it/s][Iteration 001900/002000] [loss: 0.00309828] [loss_bc: 0.00285885; loss_div: 0.00016808; loss_ff: 0.00007135] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training: 100%|█████████▉| 1998/2000 [02:25<00:00, 13.80it/s][Iteration 002000/002000] [loss: 0.00278464] [loss_bc: 0.00254607; loss_div: 0.00016450; loss_ff: 0.00007407] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training: 100%|██████████| 2000/2000 [02:26<00:00, 13.68it/s]\n",
      "[Iteration 002000/002000] [loss: 0.00278464] [loss_bc: 0.00254607; loss_div: 0.00016450; loss_ff: 0.00007407] [w_bc: 1.000000, LR: 0.000050]\n",
      "Runtime --> total: 146.43sec (2.93ms/iter.)\n",
      "Configuration:\n",
      "dim: 256, w_div: 1.000000, w_ff: 1.000000, decay_iterations: None, potential: True, vector_potential: False, \n",
      "Using device: cuda (gpus 1) ['NVIDIA RTX A6000']\n",
      "Potential Boundary: 100%|██████████| 1/1 [00:00<00:00,  1.09it/s]\n",
      "Loaded meta state: /userhome/jeon_mg/workspace/_data/NOAA12673/PINN/20170904_031200/model_final.pt\n",
      "Training:   0%|          | 0/2000 [00:00<?, ?it/s][Iteration 000000/002000] [loss: 0.00291271] [loss_bc: 0.00268186; loss_div: 0.00015271; loss_ff: 0.00007814] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:   5%|▍         | 98/2000 [00:07<02:19, 13.66it/s][Iteration 000100/002000] [loss: 0.00284111] [loss_bc: 0.00259966; loss_div: 0.00017767; loss_ff: 0.00006378] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  10%|▉         | 198/2000 [00:14<02:09, 13.87it/s][Iteration 000200/002000] [loss: 0.00293266] [loss_bc: 0.00267662; loss_div: 0.00017542; loss_ff: 0.00008062] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  15%|█▍        | 298/2000 [00:21<02:02, 13.84it/s][Iteration 000300/002000] [loss: 0.00284714] [loss_bc: 0.00258837; loss_div: 0.00017176; loss_ff: 0.00008701] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  20%|█▉        | 398/2000 [00:28<01:57, 13.62it/s][Iteration 000400/002000] [loss: 0.00292343] [loss_bc: 0.00265813; loss_div: 0.00018146; loss_ff: 0.00008384] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  25%|██▍       | 498/2000 [00:36<01:48, 13.80it/s][Iteration 000500/002000] [loss: 0.00290997] [loss_bc: 0.00266251; loss_div: 0.00015427; loss_ff: 0.00009319] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  30%|██▉       | 598/2000 [00:43<01:41, 13.80it/s][Iteration 000600/002000] [loss: 0.00302499] [loss_bc: 0.00271004; loss_div: 0.00020538; loss_ff: 0.00010958] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  35%|███▍      | 698/2000 [00:50<01:34, 13.85it/s][Iteration 000700/002000] [loss: 0.00279279] [loss_bc: 0.00254699; loss_div: 0.00017791; loss_ff: 0.00006789] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  40%|███▉      | 798/2000 [00:58<01:27, 13.79it/s][Iteration 000800/002000] [loss: 0.00306235] [loss_bc: 0.00277937; loss_div: 0.00017202; loss_ff: 0.00011097] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  45%|████▍     | 898/2000 [01:05<01:19, 13.89it/s][Iteration 000900/002000] [loss: 0.00287270] [loss_bc: 0.00254307; loss_div: 0.00022263; loss_ff: 0.00010700] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  50%|████▉     | 998/2000 [01:12<01:13, 13.58it/s][Iteration 001000/002000] [loss: 0.00306071] [loss_bc: 0.00278644; loss_div: 0.00019388; loss_ff: 0.00008039] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  55%|█████▍    | 1098/2000 [01:20<01:05, 13.81it/s][Iteration 001100/002000] [loss: 0.00293962] [loss_bc: 0.00266895; loss_div: 0.00019057; loss_ff: 0.00008011] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  60%|█████▉    | 1198/2000 [01:27<00:58, 13.71it/s][Iteration 001200/002000] [loss: 0.00294398] [loss_bc: 0.00264560; loss_div: 0.00020610; loss_ff: 0.00009229] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  65%|██████▍   | 1298/2000 [01:34<00:51, 13.73it/s][Iteration 001300/002000] [loss: 0.00300510] [loss_bc: 0.00269814; loss_div: 0.00018822; loss_ff: 0.00011874] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  70%|██████▉   | 1398/2000 [01:42<00:43, 13.86it/s][Iteration 001400/002000] [loss: 0.00300323] [loss_bc: 0.00271959; loss_div: 0.00018459; loss_ff: 0.00009905] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  75%|███████▍  | 1498/2000 [01:49<00:36, 13.89it/s][Iteration 001500/002000] [loss: 0.00294840] [loss_bc: 0.00266030; loss_div: 0.00019242; loss_ff: 0.00009568] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  80%|███████▉  | 1598/2000 [01:56<00:28, 13.88it/s][Iteration 001600/002000] [loss: 0.00298875] [loss_bc: 0.00269936; loss_div: 0.00021187; loss_ff: 0.00007752] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  85%|████████▍ | 1698/2000 [02:04<00:21, 13.88it/s][Iteration 001700/002000] [loss: 0.00284005] [loss_bc: 0.00257767; loss_div: 0.00017712; loss_ff: 0.00008526] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  90%|████████▉ | 1798/2000 [02:11<00:14, 13.91it/s][Iteration 001800/002000] [loss: 0.00297590] [loss_bc: 0.00273944; loss_div: 0.00017130; loss_ff: 0.00006516] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  95%|█████████▍| 1898/2000 [02:18<00:07, 13.77it/s][Iteration 001900/002000] [loss: 0.00293148] [loss_bc: 0.00264139; loss_div: 0.00019116; loss_ff: 0.00009893] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training: 100%|█████████▉| 1998/2000 [02:25<00:00, 13.92it/s][Iteration 002000/002000] [loss: 0.00294943] [loss_bc: 0.00269210; loss_div: 0.00017606; loss_ff: 0.00008126] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training: 100%|██████████| 2000/2000 [02:26<00:00, 13.67it/s]\n",
      "[Iteration 002000/002000] [loss: 0.00294943] [loss_bc: 0.00269210; loss_div: 0.00017606; loss_ff: 0.00008126] [w_bc: 1.000000, LR: 0.000050]\n",
      "Runtime --> total: 146.59sec (2.93ms/iter.)\n",
      "Configuration:\n",
      "dim: 256, w_div: 1.000000, w_ff: 1.000000, decay_iterations: None, potential: True, vector_potential: False, \n",
      "Using device: cuda (gpus 1) ['NVIDIA RTX A6000']\n",
      "Potential Boundary: 100%|██████████| 1/1 [00:00<00:00,  1.09it/s]\n",
      "Loaded meta state: /userhome/jeon_mg/workspace/_data/NOAA12673/PINN/20170904_032400/model_final.pt\n",
      "Training:   0%|          | 0/2000 [00:00<?, ?it/s][Iteration 000000/002000] [loss: 0.00296299] [loss_bc: 0.00268224; loss_div: 0.00018429; loss_ff: 0.00009647] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:   5%|▍         | 98/2000 [00:07<02:17, 13.88it/s][Iteration 000100/002000] [loss: 0.00296273] [loss_bc: 0.00269116; loss_div: 0.00017810; loss_ff: 0.00009347] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  10%|▉         | 198/2000 [00:14<02:10, 13.80it/s][Iteration 000200/002000] [loss: 0.00297664] [loss_bc: 0.00267420; loss_div: 0.00019352; loss_ff: 0.00010893] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  15%|█▍        | 298/2000 [00:21<02:03, 13.83it/s][Iteration 000300/002000] [loss: 0.00284904] [loss_bc: 0.00262531; loss_div: 0.00016443; loss_ff: 0.00005931] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  20%|█▉        | 398/2000 [00:28<01:54, 13.94it/s][Iteration 000400/002000] [loss: 0.00305395] [loss_bc: 0.00278944; loss_div: 0.00019574; loss_ff: 0.00006877] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  25%|██▍       | 498/2000 [00:36<01:49, 13.74it/s][Iteration 000500/002000] [loss: 0.00295127] [loss_bc: 0.00267736; loss_div: 0.00019397; loss_ff: 0.00007994] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  30%|██▉       | 598/2000 [00:43<01:42, 13.70it/s][Iteration 000600/002000] [loss: 0.00289384] [loss_bc: 0.00265921; loss_div: 0.00016289; loss_ff: 0.00007173] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  35%|███▍      | 698/2000 [00:50<01:33, 13.94it/s][Iteration 000700/002000] [loss: 0.00291702] [loss_bc: 0.00265380; loss_div: 0.00019152; loss_ff: 0.00007170] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  40%|███▉      | 798/2000 [00:58<01:27, 13.80it/s][Iteration 000800/002000] [loss: 0.00289075] [loss_bc: 0.00267253; loss_div: 0.00015365; loss_ff: 0.00006457] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  45%|████▍     | 898/2000 [01:05<01:19, 13.88it/s][Iteration 000900/002000] [loss: 0.00299132] [loss_bc: 0.00272362; loss_div: 0.00018045; loss_ff: 0.00008726] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  50%|████▉     | 998/2000 [01:12<01:12, 13.83it/s][Iteration 001000/002000] [loss: 0.00294780] [loss_bc: 0.00272034; loss_div: 0.00016012; loss_ff: 0.00006734] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  55%|█████▍    | 1098/2000 [01:20<01:05, 13.73it/s][Iteration 001100/002000] [loss: 0.00284190] [loss_bc: 0.00261635; loss_div: 0.00015668; loss_ff: 0.00006888] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  60%|█████▉    | 1198/2000 [01:27<00:58, 13.69it/s][Iteration 001200/002000] [loss: 0.00293253] [loss_bc: 0.00267422; loss_div: 0.00017896; loss_ff: 0.00007935] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  65%|██████▍   | 1298/2000 [01:34<00:50, 13.88it/s][Iteration 001300/002000] [loss: 0.00286553] [loss_bc: 0.00264492; loss_div: 0.00015313; loss_ff: 0.00006748] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  70%|██████▉   | 1398/2000 [01:42<00:43, 13.78it/s][Iteration 001400/002000] [loss: 0.00296494] [loss_bc: 0.00265978; loss_div: 0.00021860; loss_ff: 0.00008656] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  75%|███████▍  | 1498/2000 [01:49<00:36, 13.85it/s][Iteration 001500/002000] [loss: 0.00288629] [loss_bc: 0.00258325; loss_div: 0.00021359; loss_ff: 0.00008944] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  80%|███████▉  | 1598/2000 [01:56<00:29, 13.65it/s][Iteration 001600/002000] [loss: 0.00291511] [loss_bc: 0.00261601; loss_div: 0.00021329; loss_ff: 0.00008580] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  85%|████████▍ | 1698/2000 [02:03<00:21, 13.83it/s][Iteration 001700/002000] [loss: 0.00290631] [loss_bc: 0.00266434; loss_div: 0.00017922; loss_ff: 0.00006274] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  90%|████████▉ | 1798/2000 [02:11<00:14, 13.56it/s][Iteration 001800/002000] [loss: 0.00294245] [loss_bc: 0.00261272; loss_div: 0.00021065; loss_ff: 0.00011907] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  95%|█████████▍| 1898/2000 [02:18<00:07, 13.81it/s][Iteration 001900/002000] [loss: 0.00294264] [loss_bc: 0.00264246; loss_div: 0.00019314; loss_ff: 0.00010704] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training: 100%|█████████▉| 1998/2000 [02:25<00:00, 13.72it/s][Iteration 002000/002000] [loss: 0.00292327] [loss_bc: 0.00265958; loss_div: 0.00018441; loss_ff: 0.00007928] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training: 100%|██████████| 2000/2000 [02:26<00:00, 13.69it/s]\n",
      "[Iteration 002000/002000] [loss: 0.00292327] [loss_bc: 0.00265958; loss_div: 0.00018441; loss_ff: 0.00007928] [w_bc: 1.000000, LR: 0.000050]\n",
      "Runtime --> total: 146.25sec (2.93ms/iter.)\n",
      "Configuration:\n",
      "dim: 256, w_div: 1.000000, w_ff: 1.000000, decay_iterations: None, potential: True, vector_potential: False, \n",
      "Using device: cuda (gpus 1) ['NVIDIA RTX A6000']\n",
      "Potential Boundary: 100%|██████████| 1/1 [00:00<00:00,  1.06it/s]\n",
      "Loaded meta state: /userhome/jeon_mg/workspace/_data/NOAA12673/PINN/20170904_033600/model_final.pt\n",
      "Training:   0%|          | 0/2000 [00:00<?, ?it/s][Iteration 000000/002000] [loss: 0.00294598] [loss_bc: 0.00270861; loss_div: 0.00016495; loss_ff: 0.00007242] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:   5%|▍         | 98/2000 [00:07<02:17, 13.87it/s][Iteration 000100/002000] [loss: 0.00276205] [loss_bc: 0.00248133; loss_div: 0.00019133; loss_ff: 0.00008939] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  10%|▉         | 198/2000 [00:14<02:10, 13.80it/s][Iteration 000200/002000] [loss: 0.00293429] [loss_bc: 0.00264854; loss_div: 0.00018905; loss_ff: 0.00009669] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  15%|█▍        | 298/2000 [00:21<02:04, 13.72it/s][Iteration 000300/002000] [loss: 0.00294804] [loss_bc: 0.00264243; loss_div: 0.00019610; loss_ff: 0.00010951] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  20%|█▉        | 398/2000 [00:28<01:55, 13.82it/s][Iteration 000400/002000] [loss: 0.00297771] [loss_bc: 0.00268844; loss_div: 0.00019718; loss_ff: 0.00009208] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  25%|██▍       | 498/2000 [00:36<01:47, 13.98it/s][Iteration 000500/002000] [loss: 0.00293539] [loss_bc: 0.00271746; loss_div: 0.00015201; loss_ff: 0.00006592] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  30%|██▉       | 598/2000 [00:43<01:41, 13.79it/s][Iteration 000600/002000] [loss: 0.00287450] [loss_bc: 0.00260655; loss_div: 0.00019203; loss_ff: 0.00007592] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  35%|███▍      | 698/2000 [00:50<01:33, 13.89it/s][Iteration 000700/002000] [loss: 0.00295145] [loss_bc: 0.00271671; loss_div: 0.00016881; loss_ff: 0.00006594] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  40%|███▉      | 798/2000 [00:58<01:27, 13.77it/s][Iteration 000800/002000] [loss: 0.00289464] [loss_bc: 0.00260544; loss_div: 0.00019938; loss_ff: 0.00008982] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  45%|████▍     | 898/2000 [01:05<01:19, 13.83it/s][Iteration 000900/002000] [loss: 0.00291570] [loss_bc: 0.00265467; loss_div: 0.00017285; loss_ff: 0.00008818] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  50%|████▉     | 998/2000 [01:12<01:13, 13.70it/s][Iteration 001000/002000] [loss: 0.00290758] [loss_bc: 0.00264576; loss_div: 0.00016902; loss_ff: 0.00009281] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  55%|█████▍    | 1098/2000 [01:19<01:05, 13.78it/s][Iteration 001100/002000] [loss: 0.00291133] [loss_bc: 0.00267748; loss_div: 0.00016690; loss_ff: 0.00006695] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  60%|█████▉    | 1198/2000 [01:27<00:58, 13.67it/s][Iteration 001200/002000] [loss: 0.00294198] [loss_bc: 0.00267843; loss_div: 0.00017134; loss_ff: 0.00009221] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  65%|██████▍   | 1298/2000 [01:34<00:50, 13.82it/s][Iteration 001300/002000] [loss: 0.00289427] [loss_bc: 0.00263549; loss_div: 0.00017546; loss_ff: 0.00008332] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  70%|██████▉   | 1398/2000 [01:41<00:43, 13.79it/s][Iteration 001400/002000] [loss: 0.00289662] [loss_bc: 0.00263256; loss_div: 0.00020465; loss_ff: 0.00005942] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  75%|███████▍  | 1498/2000 [01:48<00:36, 13.79it/s][Iteration 001500/002000] [loss: 0.00297246] [loss_bc: 0.00270293; loss_div: 0.00017177; loss_ff: 0.00009776] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  80%|███████▉  | 1598/2000 [01:56<00:29, 13.60it/s][Iteration 001600/002000] [loss: 0.00294622] [loss_bc: 0.00266944; loss_div: 0.00019063; loss_ff: 0.00008616] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  85%|████████▍ | 1698/2000 [02:03<00:22, 13.68it/s][Iteration 001700/002000] [loss: 0.00297794] [loss_bc: 0.00264863; loss_div: 0.00023398; loss_ff: 0.00009533] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  90%|████████▉ | 1798/2000 [02:10<00:14, 13.83it/s][Iteration 001800/002000] [loss: 0.00286312] [loss_bc: 0.00260185; loss_div: 0.00017146; loss_ff: 0.00008981] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  95%|█████████▍| 1898/2000 [02:18<00:07, 13.77it/s][Iteration 001900/002000] [loss: 0.00271471] [loss_bc: 0.00246216; loss_div: 0.00017868; loss_ff: 0.00007386] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training: 100%|█████████▉| 1998/2000 [02:25<00:00, 13.84it/s][Iteration 002000/002000] [loss: 0.00283170] [loss_bc: 0.00259005; loss_div: 0.00016474; loss_ff: 0.00007690] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training: 100%|██████████| 2000/2000 [02:25<00:00, 13.72it/s]\n",
      "[Iteration 002000/002000] [loss: 0.00283170] [loss_bc: 0.00259005; loss_div: 0.00016474; loss_ff: 0.00007690] [w_bc: 1.000000, LR: 0.000050]\n",
      "Runtime --> total: 145.99sec (2.92ms/iter.)\n",
      "Configuration:\n",
      "dim: 256, w_div: 1.000000, w_ff: 1.000000, decay_iterations: None, potential: True, vector_potential: False, \n",
      "Using device: cuda (gpus 1) ['NVIDIA RTX A6000']\n",
      "Potential Boundary: 100%|██████████| 1/1 [00:00<00:00,  1.05it/s]\n",
      "Loaded meta state: /userhome/jeon_mg/workspace/_data/NOAA12673/PINN/20170904_034800/model_final.pt\n",
      "Training:   0%|          | 0/2000 [00:00<?, ?it/s][Iteration 000000/002000] [loss: 0.00294661] [loss_bc: 0.00262577; loss_div: 0.00020402; loss_ff: 0.00011682] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:   5%|▍         | 98/2000 [00:07<02:16, 13.90it/s][Iteration 000100/002000] [loss: 0.00291584] [loss_bc: 0.00268324; loss_div: 0.00016520; loss_ff: 0.00006740] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  10%|▉         | 198/2000 [00:14<02:11, 13.67it/s][Iteration 000200/002000] [loss: 0.00295995] [loss_bc: 0.00267185; loss_div: 0.00018543; loss_ff: 0.00010267] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  15%|█▍        | 298/2000 [00:21<02:03, 13.81it/s][Iteration 000300/002000] [loss: 0.00287414] [loss_bc: 0.00260765; loss_div: 0.00018193; loss_ff: 0.00008457] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  20%|█▉        | 398/2000 [00:29<01:56, 13.73it/s][Iteration 000400/002000] [loss: 0.00275515] [loss_bc: 0.00253473; loss_div: 0.00015301; loss_ff: 0.00006740] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  25%|██▍       | 498/2000 [00:36<01:50, 13.60it/s][Iteration 000500/002000] [loss: 0.00291714] [loss_bc: 0.00266747; loss_div: 0.00017921; loss_ff: 0.00007046] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  30%|██▉       | 598/2000 [00:43<01:41, 13.83it/s][Iteration 000600/002000] [loss: 0.00285366] [loss_bc: 0.00259797; loss_div: 0.00017520; loss_ff: 0.00008049] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  35%|███▍      | 698/2000 [00:50<01:34, 13.74it/s][Iteration 000700/002000] [loss: 0.00302592] [loss_bc: 0.00277792; loss_div: 0.00017328; loss_ff: 0.00007471] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  40%|███▉      | 798/2000 [00:58<01:26, 13.91it/s][Iteration 000800/002000] [loss: 0.00287482] [loss_bc: 0.00261112; loss_div: 0.00018186; loss_ff: 0.00008184] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  45%|████▍     | 898/2000 [01:05<01:20, 13.77it/s][Iteration 000900/002000] [loss: 0.00308614] [loss_bc: 0.00277804; loss_div: 0.00020285; loss_ff: 0.00010525] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  50%|████▉     | 998/2000 [01:12<01:13, 13.68it/s][Iteration 001000/002000] [loss: 0.00288581] [loss_bc: 0.00260557; loss_div: 0.00018758; loss_ff: 0.00009266] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  55%|█████▍    | 1098/2000 [01:19<01:05, 13.86it/s][Iteration 001100/002000] [loss: 0.00306244] [loss_bc: 0.00276935; loss_div: 0.00020857; loss_ff: 0.00008453] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  60%|█████▉    | 1198/2000 [01:27<00:59, 13.58it/s][Iteration 001200/002000] [loss: 0.00281235] [loss_bc: 0.00258759; loss_div: 0.00015680; loss_ff: 0.00006796] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  65%|██████▍   | 1298/2000 [01:34<00:51, 13.70it/s][Iteration 001300/002000] [loss: 0.00282112] [loss_bc: 0.00258687; loss_div: 0.00017224; loss_ff: 0.00006200] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  70%|██████▉   | 1398/2000 [01:41<00:43, 13.83it/s][Iteration 001400/002000] [loss: 0.00296990] [loss_bc: 0.00260840; loss_div: 0.00025638; loss_ff: 0.00010512] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  75%|███████▍  | 1498/2000 [01:49<00:36, 13.63it/s][Iteration 001500/002000] [loss: 0.00283545] [loss_bc: 0.00254292; loss_div: 0.00019710; loss_ff: 0.00009543] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  80%|███████▉  | 1598/2000 [01:56<00:29, 13.82it/s][Iteration 001600/002000] [loss: 0.00277101] [loss_bc: 0.00254120; loss_div: 0.00016473; loss_ff: 0.00006508] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  85%|████████▍ | 1698/2000 [02:03<00:21, 13.82it/s][Iteration 001700/002000] [loss: 0.00289286] [loss_bc: 0.00260572; loss_div: 0.00020447; loss_ff: 0.00008267] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  90%|████████▉ | 1798/2000 [02:11<00:14, 13.75it/s][Iteration 001800/002000] [loss: 0.00287173] [loss_bc: 0.00260175; loss_div: 0.00019047; loss_ff: 0.00007951] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  95%|█████████▍| 1898/2000 [02:18<00:07, 13.71it/s][Iteration 001900/002000] [loss: 0.00284036] [loss_bc: 0.00260151; loss_div: 0.00015870; loss_ff: 0.00008015] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training: 100%|█████████▉| 1998/2000 [02:25<00:00, 13.82it/s][Iteration 002000/002000] [loss: 0.00287729] [loss_bc: 0.00258362; loss_div: 0.00018642; loss_ff: 0.00010726] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training: 100%|██████████| 2000/2000 [02:25<00:00, 13.70it/s]\n",
      "[Iteration 002000/002000] [loss: 0.00287729] [loss_bc: 0.00258362; loss_div: 0.00018642; loss_ff: 0.00010726] [w_bc: 1.000000, LR: 0.000050]\n",
      "Runtime --> total: 146.12sec (2.92ms/iter.)\n",
      "Configuration:\n",
      "dim: 256, w_div: 1.000000, w_ff: 1.000000, decay_iterations: None, potential: True, vector_potential: False, \n",
      "Using device: cuda (gpus 1) ['NVIDIA RTX A6000']\n",
      "Potential Boundary: 100%|██████████| 1/1 [00:01<00:00,  1.02s/it]\n",
      "Loaded meta state: /userhome/jeon_mg/workspace/_data/NOAA12673/PINN/20170904_040000/model_final.pt\n",
      "Training:   0%|          | 0/2000 [00:00<?, ?it/s][Iteration 000000/002000] [loss: 0.00287955] [loss_bc: 0.00259592; loss_div: 0.00020562; loss_ff: 0.00007802] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:   5%|▍         | 98/2000 [00:07<02:16, 13.90it/s][Iteration 000100/002000] [loss: 0.00286931] [loss_bc: 0.00263619; loss_div: 0.00015969; loss_ff: 0.00007343] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  10%|▉         | 198/2000 [00:14<02:10, 13.83it/s][Iteration 000200/002000] [loss: 0.00301799] [loss_bc: 0.00274386; loss_div: 0.00020781; loss_ff: 0.00006632] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  15%|█▍        | 298/2000 [00:21<02:03, 13.78it/s][Iteration 000300/002000] [loss: 0.00317157] [loss_bc: 0.00288203; loss_div: 0.00018373; loss_ff: 0.00010582] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  20%|█▉        | 398/2000 [00:28<01:56, 13.70it/s][Iteration 000400/002000] [loss: 0.00304610] [loss_bc: 0.00279843; loss_div: 0.00015582; loss_ff: 0.00009186] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  25%|██▍       | 498/2000 [00:36<01:47, 14.00it/s][Iteration 000500/002000] [loss: 0.00282423] [loss_bc: 0.00258102; loss_div: 0.00017191; loss_ff: 0.00007131] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  30%|██▉       | 598/2000 [00:43<01:42, 13.67it/s][Iteration 000600/002000] [loss: 0.00284225] [loss_bc: 0.00259738; loss_div: 0.00017705; loss_ff: 0.00006782] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  35%|███▍      | 698/2000 [00:50<01:33, 13.89it/s][Iteration 000700/002000] [loss: 0.00308057] [loss_bc: 0.00278903; loss_div: 0.00020462; loss_ff: 0.00008693] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  40%|███▉      | 798/2000 [00:58<01:26, 13.85it/s][Iteration 000800/002000] [loss: 0.00302999] [loss_bc: 0.00273469; loss_div: 0.00019512; loss_ff: 0.00010018] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  45%|████▍     | 898/2000 [01:05<01:19, 13.87it/s][Iteration 000900/002000] [loss: 0.00286681] [loss_bc: 0.00262462; loss_div: 0.00017686; loss_ff: 0.00006533] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  50%|████▉     | 998/2000 [01:12<01:11, 13.95it/s][Iteration 001000/002000] [loss: 0.00289348] [loss_bc: 0.00262163; loss_div: 0.00019131; loss_ff: 0.00008054] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  55%|█████▍    | 1098/2000 [01:19<01:05, 13.83it/s][Iteration 001100/002000] [loss: 0.00288971] [loss_bc: 0.00264627; loss_div: 0.00017990; loss_ff: 0.00006354] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  60%|█████▉    | 1198/2000 [01:27<00:57, 13.95it/s][Iteration 001200/002000] [loss: 0.00285887] [loss_bc: 0.00261909; loss_div: 0.00016757; loss_ff: 0.00007220] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  65%|██████▍   | 1298/2000 [01:34<00:50, 13.88it/s][Iteration 001300/002000] [loss: 0.00312229] [loss_bc: 0.00286019; loss_div: 0.00018603; loss_ff: 0.00007607] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  70%|██████▉   | 1398/2000 [01:41<00:43, 13.74it/s][Iteration 001400/002000] [loss: 0.00283432] [loss_bc: 0.00258962; loss_div: 0.00017158; loss_ff: 0.00007312] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  75%|███████▍  | 1498/2000 [01:48<00:36, 13.79it/s][Iteration 001500/002000] [loss: 0.00311315] [loss_bc: 0.00286064; loss_div: 0.00016516; loss_ff: 0.00008735] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  80%|███████▉  | 1598/2000 [01:56<00:29, 13.64it/s][Iteration 001600/002000] [loss: 0.00284446] [loss_bc: 0.00261480; loss_div: 0.00016100; loss_ff: 0.00006866] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  85%|████████▍ | 1698/2000 [02:03<00:21, 13.84it/s][Iteration 001700/002000] [loss: 0.00280177] [loss_bc: 0.00253008; loss_div: 0.00018384; loss_ff: 0.00008785] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  90%|████████▉ | 1798/2000 [02:10<00:14, 13.86it/s][Iteration 001800/002000] [loss: 0.00313890] [loss_bc: 0.00285776; loss_div: 0.00018405; loss_ff: 0.00009709] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  95%|█████████▍| 1898/2000 [02:17<00:07, 13.78it/s][Iteration 001900/002000] [loss: 0.00282560] [loss_bc: 0.00256819; loss_div: 0.00019913; loss_ff: 0.00005828] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training: 100%|█████████▉| 1998/2000 [02:25<00:00, 13.87it/s][Iteration 002000/002000] [loss: 0.00287074] [loss_bc: 0.00263139; loss_div: 0.00016432; loss_ff: 0.00007503] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training: 100%|██████████| 2000/2000 [02:25<00:00, 13.74it/s]\n",
      "[Iteration 002000/002000] [loss: 0.00287074] [loss_bc: 0.00263139; loss_div: 0.00016432; loss_ff: 0.00007503] [w_bc: 1.000000, LR: 0.000050]\n",
      "Runtime --> total: 145.74sec (2.91ms/iter.)\n",
      "Configuration:\n",
      "dim: 256, w_div: 1.000000, w_ff: 1.000000, decay_iterations: None, potential: True, vector_potential: False, \n",
      "Using device: cuda (gpus 1) ['NVIDIA RTX A6000']\n",
      "Potential Boundary: 100%|██████████| 1/1 [00:01<00:00,  1.00s/it]\n",
      "Loaded meta state: /userhome/jeon_mg/workspace/_data/NOAA12673/PINN/20170904_041200/model_final.pt\n",
      "Training:   0%|          | 0/2000 [00:00<?, ?it/s][Iteration 000000/002000] [loss: 0.00287636] [loss_bc: 0.00261233; loss_div: 0.00019353; loss_ff: 0.00007051] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:   5%|▍         | 98/2000 [00:07<02:18, 13.69it/s][Iteration 000100/002000] [loss: 0.00325317] [loss_bc: 0.00295712; loss_div: 0.00019256; loss_ff: 0.00010349] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  10%|▉         | 198/2000 [00:14<02:11, 13.71it/s][Iteration 000200/002000] [loss: 0.00275917] [loss_bc: 0.00251418; loss_div: 0.00017764; loss_ff: 0.00006735] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  15%|█▍        | 298/2000 [00:21<02:03, 13.77it/s][Iteration 000300/002000] [loss: 0.00319568] [loss_bc: 0.00294885; loss_div: 0.00017375; loss_ff: 0.00007308] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  20%|█▉        | 398/2000 [00:29<01:55, 13.88it/s][Iteration 000400/002000] [loss: 0.00295115] [loss_bc: 0.00272439; loss_div: 0.00014458; loss_ff: 0.00008218] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  25%|██▍       | 498/2000 [00:36<01:49, 13.78it/s][Iteration 000500/002000] [loss: 0.00324082] [loss_bc: 0.00294456; loss_div: 0.00021986; loss_ff: 0.00007640] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  30%|██▉       | 598/2000 [00:43<01:42, 13.69it/s][Iteration 000600/002000] [loss: 0.00317336] [loss_bc: 0.00288050; loss_div: 0.00020281; loss_ff: 0.00009006] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  35%|███▍      | 698/2000 [00:50<01:35, 13.61it/s][Iteration 000700/002000] [loss: 0.00276347] [loss_bc: 0.00250107; loss_div: 0.00017848; loss_ff: 0.00008391] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  40%|███▉      | 798/2000 [00:58<01:27, 13.77it/s][Iteration 000800/002000] [loss: 0.00294902] [loss_bc: 0.00267518; loss_div: 0.00016434; loss_ff: 0.00010951] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  45%|████▍     | 898/2000 [01:05<01:19, 13.82it/s][Iteration 000900/002000] [loss: 0.00282512] [loss_bc: 0.00252657; loss_div: 0.00018746; loss_ff: 0.00011109] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  50%|████▉     | 998/2000 [01:12<01:11, 13.96it/s][Iteration 001000/002000] [loss: 0.00284872] [loss_bc: 0.00257984; loss_div: 0.00018385; loss_ff: 0.00008503] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  55%|█████▍    | 1098/2000 [01:19<01:06, 13.58it/s][Iteration 001100/002000] [loss: 0.00323667] [loss_bc: 0.00293629; loss_div: 0.00019597; loss_ff: 0.00010441] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  60%|█████▉    | 1198/2000 [01:27<00:57, 13.85it/s][Iteration 001200/002000] [loss: 0.00284104] [loss_bc: 0.00252467; loss_div: 0.00019009; loss_ff: 0.00012627] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  65%|██████▍   | 1298/2000 [01:34<00:51, 13.63it/s][Iteration 001300/002000] [loss: 0.00283193] [loss_bc: 0.00260279; loss_div: 0.00016041; loss_ff: 0.00006873] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  70%|██████▉   | 1398/2000 [01:41<00:43, 13.78it/s][Iteration 001400/002000] [loss: 0.00287138] [loss_bc: 0.00260213; loss_div: 0.00017899; loss_ff: 0.00009026] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  75%|███████▍  | 1498/2000 [01:49<00:36, 13.85it/s][Iteration 001500/002000] [loss: 0.00320328] [loss_bc: 0.00292709; loss_div: 0.00019365; loss_ff: 0.00008254] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  80%|███████▉  | 1598/2000 [01:56<00:29, 13.78it/s][Iteration 001600/002000] [loss: 0.00286264] [loss_bc: 0.00258280; loss_div: 0.00018934; loss_ff: 0.00009050] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  85%|████████▍ | 1698/2000 [02:03<00:21, 13.78it/s][Iteration 001700/002000] [loss: 0.00295221] [loss_bc: 0.00266920; loss_div: 0.00017892; loss_ff: 0.00010408] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  90%|████████▉ | 1798/2000 [02:10<00:14, 13.87it/s][Iteration 001800/002000] [loss: 0.00286824] [loss_bc: 0.00257211; loss_div: 0.00019169; loss_ff: 0.00010445] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  95%|█████████▍| 1898/2000 [02:18<00:07, 13.86it/s][Iteration 001900/002000] [loss: 0.00318118] [loss_bc: 0.00292658; loss_div: 0.00017737; loss_ff: 0.00007722] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training: 100%|█████████▉| 1998/2000 [02:25<00:00, 13.82it/s][Iteration 002000/002000] [loss: 0.00286891] [loss_bc: 0.00260091; loss_div: 0.00016920; loss_ff: 0.00009880] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training: 100%|██████████| 2000/2000 [02:25<00:00, 13.71it/s]\n",
      "[Iteration 002000/002000] [loss: 0.00286891] [loss_bc: 0.00260091; loss_div: 0.00016920; loss_ff: 0.00009880] [w_bc: 1.000000, LR: 0.000050]\n",
      "Runtime --> total: 146.03sec (2.92ms/iter.)\n",
      "Configuration:\n",
      "dim: 256, w_div: 1.000000, w_ff: 1.000000, decay_iterations: None, potential: True, vector_potential: False, \n",
      "Using device: cuda (gpus 1) ['NVIDIA RTX A6000']\n",
      "Potential Boundary: 100%|██████████| 1/1 [00:01<00:00,  1.04s/it]\n",
      "Loaded meta state: /userhome/jeon_mg/workspace/_data/NOAA12673/PINN/20170904_042400/model_final.pt\n",
      "Training:   0%|          | 0/2000 [00:00<?, ?it/s][Iteration 000000/002000] [loss: 0.00303550] [loss_bc: 0.00274391; loss_div: 0.00019365; loss_ff: 0.00009794] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:   5%|▍         | 98/2000 [00:07<02:18, 13.72it/s][Iteration 000100/002000] [loss: 0.00296620] [loss_bc: 0.00270722; loss_div: 0.00017852; loss_ff: 0.00008047] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  10%|▉         | 198/2000 [00:14<02:10, 13.85it/s][Iteration 000200/002000] [loss: 0.00300287] [loss_bc: 0.00275525; loss_div: 0.00017613; loss_ff: 0.00007148] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  15%|█▍        | 298/2000 [00:21<02:02, 13.94it/s][Iteration 000300/002000] [loss: 0.00284817] [loss_bc: 0.00260686; loss_div: 0.00016260; loss_ff: 0.00007871] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  20%|█▉        | 398/2000 [00:28<01:55, 13.89it/s][Iteration 000400/002000] [loss: 0.00294144] [loss_bc: 0.00269821; loss_div: 0.00017145; loss_ff: 0.00007178] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  25%|██▍       | 498/2000 [00:36<01:48, 13.85it/s][Iteration 000500/002000] [loss: 0.00291813] [loss_bc: 0.00268050; loss_div: 0.00017716; loss_ff: 0.00006047] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  30%|██▉       | 598/2000 [00:43<01:41, 13.82it/s][Iteration 000600/002000] [loss: 0.00303541] [loss_bc: 0.00280211; loss_div: 0.00014773; loss_ff: 0.00008557] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  35%|███▍      | 698/2000 [00:50<01:37, 13.41it/s][Iteration 000700/002000] [loss: 0.00295300] [loss_bc: 0.00269358; loss_div: 0.00019272; loss_ff: 0.00006671] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  40%|███▉      | 798/2000 [00:58<01:26, 13.86it/s][Iteration 000800/002000] [loss: 0.00300183] [loss_bc: 0.00274400; loss_div: 0.00018742; loss_ff: 0.00007041] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  45%|████▍     | 898/2000 [01:05<01:20, 13.69it/s][Iteration 000900/002000] [loss: 0.00296827] [loss_bc: 0.00274264; loss_div: 0.00016890; loss_ff: 0.00005673] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  50%|████▉     | 998/2000 [01:12<01:12, 13.90it/s][Iteration 001000/002000] [loss: 0.00290130] [loss_bc: 0.00267224; loss_div: 0.00015930; loss_ff: 0.00006976] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  55%|█████▍    | 1098/2000 [01:20<01:06, 13.59it/s][Iteration 001100/002000] [loss: 0.00299999] [loss_bc: 0.00267276; loss_div: 0.00020312; loss_ff: 0.00012410] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  60%|█████▉    | 1198/2000 [01:27<00:58, 13.82it/s][Iteration 001200/002000] [loss: 0.00305290] [loss_bc: 0.00276012; loss_div: 0.00019422; loss_ff: 0.00009856] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  65%|██████▍   | 1298/2000 [01:34<00:52, 13.42it/s][Iteration 001300/002000] [loss: 0.00294928] [loss_bc: 0.00263209; loss_div: 0.00019469; loss_ff: 0.00012250] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  70%|██████▉   | 1398/2000 [01:41<00:43, 13.69it/s][Iteration 001400/002000] [loss: 0.00293499] [loss_bc: 0.00268557; loss_div: 0.00017986; loss_ff: 0.00006957] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  75%|███████▍  | 1498/2000 [01:49<00:36, 13.69it/s][Iteration 001500/002000] [loss: 0.00289654] [loss_bc: 0.00259749; loss_div: 0.00019466; loss_ff: 0.00010440] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  80%|███████▉  | 1598/2000 [01:56<00:29, 13.69it/s][Iteration 001600/002000] [loss: 0.00296837] [loss_bc: 0.00265815; loss_div: 0.00022765; loss_ff: 0.00008256] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  85%|████████▍ | 1698/2000 [02:03<00:21, 13.80it/s][Iteration 001700/002000] [loss: 0.00297169] [loss_bc: 0.00270202; loss_div: 0.00019187; loss_ff: 0.00007779] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  90%|████████▉ | 1798/2000 [02:11<00:14, 13.96it/s][Iteration 001800/002000] [loss: 0.00292119] [loss_bc: 0.00266016; loss_div: 0.00018639; loss_ff: 0.00007464] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  95%|█████████▍| 1898/2000 [02:18<00:07, 13.76it/s][Iteration 001900/002000] [loss: 0.00304170] [loss_bc: 0.00277930; loss_div: 0.00018837; loss_ff: 0.00007404] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training: 100%|█████████▉| 1998/2000 [02:25<00:00, 13.84it/s][Iteration 002000/002000] [loss: 0.00287832] [loss_bc: 0.00262283; loss_div: 0.00017976; loss_ff: 0.00007573] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training: 100%|██████████| 2000/2000 [02:26<00:00, 13.69it/s]\n",
      "[Iteration 002000/002000] [loss: 0.00287832] [loss_bc: 0.00262283; loss_div: 0.00017976; loss_ff: 0.00007573] [w_bc: 1.000000, LR: 0.000050]\n",
      "Runtime --> total: 146.24sec (2.92ms/iter.)\n",
      "Configuration:\n",
      "dim: 256, w_div: 1.000000, w_ff: 1.000000, decay_iterations: None, potential: True, vector_potential: False, \n",
      "Using device: cuda (gpus 1) ['NVIDIA RTX A6000']\n",
      "Potential Boundary: 100%|██████████| 1/1 [00:01<00:00,  1.10s/it]\n",
      "Loaded meta state: /userhome/jeon_mg/workspace/_data/NOAA12673/PINN/20170904_043600/model_final.pt\n",
      "Training:   0%|          | 0/2000 [00:00<?, ?it/s][Iteration 000000/002000] [loss: 0.00313619] [loss_bc: 0.00287753; loss_div: 0.00018847; loss_ff: 0.00007019] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:   5%|▍         | 98/2000 [00:07<02:17, 13.82it/s][Iteration 000100/002000] [loss: 0.00312105] [loss_bc: 0.00286836; loss_div: 0.00018171; loss_ff: 0.00007097] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  10%|▉         | 198/2000 [00:14<02:09, 13.92it/s][Iteration 000200/002000] [loss: 0.00316838] [loss_bc: 0.00290124; loss_div: 0.00017914; loss_ff: 0.00008799] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  15%|█▍        | 298/2000 [00:21<02:02, 13.86it/s][Iteration 000300/002000] [loss: 0.00281847] [loss_bc: 0.00255787; loss_div: 0.00018808; loss_ff: 0.00007251] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  20%|█▉        | 398/2000 [00:28<01:55, 13.88it/s][Iteration 000400/002000] [loss: 0.00313143] [loss_bc: 0.00283669; loss_div: 0.00021441; loss_ff: 0.00008032] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  25%|██▍       | 498/2000 [00:36<01:49, 13.66it/s][Iteration 000500/002000] [loss: 0.00281059] [loss_bc: 0.00255512; loss_div: 0.00016890; loss_ff: 0.00008658] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  30%|██▉       | 598/2000 [00:43<01:40, 13.90it/s][Iteration 000600/002000] [loss: 0.00297672] [loss_bc: 0.00273923; loss_div: 0.00016467; loss_ff: 0.00007282] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  35%|███▍      | 698/2000 [00:50<01:34, 13.82it/s][Iteration 000700/002000] [loss: 0.00313201] [loss_bc: 0.00289316; loss_div: 0.00017048; loss_ff: 0.00006837] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  40%|███▉      | 798/2000 [00:58<01:27, 13.73it/s][Iteration 000800/002000] [loss: 0.00310275] [loss_bc: 0.00285179; loss_div: 0.00016120; loss_ff: 0.00008977] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  45%|████▍     | 898/2000 [01:05<01:19, 13.80it/s][Iteration 000900/002000] [loss: 0.00288303] [loss_bc: 0.00261922; loss_div: 0.00020033; loss_ff: 0.00006348] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  50%|████▉     | 998/2000 [01:12<01:12, 13.90it/s][Iteration 001000/002000] [loss: 0.00314596] [loss_bc: 0.00284255; loss_div: 0.00022381; loss_ff: 0.00007960] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  55%|█████▍    | 1098/2000 [01:19<01:04, 13.92it/s][Iteration 001100/002000] [loss: 0.00301442] [loss_bc: 0.00273379; loss_div: 0.00020085; loss_ff: 0.00007978] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  60%|█████▉    | 1198/2000 [01:27<00:59, 13.45it/s][Iteration 001200/002000] [loss: 0.00301088] [loss_bc: 0.00273452; loss_div: 0.00019893; loss_ff: 0.00007743] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  65%|██████▍   | 1298/2000 [01:34<00:51, 13.75it/s][Iteration 001300/002000] [loss: 0.00278675] [loss_bc: 0.00253945; loss_div: 0.00017703; loss_ff: 0.00007026] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  70%|██████▉   | 1398/2000 [01:41<00:44, 13.49it/s][Iteration 001400/002000] [loss: 0.00312067] [loss_bc: 0.00288550; loss_div: 0.00016721; loss_ff: 0.00006797] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  75%|███████▍  | 1498/2000 [01:49<00:36, 13.89it/s][Iteration 001500/002000] [loss: 0.00286030] [loss_bc: 0.00260800; loss_div: 0.00018211; loss_ff: 0.00007019] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  80%|███████▉  | 1598/2000 [01:56<00:29, 13.81it/s][Iteration 001600/002000] [loss: 0.00309416] [loss_bc: 0.00281781; loss_div: 0.00019202; loss_ff: 0.00008433] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  85%|████████▍ | 1698/2000 [02:03<00:22, 13.66it/s][Iteration 001700/002000] [loss: 0.00311230] [loss_bc: 0.00284050; loss_div: 0.00018173; loss_ff: 0.00009007] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  90%|████████▉ | 1798/2000 [02:11<00:14, 13.70it/s][Iteration 001800/002000] [loss: 0.00289548] [loss_bc: 0.00260423; loss_div: 0.00020842; loss_ff: 0.00008283] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  95%|█████████▍| 1898/2000 [02:18<00:07, 13.74it/s][Iteration 001900/002000] [loss: 0.00306927] [loss_bc: 0.00272032; loss_div: 0.00019954; loss_ff: 0.00014941] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training: 100%|█████████▉| 1998/2000 [02:25<00:00, 13.81it/s][Iteration 002000/002000] [loss: 0.00297010] [loss_bc: 0.00267144; loss_div: 0.00019623; loss_ff: 0.00010243] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training: 100%|██████████| 2000/2000 [02:25<00:00, 13.70it/s]\n",
      "[Iteration 002000/002000] [loss: 0.00297010] [loss_bc: 0.00267144; loss_div: 0.00019623; loss_ff: 0.00010243] [w_bc: 1.000000, LR: 0.000050]\n",
      "Runtime --> total: 146.20sec (2.92ms/iter.)\n",
      "Configuration:\n",
      "dim: 256, w_div: 1.000000, w_ff: 1.000000, decay_iterations: None, potential: True, vector_potential: False, \n",
      "Using device: cuda (gpus 1) ['NVIDIA RTX A6000']\n",
      "Potential Boundary: 100%|██████████| 1/1 [00:01<00:00,  1.01s/it]\n",
      "Loaded meta state: /userhome/jeon_mg/workspace/_data/NOAA12673/PINN/20170904_044800/model_final.pt\n",
      "Training:   0%|          | 0/2000 [00:00<?, ?it/s][Iteration 000000/002000] [loss: 0.00319663] [loss_bc: 0.00289872; loss_div: 0.00022294; loss_ff: 0.00007497] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:   5%|▍         | 98/2000 [00:07<02:17, 13.82it/s][Iteration 000100/002000] [loss: 0.00288498] [loss_bc: 0.00264921; loss_div: 0.00015615; loss_ff: 0.00007963] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  10%|▉         | 198/2000 [00:14<02:10, 13.84it/s][Iteration 000200/002000] [loss: 0.00319547] [loss_bc: 0.00290696; loss_div: 0.00019814; loss_ff: 0.00009037] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  15%|█▍        | 298/2000 [00:21<02:02, 13.93it/s][Iteration 000300/002000] [loss: 0.00319649] [loss_bc: 0.00290636; loss_div: 0.00020611; loss_ff: 0.00008402] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  20%|█▉        | 398/2000 [00:28<01:57, 13.68it/s][Iteration 000400/002000] [loss: 0.00300812] [loss_bc: 0.00270530; loss_div: 0.00018846; loss_ff: 0.00011437] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  25%|██▍       | 498/2000 [00:36<01:48, 13.83it/s][Iteration 000500/002000] [loss: 0.00290185] [loss_bc: 0.00264044; loss_div: 0.00018698; loss_ff: 0.00007442] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  30%|██▉       | 598/2000 [00:43<01:41, 13.79it/s][Iteration 000600/002000] [loss: 0.00304639] [loss_bc: 0.00280392; loss_div: 0.00016414; loss_ff: 0.00007834] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  35%|███▍      | 698/2000 [00:50<01:34, 13.77it/s][Iteration 000700/002000] [loss: 0.00307441] [loss_bc: 0.00280413; loss_div: 0.00019205; loss_ff: 0.00007824] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  40%|███▉      | 798/2000 [00:58<01:27, 13.75it/s][Iteration 000800/002000] [loss: 0.00293182] [loss_bc: 0.00264181; loss_div: 0.00020850; loss_ff: 0.00008152] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  45%|████▍     | 898/2000 [01:05<01:19, 13.83it/s][Iteration 000900/002000] [loss: 0.00307131] [loss_bc: 0.00281418; loss_div: 0.00017697; loss_ff: 0.00008016] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  50%|████▉     | 998/2000 [01:12<01:12, 13.74it/s][Iteration 001000/002000] [loss: 0.00300285] [loss_bc: 0.00276729; loss_div: 0.00016891; loss_ff: 0.00006666] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  55%|█████▍    | 1098/2000 [01:19<01:05, 13.82it/s][Iteration 001100/002000] [loss: 0.00313847] [loss_bc: 0.00287372; loss_div: 0.00018150; loss_ff: 0.00008325] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  60%|█████▉    | 1198/2000 [01:27<00:58, 13.81it/s][Iteration 001200/002000] [loss: 0.00311552] [loss_bc: 0.00281395; loss_div: 0.00020209; loss_ff: 0.00009948] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  65%|██████▍   | 1298/2000 [01:34<00:50, 13.80it/s][Iteration 001300/002000] [loss: 0.00312794] [loss_bc: 0.00285561; loss_div: 0.00018829; loss_ff: 0.00008404] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  70%|██████▉   | 1398/2000 [01:41<00:43, 13.72it/s][Iteration 001400/002000] [loss: 0.00315857] [loss_bc: 0.00288363; loss_div: 0.00019295; loss_ff: 0.00008199] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  75%|███████▍  | 1498/2000 [01:49<00:36, 13.89it/s][Iteration 001500/002000] [loss: 0.00313058] [loss_bc: 0.00286404; loss_div: 0.00018430; loss_ff: 0.00008225] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  80%|███████▉  | 1598/2000 [01:56<00:29, 13.61it/s][Iteration 001600/002000] [loss: 0.00311976] [loss_bc: 0.00279324; loss_div: 0.00021730; loss_ff: 0.00010922] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  85%|████████▍ | 1698/2000 [02:03<00:21, 13.79it/s][Iteration 001700/002000] [loss: 0.00312075] [loss_bc: 0.00285099; loss_div: 0.00019260; loss_ff: 0.00007716] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  90%|████████▉ | 1798/2000 [02:10<00:14, 13.98it/s][Iteration 001800/002000] [loss: 0.00289272] [loss_bc: 0.00262850; loss_div: 0.00018603; loss_ff: 0.00007819] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  95%|█████████▍| 1898/2000 [02:18<00:07, 13.86it/s][Iteration 001900/002000] [loss: 0.00306675] [loss_bc: 0.00278753; loss_div: 0.00018558; loss_ff: 0.00009364] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training: 100%|█████████▉| 1998/2000 [02:25<00:00, 13.78it/s][Iteration 002000/002000] [loss: 0.00291342] [loss_bc: 0.00262705; loss_div: 0.00019607; loss_ff: 0.00009030] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training: 100%|██████████| 2000/2000 [02:25<00:00, 13.71it/s]\n",
      "[Iteration 002000/002000] [loss: 0.00291342] [loss_bc: 0.00262705; loss_div: 0.00019607; loss_ff: 0.00009030] [w_bc: 1.000000, LR: 0.000050]\n",
      "Runtime --> total: 146.01sec (2.92ms/iter.)\n",
      "Configuration:\n",
      "dim: 256, w_div: 1.000000, w_ff: 1.000000, decay_iterations: None, potential: True, vector_potential: False, \n",
      "Using device: cuda (gpus 1) ['NVIDIA RTX A6000']\n",
      "Potential Boundary: 100%|██████████| 1/1 [00:00<00:00,  1.13it/s]\n",
      "Loaded meta state: /userhome/jeon_mg/workspace/_data/NOAA12673/PINN/20170904_050000/model_final.pt\n",
      "Training:   0%|          | 0/2000 [00:00<?, ?it/s][Iteration 000000/002000] [loss: 0.00300872] [loss_bc: 0.00276711; loss_div: 0.00015392; loss_ff: 0.00008770] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:   5%|▍         | 98/2000 [00:07<02:20, 13.55it/s][Iteration 000100/002000] [loss: 0.00314902] [loss_bc: 0.00284293; loss_div: 0.00020616; loss_ff: 0.00009992] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  10%|▉         | 198/2000 [00:14<02:09, 13.94it/s][Iteration 000200/002000] [loss: 0.00309654] [loss_bc: 0.00281551; loss_div: 0.00020186; loss_ff: 0.00007918] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  15%|█▍        | 298/2000 [00:21<02:03, 13.78it/s][Iteration 000300/002000] [loss: 0.00340643] [loss_bc: 0.00309577; loss_div: 0.00021094; loss_ff: 0.00009973] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  20%|█▉        | 398/2000 [00:29<01:56, 13.75it/s][Iteration 000400/002000] [loss: 0.00292206] [loss_bc: 0.00267830; loss_div: 0.00016935; loss_ff: 0.00007442] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  25%|██▍       | 498/2000 [00:36<01:49, 13.68it/s][Iteration 000500/002000] [loss: 0.00311665] [loss_bc: 0.00283518; loss_div: 0.00018461; loss_ff: 0.00009686] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  30%|██▉       | 598/2000 [00:43<01:41, 13.84it/s][Iteration 000600/002000] [loss: 0.00338935] [loss_bc: 0.00309415; loss_div: 0.00020888; loss_ff: 0.00008633] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  35%|███▍      | 698/2000 [00:50<01:36, 13.47it/s][Iteration 000700/002000] [loss: 0.00345659] [loss_bc: 0.00311732; loss_div: 0.00023258; loss_ff: 0.00010669] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  40%|███▉      | 798/2000 [00:58<01:26, 13.85it/s][Iteration 000800/002000] [loss: 0.00296855] [loss_bc: 0.00273807; loss_div: 0.00016599; loss_ff: 0.00006449] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  45%|████▍     | 898/2000 [01:05<01:19, 13.91it/s][Iteration 000900/002000] [loss: 0.00312519] [loss_bc: 0.00282818; loss_div: 0.00020534; loss_ff: 0.00009167] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  50%|████▉     | 998/2000 [01:12<01:12, 13.77it/s][Iteration 001000/002000] [loss: 0.00316393] [loss_bc: 0.00283089; loss_div: 0.00022038; loss_ff: 0.00011266] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  55%|█████▍    | 1098/2000 [01:20<01:06, 13.58it/s][Iteration 001100/002000] [loss: 0.00297471] [loss_bc: 0.00273056; loss_div: 0.00017865; loss_ff: 0.00006550] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  60%|█████▉    | 1198/2000 [01:27<00:57, 13.84it/s][Iteration 001200/002000] [loss: 0.00337648] [loss_bc: 0.00309818; loss_div: 0.00019983; loss_ff: 0.00007848] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  65%|██████▍   | 1298/2000 [01:34<00:51, 13.58it/s][Iteration 001300/002000] [loss: 0.00295803] [loss_bc: 0.00266166; loss_div: 0.00020737; loss_ff: 0.00008901] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  70%|██████▉   | 1398/2000 [01:42<00:44, 13.68it/s][Iteration 001400/002000] [loss: 0.00335672] [loss_bc: 0.00307583; loss_div: 0.00019403; loss_ff: 0.00008685] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  75%|███████▍  | 1498/2000 [01:49<00:36, 13.85it/s][Iteration 001500/002000] [loss: 0.00346361] [loss_bc: 0.00310219; loss_div: 0.00025640; loss_ff: 0.00010501] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  80%|███████▉  | 1598/2000 [01:56<00:28, 13.86it/s][Iteration 001600/002000] [loss: 0.00311063] [loss_bc: 0.00282647; loss_div: 0.00019337; loss_ff: 0.00009078] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  85%|████████▍ | 1698/2000 [02:03<00:22, 13.52it/s][Iteration 001700/002000] [loss: 0.00315808] [loss_bc: 0.00281560; loss_div: 0.00023398; loss_ff: 0.00010850] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  90%|████████▉ | 1798/2000 [02:11<00:14, 13.92it/s][Iteration 001800/002000] [loss: 0.00339453] [loss_bc: 0.00309660; loss_div: 0.00019594; loss_ff: 0.00010199] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  95%|█████████▍| 1898/2000 [02:18<00:07, 13.89it/s][Iteration 001900/002000] [loss: 0.00311929] [loss_bc: 0.00281325; loss_div: 0.00022470; loss_ff: 0.00008134] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training: 100%|█████████▉| 1998/2000 [02:25<00:00, 13.72it/s][Iteration 002000/002000] [loss: 0.00307413] [loss_bc: 0.00278063; loss_div: 0.00020973; loss_ff: 0.00008377] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training: 100%|██████████| 2000/2000 [02:26<00:00, 13.68it/s]\n",
      "[Iteration 002000/002000] [loss: 0.00307413] [loss_bc: 0.00278063; loss_div: 0.00020973; loss_ff: 0.00008377] [w_bc: 1.000000, LR: 0.000050]\n",
      "Runtime --> total: 146.37sec (2.93ms/iter.)\n",
      "Configuration:\n",
      "dim: 256, w_div: 1.000000, w_ff: 1.000000, decay_iterations: None, potential: True, vector_potential: False, \n",
      "Using device: cuda (gpus 1) ['NVIDIA RTX A6000']\n",
      "Potential Boundary: 100%|██████████| 1/1 [00:00<00:00,  1.12it/s]\n",
      "Loaded meta state: /userhome/jeon_mg/workspace/_data/NOAA12673/PINN/20170904_051200/model_final.pt\n",
      "Training:   0%|          | 0/2000 [00:00<?, ?it/s][Iteration 000000/002000] [loss: 0.00347163] [loss_bc: 0.00314046; loss_div: 0.00020317; loss_ff: 0.00012799] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:   5%|▍         | 98/2000 [00:07<02:16, 13.90it/s][Iteration 000100/002000] [loss: 0.00315826] [loss_bc: 0.00287978; loss_div: 0.00019230; loss_ff: 0.00008619] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  10%|▉         | 198/2000 [00:14<02:10, 13.83it/s][Iteration 000200/002000] [loss: 0.00301756] [loss_bc: 0.00277376; loss_div: 0.00017693; loss_ff: 0.00006687] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  15%|█▍        | 298/2000 [00:21<02:05, 13.60it/s][Iteration 000300/002000] [loss: 0.00308914] [loss_bc: 0.00277951; loss_div: 0.00022187; loss_ff: 0.00008775] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  20%|█▉        | 398/2000 [00:28<01:56, 13.80it/s][Iteration 000400/002000] [loss: 0.00340722] [loss_bc: 0.00311197; loss_div: 0.00021222; loss_ff: 0.00008304] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  25%|██▍       | 498/2000 [00:36<01:48, 13.86it/s][Iteration 000500/002000] [loss: 0.00315882] [loss_bc: 0.00289554; loss_div: 0.00017731; loss_ff: 0.00008596] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  30%|██▉       | 598/2000 [00:43<01:42, 13.69it/s][Iteration 000600/002000] [loss: 0.00318432] [loss_bc: 0.00286049; loss_div: 0.00021509; loss_ff: 0.00010875] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  35%|███▍      | 698/2000 [00:50<01:34, 13.74it/s][Iteration 000700/002000] [loss: 0.00313968] [loss_bc: 0.00288616; loss_div: 0.00018697; loss_ff: 0.00006655] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  40%|███▉      | 798/2000 [00:58<01:27, 13.81it/s][Iteration 000800/002000] [loss: 0.00306153] [loss_bc: 0.00277434; loss_div: 0.00020280; loss_ff: 0.00008440] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  45%|████▍     | 898/2000 [01:05<01:20, 13.76it/s][Iteration 000900/002000] [loss: 0.00318448] [loss_bc: 0.00288490; loss_div: 0.00020129; loss_ff: 0.00009829] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  50%|████▉     | 998/2000 [01:12<01:12, 13.80it/s][Iteration 001000/002000] [loss: 0.00313198] [loss_bc: 0.00284480; loss_div: 0.00020583; loss_ff: 0.00008134] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  55%|█████▍    | 1098/2000 [01:19<01:05, 13.71it/s][Iteration 001100/002000] [loss: 0.00321102] [loss_bc: 0.00295999; loss_div: 0.00017402; loss_ff: 0.00007701] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  60%|█████▉    | 1198/2000 [01:27<00:58, 13.81it/s][Iteration 001200/002000] [loss: 0.00315177] [loss_bc: 0.00288913; loss_div: 0.00017242; loss_ff: 0.00009022] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  65%|██████▍   | 1298/2000 [01:34<00:50, 13.83it/s][Iteration 001300/002000] [loss: 0.00327822] [loss_bc: 0.00295663; loss_div: 0.00022916; loss_ff: 0.00009244] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  70%|██████▉   | 1398/2000 [01:41<00:43, 13.88it/s][Iteration 001400/002000] [loss: 0.00313574] [loss_bc: 0.00284523; loss_div: 0.00019943; loss_ff: 0.00009108] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  75%|███████▍  | 1498/2000 [01:49<00:36, 13.78it/s][Iteration 001500/002000] [loss: 0.00321322] [loss_bc: 0.00295341; loss_div: 0.00017879; loss_ff: 0.00008102] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  80%|███████▉  | 1598/2000 [01:56<00:29, 13.62it/s][Iteration 001600/002000] [loss: 0.00315374] [loss_bc: 0.00284689; loss_div: 0.00022187; loss_ff: 0.00008498] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  85%|████████▍ | 1698/2000 [02:03<00:22, 13.46it/s][Iteration 001700/002000] [loss: 0.00319592] [loss_bc: 0.00283912; loss_div: 0.00022475; loss_ff: 0.00013205] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  90%|████████▉ | 1798/2000 [02:11<00:14, 13.75it/s][Iteration 001800/002000] [loss: 0.00318356] [loss_bc: 0.00286716; loss_div: 0.00022655; loss_ff: 0.00008985] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  95%|█████████▍| 1898/2000 [02:18<00:07, 13.89it/s][Iteration 001900/002000] [loss: 0.00316009] [loss_bc: 0.00284157; loss_div: 0.00021509; loss_ff: 0.00010342] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training: 100%|█████████▉| 1998/2000 [02:25<00:00, 13.88it/s][Iteration 002000/002000] [loss: 0.00309710] [loss_bc: 0.00283917; loss_div: 0.00019052; loss_ff: 0.00006741] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training: 100%|██████████| 2000/2000 [02:25<00:00, 13.71it/s]\n",
      "[Iteration 002000/002000] [loss: 0.00309710] [loss_bc: 0.00283917; loss_div: 0.00019052; loss_ff: 0.00006741] [w_bc: 1.000000, LR: 0.000050]\n",
      "Runtime --> total: 146.09sec (2.92ms/iter.)\n",
      "Configuration:\n",
      "dim: 256, w_div: 1.000000, w_ff: 1.000000, decay_iterations: None, potential: True, vector_potential: False, \n",
      "Using device: cuda (gpus 1) ['NVIDIA RTX A6000']\n",
      "Potential Boundary: 100%|██████████| 1/1 [00:01<00:00,  1.07s/it]\n",
      "Loaded meta state: /userhome/jeon_mg/workspace/_data/NOAA12673/PINN/20170904_052400/model_final.pt\n",
      "Training:   0%|          | 0/2000 [00:00<?, ?it/s][Iteration 000000/002000] [loss: 0.00330967] [loss_bc: 0.00299386; loss_div: 0.00021517; loss_ff: 0.00010063] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:   5%|▍         | 98/2000 [00:07<02:17, 13.82it/s][Iteration 000100/002000] [loss: 0.00309336] [loss_bc: 0.00283605; loss_div: 0.00018689; loss_ff: 0.00007042] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  10%|▉         | 198/2000 [00:14<02:10, 13.79it/s][Iteration 000200/002000] [loss: 0.00316012] [loss_bc: 0.00287172; loss_div: 0.00020961; loss_ff: 0.00007879] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  15%|█▍        | 298/2000 [00:21<02:03, 13.79it/s][Iteration 000300/002000] [loss: 0.00326766] [loss_bc: 0.00297303; loss_div: 0.00020416; loss_ff: 0.00009046] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  20%|█▉        | 398/2000 [00:29<01:56, 13.71it/s][Iteration 000400/002000] [loss: 0.00309076] [loss_bc: 0.00281922; loss_div: 0.00018122; loss_ff: 0.00009032] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  25%|██▍       | 498/2000 [00:36<01:48, 13.84it/s][Iteration 000500/002000] [loss: 0.00332712] [loss_bc: 0.00303591; loss_div: 0.00021729; loss_ff: 0.00007392] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  30%|██▉       | 598/2000 [00:43<01:40, 13.90it/s][Iteration 000600/002000] [loss: 0.00340544] [loss_bc: 0.00305157; loss_div: 0.00022702; loss_ff: 0.00012685] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  35%|███▍      | 698/2000 [00:50<01:34, 13.83it/s][Iteration 000700/002000] [loss: 0.00313785] [loss_bc: 0.00285149; loss_div: 0.00021984; loss_ff: 0.00006651] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  40%|███▉      | 798/2000 [00:58<01:30, 13.33it/s][Iteration 000800/002000] [loss: 0.00330731] [loss_bc: 0.00296974; loss_div: 0.00022889; loss_ff: 0.00010868] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  45%|████▍     | 898/2000 [01:05<01:20, 13.75it/s][Iteration 000900/002000] [loss: 0.00309067] [loss_bc: 0.00279077; loss_div: 0.00021211; loss_ff: 0.00008779] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  50%|████▉     | 998/2000 [01:12<01:13, 13.65it/s][Iteration 001000/002000] [loss: 0.00309751] [loss_bc: 0.00280878; loss_div: 0.00021407; loss_ff: 0.00007466] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  55%|█████▍    | 1098/2000 [01:20<01:07, 13.42it/s][Iteration 001100/002000] [loss: 0.00316537] [loss_bc: 0.00285562; loss_div: 0.00021378; loss_ff: 0.00009597] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  60%|█████▉    | 1198/2000 [01:27<00:58, 13.74it/s][Iteration 001200/002000] [loss: 0.00324101] [loss_bc: 0.00296106; loss_div: 0.00020310; loss_ff: 0.00007685] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  65%|██████▍   | 1298/2000 [01:34<00:51, 13.67it/s][Iteration 001300/002000] [loss: 0.00335584] [loss_bc: 0.00303717; loss_div: 0.00022860; loss_ff: 0.00009007] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  70%|██████▉   | 1398/2000 [01:41<00:43, 13.87it/s][Iteration 001400/002000] [loss: 0.00326297] [loss_bc: 0.00295640; loss_div: 0.00021438; loss_ff: 0.00009219] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  75%|███████▍  | 1498/2000 [01:49<00:36, 13.67it/s][Iteration 001500/002000] [loss: 0.00323280] [loss_bc: 0.00296018; loss_div: 0.00019758; loss_ff: 0.00007504] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  80%|███████▉  | 1598/2000 [01:56<00:29, 13.85it/s][Iteration 001600/002000] [loss: 0.00336336] [loss_bc: 0.00303788; loss_div: 0.00022908; loss_ff: 0.00009641] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  85%|████████▍ | 1698/2000 [02:03<00:22, 13.67it/s][Iteration 001700/002000] [loss: 0.00332323] [loss_bc: 0.00301082; loss_div: 0.00019420; loss_ff: 0.00011820] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  90%|████████▉ | 1798/2000 [02:10<00:15, 13.38it/s][Iteration 001800/002000] [loss: 0.00333599] [loss_bc: 0.00301055; loss_div: 0.00024252; loss_ff: 0.00008292] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  95%|█████████▍| 1898/2000 [02:18<00:07, 13.68it/s][Iteration 001900/002000] [loss: 0.00334973] [loss_bc: 0.00304122; loss_div: 0.00022035; loss_ff: 0.00008816] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training: 100%|█████████▉| 1998/2000 [02:25<00:00, 13.79it/s][Iteration 002000/002000] [loss: 0.00318079] [loss_bc: 0.00283742; loss_div: 0.00024142; loss_ff: 0.00010195] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training: 100%|██████████| 2000/2000 [02:25<00:00, 13.71it/s]\n",
      "[Iteration 002000/002000] [loss: 0.00318079] [loss_bc: 0.00283742; loss_div: 0.00024142; loss_ff: 0.00010195] [w_bc: 1.000000, LR: 0.000050]\n",
      "Runtime --> total: 146.10sec (2.92ms/iter.)\n",
      "Configuration:\n",
      "dim: 256, w_div: 1.000000, w_ff: 1.000000, decay_iterations: None, potential: True, vector_potential: False, \n",
      "Using device: cuda (gpus 1) ['NVIDIA RTX A6000']\n",
      "Potential Boundary: 100%|██████████| 1/1 [00:00<00:00,  1.03it/s]\n",
      "Loaded meta state: /userhome/jeon_mg/workspace/_data/NOAA12673/PINN/20170904_053600/model_final.pt\n",
      "Training:   0%|          | 0/2000 [00:00<?, ?it/s][Iteration 000000/002000] [loss: 0.00348238] [loss_bc: 0.00312542; loss_div: 0.00025651; loss_ff: 0.00010046] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:   5%|▍         | 98/2000 [00:07<02:18, 13.74it/s][Iteration 000100/002000] [loss: 0.00344921] [loss_bc: 0.00311614; loss_div: 0.00023364; loss_ff: 0.00009944] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  10%|▉         | 198/2000 [00:14<02:11, 13.73it/s][Iteration 000200/002000] [loss: 0.00332530] [loss_bc: 0.00304368; loss_div: 0.00019934; loss_ff: 0.00008228] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  15%|█▍        | 298/2000 [00:21<02:03, 13.80it/s][Iteration 000300/002000] [loss: 0.00322252] [loss_bc: 0.00295829; loss_div: 0.00018652; loss_ff: 0.00007771] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  20%|█▉        | 398/2000 [00:28<01:56, 13.75it/s][Iteration 000400/002000] [loss: 0.00326570] [loss_bc: 0.00295866; loss_div: 0.00021965; loss_ff: 0.00008739] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  25%|██▍       | 498/2000 [00:36<01:48, 13.81it/s][Iteration 000500/002000] [loss: 0.00319366] [loss_bc: 0.00286514; loss_div: 0.00020537; loss_ff: 0.00012315] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  30%|██▉       | 598/2000 [00:43<01:40, 14.01it/s][Iteration 000600/002000] [loss: 0.00325296] [loss_bc: 0.00295639; loss_div: 0.00022096; loss_ff: 0.00007562] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  35%|███▍      | 698/2000 [00:50<01:34, 13.79it/s][Iteration 000700/002000] [loss: 0.00322796] [loss_bc: 0.00295840; loss_div: 0.00018425; loss_ff: 0.00008530] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  40%|███▉      | 798/2000 [00:58<01:26, 13.88it/s][Iteration 000800/002000] [loss: 0.00327394] [loss_bc: 0.00294688; loss_div: 0.00022212; loss_ff: 0.00010494] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  45%|████▍     | 898/2000 [01:05<01:19, 13.83it/s][Iteration 000900/002000] [loss: 0.00323507] [loss_bc: 0.00296848; loss_div: 0.00019802; loss_ff: 0.00006857] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  50%|████▉     | 998/2000 [01:12<01:13, 13.71it/s][Iteration 001000/002000] [loss: 0.00326499] [loss_bc: 0.00294359; loss_div: 0.00021850; loss_ff: 0.00010290] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  55%|█████▍    | 1098/2000 [01:19<01:05, 13.75it/s][Iteration 001100/002000] [loss: 0.00332045] [loss_bc: 0.00294427; loss_div: 0.00024118; loss_ff: 0.00013499] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  60%|█████▉    | 1198/2000 [01:27<00:58, 13.61it/s][Iteration 001200/002000] [loss: 0.00340377] [loss_bc: 0.00310179; loss_div: 0.00020151; loss_ff: 0.00010047] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  65%|██████▍   | 1298/2000 [01:34<00:51, 13.68it/s][Iteration 001300/002000] [loss: 0.00321850] [loss_bc: 0.00295899; loss_div: 0.00018549; loss_ff: 0.00007402] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  70%|██████▉   | 1398/2000 [01:41<00:43, 13.81it/s][Iteration 001400/002000] [loss: 0.00328105] [loss_bc: 0.00295481; loss_div: 0.00024883; loss_ff: 0.00007741] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  75%|███████▍  | 1498/2000 [01:49<00:36, 13.78it/s][Iteration 001500/002000] [loss: 0.00344298] [loss_bc: 0.00308263; loss_div: 0.00023720; loss_ff: 0.00012316] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  80%|███████▉  | 1598/2000 [01:56<00:28, 13.98it/s][Iteration 001600/002000] [loss: 0.00324180] [loss_bc: 0.00294117; loss_div: 0.00020929; loss_ff: 0.00009134] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  85%|████████▍ | 1698/2000 [02:03<00:21, 13.83it/s][Iteration 001700/002000] [loss: 0.00339462] [loss_bc: 0.00307222; loss_div: 0.00021746; loss_ff: 0.00010494] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  90%|████████▉ | 1798/2000 [02:11<00:14, 13.82it/s][Iteration 001800/002000] [loss: 0.00340586] [loss_bc: 0.00309330; loss_div: 0.00019780; loss_ff: 0.00011476] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  95%|█████████▍| 1898/2000 [02:18<00:07, 13.61it/s][Iteration 001900/002000] [loss: 0.00321714] [loss_bc: 0.00293612; loss_div: 0.00021354; loss_ff: 0.00006748] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training: 100%|█████████▉| 1998/2000 [02:25<00:00, 13.54it/s][Iteration 002000/002000] [loss: 0.00339126] [loss_bc: 0.00307226; loss_div: 0.00021351; loss_ff: 0.00010549] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training: 100%|██████████| 2000/2000 [02:25<00:00, 13.70it/s]\n",
      "[Iteration 002000/002000] [loss: 0.00339126] [loss_bc: 0.00307226; loss_div: 0.00021351; loss_ff: 0.00010549] [w_bc: 1.000000, LR: 0.000050]\n",
      "Runtime --> total: 146.20sec (2.92ms/iter.)\n",
      "Configuration:\n",
      "dim: 256, w_div: 1.000000, w_ff: 1.000000, decay_iterations: None, potential: True, vector_potential: False, \n",
      "Using device: cuda (gpus 1) ['NVIDIA RTX A6000']\n",
      "Potential Boundary: 100%|██████████| 1/1 [00:00<00:00,  1.03it/s]\n",
      "Loaded meta state: /userhome/jeon_mg/workspace/_data/NOAA12673/PINN/20170904_054800/model_final.pt\n",
      "Training:   0%|          | 0/2000 [00:00<?, ?it/s][Iteration 000000/002000] [loss: 0.00341478] [loss_bc: 0.00311331; loss_div: 0.00020094; loss_ff: 0.00010053] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:   5%|▍         | 98/2000 [00:07<02:19, 13.61it/s][Iteration 000100/002000] [loss: 0.00347804] [loss_bc: 0.00321294; loss_div: 0.00019811; loss_ff: 0.00006699] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  10%|▉         | 198/2000 [00:14<02:10, 13.76it/s][Iteration 000200/002000] [loss: 0.00325768] [loss_bc: 0.00297240; loss_div: 0.00020435; loss_ff: 0.00008093] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  15%|█▍        | 298/2000 [00:21<02:03, 13.82it/s][Iteration 000300/002000] [loss: 0.00333173] [loss_bc: 0.00298060; loss_div: 0.00024641; loss_ff: 0.00010473] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  20%|█▉        | 398/2000 [00:29<01:55, 13.83it/s][Iteration 000400/002000] [loss: 0.00317097] [loss_bc: 0.00285698; loss_div: 0.00019985; loss_ff: 0.00011414] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  25%|██▍       | 498/2000 [00:36<01:49, 13.75it/s][Iteration 000500/002000] [loss: 0.00347062] [loss_bc: 0.00315233; loss_div: 0.00023144; loss_ff: 0.00008685] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  30%|██▉       | 598/2000 [00:43<01:41, 13.84it/s][Iteration 000600/002000] [loss: 0.00329961] [loss_bc: 0.00303789; loss_div: 0.00019133; loss_ff: 0.00007040] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  35%|███▍      | 698/2000 [00:51<01:34, 13.72it/s][Iteration 000700/002000] [loss: 0.00324586] [loss_bc: 0.00297115; loss_div: 0.00018228; loss_ff: 0.00009244] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  40%|███▉      | 798/2000 [00:58<01:27, 13.74it/s][Iteration 000800/002000] [loss: 0.00321524] [loss_bc: 0.00284365; loss_div: 0.00024156; loss_ff: 0.00013003] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  45%|████▍     | 898/2000 [01:05<01:20, 13.65it/s][Iteration 000900/002000] [loss: 0.00347040] [loss_bc: 0.00314275; loss_div: 0.00019789; loss_ff: 0.00012976] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  50%|████▉     | 998/2000 [01:13<01:13, 13.59it/s][Iteration 001000/002000] [loss: 0.00323157] [loss_bc: 0.00292026; loss_div: 0.00021430; loss_ff: 0.00009700] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  55%|█████▍    | 1098/2000 [01:20<01:06, 13.59it/s][Iteration 001100/002000] [loss: 0.00328011] [loss_bc: 0.00300737; loss_div: 0.00019979; loss_ff: 0.00007295] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  60%|█████▉    | 1198/2000 [01:27<00:59, 13.56it/s][Iteration 001200/002000] [loss: 0.00327026] [loss_bc: 0.00295758; loss_div: 0.00022480; loss_ff: 0.00008788] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  65%|██████▍   | 1298/2000 [01:35<00:51, 13.58it/s][Iteration 001300/002000] [loss: 0.00340037] [loss_bc: 0.00307210; loss_div: 0.00024207; loss_ff: 0.00008620] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  70%|██████▉   | 1398/2000 [01:42<00:43, 13.81it/s][Iteration 001400/002000] [loss: 0.00344739] [loss_bc: 0.00318873; loss_div: 0.00018340; loss_ff: 0.00007526] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  75%|███████▍  | 1498/2000 [01:49<00:36, 13.77it/s][Iteration 001500/002000] [loss: 0.00325444] [loss_bc: 0.00294173; loss_div: 0.00022733; loss_ff: 0.00008538] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  80%|███████▉  | 1598/2000 [01:57<00:29, 13.60it/s][Iteration 001600/002000] [loss: 0.00317985] [loss_bc: 0.00290999; loss_div: 0.00018466; loss_ff: 0.00008521] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  85%|████████▍ | 1698/2000 [02:04<00:22, 13.55it/s][Iteration 001700/002000] [loss: 0.00331952] [loss_bc: 0.00299108; loss_div: 0.00021589; loss_ff: 0.00011256] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  90%|████████▉ | 1798/2000 [02:12<00:14, 13.63it/s][Iteration 001800/002000] [loss: 0.00346766] [loss_bc: 0.00317989; loss_div: 0.00020732; loss_ff: 0.00008045] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  95%|█████████▍| 1898/2000 [02:19<00:07, 13.61it/s][Iteration 001900/002000] [loss: 0.00350626] [loss_bc: 0.00318113; loss_div: 0.00021991; loss_ff: 0.00010522] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training: 100%|█████████▉| 1998/2000 [02:26<00:00, 13.77it/s][Iteration 002000/002000] [loss: 0.00344528] [loss_bc: 0.00318066; loss_div: 0.00018874; loss_ff: 0.00007588] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training: 100%|██████████| 2000/2000 [02:27<00:00, 13.59it/s]\n",
      "[Iteration 002000/002000] [loss: 0.00344528] [loss_bc: 0.00318066; loss_div: 0.00018874; loss_ff: 0.00007588] [w_bc: 1.000000, LR: 0.000050]\n",
      "Runtime --> total: 147.34sec (2.95ms/iter.)\n",
      "Configuration:\n",
      "dim: 256, w_div: 1.000000, w_ff: 1.000000, decay_iterations: None, potential: True, vector_potential: False, \n",
      "Using device: cuda (gpus 1) ['NVIDIA RTX A6000']\n",
      "Potential Boundary: 100%|██████████| 1/1 [00:00<00:00,  1.09it/s]\n",
      "Loaded meta state: /userhome/jeon_mg/workspace/_data/NOAA12673/PINN/20170904_060000/model_final.pt\n",
      "Training:   0%|          | 0/2000 [00:00<?, ?it/s][Iteration 000000/002000] [loss: 0.00478575] [loss_bc: 0.00450771; loss_div: 0.00019504; loss_ff: 0.00008300] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:   5%|▍         | 98/2000 [00:07<02:17, 13.83it/s][Iteration 000100/002000] [loss: 0.00391519] [loss_bc: 0.00351254; loss_div: 0.00029200; loss_ff: 0.00011064] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  10%|▉         | 198/2000 [00:14<02:12, 13.60it/s][Iteration 000200/002000] [loss: 0.00376422] [loss_bc: 0.00342015; loss_div: 0.00023951; loss_ff: 0.00010456] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  15%|█▍        | 298/2000 [00:21<02:05, 13.54it/s][Iteration 000300/002000] [loss: 0.00406256] [loss_bc: 0.00367693; loss_div: 0.00026188; loss_ff: 0.00012375] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  20%|█▉        | 398/2000 [00:29<01:57, 13.63it/s][Iteration 000400/002000] [loss: 0.00367857] [loss_bc: 0.00330204; loss_div: 0.00026976; loss_ff: 0.00010677] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  25%|██▍       | 498/2000 [00:36<01:50, 13.57it/s][Iteration 000500/002000] [loss: 0.00363697] [loss_bc: 0.00327705; loss_div: 0.00025080; loss_ff: 0.00010912] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  30%|██▉       | 598/2000 [00:44<01:44, 13.37it/s][Iteration 000600/002000] [loss: 0.00371240] [loss_bc: 0.00332395; loss_div: 0.00026057; loss_ff: 0.00012787] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  35%|███▍      | 698/2000 [00:51<01:37, 13.36it/s][Iteration 000700/002000] [loss: 0.00392351] [loss_bc: 0.00356996; loss_div: 0.00025023; loss_ff: 0.00010331] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  40%|███▉      | 798/2000 [00:58<01:28, 13.61it/s][Iteration 000800/002000] [loss: 0.00374346] [loss_bc: 0.00336234; loss_div: 0.00027407; loss_ff: 0.00010705] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  45%|████▍     | 898/2000 [01:06<01:21, 13.53it/s][Iteration 000900/002000] [loss: 0.00382397] [loss_bc: 0.00347314; loss_div: 0.00024524; loss_ff: 0.00010560] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  50%|████▉     | 998/2000 [01:13<01:14, 13.53it/s][Iteration 001000/002000] [loss: 0.00373607] [loss_bc: 0.00333093; loss_div: 0.00027447; loss_ff: 0.00013067] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  55%|█████▍    | 1098/2000 [01:20<01:06, 13.62it/s][Iteration 001100/002000] [loss: 0.00369476] [loss_bc: 0.00332398; loss_div: 0.00027055; loss_ff: 0.00010023] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  60%|█████▉    | 1198/2000 [01:28<00:58, 13.61it/s][Iteration 001200/002000] [loss: 0.00368740] [loss_bc: 0.00330709; loss_div: 0.00025102; loss_ff: 0.00012930] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  65%|██████▍   | 1298/2000 [01:35<00:51, 13.72it/s][Iteration 001300/002000] [loss: 0.00362738] [loss_bc: 0.00330211; loss_div: 0.00021873; loss_ff: 0.00010654] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  70%|██████▉   | 1398/2000 [01:42<00:44, 13.63it/s][Iteration 001400/002000] [loss: 0.00378849] [loss_bc: 0.00342328; loss_div: 0.00026514; loss_ff: 0.00010007] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  75%|███████▍  | 1498/2000 [01:50<00:36, 13.57it/s][Iteration 001500/002000] [loss: 0.00370467] [loss_bc: 0.00328971; loss_div: 0.00028656; loss_ff: 0.00012840] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  80%|███████▉  | 1598/2000 [01:57<00:29, 13.56it/s][Iteration 001600/002000] [loss: 0.00363195] [loss_bc: 0.00327643; loss_div: 0.00025732; loss_ff: 0.00009819] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  85%|████████▍ | 1698/2000 [02:05<00:22, 13.62it/s][Iteration 001700/002000] [loss: 0.00362951] [loss_bc: 0.00326662; loss_div: 0.00025931; loss_ff: 0.00010358] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  90%|████████▉ | 1798/2000 [02:12<00:14, 13.50it/s][Iteration 001800/002000] [loss: 0.00383676] [loss_bc: 0.00343939; loss_div: 0.00029445; loss_ff: 0.00010293] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  95%|█████████▍| 1898/2000 [02:19<00:07, 13.88it/s][Iteration 001900/002000] [loss: 0.00363812] [loss_bc: 0.00325368; loss_div: 0.00028156; loss_ff: 0.00010287] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training: 100%|█████████▉| 1998/2000 [02:26<00:00, 13.58it/s][Iteration 002000/002000] [loss: 0.00344597] [loss_bc: 0.00312678; loss_div: 0.00022390; loss_ff: 0.00009529] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training: 100%|██████████| 2000/2000 [02:27<00:00, 13.58it/s]\n",
      "[Iteration 002000/002000] [loss: 0.00344597] [loss_bc: 0.00312678; loss_div: 0.00022390; loss_ff: 0.00009529] [w_bc: 1.000000, LR: 0.000050]\n",
      "Runtime --> total: 147.44sec (2.95ms/iter.)\n",
      "Configuration:\n",
      "dim: 256, w_div: 1.000000, w_ff: 1.000000, decay_iterations: None, potential: True, vector_potential: False, \n",
      "Using device: cuda (gpus 1) ['NVIDIA RTX A6000']\n",
      "Potential Boundary: 100%|██████████| 1/1 [00:00<00:00,  1.05it/s]\n",
      "Loaded meta state: /userhome/jeon_mg/workspace/_data/NOAA12673/PINN/20170904_083600/model_final.pt\n",
      "Training:   0%|          | 0/2000 [00:00<?, ?it/s][Iteration 000000/002000] [loss: 0.00360039] [loss_bc: 0.00329273; loss_div: 0.00021407; loss_ff: 0.00009359] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:   5%|▍         | 98/2000 [00:07<02:20, 13.54it/s][Iteration 000100/002000] [loss: 0.00358838] [loss_bc: 0.00327232; loss_div: 0.00022222; loss_ff: 0.00009384] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  10%|▉         | 198/2000 [00:14<02:11, 13.72it/s][Iteration 000200/002000] [loss: 0.00364278] [loss_bc: 0.00328916; loss_div: 0.00026929; loss_ff: 0.00008434] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  15%|█▍        | 298/2000 [00:21<02:05, 13.57it/s][Iteration 000300/002000] [loss: 0.00363734] [loss_bc: 0.00330173; loss_div: 0.00024471; loss_ff: 0.00009089] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  20%|█▉        | 398/2000 [00:29<01:58, 13.52it/s][Iteration 000400/002000] [loss: 0.00363048] [loss_bc: 0.00327765; loss_div: 0.00025744; loss_ff: 0.00009539] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  25%|██▍       | 498/2000 [00:36<01:50, 13.58it/s][Iteration 000500/002000] [loss: 0.00373504] [loss_bc: 0.00331621; loss_div: 0.00029152; loss_ff: 0.00012732] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  30%|██▉       | 598/2000 [00:44<01:43, 13.57it/s][Iteration 000600/002000] [loss: 0.00365423] [loss_bc: 0.00327606; loss_div: 0.00027140; loss_ff: 0.00010678] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  35%|███▍      | 698/2000 [00:51<01:36, 13.55it/s][Iteration 000700/002000] [loss: 0.00360299] [loss_bc: 0.00325289; loss_div: 0.00024128; loss_ff: 0.00010882] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  40%|███▉      | 798/2000 [00:58<01:26, 13.91it/s][Iteration 000800/002000] [loss: 0.00363121] [loss_bc: 0.00324761; loss_div: 0.00028250; loss_ff: 0.00010111] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  45%|████▍     | 898/2000 [01:06<01:20, 13.62it/s][Iteration 000900/002000] [loss: 0.00365535] [loss_bc: 0.00326869; loss_div: 0.00028383; loss_ff: 0.00010283] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  50%|████▉     | 998/2000 [01:13<01:12, 13.86it/s][Iteration 001000/002000] [loss: 0.00360372] [loss_bc: 0.00325491; loss_div: 0.00024804; loss_ff: 0.00010077] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  55%|█████▍    | 1098/2000 [01:20<01:04, 13.92it/s][Iteration 001100/002000] [loss: 0.00356226] [loss_bc: 0.00322105; loss_div: 0.00025869; loss_ff: 0.00008251] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  60%|█████▉    | 1198/2000 [01:28<00:59, 13.48it/s][Iteration 001200/002000] [loss: 0.00345105] [loss_bc: 0.00303801; loss_div: 0.00028156; loss_ff: 0.00013148] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  65%|██████▍   | 1298/2000 [01:35<00:51, 13.61it/s][Iteration 001300/002000] [loss: 0.00363713] [loss_bc: 0.00319787; loss_div: 0.00031976; loss_ff: 0.00011950] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  70%|██████▉   | 1398/2000 [01:43<00:44, 13.56it/s][Iteration 001400/002000] [loss: 0.00378671] [loss_bc: 0.00341046; loss_div: 0.00024322; loss_ff: 0.00013303] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  75%|███████▍  | 1498/2000 [01:50<00:36, 13.81it/s][Iteration 001500/002000] [loss: 0.00359443] [loss_bc: 0.00325062; loss_div: 0.00024863; loss_ff: 0.00009518] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  80%|███████▉  | 1598/2000 [01:57<00:29, 13.63it/s][Iteration 001600/002000] [loss: 0.00362469] [loss_bc: 0.00324911; loss_div: 0.00024960; loss_ff: 0.00012598] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  85%|████████▍ | 1698/2000 [02:05<00:22, 13.65it/s][Iteration 001700/002000] [loss: 0.00356475] [loss_bc: 0.00319047; loss_div: 0.00026969; loss_ff: 0.00010459] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  90%|████████▉ | 1798/2000 [02:12<00:14, 13.55it/s][Iteration 001800/002000] [loss: 0.00370429] [loss_bc: 0.00340316; loss_div: 0.00021731; loss_ff: 0.00008382] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  95%|█████████▍| 1898/2000 [02:19<00:07, 13.79it/s][Iteration 001900/002000] [loss: 0.00352790] [loss_bc: 0.00319062; loss_div: 0.00023372; loss_ff: 0.00010357] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training: 100%|█████████▉| 1998/2000 [02:27<00:00, 13.52it/s][Iteration 002000/002000] [loss: 0.00349193] [loss_bc: 0.00318011; loss_div: 0.00021438; loss_ff: 0.00009744] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training: 100%|██████████| 2000/2000 [02:27<00:00, 13.56it/s]\n",
      "[Iteration 002000/002000] [loss: 0.00349193] [loss_bc: 0.00318011; loss_div: 0.00021438; loss_ff: 0.00009744] [w_bc: 1.000000, LR: 0.000050]\n",
      "Runtime --> total: 147.68sec (2.95ms/iter.)\n",
      "Configuration:\n",
      "dim: 256, w_div: 1.000000, w_ff: 1.000000, decay_iterations: None, potential: True, vector_potential: False, \n",
      "Using device: cuda (gpus 1) ['NVIDIA RTX A6000']\n",
      "Potential Boundary: 100%|██████████| 1/1 [00:00<00:00,  1.05it/s]\n",
      "Loaded meta state: /userhome/jeon_mg/workspace/_data/NOAA12673/PINN/20170904_084800/model_final.pt\n",
      "Training:   0%|          | 0/2000 [00:00<?, ?it/s][Iteration 000000/002000] [loss: 0.00422066] [loss_bc: 0.00385989; loss_div: 0.00026264; loss_ff: 0.00009813] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:   5%|▍         | 98/2000 [00:07<02:19, 13.60it/s][Iteration 000100/002000] [loss: 0.00381515] [loss_bc: 0.00350203; loss_div: 0.00023761; loss_ff: 0.00007550] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  10%|▉         | 198/2000 [00:14<02:12, 13.60it/s][Iteration 000200/002000] [loss: 0.00388227] [loss_bc: 0.00354906; loss_div: 0.00024305; loss_ff: 0.00009016] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  15%|█▍        | 298/2000 [00:21<02:02, 13.85it/s][Iteration 000300/002000] [loss: 0.00399934] [loss_bc: 0.00360593; loss_div: 0.00026957; loss_ff: 0.00012384] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  20%|█▉        | 398/2000 [00:29<01:57, 13.64it/s][Iteration 000400/002000] [loss: 0.00397918] [loss_bc: 0.00360225; loss_div: 0.00025810; loss_ff: 0.00011883] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  25%|██▍       | 498/2000 [00:37<01:50, 13.65it/s][Iteration 000500/002000] [loss: 0.00421850] [loss_bc: 0.00381702; loss_div: 0.00029322; loss_ff: 0.00010826] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  30%|██▉       | 598/2000 [00:44<01:43, 13.59it/s][Iteration 000600/002000] [loss: 0.00424057] [loss_bc: 0.00384471; loss_div: 0.00027642; loss_ff: 0.00011944] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  35%|███▍      | 698/2000 [00:51<01:36, 13.47it/s][Iteration 000700/002000] [loss: 0.00382973] [loss_bc: 0.00352446; loss_div: 0.00021339; loss_ff: 0.00009188] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  40%|███▉      | 798/2000 [00:59<01:28, 13.57it/s][Iteration 000800/002000] [loss: 0.00389781] [loss_bc: 0.00357618; loss_div: 0.00022452; loss_ff: 0.00009711] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  45%|████▍     | 898/2000 [01:06<01:21, 13.60it/s][Iteration 000900/002000] [loss: 0.00392235] [loss_bc: 0.00346724; loss_div: 0.00027358; loss_ff: 0.00018153] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  50%|████▉     | 998/2000 [01:14<01:13, 13.60it/s][Iteration 001000/002000] [loss: 0.00419158] [loss_bc: 0.00379665; loss_div: 0.00027761; loss_ff: 0.00011732] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  55%|█████▍    | 1098/2000 [01:21<01:07, 13.45it/s][Iteration 001100/002000] [loss: 0.00416206] [loss_bc: 0.00379709; loss_div: 0.00026364; loss_ff: 0.00010133] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  60%|█████▉    | 1198/2000 [01:28<00:59, 13.56it/s][Iteration 001200/002000] [loss: 0.00383615] [loss_bc: 0.00349562; loss_div: 0.00024056; loss_ff: 0.00009997] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  65%|██████▍   | 1298/2000 [01:36<00:50, 13.84it/s][Iteration 001300/002000] [loss: 0.00416019] [loss_bc: 0.00380994; loss_div: 0.00024484; loss_ff: 0.00010541] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  70%|██████▉   | 1398/2000 [01:43<00:44, 13.52it/s][Iteration 001400/002000] [loss: 0.00403775] [loss_bc: 0.00366000; loss_div: 0.00027747; loss_ff: 0.00010028] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  75%|███████▍  | 1498/2000 [01:50<00:36, 13.93it/s][Iteration 001500/002000] [loss: 0.00414402] [loss_bc: 0.00380105; loss_div: 0.00024016; loss_ff: 0.00010281] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  80%|███████▉  | 1598/2000 [01:58<00:29, 13.57it/s][Iteration 001600/002000] [loss: 0.00377822] [loss_bc: 0.00343762; loss_div: 0.00024284; loss_ff: 0.00009776] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  85%|████████▍ | 1698/2000 [02:05<00:22, 13.66it/s][Iteration 001700/002000] [loss: 0.00416131] [loss_bc: 0.00377857; loss_div: 0.00026927; loss_ff: 0.00011347] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  90%|████████▉ | 1798/2000 [02:12<00:14, 13.52it/s][Iteration 001800/002000] [loss: 0.00383763] [loss_bc: 0.00347787; loss_div: 0.00025669; loss_ff: 0.00010307] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  95%|█████████▍| 1898/2000 [02:20<00:07, 13.51it/s][Iteration 001900/002000] [loss: 0.00404539] [loss_bc: 0.00367104; loss_div: 0.00025927; loss_ff: 0.00011508] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training: 100%|█████████▉| 1998/2000 [02:27<00:00, 13.64it/s][Iteration 002000/002000] [loss: 0.00394973] [loss_bc: 0.00353907; loss_div: 0.00031164; loss_ff: 0.00009902] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training: 100%|██████████| 2000/2000 [02:28<00:00, 13.51it/s]\n",
      "[Iteration 002000/002000] [loss: 0.00394973] [loss_bc: 0.00353907; loss_div: 0.00031164; loss_ff: 0.00009902] [w_bc: 1.000000, LR: 0.000050]\n",
      "Runtime --> total: 148.25sec (2.97ms/iter.)\n",
      "Configuration:\n",
      "dim: 256, w_div: 1.000000, w_ff: 1.000000, decay_iterations: None, potential: True, vector_potential: False, \n",
      "Using device: cuda (gpus 1) ['NVIDIA RTX A6000']\n",
      "Potential Boundary: 100%|██████████| 1/1 [00:00<00:00,  1.86it/s]\n",
      "Loaded meta state: /userhome/jeon_mg/workspace/_data/NOAA12673/PINN/20170904_090000/model_final.pt\n",
      "Training:   0%|          | 0/2000 [00:00<?, ?it/s][Iteration 000000/002000] [loss: 0.00347497] [loss_bc: 0.00307473; loss_div: 0.00029364; loss_ff: 0.00010660] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:   5%|▍         | 98/2000 [00:07<02:19, 13.60it/s][Iteration 000100/002000] [loss: 0.00330658] [loss_bc: 0.00293592; loss_div: 0.00025406; loss_ff: 0.00011659] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  10%|▉         | 198/2000 [00:14<02:09, 13.86it/s][Iteration 000200/002000] [loss: 0.00364702] [loss_bc: 0.00329124; loss_div: 0.00026193; loss_ff: 0.00009385] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  15%|█▍        | 298/2000 [00:21<02:08, 13.23it/s][Iteration 000300/002000] [loss: 0.00371430] [loss_bc: 0.00331325; loss_div: 0.00028614; loss_ff: 0.00011492] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  20%|█▉        | 398/2000 [00:29<01:58, 13.47it/s][Iteration 000400/002000] [loss: 0.00381889] [loss_bc: 0.00336905; loss_div: 0.00033766; loss_ff: 0.00011218] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  25%|██▍       | 498/2000 [00:36<01:50, 13.59it/s][Iteration 000500/002000] [loss: 0.00373157] [loss_bc: 0.00336557; loss_div: 0.00027265; loss_ff: 0.00009336] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  30%|██▉       | 598/2000 [00:43<01:42, 13.67it/s][Iteration 000600/002000] [loss: 0.00369979] [loss_bc: 0.00336597; loss_div: 0.00024887; loss_ff: 0.00008495] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  35%|███▍      | 698/2000 [00:51<01:35, 13.61it/s][Iteration 000700/002000] [loss: 0.00363148] [loss_bc: 0.00328446; loss_div: 0.00025640; loss_ff: 0.00009062] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  40%|███▉      | 798/2000 [00:58<01:28, 13.62it/s][Iteration 000800/002000] [loss: 0.00346398] [loss_bc: 0.00307070; loss_div: 0.00029580; loss_ff: 0.00009748] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  45%|████▍     | 898/2000 [01:06<01:21, 13.58it/s][Iteration 000900/002000] [loss: 0.00367982] [loss_bc: 0.00327252; loss_div: 0.00029680; loss_ff: 0.00011050] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  50%|████▉     | 998/2000 [01:13<01:13, 13.58it/s][Iteration 001000/002000] [loss: 0.00344194] [loss_bc: 0.00305985; loss_div: 0.00027961; loss_ff: 0.00010248] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  55%|█████▍    | 1098/2000 [01:20<01:05, 13.75it/s][Iteration 001100/002000] [loss: 0.00369016] [loss_bc: 0.00332942; loss_div: 0.00024499; loss_ff: 0.00011574] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  60%|█████▉    | 1198/2000 [01:28<00:58, 13.63it/s][Iteration 001200/002000] [loss: 0.00333810] [loss_bc: 0.00301825; loss_div: 0.00023536; loss_ff: 0.00008450] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  65%|██████▍   | 1298/2000 [01:35<00:51, 13.56it/s][Iteration 001300/002000] [loss: 0.00337692] [loss_bc: 0.00304778; loss_div: 0.00023514; loss_ff: 0.00009400] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  70%|██████▉   | 1398/2000 [01:43<00:44, 13.56it/s][Iteration 001400/002000] [loss: 0.00364894] [loss_bc: 0.00331181; loss_div: 0.00023945; loss_ff: 0.00009768] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  75%|███████▍  | 1498/2000 [01:50<00:36, 13.57it/s][Iteration 001500/002000] [loss: 0.00363940] [loss_bc: 0.00333275; loss_div: 0.00022667; loss_ff: 0.00007998] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  80%|███████▉  | 1598/2000 [01:57<00:29, 13.55it/s][Iteration 001600/002000] [loss: 0.00358707] [loss_bc: 0.00325250; loss_div: 0.00022354; loss_ff: 0.00011103] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  85%|████████▍ | 1698/2000 [02:05<00:22, 13.55it/s][Iteration 001700/002000] [loss: 0.00362349] [loss_bc: 0.00323616; loss_div: 0.00025873; loss_ff: 0.00012860] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  90%|████████▉ | 1798/2000 [02:12<00:14, 13.56it/s][Iteration 001800/002000] [loss: 0.00325310] [loss_bc: 0.00288030; loss_div: 0.00028278; loss_ff: 0.00009002] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  95%|█████████▍| 1898/2000 [02:19<00:07, 13.63it/s][Iteration 001900/002000] [loss: 0.00367785] [loss_bc: 0.00329101; loss_div: 0.00025622; loss_ff: 0.00013062] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training: 100%|█████████▉| 1998/2000 [02:27<00:00, 13.62it/s][Iteration 002000/002000] [loss: 0.00360903] [loss_bc: 0.00324801; loss_div: 0.00024399; loss_ff: 0.00011703] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training: 100%|██████████| 2000/2000 [02:27<00:00, 13.54it/s]\n",
      "[Iteration 002000/002000] [loss: 0.00360903] [loss_bc: 0.00324801; loss_div: 0.00024399; loss_ff: 0.00011703] [w_bc: 1.000000, LR: 0.000050]\n",
      "Runtime --> total: 147.86sec (2.96ms/iter.)\n",
      "Configuration:\n",
      "dim: 256, w_div: 1.000000, w_ff: 1.000000, decay_iterations: None, potential: True, vector_potential: False, \n",
      "Using device: cuda (gpus 1) ['NVIDIA RTX A6000']\n",
      "Potential Boundary: 100%|██████████| 1/1 [00:00<00:00,  1.03it/s]\n",
      "Loaded meta state: /userhome/jeon_mg/workspace/_data/NOAA12673/PINN/20170904_091200/model_final.pt\n",
      "Training:   0%|          | 0/2000 [00:00<?, ?it/s][Iteration 000000/002000] [loss: 0.00360422] [loss_bc: 0.00320178; loss_div: 0.00024299; loss_ff: 0.00015945] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:   5%|▍         | 98/2000 [00:07<02:19, 13.68it/s][Iteration 000100/002000] [loss: 0.00331630] [loss_bc: 0.00298983; loss_div: 0.00023792; loss_ff: 0.00008854] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  10%|▉         | 198/2000 [00:14<02:12, 13.60it/s][Iteration 000200/002000] [loss: 0.00327530] [loss_bc: 0.00295288; loss_div: 0.00023178; loss_ff: 0.00009064] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  15%|█▍        | 298/2000 [00:21<02:05, 13.61it/s][Iteration 000300/002000] [loss: 0.00366327] [loss_bc: 0.00330253; loss_div: 0.00025392; loss_ff: 0.00010682] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  20%|█▉        | 398/2000 [00:29<01:58, 13.57it/s][Iteration 000400/002000] [loss: 0.00331437] [loss_bc: 0.00297872; loss_div: 0.00023946; loss_ff: 0.00009619] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  25%|██▍       | 498/2000 [00:36<01:50, 13.55it/s][Iteration 000500/002000] [loss: 0.00392088] [loss_bc: 0.00354883; loss_div: 0.00026733; loss_ff: 0.00010472] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  30%|██▉       | 598/2000 [00:44<01:43, 13.57it/s][Iteration 000600/002000] [loss: 0.00362537] [loss_bc: 0.00330250; loss_div: 0.00023381; loss_ff: 0.00008905] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  35%|███▍      | 698/2000 [00:51<01:35, 13.57it/s][Iteration 000700/002000] [loss: 0.00349322] [loss_bc: 0.00315753; loss_div: 0.00023917; loss_ff: 0.00009652] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  40%|███▉      | 798/2000 [00:58<01:28, 13.59it/s][Iteration 000800/002000] [loss: 0.00361666] [loss_bc: 0.00320498; loss_div: 0.00029094; loss_ff: 0.00012074] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  45%|████▍     | 898/2000 [01:06<01:21, 13.49it/s][Iteration 000900/002000] [loss: 0.00360356] [loss_bc: 0.00326187; loss_div: 0.00024371; loss_ff: 0.00009798] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  50%|████▉     | 998/2000 [01:13<01:14, 13.54it/s][Iteration 001000/002000] [loss: 0.00353655] [loss_bc: 0.00315471; loss_div: 0.00026846; loss_ff: 0.00011338] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  55%|█████▍    | 1098/2000 [01:20<01:05, 13.87it/s][Iteration 001100/002000] [loss: 0.00361894] [loss_bc: 0.00326570; loss_div: 0.00024800; loss_ff: 0.00010525] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  60%|█████▉    | 1198/2000 [01:28<00:58, 13.71it/s][Iteration 001200/002000] [loss: 0.00355209] [loss_bc: 0.00317773; loss_div: 0.00027785; loss_ff: 0.00009650] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  65%|██████▍   | 1298/2000 [01:35<00:50, 13.84it/s][Iteration 001300/002000] [loss: 0.00356254] [loss_bc: 0.00318694; loss_div: 0.00027270; loss_ff: 0.00010290] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  70%|██████▉   | 1398/2000 [01:42<00:44, 13.57it/s][Iteration 001400/002000] [loss: 0.00352631] [loss_bc: 0.00314364; loss_div: 0.00027210; loss_ff: 0.00011057] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  75%|███████▍  | 1498/2000 [01:50<00:36, 13.72it/s][Iteration 001500/002000] [loss: 0.00328073] [loss_bc: 0.00291501; loss_div: 0.00025902; loss_ff: 0.00010670] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  80%|███████▉  | 1598/2000 [01:57<00:29, 13.64it/s][Iteration 001600/002000] [loss: 0.00387075] [loss_bc: 0.00351633; loss_div: 0.00023550; loss_ff: 0.00011892] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  85%|████████▍ | 1698/2000 [02:05<00:21, 13.93it/s][Iteration 001700/002000] [loss: 0.00353216] [loss_bc: 0.00313375; loss_div: 0.00029218; loss_ff: 0.00010623] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  90%|████████▉ | 1798/2000 [02:12<00:14, 13.57it/s][Iteration 001800/002000] [loss: 0.00339649] [loss_bc: 0.00308210; loss_div: 0.00021676; loss_ff: 0.00009764] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  95%|█████████▍| 1898/2000 [02:19<00:07, 13.60it/s][Iteration 001900/002000] [loss: 0.00351597] [loss_bc: 0.00312788; loss_div: 0.00026457; loss_ff: 0.00012352] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training: 100%|█████████▉| 1998/2000 [02:27<00:00, 13.66it/s][Iteration 002000/002000] [loss: 0.00358912] [loss_bc: 0.00322662; loss_div: 0.00025251; loss_ff: 0.00010998] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training: 100%|██████████| 2000/2000 [02:27<00:00, 13.57it/s]\n",
      "[Iteration 002000/002000] [loss: 0.00358912] [loss_bc: 0.00322662; loss_div: 0.00025251; loss_ff: 0.00010998] [w_bc: 1.000000, LR: 0.000050]\n",
      "Runtime --> total: 147.65sec (2.95ms/iter.)\n",
      "Configuration:\n",
      "dim: 256, w_div: 1.000000, w_ff: 1.000000, decay_iterations: None, potential: True, vector_potential: False, \n",
      "Using device: cuda (gpus 1) ['NVIDIA RTX A6000']\n",
      "Potential Boundary: 100%|██████████| 1/1 [00:00<00:00,  1.05it/s]\n",
      "Loaded meta state: /userhome/jeon_mg/workspace/_data/NOAA12673/PINN/20170904_092400/model_final.pt\n",
      "Training:   0%|          | 0/2000 [00:00<?, ?it/s][Iteration 000000/002000] [loss: 0.00352225] [loss_bc: 0.00308425; loss_div: 0.00027146; loss_ff: 0.00016654] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:   5%|▍         | 98/2000 [00:07<02:17, 13.80it/s][Iteration 000100/002000] [loss: 0.00360278] [loss_bc: 0.00327993; loss_div: 0.00022434; loss_ff: 0.00009851] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  10%|▉         | 198/2000 [00:14<02:12, 13.63it/s][Iteration 000200/002000] [loss: 0.00343223] [loss_bc: 0.00304054; loss_div: 0.00025639; loss_ff: 0.00013530] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  15%|█▍        | 298/2000 [00:21<02:05, 13.56it/s][Iteration 000300/002000] [loss: 0.00364855] [loss_bc: 0.00328616; loss_div: 0.00025799; loss_ff: 0.00010440] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  20%|█▉        | 398/2000 [00:29<01:58, 13.50it/s][Iteration 000400/002000] [loss: 0.00355020] [loss_bc: 0.00318380; loss_div: 0.00026563; loss_ff: 0.00010077] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  25%|██▍       | 498/2000 [00:36<01:51, 13.53it/s][Iteration 000500/002000] [loss: 0.00343205] [loss_bc: 0.00302759; loss_div: 0.00026634; loss_ff: 0.00013812] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  30%|██▉       | 598/2000 [00:44<01:43, 13.54it/s][Iteration 000600/002000] [loss: 0.00367779] [loss_bc: 0.00327322; loss_div: 0.00026974; loss_ff: 0.00013484] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  35%|███▍      | 698/2000 [00:51<01:35, 13.57it/s][Iteration 000700/002000] [loss: 0.00364818] [loss_bc: 0.00325149; loss_div: 0.00024611; loss_ff: 0.00015058] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  40%|███▉      | 798/2000 [00:58<01:28, 13.65it/s][Iteration 000800/002000] [loss: 0.00345287] [loss_bc: 0.00304674; loss_div: 0.00029776; loss_ff: 0.00010837] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  45%|████▍     | 898/2000 [01:06<01:21, 13.58it/s][Iteration 000900/002000] [loss: 0.00361796] [loss_bc: 0.00324425; loss_div: 0.00025904; loss_ff: 0.00011467] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  50%|████▉     | 998/2000 [01:13<01:14, 13.53it/s][Iteration 001000/002000] [loss: 0.00351178] [loss_bc: 0.00316582; loss_div: 0.00025423; loss_ff: 0.00009173] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  55%|█████▍    | 1098/2000 [01:20<01:06, 13.48it/s][Iteration 001100/002000] [loss: 0.00357895] [loss_bc: 0.00326004; loss_div: 0.00022400; loss_ff: 0.00009491] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  60%|█████▉    | 1198/2000 [01:28<00:59, 13.58it/s][Iteration 001200/002000] [loss: 0.00365049] [loss_bc: 0.00321046; loss_div: 0.00028382; loss_ff: 0.00015621] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  65%|██████▍   | 1298/2000 [01:35<00:51, 13.64it/s][Iteration 001300/002000] [loss: 0.00337795] [loss_bc: 0.00303237; loss_div: 0.00023459; loss_ff: 0.00011099] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  70%|██████▉   | 1398/2000 [01:42<00:43, 13.83it/s][Iteration 001400/002000] [loss: 0.00355862] [loss_bc: 0.00319788; loss_div: 0.00025518; loss_ff: 0.00010556] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  75%|███████▍  | 1498/2000 [01:50<00:37, 13.57it/s][Iteration 001500/002000] [loss: 0.00341143] [loss_bc: 0.00302818; loss_div: 0.00026930; loss_ff: 0.00011395] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  80%|███████▉  | 1598/2000 [01:57<00:29, 13.60it/s][Iteration 001600/002000] [loss: 0.00362206] [loss_bc: 0.00324499; loss_div: 0.00027788; loss_ff: 0.00009919] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  85%|████████▍ | 1698/2000 [02:05<00:22, 13.38it/s][Iteration 001700/002000] [loss: 0.00358500] [loss_bc: 0.00323161; loss_div: 0.00022571; loss_ff: 0.00012768] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  90%|████████▉ | 1798/2000 [02:12<00:15, 13.44it/s][Iteration 001800/002000] [loss: 0.00344827] [loss_bc: 0.00313782; loss_div: 0.00021933; loss_ff: 0.00009111] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  95%|█████████▍| 1898/2000 [02:19<00:07, 13.57it/s][Iteration 001900/002000] [loss: 0.00355113] [loss_bc: 0.00310875; loss_div: 0.00029791; loss_ff: 0.00014446] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training: 100%|█████████▉| 1998/2000 [02:27<00:00, 13.57it/s][Iteration 002000/002000] [loss: 0.00339057] [loss_bc: 0.00299494; loss_div: 0.00027540; loss_ff: 0.00012023] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training: 100%|██████████| 2000/2000 [02:27<00:00, 13.55it/s]\n",
      "[Iteration 002000/002000] [loss: 0.00339057] [loss_bc: 0.00299494; loss_div: 0.00027540; loss_ff: 0.00012023] [w_bc: 1.000000, LR: 0.000050]\n",
      "Runtime --> total: 147.87sec (2.96ms/iter.)\n",
      "Configuration:\n",
      "dim: 256, w_div: 1.000000, w_ff: 1.000000, decay_iterations: None, potential: True, vector_potential: False, \n",
      "Using device: cuda (gpus 1) ['NVIDIA RTX A6000']\n",
      "Potential Boundary: 100%|██████████| 1/1 [00:00<00:00,  1.10it/s]\n",
      "Loaded meta state: /userhome/jeon_mg/workspace/_data/NOAA12673/PINN/20170904_093600/model_final.pt\n",
      "Training:   0%|          | 0/2000 [00:00<?, ?it/s][Iteration 000000/002000] [loss: 0.00330883] [loss_bc: 0.00299408; loss_div: 0.00022356; loss_ff: 0.00009120] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:   5%|▍         | 98/2000 [00:07<02:17, 13.84it/s][Iteration 000100/002000] [loss: 0.00386048] [loss_bc: 0.00338900; loss_div: 0.00033737; loss_ff: 0.00013411] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  10%|▉         | 198/2000 [00:14<02:09, 13.88it/s][Iteration 000200/002000] [loss: 0.00338608] [loss_bc: 0.00300526; loss_div: 0.00026832; loss_ff: 0.00011250] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  15%|█▍        | 298/2000 [00:21<02:05, 13.60it/s][Iteration 000300/002000] [loss: 0.00375507] [loss_bc: 0.00339409; loss_div: 0.00025217; loss_ff: 0.00010881] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  20%|█▉        | 398/2000 [00:29<01:57, 13.58it/s][Iteration 000400/002000] [loss: 0.00352990] [loss_bc: 0.00320821; loss_div: 0.00025069; loss_ff: 0.00007101] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  25%|██▍       | 498/2000 [00:36<01:53, 13.22it/s][Iteration 000500/002000] [loss: 0.00373929] [loss_bc: 0.00333727; loss_div: 0.00029620; loss_ff: 0.00010582] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  30%|██▉       | 598/2000 [00:43<01:43, 13.60it/s][Iteration 000600/002000] [loss: 0.00332316] [loss_bc: 0.00296341; loss_div: 0.00024097; loss_ff: 0.00011878] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  35%|███▍      | 698/2000 [00:51<01:35, 13.70it/s][Iteration 000700/002000] [loss: 0.00392151] [loss_bc: 0.00347843; loss_div: 0.00031840; loss_ff: 0.00012469] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  40%|███▉      | 798/2000 [00:58<01:28, 13.66it/s][Iteration 000800/002000] [loss: 0.00380932] [loss_bc: 0.00338560; loss_div: 0.00031646; loss_ff: 0.00010725] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  45%|████▍     | 898/2000 [01:05<01:21, 13.60it/s][Iteration 000900/002000] [loss: 0.00366249] [loss_bc: 0.00320413; loss_div: 0.00032853; loss_ff: 0.00012984] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  50%|████▉     | 998/2000 [01:13<01:13, 13.65it/s][Iteration 001000/002000] [loss: 0.00360704] [loss_bc: 0.00320863; loss_div: 0.00029232; loss_ff: 0.00010609] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  55%|█████▍    | 1098/2000 [01:20<01:06, 13.65it/s][Iteration 001100/002000] [loss: 0.00362716] [loss_bc: 0.00319831; loss_div: 0.00028572; loss_ff: 0.00014312] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  60%|█████▉    | 1198/2000 [01:28<00:57, 13.84it/s][Iteration 001200/002000] [loss: 0.00330496] [loss_bc: 0.00295043; loss_div: 0.00026690; loss_ff: 0.00008763] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  65%|██████▍   | 1298/2000 [01:35<00:51, 13.57it/s][Iteration 001300/002000] [loss: 0.00372291] [loss_bc: 0.00331708; loss_div: 0.00029584; loss_ff: 0.00010998] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  70%|██████▉   | 1398/2000 [01:42<00:44, 13.53it/s][Iteration 001400/002000] [loss: 0.00335010] [loss_bc: 0.00297204; loss_div: 0.00025319; loss_ff: 0.00012487] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  75%|███████▍  | 1498/2000 [01:50<00:36, 13.60it/s][Iteration 001500/002000] [loss: 0.00357162] [loss_bc: 0.00319046; loss_div: 0.00026749; loss_ff: 0.00011366] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  80%|███████▉  | 1598/2000 [01:57<00:29, 13.77it/s][Iteration 001600/002000] [loss: 0.00350518] [loss_bc: 0.00316259; loss_div: 0.00025398; loss_ff: 0.00008861] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  85%|████████▍ | 1698/2000 [02:04<00:22, 13.65it/s][Iteration 001700/002000] [loss: 0.00372635] [loss_bc: 0.00335315; loss_div: 0.00024090; loss_ff: 0.00013230] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  90%|████████▉ | 1798/2000 [02:12<00:14, 13.58it/s][Iteration 001800/002000] [loss: 0.00333804] [loss_bc: 0.00294046; loss_div: 0.00029122; loss_ff: 0.00010636] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  95%|█████████▍| 1898/2000 [02:19<00:07, 13.54it/s][Iteration 001900/002000] [loss: 0.00369802] [loss_bc: 0.00329840; loss_div: 0.00026820; loss_ff: 0.00013142] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training: 100%|█████████▉| 1998/2000 [02:26<00:00, 13.64it/s][Iteration 002000/002000] [loss: 0.00355046] [loss_bc: 0.00317752; loss_div: 0.00026845; loss_ff: 0.00010449] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training: 100%|██████████| 2000/2000 [02:27<00:00, 13.58it/s]\n",
      "[Iteration 002000/002000] [loss: 0.00355046] [loss_bc: 0.00317752; loss_div: 0.00026845; loss_ff: 0.00010449] [w_bc: 1.000000, LR: 0.000050]\n",
      "Runtime --> total: 147.47sec (2.95ms/iter.)\n",
      "Configuration:\n",
      "dim: 256, w_div: 1.000000, w_ff: 1.000000, decay_iterations: None, potential: True, vector_potential: False, \n",
      "Using device: cuda (gpus 1) ['NVIDIA RTX A6000']\n",
      "Potential Boundary: 100%|██████████| 1/1 [00:00<00:00,  1.03it/s]\n",
      "Loaded meta state: /userhome/jeon_mg/workspace/_data/NOAA12673/PINN/20170904_094800/model_final.pt\n",
      "Training:   0%|          | 0/2000 [00:00<?, ?it/s][Iteration 000000/002000] [loss: 0.00361129] [loss_bc: 0.00321875; loss_div: 0.00025951; loss_ff: 0.00013303] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:   5%|▍         | 98/2000 [00:07<02:21, 13.46it/s][Iteration 000100/002000] [loss: 0.00361956] [loss_bc: 0.00324847; loss_div: 0.00025485; loss_ff: 0.00011624] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  10%|▉         | 198/2000 [00:14<02:12, 13.58it/s][Iteration 000200/002000] [loss: 0.00367597] [loss_bc: 0.00324221; loss_div: 0.00030443; loss_ff: 0.00012933] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  15%|█▍        | 298/2000 [00:21<02:04, 13.63it/s][Iteration 000300/002000] [loss: 0.00374651] [loss_bc: 0.00336291; loss_div: 0.00028137; loss_ff: 0.00010223] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  20%|█▉        | 398/2000 [00:29<01:57, 13.65it/s][Iteration 000400/002000] [loss: 0.00354790] [loss_bc: 0.00317204; loss_div: 0.00025982; loss_ff: 0.00011604] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  25%|██▍       | 498/2000 [00:36<01:50, 13.58it/s][Iteration 000500/002000] [loss: 0.00352000] [loss_bc: 0.00310991; loss_div: 0.00029839; loss_ff: 0.00011170] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  30%|██▉       | 598/2000 [00:44<01:42, 13.65it/s][Iteration 000600/002000] [loss: 0.00355465] [loss_bc: 0.00315658; loss_div: 0.00029231; loss_ff: 0.00010576] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  35%|███▍      | 698/2000 [00:51<01:33, 13.88it/s][Iteration 000700/002000] [loss: 0.00360544] [loss_bc: 0.00322046; loss_div: 0.00028187; loss_ff: 0.00010310] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  40%|███▉      | 798/2000 [00:58<01:28, 13.54it/s][Iteration 000800/002000] [loss: 0.00365482] [loss_bc: 0.00326393; loss_div: 0.00027709; loss_ff: 0.00011379] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  45%|████▍     | 898/2000 [01:06<01:21, 13.56it/s][Iteration 000900/002000] [loss: 0.00347170] [loss_bc: 0.00315685; loss_div: 0.00022371; loss_ff: 0.00009114] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  50%|████▉     | 998/2000 [01:13<01:14, 13.47it/s][Iteration 001000/002000] [loss: 0.00351936] [loss_bc: 0.00316304; loss_div: 0.00024660; loss_ff: 0.00010972] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  55%|█████▍    | 1098/2000 [01:20<01:07, 13.45it/s][Iteration 001100/002000] [loss: 0.00348941] [loss_bc: 0.00314717; loss_div: 0.00025781; loss_ff: 0.00008443] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  60%|█████▉    | 1198/2000 [01:28<00:58, 13.79it/s][Iteration 001200/002000] [loss: 0.00333331] [loss_bc: 0.00298906; loss_div: 0.00024932; loss_ff: 0.00009493] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  65%|██████▍   | 1298/2000 [01:35<00:51, 13.58it/s][Iteration 001300/002000] [loss: 0.00343048] [loss_bc: 0.00309281; loss_div: 0.00025069; loss_ff: 0.00008698] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  70%|██████▉   | 1398/2000 [01:43<00:44, 13.62it/s][Iteration 001400/002000] [loss: 0.00338886] [loss_bc: 0.00298719; loss_div: 0.00028237; loss_ff: 0.00011930] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  75%|███████▍  | 1498/2000 [01:50<00:37, 13.48it/s][Iteration 001500/002000] [loss: 0.00358163] [loss_bc: 0.00319128; loss_div: 0.00025283; loss_ff: 0.00013752] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  80%|███████▉  | 1598/2000 [01:57<00:29, 13.57it/s][Iteration 001600/002000] [loss: 0.00349620] [loss_bc: 0.00313475; loss_div: 0.00024897; loss_ff: 0.00011248] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  85%|████████▍ | 1698/2000 [02:05<00:22, 13.58it/s][Iteration 001700/002000] [loss: 0.00366078] [loss_bc: 0.00332753; loss_div: 0.00023955; loss_ff: 0.00009369] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  90%|████████▉ | 1798/2000 [02:12<00:14, 13.55it/s][Iteration 001800/002000] [loss: 0.00358050] [loss_bc: 0.00313129; loss_div: 0.00031690; loss_ff: 0.00013231] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  95%|█████████▍| 1898/2000 [02:19<00:07, 13.85it/s][Iteration 001900/002000] [loss: 0.00361092] [loss_bc: 0.00324059; loss_div: 0.00027863; loss_ff: 0.00009170] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training: 100%|█████████▉| 1998/2000 [02:27<00:00, 13.61it/s][Iteration 002000/002000] [loss: 0.00349674] [loss_bc: 0.00313647; loss_div: 0.00026239; loss_ff: 0.00009788] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training: 100%|██████████| 2000/2000 [02:27<00:00, 13.54it/s]\n",
      "[Iteration 002000/002000] [loss: 0.00349674] [loss_bc: 0.00313647; loss_div: 0.00026239; loss_ff: 0.00009788] [w_bc: 1.000000, LR: 0.000050]\n",
      "Runtime --> total: 147.84sec (2.96ms/iter.)\n",
      "Configuration:\n",
      "dim: 256, w_div: 1.000000, w_ff: 1.000000, decay_iterations: None, potential: True, vector_potential: False, \n",
      "Using device: cuda (gpus 1) ['NVIDIA RTX A6000']\n",
      "Potential Boundary: 100%|██████████| 1/1 [00:01<00:00,  1.27s/it]\n",
      "Loaded meta state: /userhome/jeon_mg/workspace/_data/NOAA12673/PINN/20170904_100000/model_final.pt\n",
      "Training:   0%|          | 0/2000 [00:00<?, ?it/s][Iteration 000000/002000] [loss: 0.00368161] [loss_bc: 0.00320326; loss_div: 0.00031410; loss_ff: 0.00016424] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:   5%|▍         | 98/2000 [00:07<02:20, 13.50it/s][Iteration 000100/002000] [loss: 0.00376488] [loss_bc: 0.00338795; loss_div: 0.00026585; loss_ff: 0.00011108] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  10%|▉         | 198/2000 [00:14<02:12, 13.58it/s][Iteration 000200/002000] [loss: 0.00357005] [loss_bc: 0.00319019; loss_div: 0.00028290; loss_ff: 0.00009696] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  15%|█▍        | 298/2000 [00:21<02:05, 13.59it/s][Iteration 000300/002000] [loss: 0.00356624] [loss_bc: 0.00318128; loss_div: 0.00027329; loss_ff: 0.00011167] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  20%|█▉        | 398/2000 [00:29<01:57, 13.65it/s][Iteration 000400/002000] [loss: 0.00354371] [loss_bc: 0.00318299; loss_div: 0.00025662; loss_ff: 0.00010410] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  25%|██▍       | 498/2000 [00:36<01:50, 13.60it/s][Iteration 000500/002000] [loss: 0.00374897] [loss_bc: 0.00337134; loss_div: 0.00027740; loss_ff: 0.00010023] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  30%|██▉       | 598/2000 [00:44<01:42, 13.65it/s][Iteration 000600/002000] [loss: 0.00347447] [loss_bc: 0.00307188; loss_div: 0.00029000; loss_ff: 0.00011259] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  35%|███▍      | 698/2000 [00:51<01:35, 13.61it/s][Iteration 000700/002000] [loss: 0.00342992] [loss_bc: 0.00305768; loss_div: 0.00027872; loss_ff: 0.00009352] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  40%|███▉      | 798/2000 [00:58<01:27, 13.67it/s][Iteration 000800/002000] [loss: 0.00354687] [loss_bc: 0.00318143; loss_div: 0.00026648; loss_ff: 0.00009896] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  45%|████▍     | 898/2000 [01:06<01:21, 13.52it/s][Iteration 000900/002000] [loss: 0.00345298] [loss_bc: 0.00306104; loss_div: 0.00030011; loss_ff: 0.00009182] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  50%|████▉     | 998/2000 [01:13<01:13, 13.72it/s][Iteration 001000/002000] [loss: 0.00353242] [loss_bc: 0.00317103; loss_div: 0.00026631; loss_ff: 0.00009508] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  55%|█████▍    | 1098/2000 [01:20<01:06, 13.61it/s][Iteration 001100/002000] [loss: 0.00385546] [loss_bc: 0.00334948; loss_div: 0.00030758; loss_ff: 0.00019841] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  60%|█████▉    | 1198/2000 [01:28<00:58, 13.61it/s][Iteration 001200/002000] [loss: 0.00350404] [loss_bc: 0.00310807; loss_div: 0.00027049; loss_ff: 0.00012547] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  65%|██████▍   | 1298/2000 [01:35<00:50, 13.85it/s][Iteration 001300/002000] [loss: 0.00364501] [loss_bc: 0.00317038; loss_div: 0.00033048; loss_ff: 0.00014414] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  70%|██████▉   | 1398/2000 [01:42<00:44, 13.58it/s][Iteration 001400/002000] [loss: 0.00351272] [loss_bc: 0.00306183; loss_div: 0.00031641; loss_ff: 0.00013448] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  75%|███████▍  | 1498/2000 [01:50<00:36, 13.61it/s][Iteration 001500/002000] [loss: 0.00363598] [loss_bc: 0.00325454; loss_div: 0.00027615; loss_ff: 0.00010529] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  80%|███████▉  | 1598/2000 [01:57<00:29, 13.63it/s][Iteration 001600/002000] [loss: 0.00340691] [loss_bc: 0.00305219; loss_div: 0.00025555; loss_ff: 0.00009917] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  85%|████████▍ | 1698/2000 [02:05<00:21, 13.86it/s][Iteration 001700/002000] [loss: 0.00375821] [loss_bc: 0.00341090; loss_div: 0.00024081; loss_ff: 0.00010649] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  90%|████████▉ | 1798/2000 [02:12<00:14, 13.58it/s][Iteration 001800/002000] [loss: 0.00360993] [loss_bc: 0.00316206; loss_div: 0.00030547; loss_ff: 0.00014241] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  95%|█████████▍| 1898/2000 [02:19<00:07, 13.64it/s][Iteration 001900/002000] [loss: 0.00345709] [loss_bc: 0.00308983; loss_div: 0.00026383; loss_ff: 0.00010343] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training: 100%|█████████▉| 1998/2000 [02:27<00:00, 13.82it/s][Iteration 002000/002000] [loss: 0.00345398] [loss_bc: 0.00304091; loss_div: 0.00027982; loss_ff: 0.00013325] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training: 100%|██████████| 2000/2000 [02:27<00:00, 13.56it/s]\n",
      "[Iteration 002000/002000] [loss: 0.00345398] [loss_bc: 0.00304091; loss_div: 0.00027982; loss_ff: 0.00013325] [w_bc: 1.000000, LR: 0.000050]\n",
      "Runtime --> total: 147.70sec (2.95ms/iter.)\n",
      "Configuration:\n",
      "dim: 256, w_div: 1.000000, w_ff: 1.000000, decay_iterations: None, potential: True, vector_potential: False, \n",
      "Using device: cuda (gpus 1) ['NVIDIA RTX A6000']\n",
      "Potential Boundary: 100%|██████████| 1/1 [00:00<00:00,  1.05it/s]\n",
      "Loaded meta state: /userhome/jeon_mg/workspace/_data/NOAA12673/PINN/20170904_101200/model_final.pt\n",
      "Training:   0%|          | 0/2000 [00:00<?, ?it/s][Iteration 000000/002000] [loss: 0.00359886] [loss_bc: 0.00317029; loss_div: 0.00028936; loss_ff: 0.00013921] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:   5%|▍         | 98/2000 [00:07<02:18, 13.75it/s][Iteration 000100/002000] [loss: 0.00376205] [loss_bc: 0.00333656; loss_div: 0.00029443; loss_ff: 0.00013106] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  10%|▉         | 198/2000 [00:14<02:13, 13.53it/s][Iteration 000200/002000] [loss: 0.00343967] [loss_bc: 0.00308033; loss_div: 0.00025623; loss_ff: 0.00010311] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  15%|█▍        | 298/2000 [00:21<02:04, 13.62it/s][Iteration 000300/002000] [loss: 0.00385305] [loss_bc: 0.00346531; loss_div: 0.00027991; loss_ff: 0.00010782] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  20%|█▉        | 398/2000 [00:29<01:57, 13.64it/s][Iteration 000400/002000] [loss: 0.00349376] [loss_bc: 0.00307125; loss_div: 0.00030785; loss_ff: 0.00011467] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  25%|██▍       | 498/2000 [00:36<01:50, 13.58it/s][Iteration 000500/002000] [loss: 0.00387684] [loss_bc: 0.00345580; loss_div: 0.00028096; loss_ff: 0.00014009] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  30%|██▉       | 598/2000 [00:44<01:43, 13.48it/s][Iteration 000600/002000] [loss: 0.00363213] [loss_bc: 0.00325849; loss_div: 0.00025746; loss_ff: 0.00011618] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  35%|███▍      | 698/2000 [00:51<01:36, 13.53it/s][Iteration 000700/002000] [loss: 0.00366186] [loss_bc: 0.00331033; loss_div: 0.00026199; loss_ff: 0.00008954] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  40%|███▉      | 798/2000 [00:58<01:28, 13.63it/s][Iteration 000800/002000] [loss: 0.00359893] [loss_bc: 0.00322303; loss_div: 0.00027842; loss_ff: 0.00009749] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  45%|████▍     | 898/2000 [01:06<01:21, 13.60it/s][Iteration 000900/002000] [loss: 0.00365805] [loss_bc: 0.00325145; loss_div: 0.00027550; loss_ff: 0.00013110] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  50%|████▉     | 998/2000 [01:13<01:13, 13.57it/s][Iteration 001000/002000] [loss: 0.00349780] [loss_bc: 0.00313744; loss_div: 0.00026189; loss_ff: 0.00009847] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  55%|█████▍    | 1098/2000 [01:21<01:06, 13.64it/s][Iteration 001100/002000] [loss: 0.00369728] [loss_bc: 0.00329340; loss_div: 0.00026868; loss_ff: 0.00013520] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  60%|█████▉    | 1198/2000 [01:28<00:59, 13.48it/s][Iteration 001200/002000] [loss: 0.00358225] [loss_bc: 0.00319045; loss_div: 0.00028214; loss_ff: 0.00010966] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  65%|██████▍   | 1298/2000 [01:35<00:51, 13.63it/s][Iteration 001300/002000] [loss: 0.00367015] [loss_bc: 0.00329091; loss_div: 0.00026538; loss_ff: 0.00011386] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  70%|██████▉   | 1398/2000 [01:43<00:44, 13.51it/s][Iteration 001400/002000] [loss: 0.00383539] [loss_bc: 0.00343122; loss_div: 0.00028642; loss_ff: 0.00011775] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  75%|███████▍  | 1498/2000 [01:50<00:36, 13.58it/s][Iteration 001500/002000] [loss: 0.00368465] [loss_bc: 0.00328161; loss_div: 0.00028704; loss_ff: 0.00011599] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  80%|███████▉  | 1598/2000 [01:57<00:29, 13.56it/s][Iteration 001600/002000] [loss: 0.00350882] [loss_bc: 0.00312716; loss_div: 0.00026541; loss_ff: 0.00011625] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  85%|████████▍ | 1698/2000 [02:05<00:22, 13.53it/s][Iteration 001700/002000] [loss: 0.00362691] [loss_bc: 0.00321391; loss_div: 0.00025958; loss_ff: 0.00015342] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  90%|████████▉ | 1798/2000 [02:12<00:14, 13.57it/s][Iteration 001800/002000] [loss: 0.00360497] [loss_bc: 0.00323409; loss_div: 0.00026692; loss_ff: 0.00010396] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  95%|█████████▍| 1898/2000 [02:20<00:07, 13.72it/s][Iteration 001900/002000] [loss: 0.00363018] [loss_bc: 0.00321454; loss_div: 0.00029891; loss_ff: 0.00011673] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training: 100%|█████████▉| 1998/2000 [02:27<00:00, 13.58it/s][Iteration 002000/002000] [loss: 0.00336649] [loss_bc: 0.00295371; loss_div: 0.00029359; loss_ff: 0.00011919] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training: 100%|██████████| 2000/2000 [02:27<00:00, 13.53it/s]\n",
      "[Iteration 002000/002000] [loss: 0.00336649] [loss_bc: 0.00295371; loss_div: 0.00029359; loss_ff: 0.00011919] [w_bc: 1.000000, LR: 0.000050]\n",
      "Runtime --> total: 148.04sec (2.96ms/iter.)\n",
      "Configuration:\n",
      "dim: 256, w_div: 1.000000, w_ff: 1.000000, decay_iterations: None, potential: True, vector_potential: False, \n",
      "Using device: cuda (gpus 1) ['NVIDIA RTX A6000']\n",
      "Potential Boundary: 100%|██████████| 1/1 [00:01<00:00,  1.00s/it]\n",
      "Loaded meta state: /userhome/jeon_mg/workspace/_data/NOAA12673/PINN/20170904_102400/model_final.pt\n",
      "Training:   0%|          | 0/2000 [00:00<?, ?it/s][Iteration 000000/002000] [loss: 0.00342261] [loss_bc: 0.00304844; loss_div: 0.00025275; loss_ff: 0.00012142] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:   5%|▍         | 98/2000 [00:07<02:19, 13.63it/s][Iteration 000100/002000] [loss: 0.00361872] [loss_bc: 0.00324103; loss_div: 0.00027222; loss_ff: 0.00010547] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  10%|▉         | 198/2000 [00:14<02:09, 13.94it/s][Iteration 000200/002000] [loss: 0.00385922] [loss_bc: 0.00346335; loss_div: 0.00028358; loss_ff: 0.00011228] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  15%|█▍        | 298/2000 [00:21<02:05, 13.55it/s][Iteration 000300/002000] [loss: 0.00393752] [loss_bc: 0.00345708; loss_div: 0.00033017; loss_ff: 0.00015028] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  20%|█▉        | 398/2000 [00:29<01:56, 13.79it/s][Iteration 000400/002000] [loss: 0.00351926] [loss_bc: 0.00309537; loss_div: 0.00029041; loss_ff: 0.00013347] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  25%|██▍       | 498/2000 [00:36<01:48, 13.87it/s][Iteration 000500/002000] [loss: 0.00367099] [loss_bc: 0.00322346; loss_div: 0.00034336; loss_ff: 0.00010416] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  30%|██▉       | 598/2000 [00:43<01:42, 13.68it/s][Iteration 000600/002000] [loss: 0.00346103] [loss_bc: 0.00302761; loss_div: 0.00032051; loss_ff: 0.00011290] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  35%|███▍      | 698/2000 [00:51<01:35, 13.63it/s][Iteration 000700/002000] [loss: 0.00353102] [loss_bc: 0.00321546; loss_div: 0.00023414; loss_ff: 0.00008142] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  40%|███▉      | 798/2000 [00:58<01:27, 13.80it/s][Iteration 000800/002000] [loss: 0.00359742] [loss_bc: 0.00316883; loss_div: 0.00030710; loss_ff: 0.00012149] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  45%|████▍     | 898/2000 [01:05<01:20, 13.72it/s][Iteration 000900/002000] [loss: 0.00358752] [loss_bc: 0.00321338; loss_div: 0.00027320; loss_ff: 0.00010094] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  50%|████▉     | 998/2000 [01:13<01:13, 13.71it/s][Iteration 001000/002000] [loss: 0.00339546] [loss_bc: 0.00304399; loss_div: 0.00025361; loss_ff: 0.00009786] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  55%|█████▍    | 1098/2000 [01:20<01:06, 13.59it/s][Iteration 001100/002000] [loss: 0.00352335] [loss_bc: 0.00303779; loss_div: 0.00031903; loss_ff: 0.00016654] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  60%|█████▉    | 1198/2000 [01:28<00:59, 13.56it/s][Iteration 001200/002000] [loss: 0.00360656] [loss_bc: 0.00320718; loss_div: 0.00030470; loss_ff: 0.00009468] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  65%|██████▍   | 1298/2000 [01:35<00:51, 13.53it/s][Iteration 001300/002000] [loss: 0.00350226] [loss_bc: 0.00307755; loss_div: 0.00031297; loss_ff: 0.00011173] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  70%|██████▉   | 1398/2000 [01:42<00:44, 13.53it/s][Iteration 001400/002000] [loss: 0.00359674] [loss_bc: 0.00320288; loss_div: 0.00028498; loss_ff: 0.00010888] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  75%|███████▍  | 1498/2000 [01:50<00:37, 13.51it/s][Iteration 001500/002000] [loss: 0.00359861] [loss_bc: 0.00318958; loss_div: 0.00030482; loss_ff: 0.00010421] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  80%|███████▉  | 1598/2000 [01:57<00:29, 13.62it/s][Iteration 001600/002000] [loss: 0.00359319] [loss_bc: 0.00319790; loss_div: 0.00030072; loss_ff: 0.00009457] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  85%|████████▍ | 1698/2000 [02:04<00:22, 13.62it/s][Iteration 001700/002000] [loss: 0.00358305] [loss_bc: 0.00319743; loss_div: 0.00026577; loss_ff: 0.00011985] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  90%|████████▉ | 1798/2000 [02:12<00:14, 13.51it/s][Iteration 001800/002000] [loss: 0.00349661] [loss_bc: 0.00302669; loss_div: 0.00030963; loss_ff: 0.00016028] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  95%|█████████▍| 1898/2000 [02:19<00:07, 13.51it/s][Iteration 001900/002000] [loss: 0.00339720] [loss_bc: 0.00300874; loss_div: 0.00027956; loss_ff: 0.00010890] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training: 100%|█████████▉| 1998/2000 [02:27<00:00, 13.55it/s][Iteration 002000/002000] [loss: 0.00350900] [loss_bc: 0.00306496; loss_div: 0.00033795; loss_ff: 0.00010609] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training: 100%|██████████| 2000/2000 [02:27<00:00, 13.57it/s]\n",
      "[Iteration 002000/002000] [loss: 0.00350900] [loss_bc: 0.00306496; loss_div: 0.00033795; loss_ff: 0.00010609] [w_bc: 1.000000, LR: 0.000050]\n",
      "Runtime --> total: 147.58sec (2.95ms/iter.)\n",
      "Configuration:\n",
      "dim: 256, w_div: 1.000000, w_ff: 1.000000, decay_iterations: None, potential: True, vector_potential: False, \n",
      "Using device: cuda (gpus 1) ['NVIDIA RTX A6000']\n",
      "Potential Boundary: 100%|██████████| 1/1 [00:00<00:00,  1.08it/s]\n",
      "Loaded meta state: /userhome/jeon_mg/workspace/_data/NOAA12673/PINN/20170904_103600/model_final.pt\n",
      "Training:   0%|          | 0/2000 [00:00<?, ?it/s][Iteration 000000/002000] [loss: 0.00357561] [loss_bc: 0.00320374; loss_div: 0.00027917; loss_ff: 0.00009269] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:   5%|▍         | 98/2000 [00:07<02:21, 13.48it/s][Iteration 000100/002000] [loss: 0.00351244] [loss_bc: 0.00312632; loss_div: 0.00028669; loss_ff: 0.00009943] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  10%|▉         | 198/2000 [00:14<02:12, 13.59it/s][Iteration 000200/002000] [loss: 0.00381766] [loss_bc: 0.00340219; loss_div: 0.00029313; loss_ff: 0.00012234] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  15%|█▍        | 298/2000 [00:21<02:04, 13.63it/s][Iteration 000300/002000] [loss: 0.00361368] [loss_bc: 0.00319087; loss_div: 0.00029792; loss_ff: 0.00012489] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  20%|█▉        | 398/2000 [00:29<01:58, 13.50it/s][Iteration 000400/002000] [loss: 0.00348066] [loss_bc: 0.00306004; loss_div: 0.00029184; loss_ff: 0.00012878] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  25%|██▍       | 498/2000 [00:36<01:50, 13.56it/s][Iteration 000500/002000] [loss: 0.00365411] [loss_bc: 0.00320779; loss_div: 0.00032040; loss_ff: 0.00012592] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  30%|██▉       | 598/2000 [00:44<01:43, 13.57it/s][Iteration 000600/002000] [loss: 0.00327678] [loss_bc: 0.00287016; loss_div: 0.00027696; loss_ff: 0.00012966] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  35%|███▍      | 698/2000 [00:51<01:35, 13.62it/s][Iteration 000700/002000] [loss: 0.00393305] [loss_bc: 0.00346166; loss_div: 0.00032430; loss_ff: 0.00014709] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  40%|███▉      | 798/2000 [00:58<01:28, 13.55it/s][Iteration 000800/002000] [loss: 0.00349192] [loss_bc: 0.00310816; loss_div: 0.00028291; loss_ff: 0.00010085] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  45%|████▍     | 898/2000 [01:06<01:19, 13.84it/s][Iteration 000900/002000] [loss: 0.00352421] [loss_bc: 0.00317055; loss_div: 0.00025961; loss_ff: 0.00009405] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  50%|████▉     | 998/2000 [01:13<01:13, 13.57it/s][Iteration 001000/002000] [loss: 0.00395923] [loss_bc: 0.00344781; loss_div: 0.00033644; loss_ff: 0.00017498] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  55%|█████▍    | 1098/2000 [01:20<01:06, 13.60it/s][Iteration 001100/002000] [loss: 0.00345264] [loss_bc: 0.00303999; loss_div: 0.00028579; loss_ff: 0.00012685] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  60%|█████▉    | 1198/2000 [01:28<00:58, 13.64it/s][Iteration 001200/002000] [loss: 0.00360090] [loss_bc: 0.00318277; loss_div: 0.00030229; loss_ff: 0.00011584] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  65%|██████▍   | 1298/2000 [01:35<00:50, 13.81it/s][Iteration 001300/002000] [loss: 0.00328916] [loss_bc: 0.00285072; loss_div: 0.00030529; loss_ff: 0.00013315] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  70%|██████▉   | 1398/2000 [01:43<00:43, 13.88it/s][Iteration 001400/002000] [loss: 0.00353282] [loss_bc: 0.00318267; loss_div: 0.00026644; loss_ff: 0.00008371] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  75%|███████▍  | 1498/2000 [01:50<00:36, 13.61it/s][Iteration 001500/002000] [loss: 0.00324951] [loss_bc: 0.00284762; loss_div: 0.00029453; loss_ff: 0.00010736] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  80%|███████▉  | 1598/2000 [01:57<00:29, 13.64it/s][Iteration 001600/002000] [loss: 0.00342559] [loss_bc: 0.00304323; loss_div: 0.00025380; loss_ff: 0.00012856] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  85%|████████▍ | 1698/2000 [02:05<00:22, 13.48it/s][Iteration 001700/002000] [loss: 0.00355049] [loss_bc: 0.00315367; loss_div: 0.00029795; loss_ff: 0.00009888] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  90%|████████▉ | 1798/2000 [02:12<00:14, 13.52it/s][Iteration 001800/002000] [loss: 0.00361753] [loss_bc: 0.00318031; loss_div: 0.00029953; loss_ff: 0.00013769] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  95%|█████████▍| 1898/2000 [02:19<00:07, 13.62it/s][Iteration 001900/002000] [loss: 0.00360573] [loss_bc: 0.00318187; loss_div: 0.00029219; loss_ff: 0.00013167] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training: 100%|█████████▉| 1998/2000 [02:27<00:00, 13.63it/s][Iteration 002000/002000] [loss: 0.00357414] [loss_bc: 0.00314277; loss_div: 0.00030988; loss_ff: 0.00012149] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training: 100%|██████████| 2000/2000 [02:27<00:00, 13.54it/s]\n",
      "[Iteration 002000/002000] [loss: 0.00357414] [loss_bc: 0.00314277; loss_div: 0.00030988; loss_ff: 0.00012149] [w_bc: 1.000000, LR: 0.000050]\n",
      "Runtime --> total: 147.85sec (2.96ms/iter.)\n",
      "Configuration:\n",
      "dim: 256, w_div: 1.000000, w_ff: 1.000000, decay_iterations: None, potential: True, vector_potential: False, \n",
      "Using device: cuda (gpus 1) ['NVIDIA RTX A6000']\n",
      "Potential Boundary: 100%|██████████| 1/1 [00:00<00:00,  1.10it/s]\n",
      "Loaded meta state: /userhome/jeon_mg/workspace/_data/NOAA12673/PINN/20170904_104800/model_final.pt\n",
      "Training:   0%|          | 0/2000 [00:00<?, ?it/s][Iteration 000000/002000] [loss: 0.00373655] [loss_bc: 0.00326792; loss_div: 0.00031867; loss_ff: 0.00014996] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:   5%|▍         | 98/2000 [00:07<02:21, 13.47it/s][Iteration 000100/002000] [loss: 0.00357821] [loss_bc: 0.00322998; loss_div: 0.00025276; loss_ff: 0.00009547] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  10%|▉         | 198/2000 [00:14<02:13, 13.53it/s][Iteration 000200/002000] [loss: 0.00349151] [loss_bc: 0.00313204; loss_div: 0.00026939; loss_ff: 0.00009008] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  15%|█▍        | 298/2000 [00:21<02:04, 13.66it/s][Iteration 000300/002000] [loss: 0.00344004] [loss_bc: 0.00304362; loss_div: 0.00028193; loss_ff: 0.00011448] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  20%|█▉        | 398/2000 [00:29<01:58, 13.47it/s][Iteration 000400/002000] [loss: 0.00353635] [loss_bc: 0.00314830; loss_div: 0.00026008; loss_ff: 0.00012797] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  25%|██▍       | 498/2000 [00:36<01:50, 13.56it/s][Iteration 000500/002000] [loss: 0.00355818] [loss_bc: 0.00312325; loss_div: 0.00031717; loss_ff: 0.00011776] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  30%|██▉       | 598/2000 [00:44<01:43, 13.60it/s][Iteration 000600/002000] [loss: 0.00357591] [loss_bc: 0.00315596; loss_div: 0.00028915; loss_ff: 0.00013079] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  35%|███▍      | 698/2000 [00:51<01:35, 13.59it/s][Iteration 000700/002000] [loss: 0.00367375] [loss_bc: 0.00329015; loss_div: 0.00028529; loss_ff: 0.00009831] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  40%|███▉      | 798/2000 [00:58<01:28, 13.59it/s][Iteration 000800/002000] [loss: 0.00340081] [loss_bc: 0.00303500; loss_div: 0.00026558; loss_ff: 0.00010024] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  45%|████▍     | 898/2000 [01:06<01:21, 13.55it/s][Iteration 000900/002000] [loss: 0.00362455] [loss_bc: 0.00323966; loss_div: 0.00025929; loss_ff: 0.00012560] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  50%|████▉     | 998/2000 [01:13<01:14, 13.53it/s][Iteration 001000/002000] [loss: 0.00372255] [loss_bc: 0.00330643; loss_div: 0.00028662; loss_ff: 0.00012950] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  55%|█████▍    | 1098/2000 [01:21<01:05, 13.67it/s][Iteration 001100/002000] [loss: 0.00354828] [loss_bc: 0.00318739; loss_div: 0.00026820; loss_ff: 0.00009269] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  60%|█████▉    | 1198/2000 [01:28<00:58, 13.61it/s][Iteration 001200/002000] [loss: 0.00361175] [loss_bc: 0.00320170; loss_div: 0.00029185; loss_ff: 0.00011820] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  65%|██████▍   | 1298/2000 [01:35<00:50, 13.82it/s][Iteration 001300/002000] [loss: 0.00369166] [loss_bc: 0.00329426; loss_div: 0.00027231; loss_ff: 0.00012509] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  70%|██████▉   | 1398/2000 [01:43<00:44, 13.60it/s][Iteration 001400/002000] [loss: 0.00364448] [loss_bc: 0.00320209; loss_div: 0.00029883; loss_ff: 0.00014355] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  75%|███████▍  | 1498/2000 [01:50<00:37, 13.45it/s][Iteration 001500/002000] [loss: 0.00361537] [loss_bc: 0.00320768; loss_div: 0.00030210; loss_ff: 0.00010558] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  80%|███████▉  | 1598/2000 [01:57<00:29, 13.54it/s][Iteration 001600/002000] [loss: 0.00371780] [loss_bc: 0.00327116; loss_div: 0.00032351; loss_ff: 0.00012313] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  85%|████████▍ | 1698/2000 [02:05<00:22, 13.63it/s][Iteration 001700/002000] [loss: 0.00369130] [loss_bc: 0.00327704; loss_div: 0.00026903; loss_ff: 0.00014523] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  90%|████████▉ | 1798/2000 [02:12<00:14, 13.62it/s][Iteration 001800/002000] [loss: 0.00348035] [loss_bc: 0.00311361; loss_div: 0.00026987; loss_ff: 0.00009687] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  95%|█████████▍| 1898/2000 [02:20<00:07, 13.61it/s][Iteration 001900/002000] [loss: 0.00360797] [loss_bc: 0.00323405; loss_div: 0.00025977; loss_ff: 0.00011415] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training: 100%|█████████▉| 1998/2000 [02:27<00:00, 13.61it/s][Iteration 002000/002000] [loss: 0.00369114] [loss_bc: 0.00326000; loss_div: 0.00028842; loss_ff: 0.00014272] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training: 100%|██████████| 2000/2000 [02:27<00:00, 13.53it/s]\n",
      "[Iteration 002000/002000] [loss: 0.00369114] [loss_bc: 0.00326000; loss_div: 0.00028842; loss_ff: 0.00014272] [w_bc: 1.000000, LR: 0.000050]\n",
      "Runtime --> total: 147.97sec (2.96ms/iter.)\n",
      "Configuration:\n",
      "dim: 256, w_div: 1.000000, w_ff: 1.000000, decay_iterations: None, potential: True, vector_potential: False, \n",
      "Using device: cuda (gpus 1) ['NVIDIA RTX A6000']\n",
      "Potential Boundary: 100%|██████████| 1/1 [00:00<00:00,  1.01it/s]\n",
      "Loaded meta state: /userhome/jeon_mg/workspace/_data/NOAA12673/PINN/20170904_110000/model_final.pt\n",
      "Training:   0%|          | 0/2000 [00:00<?, ?it/s][Iteration 000000/002000] [loss: 0.00368208] [loss_bc: 0.00330742; loss_div: 0.00026190; loss_ff: 0.00011276] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:   5%|▍         | 98/2000 [00:07<02:20, 13.56it/s][Iteration 000100/002000] [loss: 0.00355828] [loss_bc: 0.00317356; loss_div: 0.00027480; loss_ff: 0.00010991] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  10%|▉         | 198/2000 [00:14<02:12, 13.63it/s][Iteration 000200/002000] [loss: 0.00372255] [loss_bc: 0.00326967; loss_div: 0.00030032; loss_ff: 0.00015256] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  15%|█▍        | 298/2000 [00:21<02:03, 13.75it/s][Iteration 000300/002000] [loss: 0.00368431] [loss_bc: 0.00329928; loss_div: 0.00029579; loss_ff: 0.00008924] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  20%|█▉        | 398/2000 [00:29<01:57, 13.61it/s][Iteration 000400/002000] [loss: 0.00368972] [loss_bc: 0.00329173; loss_div: 0.00027254; loss_ff: 0.00012545] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  25%|██▍       | 498/2000 [00:36<01:48, 13.81it/s][Iteration 000500/002000] [loss: 0.00359090] [loss_bc: 0.00318496; loss_div: 0.00031285; loss_ff: 0.00009309] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  30%|██▉       | 598/2000 [00:43<01:43, 13.51it/s][Iteration 000600/002000] [loss: 0.00363729] [loss_bc: 0.00315142; loss_div: 0.00033707; loss_ff: 0.00014879] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  35%|███▍      | 698/2000 [00:51<01:36, 13.54it/s][Iteration 000700/002000] [loss: 0.00362603] [loss_bc: 0.00325264; loss_div: 0.00026653; loss_ff: 0.00010686] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  40%|███▉      | 798/2000 [00:58<01:27, 13.74it/s][Iteration 000800/002000] [loss: 0.00367537] [loss_bc: 0.00328287; loss_div: 0.00029645; loss_ff: 0.00009605] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  45%|████▍     | 898/2000 [01:06<01:21, 13.56it/s][Iteration 000900/002000] [loss: 0.00362912] [loss_bc: 0.00321223; loss_div: 0.00027282; loss_ff: 0.00014407] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  50%|████▉     | 998/2000 [01:13<01:14, 13.54it/s][Iteration 001000/002000] [loss: 0.00374105] [loss_bc: 0.00328165; loss_div: 0.00031811; loss_ff: 0.00014129] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  55%|█████▍    | 1098/2000 [01:20<01:06, 13.57it/s][Iteration 001100/002000] [loss: 0.00355219] [loss_bc: 0.00314403; loss_div: 0.00031380; loss_ff: 0.00009436] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  60%|█████▉    | 1198/2000 [01:28<00:58, 13.78it/s][Iteration 001200/002000] [loss: 0.00367533] [loss_bc: 0.00327278; loss_div: 0.00028999; loss_ff: 0.00011256] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  65%|██████▍   | 1298/2000 [01:35<00:51, 13.61it/s][Iteration 001300/002000] [loss: 0.00350463] [loss_bc: 0.00314364; loss_div: 0.00025829; loss_ff: 0.00010271] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  70%|██████▉   | 1398/2000 [01:43<00:44, 13.61it/s][Iteration 001400/002000] [loss: 0.00360042] [loss_bc: 0.00317486; loss_div: 0.00031362; loss_ff: 0.00011194] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  75%|███████▍  | 1498/2000 [01:50<00:36, 13.60it/s][Iteration 001500/002000] [loss: 0.00364775] [loss_bc: 0.00327537; loss_div: 0.00026683; loss_ff: 0.00010555] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  80%|███████▉  | 1598/2000 [01:57<00:29, 13.85it/s][Iteration 001600/002000] [loss: 0.00379922] [loss_bc: 0.00335129; loss_div: 0.00032288; loss_ff: 0.00012504] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  85%|████████▍ | 1698/2000 [02:05<00:22, 13.60it/s][Iteration 001700/002000] [loss: 0.00359179] [loss_bc: 0.00318451; loss_div: 0.00028232; loss_ff: 0.00012496] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  90%|████████▉ | 1798/2000 [02:12<00:14, 13.88it/s][Iteration 001800/002000] [loss: 0.00357263] [loss_bc: 0.00323736; loss_div: 0.00024796; loss_ff: 0.00008731] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  95%|█████████▍| 1898/2000 [02:19<00:07, 13.93it/s][Iteration 001900/002000] [loss: 0.00358777] [loss_bc: 0.00312339; loss_div: 0.00034045; loss_ff: 0.00012392] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training: 100%|█████████▉| 1998/2000 [02:26<00:00, 13.94it/s][Iteration 002000/002000] [loss: 0.00376136] [loss_bc: 0.00333838; loss_div: 0.00032027; loss_ff: 0.00010271] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training: 100%|██████████| 2000/2000 [02:27<00:00, 13.57it/s]\n",
      "[Iteration 002000/002000] [loss: 0.00376136] [loss_bc: 0.00333838; loss_div: 0.00032027; loss_ff: 0.00010271] [w_bc: 1.000000, LR: 0.000050]\n",
      "Runtime --> total: 147.53sec (2.95ms/iter.)\n",
      "Configuration:\n",
      "dim: 256, w_div: 1.000000, w_ff: 1.000000, decay_iterations: None, potential: True, vector_potential: False, \n",
      "Using device: cuda (gpus 1) ['NVIDIA RTX A6000']\n",
      "Potential Boundary: 100%|██████████| 1/1 [00:01<00:00,  1.02s/it]\n",
      "Loaded meta state: /userhome/jeon_mg/workspace/_data/NOAA12673/PINN/20170904_111200/model_final.pt\n",
      "Training:   0%|          | 0/2000 [00:00<?, ?it/s][Iteration 000000/002000] [loss: 0.00337766] [loss_bc: 0.00295517; loss_div: 0.00032182; loss_ff: 0.00010067] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:   5%|▍         | 98/2000 [00:07<02:20, 13.57it/s][Iteration 000100/002000] [loss: 0.00369550] [loss_bc: 0.00326969; loss_div: 0.00031812; loss_ff: 0.00010769] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  10%|▉         | 198/2000 [00:14<02:12, 13.59it/s][Iteration 000200/002000] [loss: 0.00369730] [loss_bc: 0.00332089; loss_div: 0.00027466; loss_ff: 0.00010175] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  15%|█▍        | 298/2000 [00:21<02:02, 13.90it/s][Iteration 000300/002000] [loss: 0.00370687] [loss_bc: 0.00327886; loss_div: 0.00032638; loss_ff: 0.00010163] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  20%|█▉        | 398/2000 [00:29<01:57, 13.66it/s][Iteration 000400/002000] [loss: 0.00380666] [loss_bc: 0.00336123; loss_div: 0.00031125; loss_ff: 0.00013418] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  25%|██▍       | 498/2000 [00:36<01:50, 13.61it/s][Iteration 000500/002000] [loss: 0.00345413] [loss_bc: 0.00300840; loss_div: 0.00030240; loss_ff: 0.00014333] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  30%|██▉       | 598/2000 [00:43<01:42, 13.62it/s][Iteration 000600/002000] [loss: 0.00334069] [loss_bc: 0.00294054; loss_div: 0.00028396; loss_ff: 0.00011619] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  35%|███▍      | 698/2000 [00:51<01:35, 13.66it/s][Iteration 000700/002000] [loss: 0.00375666] [loss_bc: 0.00335421; loss_div: 0.00027615; loss_ff: 0.00012631] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  40%|███▉      | 798/2000 [00:58<01:28, 13.59it/s][Iteration 000800/002000] [loss: 0.00365328] [loss_bc: 0.00321197; loss_div: 0.00030933; loss_ff: 0.00013198] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  45%|████▍     | 898/2000 [01:06<01:21, 13.58it/s][Iteration 000900/002000] [loss: 0.00374793] [loss_bc: 0.00334909; loss_div: 0.00027209; loss_ff: 0.00012675] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  50%|████▉     | 998/2000 [01:13<01:13, 13.65it/s][Iteration 001000/002000] [loss: 0.00366047] [loss_bc: 0.00326703; loss_div: 0.00029000; loss_ff: 0.00010345] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  55%|█████▍    | 1098/2000 [01:20<01:06, 13.57it/s][Iteration 001100/002000] [loss: 0.00376115] [loss_bc: 0.00335162; loss_div: 0.00029462; loss_ff: 0.00011491] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  60%|█████▉    | 1198/2000 [01:28<00:57, 13.96it/s][Iteration 001200/002000] [loss: 0.00376000] [loss_bc: 0.00335031; loss_div: 0.00029370; loss_ff: 0.00011598] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  65%|██████▍   | 1298/2000 [01:35<00:51, 13.56it/s][Iteration 001300/002000] [loss: 0.00350032] [loss_bc: 0.00313269; loss_div: 0.00025625; loss_ff: 0.00011137] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  70%|██████▉   | 1398/2000 [01:42<00:43, 13.75it/s][Iteration 001400/002000] [loss: 0.00372781] [loss_bc: 0.00333812; loss_div: 0.00028824; loss_ff: 0.00010145] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  75%|███████▍  | 1498/2000 [01:50<00:36, 13.63it/s][Iteration 001500/002000] [loss: 0.00359382] [loss_bc: 0.00319800; loss_div: 0.00026754; loss_ff: 0.00012828] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  80%|███████▉  | 1598/2000 [01:57<00:29, 13.61it/s][Iteration 001600/002000] [loss: 0.00354823] [loss_bc: 0.00320069; loss_div: 0.00025575; loss_ff: 0.00009180] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  85%|████████▍ | 1698/2000 [02:04<00:22, 13.54it/s][Iteration 001700/002000] [loss: 0.00368770] [loss_bc: 0.00322678; loss_div: 0.00034956; loss_ff: 0.00011136] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  90%|████████▉ | 1798/2000 [02:12<00:14, 13.51it/s][Iteration 001800/002000] [loss: 0.00330444] [loss_bc: 0.00292199; loss_div: 0.00028440; loss_ff: 0.00009806] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  95%|█████████▍| 1898/2000 [02:19<00:07, 13.95it/s][Iteration 001900/002000] [loss: 0.00343596] [loss_bc: 0.00297824; loss_div: 0.00035016; loss_ff: 0.00010756] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training: 100%|█████████▉| 1998/2000 [02:26<00:00, 13.60it/s][Iteration 002000/002000] [loss: 0.00378830] [loss_bc: 0.00333133; loss_div: 0.00035078; loss_ff: 0.00010620] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training: 100%|██████████| 2000/2000 [02:27<00:00, 13.58it/s]\n",
      "[Iteration 002000/002000] [loss: 0.00378830] [loss_bc: 0.00333133; loss_div: 0.00035078; loss_ff: 0.00010620] [w_bc: 1.000000, LR: 0.000050]\n",
      "Runtime --> total: 147.47sec (2.95ms/iter.)\n",
      "Configuration:\n",
      "dim: 256, w_div: 1.000000, w_ff: 1.000000, decay_iterations: None, potential: True, vector_potential: False, \n",
      "Using device: cuda (gpus 1) ['NVIDIA RTX A6000']\n",
      "Potential Boundary: 100%|██████████| 1/1 [00:01<00:00,  1.03s/it]\n",
      "Loaded meta state: /userhome/jeon_mg/workspace/_data/NOAA12673/PINN/20170904_112400/model_final.pt\n",
      "Training:   0%|          | 0/2000 [00:00<?, ?it/s][Iteration 000000/002000] [loss: 0.00356939] [loss_bc: 0.00315962; loss_div: 0.00031230; loss_ff: 0.00009747] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:   5%|▍         | 98/2000 [00:07<02:19, 13.62it/s][Iteration 000100/002000] [loss: 0.00347920] [loss_bc: 0.00309473; loss_div: 0.00026887; loss_ff: 0.00011560] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  10%|▉         | 198/2000 [00:14<02:12, 13.57it/s][Iteration 000200/002000] [loss: 0.00397900] [loss_bc: 0.00353400; loss_div: 0.00030154; loss_ff: 0.00014346] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  15%|█▍        | 298/2000 [00:21<02:03, 13.75it/s][Iteration 000300/002000] [loss: 0.00347973] [loss_bc: 0.00306612; loss_div: 0.00029910; loss_ff: 0.00011452] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  20%|█▉        | 398/2000 [00:29<01:58, 13.57it/s][Iteration 000400/002000] [loss: 0.00363608] [loss_bc: 0.00323535; loss_div: 0.00028223; loss_ff: 0.00011850] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  25%|██▍       | 498/2000 [00:36<01:51, 13.46it/s][Iteration 000500/002000] [loss: 0.00341421] [loss_bc: 0.00306109; loss_div: 0.00027258; loss_ff: 0.00008054] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  30%|██▉       | 598/2000 [00:43<01:42, 13.62it/s][Iteration 000600/002000] [loss: 0.00347440] [loss_bc: 0.00307980; loss_div: 0.00028815; loss_ff: 0.00010645] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  35%|███▍      | 698/2000 [00:51<01:35, 13.64it/s][Iteration 000700/002000] [loss: 0.00371057] [loss_bc: 0.00325849; loss_div: 0.00031165; loss_ff: 0.00014043] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  40%|███▉      | 798/2000 [00:58<01:26, 13.88it/s][Iteration 000800/002000] [loss: 0.00338654] [loss_bc: 0.00304868; loss_div: 0.00025581; loss_ff: 0.00008205] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  45%|████▍     | 898/2000 [01:05<01:19, 13.90it/s][Iteration 000900/002000] [loss: 0.00380316] [loss_bc: 0.00333233; loss_div: 0.00036141; loss_ff: 0.00010942] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  50%|████▉     | 998/2000 [01:13<01:12, 13.91it/s][Iteration 001000/002000] [loss: 0.00378059] [loss_bc: 0.00333245; loss_div: 0.00032573; loss_ff: 0.00012241] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  55%|█████▍    | 1098/2000 [01:20<01:07, 13.45it/s][Iteration 001100/002000] [loss: 0.00343668] [loss_bc: 0.00305009; loss_div: 0.00029677; loss_ff: 0.00008982] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  60%|█████▉    | 1198/2000 [01:27<00:58, 13.71it/s][Iteration 001200/002000] [loss: 0.00351824] [loss_bc: 0.00305135; loss_div: 0.00033820; loss_ff: 0.00012869] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  65%|██████▍   | 1298/2000 [01:35<00:50, 13.93it/s][Iteration 001300/002000] [loss: 0.00352906] [loss_bc: 0.00307350; loss_div: 0.00033253; loss_ff: 0.00012304] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  70%|██████▉   | 1398/2000 [01:42<00:43, 13.80it/s][Iteration 001400/002000] [loss: 0.00378700] [loss_bc: 0.00332743; loss_div: 0.00030964; loss_ff: 0.00014992] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  75%|███████▍  | 1498/2000 [01:49<00:36, 13.57it/s][Iteration 001500/002000] [loss: 0.00378599] [loss_bc: 0.00333099; loss_div: 0.00029890; loss_ff: 0.00015610] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  80%|███████▉  | 1598/2000 [01:57<00:29, 13.48it/s][Iteration 001600/002000] [loss: 0.00354030] [loss_bc: 0.00312203; loss_div: 0.00030022; loss_ff: 0.00011805] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  85%|████████▍ | 1698/2000 [02:04<00:22, 13.56it/s][Iteration 001700/002000] [loss: 0.00365055] [loss_bc: 0.00323925; loss_div: 0.00029672; loss_ff: 0.00011458] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  90%|████████▉ | 1798/2000 [02:11<00:14, 13.56it/s][Iteration 001800/002000] [loss: 0.00378174] [loss_bc: 0.00332055; loss_div: 0.00029731; loss_ff: 0.00016387] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  95%|█████████▍| 1898/2000 [02:19<00:07, 13.80it/s][Iteration 001900/002000] [loss: 0.00365143] [loss_bc: 0.00324216; loss_div: 0.00028769; loss_ff: 0.00012158] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training: 100%|█████████▉| 1998/2000 [02:26<00:00, 13.75it/s][Iteration 002000/002000] [loss: 0.00351483] [loss_bc: 0.00311577; loss_div: 0.00030610; loss_ff: 0.00009297] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training: 100%|██████████| 2000/2000 [02:27<00:00, 13.56it/s]\n",
      "[Iteration 002000/002000] [loss: 0.00351483] [loss_bc: 0.00311577; loss_div: 0.00030610; loss_ff: 0.00009297] [w_bc: 1.000000, LR: 0.000050]\n",
      "Runtime --> total: 147.62sec (2.95ms/iter.)\n",
      "Configuration:\n",
      "dim: 256, w_div: 1.000000, w_ff: 1.000000, decay_iterations: None, potential: True, vector_potential: False, \n",
      "Using device: cuda (gpus 1) ['NVIDIA RTX A6000']\n",
      "Potential Boundary: 100%|██████████| 1/1 [00:00<00:00,  1.38it/s]\n",
      "Loaded meta state: /userhome/jeon_mg/workspace/_data/NOAA12673/PINN/20170904_113600/model_final.pt\n",
      "Training:   0%|          | 0/2000 [00:00<?, ?it/s][Iteration 000000/002000] [loss: 0.00353291] [loss_bc: 0.00313013; loss_div: 0.00030470; loss_ff: 0.00009808] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:   5%|▍         | 98/2000 [00:07<02:20, 13.58it/s][Iteration 000100/002000] [loss: 0.00374149] [loss_bc: 0.00331662; loss_div: 0.00029709; loss_ff: 0.00012778] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  10%|▉         | 198/2000 [00:14<02:10, 13.80it/s][Iteration 000200/002000] [loss: 0.00348828] [loss_bc: 0.00310235; loss_div: 0.00027056; loss_ff: 0.00011537] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  15%|█▍        | 298/2000 [00:21<02:04, 13.68it/s][Iteration 000300/002000] [loss: 0.00376040] [loss_bc: 0.00328818; loss_div: 0.00036331; loss_ff: 0.00010891] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  20%|█▉        | 398/2000 [00:29<01:58, 13.53it/s][Iteration 000400/002000] [loss: 0.00364310] [loss_bc: 0.00325163; loss_div: 0.00029215; loss_ff: 0.00009932] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  25%|██▍       | 498/2000 [00:36<01:51, 13.53it/s][Iteration 000500/002000] [loss: 0.00371786] [loss_bc: 0.00329570; loss_div: 0.00029288; loss_ff: 0.00012928] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  30%|██▉       | 598/2000 [00:43<01:43, 13.61it/s][Iteration 000600/002000] [loss: 0.00372631] [loss_bc: 0.00330026; loss_div: 0.00030957; loss_ff: 0.00011648] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  35%|███▍      | 698/2000 [00:51<01:35, 13.62it/s][Iteration 000700/002000] [loss: 0.00360254] [loss_bc: 0.00321255; loss_div: 0.00027591; loss_ff: 0.00011408] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  40%|███▉      | 798/2000 [00:58<01:26, 13.89it/s][Iteration 000800/002000] [loss: 0.00359318] [loss_bc: 0.00321601; loss_div: 0.00027086; loss_ff: 0.00010631] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  45%|████▍     | 898/2000 [01:05<01:21, 13.53it/s][Iteration 000900/002000] [loss: 0.00377542] [loss_bc: 0.00322253; loss_div: 0.00037632; loss_ff: 0.00017656] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  50%|████▉     | 998/2000 [01:13<01:13, 13.65it/s][Iteration 001000/002000] [loss: 0.00369318] [loss_bc: 0.00326479; loss_div: 0.00030395; loss_ff: 0.00012443] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  55%|█████▍    | 1098/2000 [01:20<01:05, 13.78it/s][Iteration 001100/002000] [loss: 0.00359481] [loss_bc: 0.00323791; loss_div: 0.00026597; loss_ff: 0.00009094] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  60%|█████▉    | 1198/2000 [01:28<00:59, 13.57it/s][Iteration 001200/002000] [loss: 0.00354734] [loss_bc: 0.00321193; loss_div: 0.00023539; loss_ff: 0.00010002] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  65%|██████▍   | 1298/2000 [01:35<00:51, 13.63it/s][Iteration 001300/002000] [loss: 0.00367982] [loss_bc: 0.00326196; loss_div: 0.00029720; loss_ff: 0.00012066] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  70%|██████▉   | 1398/2000 [01:42<00:44, 13.68it/s][Iteration 001400/002000] [loss: 0.00363050] [loss_bc: 0.00323488; loss_div: 0.00027809; loss_ff: 0.00011753] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  75%|███████▍  | 1498/2000 [01:50<00:37, 13.49it/s][Iteration 001500/002000] [loss: 0.00361063] [loss_bc: 0.00318732; loss_div: 0.00029882; loss_ff: 0.00012449] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  80%|███████▉  | 1598/2000 [01:57<00:29, 13.71it/s][Iteration 001600/002000] [loss: 0.00348239] [loss_bc: 0.00308751; loss_div: 0.00028693; loss_ff: 0.00010795] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  85%|████████▍ | 1698/2000 [02:04<00:21, 13.78it/s][Iteration 001700/002000] [loss: 0.00356118] [loss_bc: 0.00319809; loss_div: 0.00026843; loss_ff: 0.00009466] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  90%|████████▉ | 1798/2000 [02:12<00:14, 13.75it/s][Iteration 001800/002000] [loss: 0.00352286] [loss_bc: 0.00309301; loss_div: 0.00030846; loss_ff: 0.00012139] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  95%|█████████▍| 1898/2000 [02:19<00:07, 13.65it/s][Iteration 001900/002000] [loss: 0.00358763] [loss_bc: 0.00306832; loss_div: 0.00034447; loss_ff: 0.00017484] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training: 100%|█████████▉| 1998/2000 [02:26<00:00, 13.76it/s][Iteration 002000/002000] [loss: 0.00371318] [loss_bc: 0.00325307; loss_div: 0.00033216; loss_ff: 0.00012795] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training: 100%|██████████| 2000/2000 [02:27<00:00, 13.60it/s]\n",
      "[Iteration 002000/002000] [loss: 0.00371318] [loss_bc: 0.00325307; loss_div: 0.00033216; loss_ff: 0.00012795] [w_bc: 1.000000, LR: 0.000050]\n",
      "Runtime --> total: 147.37sec (2.95ms/iter.)\n",
      "Configuration:\n",
      "dim: 256, w_div: 1.000000, w_ff: 1.000000, decay_iterations: None, potential: True, vector_potential: False, \n",
      "Using device: cuda (gpus 1) ['NVIDIA RTX A6000']\n",
      "Potential Boundary: 100%|██████████| 1/1 [00:00<00:00,  1.71it/s]\n",
      "Loaded meta state: /userhome/jeon_mg/workspace/_data/NOAA12673/PINN/20170904_114800/model_final.pt\n",
      "Training:   0%|          | 0/2000 [00:00<?, ?it/s][Iteration 000000/002000] [loss: 0.00365230] [loss_bc: 0.00325641; loss_div: 0.00029693; loss_ff: 0.00009896] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:   5%|▍         | 98/2000 [00:07<02:21, 13.48it/s][Iteration 000100/002000] [loss: 0.00374301] [loss_bc: 0.00325792; loss_div: 0.00035143; loss_ff: 0.00013367] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  10%|▉         | 198/2000 [00:14<02:12, 13.58it/s][Iteration 000200/002000] [loss: 0.00389012] [loss_bc: 0.00343097; loss_div: 0.00034951; loss_ff: 0.00010963] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  15%|█▍        | 298/2000 [00:21<02:04, 13.71it/s][Iteration 000300/002000] [loss: 0.00367506] [loss_bc: 0.00324129; loss_div: 0.00031780; loss_ff: 0.00011596] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  20%|█▉        | 398/2000 [00:29<01:55, 13.82it/s][Iteration 000400/002000] [loss: 0.00367804] [loss_bc: 0.00324525; loss_div: 0.00029158; loss_ff: 0.00014120] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  25%|██▍       | 498/2000 [00:36<01:50, 13.57it/s][Iteration 000500/002000] [loss: 0.00383402] [loss_bc: 0.00343180; loss_div: 0.00029032; loss_ff: 0.00011190] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  30%|██▉       | 598/2000 [00:43<01:42, 13.70it/s][Iteration 000600/002000] [loss: 0.00341055] [loss_bc: 0.00302758; loss_div: 0.00028485; loss_ff: 0.00009812] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  35%|███▍      | 698/2000 [00:51<01:34, 13.74it/s][Iteration 000700/002000] [loss: 0.00388121] [loss_bc: 0.00342673; loss_div: 0.00034263; loss_ff: 0.00011185] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  40%|███▉      | 798/2000 [00:58<01:26, 13.82it/s][Iteration 000800/002000] [loss: 0.00365035] [loss_bc: 0.00324125; loss_div: 0.00029158; loss_ff: 0.00011753] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  45%|████▍     | 898/2000 [01:05<01:20, 13.77it/s][Iteration 000900/002000] [loss: 0.00333661] [loss_bc: 0.00287647; loss_div: 0.00032251; loss_ff: 0.00013762] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  50%|████▉     | 998/2000 [01:13<01:12, 13.77it/s][Iteration 001000/002000] [loss: 0.00363521] [loss_bc: 0.00320437; loss_div: 0.00030379; loss_ff: 0.00012706] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  55%|█████▍    | 1098/2000 [01:20<01:05, 13.72it/s][Iteration 001100/002000] [loss: 0.00369299] [loss_bc: 0.00325860; loss_div: 0.00033249; loss_ff: 0.00010190] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  60%|█████▉    | 1198/2000 [01:27<00:58, 13.67it/s][Iteration 001200/002000] [loss: 0.00378362] [loss_bc: 0.00338076; loss_div: 0.00028765; loss_ff: 0.00011520] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  65%|██████▍   | 1298/2000 [01:35<00:51, 13.57it/s][Iteration 001300/002000] [loss: 0.00354104] [loss_bc: 0.00315569; loss_div: 0.00027880; loss_ff: 0.00010655] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  70%|██████▉   | 1398/2000 [01:42<00:44, 13.58it/s][Iteration 001400/002000] [loss: 0.00376610] [loss_bc: 0.00337453; loss_div: 0.00026658; loss_ff: 0.00012498] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  75%|███████▍  | 1498/2000 [01:49<00:36, 13.62it/s][Iteration 001500/002000] [loss: 0.00355728] [loss_bc: 0.00317333; loss_div: 0.00026910; loss_ff: 0.00011484] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  80%|███████▉  | 1598/2000 [01:57<00:29, 13.86it/s][Iteration 001600/002000] [loss: 0.00360008] [loss_bc: 0.00315860; loss_div: 0.00033381; loss_ff: 0.00010767] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  85%|████████▍ | 1698/2000 [02:04<00:22, 13.65it/s][Iteration 001700/002000] [loss: 0.00341634] [loss_bc: 0.00300560; loss_div: 0.00029623; loss_ff: 0.00011451] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  90%|████████▉ | 1798/2000 [02:11<00:14, 13.78it/s][Iteration 001800/002000] [loss: 0.00358508] [loss_bc: 0.00316697; loss_div: 0.00030616; loss_ff: 0.00011195] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  95%|█████████▍| 1898/2000 [02:19<00:07, 13.69it/s][Iteration 001900/002000] [loss: 0.00379971] [loss_bc: 0.00339702; loss_div: 0.00030588; loss_ff: 0.00009681] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training: 100%|█████████▉| 1998/2000 [02:26<00:00, 13.68it/s][Iteration 002000/002000] [loss: 0.00342471] [loss_bc: 0.00300360; loss_div: 0.00030673; loss_ff: 0.00011438] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training: 100%|██████████| 2000/2000 [02:26<00:00, 13.63it/s]\n",
      "[Iteration 002000/002000] [loss: 0.00342471] [loss_bc: 0.00300360; loss_div: 0.00030673; loss_ff: 0.00011438] [w_bc: 1.000000, LR: 0.000050]\n",
      "Runtime --> total: 146.94sec (2.94ms/iter.)\n",
      "Configuration:\n",
      "dim: 256, w_div: 1.000000, w_ff: 1.000000, decay_iterations: None, potential: True, vector_potential: False, \n",
      "Using device: cuda (gpus 1) ['NVIDIA RTX A6000']\n",
      "Potential Boundary: 100%|██████████| 1/1 [00:00<00:00,  1.66it/s]\n",
      "Loaded meta state: /userhome/jeon_mg/workspace/_data/NOAA12673/PINN/20170904_120000/model_final.pt\n",
      "Training:   0%|          | 0/2000 [00:00<?, ?it/s][Iteration 000000/002000] [loss: 0.00358163] [loss_bc: 0.00317831; loss_div: 0.00028542; loss_ff: 0.00011789] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:   5%|▍         | 98/2000 [00:07<02:19, 13.62it/s][Iteration 000100/002000] [loss: 0.00333690] [loss_bc: 0.00291103; loss_div: 0.00028506; loss_ff: 0.00014082] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  10%|▉         | 198/2000 [00:14<02:11, 13.71it/s][Iteration 000200/002000] [loss: 0.00403776] [loss_bc: 0.00358856; loss_div: 0.00030944; loss_ff: 0.00013977] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  15%|█▍        | 298/2000 [00:21<02:03, 13.73it/s][Iteration 000300/002000] [loss: 0.00356536] [loss_bc: 0.00316732; loss_div: 0.00028923; loss_ff: 0.00010881] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  20%|█▉        | 398/2000 [00:29<01:56, 13.74it/s][Iteration 000400/002000] [loss: 0.00384188] [loss_bc: 0.00340882; loss_div: 0.00031680; loss_ff: 0.00011626] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  25%|██▍       | 498/2000 [00:36<01:50, 13.61it/s][Iteration 000500/002000] [loss: 0.00356119] [loss_bc: 0.00315792; loss_div: 0.00030237; loss_ff: 0.00010090] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  30%|██▉       | 598/2000 [00:43<01:42, 13.71it/s][Iteration 000600/002000] [loss: 0.00364962] [loss_bc: 0.00314360; loss_div: 0.00037761; loss_ff: 0.00012841] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  35%|███▍      | 698/2000 [00:51<01:34, 13.71it/s][Iteration 000700/002000] [loss: 0.00352046] [loss_bc: 0.00310150; loss_div: 0.00030508; loss_ff: 0.00011388] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  40%|███▉      | 798/2000 [00:58<01:27, 13.75it/s][Iteration 000800/002000] [loss: 0.00346296] [loss_bc: 0.00307950; loss_div: 0.00027919; loss_ff: 0.00010427] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  45%|████▍     | 898/2000 [01:05<01:20, 13.66it/s][Iteration 000900/002000] [loss: 0.00373550] [loss_bc: 0.00330592; loss_div: 0.00029995; loss_ff: 0.00012963] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  50%|████▉     | 998/2000 [01:13<01:14, 13.52it/s][Iteration 001000/002000] [loss: 0.00385803] [loss_bc: 0.00340923; loss_div: 0.00032374; loss_ff: 0.00012507] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  55%|█████▍    | 1098/2000 [01:20<01:06, 13.60it/s][Iteration 001100/002000] [loss: 0.00365889] [loss_bc: 0.00314569; loss_div: 0.00036895; loss_ff: 0.00014425] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  60%|█████▉    | 1198/2000 [01:27<00:58, 13.78it/s][Iteration 001200/002000] [loss: 0.00405036] [loss_bc: 0.00355889; loss_div: 0.00035410; loss_ff: 0.00013737] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  65%|██████▍   | 1298/2000 [01:34<00:51, 13.70it/s][Iteration 001300/002000] [loss: 0.00354100] [loss_bc: 0.00306687; loss_div: 0.00035198; loss_ff: 0.00012215] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  70%|██████▉   | 1398/2000 [01:42<00:43, 13.80it/s][Iteration 001400/002000] [loss: 0.00398055] [loss_bc: 0.00356282; loss_div: 0.00028064; loss_ff: 0.00013710] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  75%|███████▍  | 1498/2000 [01:49<00:36, 13.83it/s][Iteration 001500/002000] [loss: 0.00345486] [loss_bc: 0.00306543; loss_div: 0.00027410; loss_ff: 0.00011533] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  80%|███████▉  | 1598/2000 [01:56<00:29, 13.65it/s][Iteration 001600/002000] [loss: 0.00330678] [loss_bc: 0.00288716; loss_div: 0.00029411; loss_ff: 0.00012551] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  85%|████████▍ | 1698/2000 [02:04<00:21, 13.82it/s][Iteration 001700/002000] [loss: 0.00333381] [loss_bc: 0.00295739; loss_div: 0.00028022; loss_ff: 0.00009620] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  90%|████████▉ | 1798/2000 [02:11<00:14, 13.70it/s][Iteration 001800/002000] [loss: 0.00337067] [loss_bc: 0.00287664; loss_div: 0.00037897; loss_ff: 0.00011506] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  95%|█████████▍| 1898/2000 [02:18<00:07, 13.55it/s][Iteration 001900/002000] [loss: 0.00351189] [loss_bc: 0.00313605; loss_div: 0.00026453; loss_ff: 0.00011130] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training: 100%|█████████▉| 1998/2000 [02:26<00:00, 13.79it/s][Iteration 002000/002000] [loss: 0.00363985] [loss_bc: 0.00313152; loss_div: 0.00035608; loss_ff: 0.00015225] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training: 100%|██████████| 2000/2000 [02:26<00:00, 13.65it/s]\n",
      "[Iteration 002000/002000] [loss: 0.00363985] [loss_bc: 0.00313152; loss_div: 0.00035608; loss_ff: 0.00015225] [w_bc: 1.000000, LR: 0.000050]\n",
      "Runtime --> total: 146.67sec (2.93ms/iter.)\n",
      "Configuration:\n",
      "dim: 256, w_div: 1.000000, w_ff: 1.000000, decay_iterations: None, potential: True, vector_potential: False, \n",
      "Using device: cuda (gpus 1) ['NVIDIA RTX A6000']\n",
      "Potential Boundary: 100%|██████████| 1/1 [00:00<00:00,  1.55it/s]\n",
      "Loaded meta state: /userhome/jeon_mg/workspace/_data/NOAA12673/PINN/20170904_121200/model_final.pt\n",
      "Training:   0%|          | 0/2000 [00:00<?, ?it/s][Iteration 000000/002000] [loss: 0.00357917] [loss_bc: 0.00309568; loss_div: 0.00035695; loss_ff: 0.00012653] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:   5%|▍         | 98/2000 [00:07<02:17, 13.83it/s][Iteration 000100/002000] [loss: 0.00364103] [loss_bc: 0.00324390; loss_div: 0.00030721; loss_ff: 0.00008992] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  10%|▉         | 198/2000 [00:14<02:10, 13.86it/s][Iteration 000200/002000] [loss: 0.00372551] [loss_bc: 0.00326698; loss_div: 0.00034739; loss_ff: 0.00011115] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  15%|█▍        | 298/2000 [00:21<02:04, 13.67it/s][Iteration 000300/002000] [loss: 0.00336581] [loss_bc: 0.00295623; loss_div: 0.00030459; loss_ff: 0.00010500] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  20%|█▉        | 398/2000 [00:28<01:56, 13.74it/s][Iteration 000400/002000] [loss: 0.00366469] [loss_bc: 0.00325511; loss_div: 0.00029975; loss_ff: 0.00010983] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  25%|██▍       | 498/2000 [00:36<01:49, 13.76it/s][Iteration 000500/002000] [loss: 0.00354061] [loss_bc: 0.00314741; loss_div: 0.00028862; loss_ff: 0.00010459] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  30%|██▉       | 598/2000 [00:43<01:41, 13.79it/s][Iteration 000600/002000] [loss: 0.00395867] [loss_bc: 0.00346577; loss_div: 0.00034540; loss_ff: 0.00014750] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  35%|███▍      | 698/2000 [00:50<01:35, 13.63it/s][Iteration 000700/002000] [loss: 0.00363327] [loss_bc: 0.00320145; loss_div: 0.00033782; loss_ff: 0.00009401] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  40%|███▉      | 798/2000 [00:58<01:27, 13.79it/s][Iteration 000800/002000] [loss: 0.00358244] [loss_bc: 0.00315939; loss_div: 0.00029407; loss_ff: 0.00012898] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  45%|████▍     | 898/2000 [01:05<01:19, 13.79it/s][Iteration 000900/002000] [loss: 0.00377913] [loss_bc: 0.00330343; loss_div: 0.00032674; loss_ff: 0.00014895] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  50%|████▉     | 998/2000 [01:12<01:12, 13.83it/s][Iteration 001000/002000] [loss: 0.00363100] [loss_bc: 0.00321153; loss_div: 0.00030643; loss_ff: 0.00011303] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  55%|█████▍    | 1098/2000 [01:20<01:06, 13.64it/s][Iteration 001100/002000] [loss: 0.00361357] [loss_bc: 0.00323718; loss_div: 0.00027910; loss_ff: 0.00009729] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  60%|█████▉    | 1198/2000 [01:27<00:58, 13.78it/s][Iteration 001200/002000] [loss: 0.00368593] [loss_bc: 0.00324038; loss_div: 0.00031311; loss_ff: 0.00013245] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  65%|██████▍   | 1298/2000 [01:34<00:50, 13.81it/s][Iteration 001300/002000] [loss: 0.00362583] [loss_bc: 0.00314523; loss_div: 0.00031154; loss_ff: 0.00016906] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  70%|██████▉   | 1398/2000 [01:42<00:43, 13.83it/s][Iteration 001400/002000] [loss: 0.00360049] [loss_bc: 0.00315913; loss_div: 0.00030457; loss_ff: 0.00013680] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  75%|███████▍  | 1498/2000 [01:49<00:37, 13.56it/s][Iteration 001500/002000] [loss: 0.00331232] [loss_bc: 0.00294164; loss_div: 0.00027419; loss_ff: 0.00009649] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  80%|███████▉  | 1598/2000 [01:56<00:29, 13.80it/s][Iteration 001600/002000] [loss: 0.00357052] [loss_bc: 0.00316883; loss_div: 0.00029342; loss_ff: 0.00010827] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  85%|████████▍ | 1698/2000 [02:04<00:21, 13.75it/s][Iteration 001700/002000] [loss: 0.00376836] [loss_bc: 0.00324874; loss_div: 0.00037073; loss_ff: 0.00014889] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  90%|████████▉ | 1798/2000 [02:11<00:14, 13.56it/s][Iteration 001800/002000] [loss: 0.00358871] [loss_bc: 0.00315908; loss_div: 0.00031298; loss_ff: 0.00011665] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  95%|█████████▍| 1898/2000 [02:18<00:07, 13.85it/s][Iteration 001900/002000] [loss: 0.00350850] [loss_bc: 0.00314583; loss_div: 0.00026846; loss_ff: 0.00009420] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training: 100%|█████████▉| 1998/2000 [02:26<00:00, 13.45it/s][Iteration 002000/002000] [loss: 0.00365426] [loss_bc: 0.00323664; loss_div: 0.00031661; loss_ff: 0.00010101] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training: 100%|██████████| 2000/2000 [02:26<00:00, 13.65it/s]\n",
      "[Iteration 002000/002000] [loss: 0.00365426] [loss_bc: 0.00323664; loss_div: 0.00031661; loss_ff: 0.00010101] [w_bc: 1.000000, LR: 0.000050]\n",
      "Runtime --> total: 146.79sec (2.94ms/iter.)\n",
      "Configuration:\n",
      "dim: 256, w_div: 1.000000, w_ff: 1.000000, decay_iterations: None, potential: True, vector_potential: False, \n",
      "Using device: cuda (gpus 1) ['NVIDIA RTX A6000']\n",
      "Potential Boundary: 100%|██████████| 1/1 [00:01<00:00,  1.19s/it]\n",
      "Loaded meta state: /userhome/jeon_mg/workspace/_data/NOAA12673/PINN/20170904_122400/model_final.pt\n",
      "Training:   0%|          | 0/2000 [00:00<?, ?it/s][Iteration 000000/002000] [loss: 0.00381501] [loss_bc: 0.00329799; loss_div: 0.00035726; loss_ff: 0.00015976] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:   5%|▍         | 98/2000 [00:07<02:18, 13.71it/s][Iteration 000100/002000] [loss: 0.00376778] [loss_bc: 0.00337748; loss_div: 0.00027812; loss_ff: 0.00011218] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  10%|▉         | 198/2000 [00:14<02:10, 13.84it/s][Iteration 000200/002000] [loss: 0.00385886] [loss_bc: 0.00341481; loss_div: 0.00031696; loss_ff: 0.00012709] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  15%|█▍        | 298/2000 [00:21<02:03, 13.83it/s][Iteration 000300/002000] [loss: 0.00374018] [loss_bc: 0.00336322; loss_div: 0.00028581; loss_ff: 0.00009115] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  20%|█▉        | 398/2000 [00:28<01:57, 13.65it/s][Iteration 000400/002000] [loss: 0.00345658] [loss_bc: 0.00305014; loss_div: 0.00030486; loss_ff: 0.00010158] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  25%|██▍       | 498/2000 [00:36<01:49, 13.72it/s][Iteration 000500/002000] [loss: 0.00364561] [loss_bc: 0.00326597; loss_div: 0.00027542; loss_ff: 0.00010422] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  30%|██▉       | 598/2000 [00:43<01:43, 13.61it/s][Iteration 000600/002000] [loss: 0.00372760] [loss_bc: 0.00335580; loss_div: 0.00027831; loss_ff: 0.00009349] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  35%|███▍      | 698/2000 [00:50<01:33, 13.89it/s][Iteration 000700/002000] [loss: 0.00365686] [loss_bc: 0.00325783; loss_div: 0.00028813; loss_ff: 0.00011090] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  40%|███▉      | 798/2000 [00:58<01:27, 13.72it/s][Iteration 000800/002000] [loss: 0.00352176] [loss_bc: 0.00309692; loss_div: 0.00030105; loss_ff: 0.00012379] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  45%|████▍     | 898/2000 [01:05<01:21, 13.45it/s][Iteration 000900/002000] [loss: 0.00347498] [loss_bc: 0.00309585; loss_div: 0.00026666; loss_ff: 0.00011247] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  50%|████▉     | 998/2000 [01:12<01:12, 13.77it/s][Iteration 001000/002000] [loss: 0.00336714] [loss_bc: 0.00294339; loss_div: 0.00029998; loss_ff: 0.00012377] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  55%|█████▍    | 1098/2000 [01:20<01:05, 13.87it/s][Iteration 001100/002000] [loss: 0.00385863] [loss_bc: 0.00334091; loss_div: 0.00036509; loss_ff: 0.00015264] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  60%|█████▉    | 1198/2000 [01:27<00:58, 13.81it/s][Iteration 001200/002000] [loss: 0.00352468] [loss_bc: 0.00303532; loss_div: 0.00037260; loss_ff: 0.00011675] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  65%|██████▍   | 1298/2000 [01:34<00:50, 13.83it/s][Iteration 001300/002000] [loss: 0.00349652] [loss_bc: 0.00308530; loss_div: 0.00029343; loss_ff: 0.00011779] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  70%|██████▉   | 1398/2000 [01:42<00:43, 13.74it/s][Iteration 001400/002000] [loss: 0.00381363] [loss_bc: 0.00333594; loss_div: 0.00036714; loss_ff: 0.00011056] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  75%|███████▍  | 1498/2000 [01:49<00:36, 13.69it/s][Iteration 001500/002000] [loss: 0.00357358] [loss_bc: 0.00308621; loss_div: 0.00035616; loss_ff: 0.00013121] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  80%|███████▉  | 1598/2000 [01:56<00:29, 13.78it/s][Iteration 001600/002000] [loss: 0.00373583] [loss_bc: 0.00337101; loss_div: 0.00027759; loss_ff: 0.00008722] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  85%|████████▍ | 1698/2000 [02:03<00:22, 13.63it/s][Iteration 001700/002000] [loss: 0.00347360] [loss_bc: 0.00307896; loss_div: 0.00029104; loss_ff: 0.00010360] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  90%|████████▉ | 1798/2000 [02:11<00:14, 13.79it/s][Iteration 001800/002000] [loss: 0.00357703] [loss_bc: 0.00308022; loss_div: 0.00032615; loss_ff: 0.00017066] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  95%|█████████▍| 1898/2000 [02:18<00:07, 13.52it/s][Iteration 001900/002000] [loss: 0.00380816] [loss_bc: 0.00333488; loss_div: 0.00035386; loss_ff: 0.00011942] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training: 100%|█████████▉| 1998/2000 [02:25<00:00, 13.66it/s][Iteration 002000/002000] [loss: 0.00352520] [loss_bc: 0.00308237; loss_div: 0.00031711; loss_ff: 0.00012572] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training: 100%|██████████| 2000/2000 [02:26<00:00, 13.68it/s]\n",
      "[Iteration 002000/002000] [loss: 0.00352520] [loss_bc: 0.00308237; loss_div: 0.00031711; loss_ff: 0.00012572] [w_bc: 1.000000, LR: 0.000050]\n",
      "Runtime --> total: 146.47sec (2.93ms/iter.)\n",
      "Configuration:\n",
      "dim: 256, w_div: 1.000000, w_ff: 1.000000, decay_iterations: None, potential: True, vector_potential: False, \n",
      "Using device: cuda (gpus 1) ['NVIDIA RTX A6000']\n",
      "Potential Boundary: 100%|██████████| 1/1 [00:01<00:00,  1.13s/it]\n",
      "Loaded meta state: /userhome/jeon_mg/workspace/_data/NOAA12673/PINN/20170904_123600/model_final.pt\n",
      "Training:   0%|          | 0/2000 [00:00<?, ?it/s][Iteration 000000/002000] [loss: 0.00359119] [loss_bc: 0.00317178; loss_div: 0.00031544; loss_ff: 0.00010398] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:   5%|▍         | 98/2000 [00:07<02:19, 13.66it/s][Iteration 000100/002000] [loss: 0.00360206] [loss_bc: 0.00321834; loss_div: 0.00028688; loss_ff: 0.00009684] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  10%|▉         | 198/2000 [00:14<02:09, 13.87it/s][Iteration 000200/002000] [loss: 0.00380322] [loss_bc: 0.00322434; loss_div: 0.00039890; loss_ff: 0.00017999] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  15%|█▍        | 298/2000 [00:21<02:05, 13.59it/s][Iteration 000300/002000] [loss: 0.00363538] [loss_bc: 0.00321065; loss_div: 0.00030661; loss_ff: 0.00011812] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  20%|█▉        | 398/2000 [00:29<01:55, 13.83it/s][Iteration 000400/002000] [loss: 0.00352928] [loss_bc: 0.00316809; loss_div: 0.00027116; loss_ff: 0.00009003] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  25%|██▍       | 498/2000 [00:36<01:48, 13.84it/s][Iteration 000500/002000] [loss: 0.00378354] [loss_bc: 0.00337594; loss_div: 0.00028825; loss_ff: 0.00011934] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  30%|██▉       | 598/2000 [00:43<01:41, 13.78it/s][Iteration 000600/002000] [loss: 0.00364515] [loss_bc: 0.00319872; loss_div: 0.00032240; loss_ff: 0.00012402] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  35%|███▍      | 698/2000 [00:50<01:34, 13.78it/s][Iteration 000700/002000] [loss: 0.00366036] [loss_bc: 0.00321925; loss_div: 0.00032117; loss_ff: 0.00011993] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  40%|███▉      | 798/2000 [00:58<01:28, 13.60it/s][Iteration 000800/002000] [loss: 0.00353371] [loss_bc: 0.00319988; loss_div: 0.00025100; loss_ff: 0.00008282] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  45%|████▍     | 898/2000 [01:05<01:19, 13.80it/s][Iteration 000900/002000] [loss: 0.00379259] [loss_bc: 0.00336702; loss_div: 0.00030625; loss_ff: 0.00011932] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  50%|████▉     | 998/2000 [01:12<01:13, 13.69it/s][Iteration 001000/002000] [loss: 0.00355943] [loss_bc: 0.00314960; loss_div: 0.00029468; loss_ff: 0.00011515] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  55%|█████▍    | 1098/2000 [01:20<01:05, 13.72it/s][Iteration 001100/002000] [loss: 0.00386646] [loss_bc: 0.00332382; loss_div: 0.00040111; loss_ff: 0.00014153] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  60%|█████▉    | 1198/2000 [01:27<00:57, 13.85it/s][Iteration 001200/002000] [loss: 0.00370698] [loss_bc: 0.00325542; loss_div: 0.00035673; loss_ff: 0.00009483] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  65%|██████▍   | 1298/2000 [01:34<00:51, 13.68it/s][Iteration 001300/002000] [loss: 0.00355167] [loss_bc: 0.00314488; loss_div: 0.00029072; loss_ff: 0.00011607] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  70%|██████▉   | 1398/2000 [01:42<00:43, 13.82it/s][Iteration 001400/002000] [loss: 0.00365724] [loss_bc: 0.00318530; loss_div: 0.00036401; loss_ff: 0.00010792] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  75%|███████▍  | 1498/2000 [01:49<00:37, 13.54it/s][Iteration 001500/002000] [loss: 0.00371128] [loss_bc: 0.00331720; loss_div: 0.00028686; loss_ff: 0.00010723] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  80%|███████▉  | 1598/2000 [01:56<00:29, 13.85it/s][Iteration 001600/002000] [loss: 0.00352601] [loss_bc: 0.00313924; loss_div: 0.00028075; loss_ff: 0.00010602] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  85%|████████▍ | 1698/2000 [02:03<00:21, 13.84it/s][Iteration 001700/002000] [loss: 0.00354968] [loss_bc: 0.00313491; loss_div: 0.00028819; loss_ff: 0.00012658] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  90%|████████▉ | 1798/2000 [02:11<00:14, 13.79it/s][Iteration 001800/002000] [loss: 0.00362380] [loss_bc: 0.00313237; loss_div: 0.00036500; loss_ff: 0.00012643] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  95%|█████████▍| 1898/2000 [02:18<00:07, 13.56it/s][Iteration 001900/002000] [loss: 0.00367969] [loss_bc: 0.00323607; loss_div: 0.00033287; loss_ff: 0.00011076] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training: 100%|█████████▉| 1998/2000 [02:25<00:00, 13.89it/s][Iteration 002000/002000] [loss: 0.00373344] [loss_bc: 0.00334773; loss_div: 0.00027455; loss_ff: 0.00011116] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training: 100%|██████████| 2000/2000 [02:26<00:00, 13.67it/s]\n",
      "[Iteration 002000/002000] [loss: 0.00373344] [loss_bc: 0.00334773; loss_div: 0.00027455; loss_ff: 0.00011116] [w_bc: 1.000000, LR: 0.000050]\n",
      "Runtime --> total: 146.45sec (2.93ms/iter.)\n",
      "Configuration:\n",
      "dim: 256, w_div: 1.000000, w_ff: 1.000000, decay_iterations: None, potential: True, vector_potential: False, \n",
      "Using device: cuda (gpus 1) ['NVIDIA RTX A6000']\n",
      "Potential Boundary: 100%|██████████| 1/1 [00:01<00:00,  1.01s/it]\n",
      "Loaded meta state: /userhome/jeon_mg/workspace/_data/NOAA12673/PINN/20170904_124800/model_final.pt\n",
      "Training:   0%|          | 0/2000 [00:00<?, ?it/s][Iteration 000000/002000] [loss: 0.00371534] [loss_bc: 0.00334727; loss_div: 0.00025899; loss_ff: 0.00010909] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:   5%|▍         | 98/2000 [00:07<02:18, 13.77it/s][Iteration 000100/002000] [loss: 0.00372067] [loss_bc: 0.00332131; loss_div: 0.00026601; loss_ff: 0.00013335] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  10%|▉         | 198/2000 [00:14<02:11, 13.71it/s][Iteration 000200/002000] [loss: 0.00344952] [loss_bc: 0.00308411; loss_div: 0.00026395; loss_ff: 0.00010146] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  15%|█▍        | 298/2000 [00:21<02:03, 13.74it/s][Iteration 000300/002000] [loss: 0.00363085] [loss_bc: 0.00322611; loss_div: 0.00028350; loss_ff: 0.00012124] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  20%|█▉        | 398/2000 [00:29<01:56, 13.78it/s][Iteration 000400/002000] [loss: 0.00370430] [loss_bc: 0.00327930; loss_div: 0.00031007; loss_ff: 0.00011492] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  25%|██▍       | 498/2000 [00:36<01:48, 13.86it/s][Iteration 000500/002000] [loss: 0.00355982] [loss_bc: 0.00314412; loss_div: 0.00031287; loss_ff: 0.00010283] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  30%|██▉       | 598/2000 [00:43<01:41, 13.78it/s][Iteration 000600/002000] [loss: 0.00364082] [loss_bc: 0.00326611; loss_div: 0.00027028; loss_ff: 0.00010443] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  35%|███▍      | 698/2000 [00:51<01:35, 13.62it/s][Iteration 000700/002000] [loss: 0.00370316] [loss_bc: 0.00326628; loss_div: 0.00031469; loss_ff: 0.00012219] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  40%|███▉      | 798/2000 [00:58<01:26, 13.89it/s][Iteration 000800/002000] [loss: 0.00356513] [loss_bc: 0.00313165; loss_div: 0.00031790; loss_ff: 0.00011557] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  45%|████▍     | 898/2000 [01:05<01:19, 13.85it/s][Iteration 000900/002000] [loss: 0.00370116] [loss_bc: 0.00324638; loss_div: 0.00031487; loss_ff: 0.00013991] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  50%|████▉     | 998/2000 [01:12<01:12, 13.83it/s][Iteration 001000/002000] [loss: 0.00371624] [loss_bc: 0.00326791; loss_div: 0.00029783; loss_ff: 0.00015050] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  55%|█████▍    | 1098/2000 [01:20<01:05, 13.81it/s][Iteration 001100/002000] [loss: 0.00348585] [loss_bc: 0.00312534; loss_div: 0.00025668; loss_ff: 0.00010383] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  60%|█████▉    | 1198/2000 [01:27<00:59, 13.55it/s][Iteration 001200/002000] [loss: 0.00350511] [loss_bc: 0.00306729; loss_div: 0.00032026; loss_ff: 0.00011757] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  65%|██████▍   | 1298/2000 [01:34<00:51, 13.64it/s][Iteration 001300/002000] [loss: 0.00371849] [loss_bc: 0.00320636; loss_div: 0.00037954; loss_ff: 0.00013259] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  70%|██████▉   | 1398/2000 [01:42<00:44, 13.59it/s][Iteration 001400/002000] [loss: 0.00360721] [loss_bc: 0.00321054; loss_div: 0.00029297; loss_ff: 0.00010370] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  75%|███████▍  | 1498/2000 [01:49<00:36, 13.61it/s][Iteration 001500/002000] [loss: 0.00368389] [loss_bc: 0.00327641; loss_div: 0.00030295; loss_ff: 0.00010453] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  80%|███████▉  | 1598/2000 [01:56<00:28, 13.96it/s][Iteration 001600/002000] [loss: 0.00379202] [loss_bc: 0.00325244; loss_div: 0.00039613; loss_ff: 0.00014344] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  85%|████████▍ | 1698/2000 [02:04<00:22, 13.70it/s][Iteration 001700/002000] [loss: 0.00362567] [loss_bc: 0.00324536; loss_div: 0.00028718; loss_ff: 0.00009313] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  90%|████████▉ | 1798/2000 [02:11<00:14, 13.52it/s][Iteration 001800/002000] [loss: 0.00384885] [loss_bc: 0.00331209; loss_div: 0.00038851; loss_ff: 0.00014825] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  95%|█████████▍| 1898/2000 [02:18<00:07, 13.57it/s][Iteration 001900/002000] [loss: 0.00374630] [loss_bc: 0.00324108; loss_div: 0.00038552; loss_ff: 0.00011969] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training: 100%|█████████▉| 1998/2000 [02:26<00:00, 13.53it/s][Iteration 002000/002000] [loss: 0.00370480] [loss_bc: 0.00319283; loss_div: 0.00040760; loss_ff: 0.00010438] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training: 100%|██████████| 2000/2000 [02:26<00:00, 13.64it/s]\n",
      "[Iteration 002000/002000] [loss: 0.00370480] [loss_bc: 0.00319283; loss_div: 0.00040760; loss_ff: 0.00010438] [w_bc: 1.000000, LR: 0.000050]\n",
      "Runtime --> total: 146.85sec (2.94ms/iter.)\n",
      "Configuration:\n",
      "dim: 256, w_div: 1.000000, w_ff: 1.000000, decay_iterations: None, potential: True, vector_potential: False, \n",
      "Using device: cuda (gpus 1) ['NVIDIA RTX A6000']\n",
      "Potential Boundary: 100%|██████████| 1/1 [00:00<00:00,  1.03it/s]\n",
      "Loaded meta state: /userhome/jeon_mg/workspace/_data/NOAA12673/PINN/20170904_130000/model_final.pt\n",
      "Training:   0%|          | 0/2000 [00:00<?, ?it/s][Iteration 000000/002000] [loss: 0.00378183] [loss_bc: 0.00333956; loss_div: 0.00032789; loss_ff: 0.00011438] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:   5%|▍         | 98/2000 [00:07<02:19, 13.63it/s][Iteration 000100/002000] [loss: 0.00368298] [loss_bc: 0.00321379; loss_div: 0.00033592; loss_ff: 0.00013326] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  10%|▉         | 198/2000 [00:14<02:12, 13.58it/s][Iteration 000200/002000] [loss: 0.00371803] [loss_bc: 0.00328841; loss_div: 0.00030573; loss_ff: 0.00012389] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  15%|█▍        | 298/2000 [00:22<02:05, 13.59it/s][Iteration 000300/002000] [loss: 0.00355819] [loss_bc: 0.00313446; loss_div: 0.00032382; loss_ff: 0.00009991] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  20%|█▉        | 398/2000 [00:29<01:58, 13.50it/s][Iteration 000400/002000] [loss: 0.00330424] [loss_bc: 0.00289322; loss_div: 0.00031970; loss_ff: 0.00009132] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  25%|██▍       | 498/2000 [00:36<01:53, 13.23it/s][Iteration 000500/002000] [loss: 0.00364121] [loss_bc: 0.00313038; loss_div: 0.00037462; loss_ff: 0.00013621] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  30%|██▉       | 598/2000 [00:44<01:43, 13.53it/s][Iteration 000600/002000] [loss: 0.00344362] [loss_bc: 0.00306157; loss_div: 0.00027286; loss_ff: 0.00010919] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  35%|███▍      | 698/2000 [00:51<01:35, 13.58it/s][Iteration 000700/002000] [loss: 0.00373595] [loss_bc: 0.00330569; loss_div: 0.00031158; loss_ff: 0.00011868] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  40%|███▉      | 798/2000 [00:58<01:28, 13.57it/s][Iteration 000800/002000] [loss: 0.00373213] [loss_bc: 0.00327291; loss_div: 0.00031760; loss_ff: 0.00014162] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  45%|████▍     | 898/2000 [01:06<01:20, 13.61it/s][Iteration 000900/002000] [loss: 0.00379984] [loss_bc: 0.00330932; loss_div: 0.00032724; loss_ff: 0.00016328] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  50%|████▉     | 998/2000 [01:13<01:13, 13.70it/s][Iteration 001000/002000] [loss: 0.00355341] [loss_bc: 0.00319231; loss_div: 0.00026054; loss_ff: 0.00010056] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  55%|█████▍    | 1098/2000 [01:21<01:06, 13.57it/s][Iteration 001100/002000] [loss: 0.00329297] [loss_bc: 0.00288151; loss_div: 0.00031979; loss_ff: 0.00009168] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  60%|█████▉    | 1198/2000 [01:28<00:59, 13.58it/s][Iteration 001200/002000] [loss: 0.00367317] [loss_bc: 0.00319518; loss_div: 0.00035317; loss_ff: 0.00012483] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  65%|██████▍   | 1298/2000 [01:35<00:51, 13.58it/s][Iteration 001300/002000] [loss: 0.00389523] [loss_bc: 0.00329629; loss_div: 0.00043560; loss_ff: 0.00016335] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  70%|██████▉   | 1398/2000 [01:43<00:45, 13.35it/s][Iteration 001400/002000] [loss: 0.00340487] [loss_bc: 0.00305543; loss_div: 0.00025129; loss_ff: 0.00009815] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  75%|███████▍  | 1498/2000 [01:50<00:36, 13.79it/s][Iteration 001500/002000] [loss: 0.00376368] [loss_bc: 0.00329418; loss_div: 0.00035795; loss_ff: 0.00011156] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  80%|███████▉  | 1598/2000 [01:57<00:29, 13.80it/s][Iteration 001600/002000] [loss: 0.00352853] [loss_bc: 0.00310452; loss_div: 0.00030926; loss_ff: 0.00011475] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  85%|████████▍ | 1698/2000 [02:05<00:22, 13.71it/s][Iteration 001700/002000] [loss: 0.00351099] [loss_bc: 0.00304739; loss_div: 0.00033002; loss_ff: 0.00013359] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  90%|████████▉ | 1798/2000 [02:12<00:14, 13.65it/s][Iteration 001800/002000] [loss: 0.00358884] [loss_bc: 0.00319515; loss_div: 0.00028041; loss_ff: 0.00011328] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  95%|█████████▍| 1898/2000 [02:20<00:07, 13.55it/s][Iteration 001900/002000] [loss: 0.00365354] [loss_bc: 0.00317946; loss_div: 0.00033306; loss_ff: 0.00014102] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training: 100%|█████████▉| 1998/2000 [02:27<00:00, 13.58it/s][Iteration 002000/002000] [loss: 0.00358916] [loss_bc: 0.00311286; loss_div: 0.00034452; loss_ff: 0.00013179] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training: 100%|██████████| 2000/2000 [02:27<00:00, 13.53it/s]\n",
      "[Iteration 002000/002000] [loss: 0.00358916] [loss_bc: 0.00311286; loss_div: 0.00034452; loss_ff: 0.00013179] [w_bc: 1.000000, LR: 0.000050]\n",
      "Runtime --> total: 147.97sec (2.96ms/iter.)\n",
      "Configuration:\n",
      "dim: 256, w_div: 1.000000, w_ff: 1.000000, decay_iterations: None, potential: True, vector_potential: False, \n",
      "Using device: cuda (gpus 1) ['NVIDIA RTX A6000']\n",
      "Potential Boundary: 100%|██████████| 1/1 [00:00<00:00,  1.02it/s]\n",
      "Loaded meta state: /userhome/jeon_mg/workspace/_data/NOAA12673/PINN/20170904_131200/model_final.pt\n",
      "Training:   0%|          | 0/2000 [00:00<?, ?it/s][Iteration 000000/002000] [loss: 0.00371276] [loss_bc: 0.00331134; loss_div: 0.00029160; loss_ff: 0.00010983] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:   5%|▍         | 98/2000 [00:07<02:20, 13.54it/s][Iteration 000100/002000] [loss: 0.00352281] [loss_bc: 0.00309848; loss_div: 0.00031035; loss_ff: 0.00011397] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  10%|▉         | 198/2000 [00:14<02:13, 13.49it/s][Iteration 000200/002000] [loss: 0.00348448] [loss_bc: 0.00308761; loss_div: 0.00029419; loss_ff: 0.00010268] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  15%|█▍        | 298/2000 [00:22<02:05, 13.55it/s][Iteration 000300/002000] [loss: 0.00367452] [loss_bc: 0.00328244; loss_div: 0.00028027; loss_ff: 0.00011181] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  20%|█▉        | 398/2000 [00:29<01:57, 13.61it/s][Iteration 000400/002000] [loss: 0.00354969] [loss_bc: 0.00317860; loss_div: 0.00026684; loss_ff: 0.00010425] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  25%|██▍       | 498/2000 [00:36<01:50, 13.64it/s][Iteration 000500/002000] [loss: 0.00358737] [loss_bc: 0.00314477; loss_div: 0.00033638; loss_ff: 0.00010622] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  30%|██▉       | 598/2000 [00:44<01:43, 13.59it/s][Iteration 000600/002000] [loss: 0.00356053] [loss_bc: 0.00306319; loss_div: 0.00037056; loss_ff: 0.00012679] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  35%|███▍      | 698/2000 [00:51<01:35, 13.58it/s][Iteration 000700/002000] [loss: 0.00358060] [loss_bc: 0.00314283; loss_div: 0.00032620; loss_ff: 0.00011157] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  40%|███▉      | 798/2000 [00:58<01:28, 13.64it/s][Iteration 000800/002000] [loss: 0.00350872] [loss_bc: 0.00307756; loss_div: 0.00031930; loss_ff: 0.00011185] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  45%|████▍     | 898/2000 [01:06<01:20, 13.69it/s][Iteration 000900/002000] [loss: 0.00374267] [loss_bc: 0.00337137; loss_div: 0.00027308; loss_ff: 0.00009822] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  50%|████▉     | 998/2000 [01:13<01:13, 13.61it/s][Iteration 001000/002000] [loss: 0.00380724] [loss_bc: 0.00336562; loss_div: 0.00030931; loss_ff: 0.00013231] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  55%|█████▍    | 1098/2000 [01:21<01:06, 13.47it/s][Iteration 001100/002000] [loss: 0.00342319] [loss_bc: 0.00306765; loss_div: 0.00026734; loss_ff: 0.00008820] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  60%|█████▉    | 1198/2000 [01:28<00:59, 13.51it/s][Iteration 001200/002000] [loss: 0.00374346] [loss_bc: 0.00328655; loss_div: 0.00031280; loss_ff: 0.00014411] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  65%|██████▍   | 1298/2000 [01:35<00:51, 13.60it/s][Iteration 001300/002000] [loss: 0.00359194] [loss_bc: 0.00313948; loss_div: 0.00032874; loss_ff: 0.00012372] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  70%|██████▉   | 1398/2000 [01:43<00:44, 13.67it/s][Iteration 001400/002000] [loss: 0.00380281] [loss_bc: 0.00335704; loss_div: 0.00030796; loss_ff: 0.00013781] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  75%|███████▍  | 1498/2000 [01:50<00:36, 13.61it/s][Iteration 001500/002000] [loss: 0.00376159] [loss_bc: 0.00325922; loss_div: 0.00036073; loss_ff: 0.00014164] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  80%|███████▉  | 1598/2000 [01:57<00:29, 13.54it/s][Iteration 001600/002000] [loss: 0.00381719] [loss_bc: 0.00335473; loss_div: 0.00032426; loss_ff: 0.00013819] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  85%|████████▍ | 1698/2000 [02:05<00:22, 13.58it/s][Iteration 001700/002000] [loss: 0.00362288] [loss_bc: 0.00315835; loss_div: 0.00033022; loss_ff: 0.00013431] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  90%|████████▉ | 1798/2000 [02:12<00:14, 13.60it/s][Iteration 001800/002000] [loss: 0.00353228] [loss_bc: 0.00307923; loss_div: 0.00033965; loss_ff: 0.00011340] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  95%|█████████▍| 1898/2000 [02:20<00:07, 13.56it/s][Iteration 001900/002000] [loss: 0.00360023] [loss_bc: 0.00314849; loss_div: 0.00030085; loss_ff: 0.00015089] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training: 100%|█████████▉| 1998/2000 [02:27<00:00, 13.72it/s][Iteration 002000/002000] [loss: 0.00382955] [loss_bc: 0.00334943; loss_div: 0.00034294; loss_ff: 0.00013717] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training: 100%|██████████| 2000/2000 [02:27<00:00, 13.53it/s]\n",
      "[Iteration 002000/002000] [loss: 0.00382955] [loss_bc: 0.00334943; loss_div: 0.00034294; loss_ff: 0.00013717] [w_bc: 1.000000, LR: 0.000050]\n",
      "Runtime --> total: 147.98sec (2.96ms/iter.)\n",
      "Configuration:\n",
      "dim: 256, w_div: 1.000000, w_ff: 1.000000, decay_iterations: None, potential: True, vector_potential: False, \n",
      "Using device: cuda (gpus 1) ['NVIDIA RTX A6000']\n",
      "Potential Boundary: 100%|██████████| 1/1 [00:01<00:00,  1.05s/it]\n",
      "Loaded meta state: /userhome/jeon_mg/workspace/_data/NOAA12673/PINN/20170904_132400/model_final.pt\n",
      "Training:   0%|          | 0/2000 [00:00<?, ?it/s][Iteration 000000/002000] [loss: 0.00375772] [loss_bc: 0.00336533; loss_div: 0.00028097; loss_ff: 0.00011142] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:   5%|▍         | 98/2000 [00:07<02:19, 13.59it/s][Iteration 000100/002000] [loss: 0.00368658] [loss_bc: 0.00317567; loss_div: 0.00037082; loss_ff: 0.00014009] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  10%|▉         | 198/2000 [00:14<02:11, 13.67it/s][Iteration 000200/002000] [loss: 0.00361918] [loss_bc: 0.00322716; loss_div: 0.00028469; loss_ff: 0.00010733] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  15%|█▍        | 298/2000 [00:21<02:04, 13.65it/s][Iteration 000300/002000] [loss: 0.00368370] [loss_bc: 0.00322710; loss_div: 0.00033238; loss_ff: 0.00012422] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  20%|█▉        | 398/2000 [00:29<01:58, 13.55it/s][Iteration 000400/002000] [loss: 0.00361668] [loss_bc: 0.00306683; loss_div: 0.00038310; loss_ff: 0.00016675] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  25%|██▍       | 498/2000 [00:36<01:50, 13.56it/s][Iteration 000500/002000] [loss: 0.00352373] [loss_bc: 0.00309696; loss_div: 0.00031063; loss_ff: 0.00011613] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  30%|██▉       | 598/2000 [00:43<01:42, 13.62it/s][Iteration 000600/002000] [loss: 0.00356072] [loss_bc: 0.00311483; loss_div: 0.00032286; loss_ff: 0.00012302] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  35%|███▍      | 698/2000 [00:51<01:35, 13.62it/s][Iteration 000700/002000] [loss: 0.00346816] [loss_bc: 0.00309290; loss_div: 0.00028299; loss_ff: 0.00009226] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  40%|███▉      | 798/2000 [00:58<01:28, 13.58it/s][Iteration 000800/002000] [loss: 0.00356074] [loss_bc: 0.00305166; loss_div: 0.00035898; loss_ff: 0.00015011] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  45%|████▍     | 898/2000 [01:06<01:20, 13.65it/s][Iteration 000900/002000] [loss: 0.00349249] [loss_bc: 0.00305329; loss_div: 0.00034005; loss_ff: 0.00009915] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  50%|████▉     | 998/2000 [01:13<01:12, 13.88it/s][Iteration 001000/002000] [loss: 0.00377733] [loss_bc: 0.00332684; loss_div: 0.00033088; loss_ff: 0.00011962] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  55%|█████▍    | 1098/2000 [01:20<01:05, 13.68it/s][Iteration 001100/002000] [loss: 0.00359836] [loss_bc: 0.00313603; loss_div: 0.00033442; loss_ff: 0.00012791] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  60%|█████▉    | 1198/2000 [01:28<00:59, 13.58it/s][Iteration 001200/002000] [loss: 0.00355028] [loss_bc: 0.00310195; loss_div: 0.00032973; loss_ff: 0.00011860] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  65%|██████▍   | 1298/2000 [01:35<00:51, 13.60it/s][Iteration 001300/002000] [loss: 0.00357008] [loss_bc: 0.00307958; loss_div: 0.00033054; loss_ff: 0.00015995] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  70%|██████▉   | 1398/2000 [01:42<00:45, 13.36it/s][Iteration 001400/002000] [loss: 0.00344833] [loss_bc: 0.00301125; loss_div: 0.00031150; loss_ff: 0.00012559] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  75%|███████▍  | 1498/2000 [01:50<00:36, 13.62it/s][Iteration 001500/002000] [loss: 0.00351268] [loss_bc: 0.00313906; loss_div: 0.00027490; loss_ff: 0.00009872] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  80%|███████▉  | 1598/2000 [01:57<00:29, 13.61it/s][Iteration 001600/002000] [loss: 0.00353993] [loss_bc: 0.00309094; loss_div: 0.00033610; loss_ff: 0.00011289] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  85%|████████▍ | 1698/2000 [02:04<00:22, 13.59it/s][Iteration 001700/002000] [loss: 0.00359578] [loss_bc: 0.00309913; loss_div: 0.00037882; loss_ff: 0.00011783] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  90%|████████▉ | 1798/2000 [02:12<00:14, 13.68it/s][Iteration 001800/002000] [loss: 0.00347911] [loss_bc: 0.00303560; loss_div: 0.00033003; loss_ff: 0.00011348] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  95%|█████████▍| 1898/2000 [02:19<00:07, 13.62it/s][Iteration 001900/002000] [loss: 0.00378218] [loss_bc: 0.00331534; loss_div: 0.00035210; loss_ff: 0.00011475] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training: 100%|█████████▉| 1998/2000 [02:26<00:00, 13.53it/s][Iteration 002000/002000] [loss: 0.00388143] [loss_bc: 0.00331039; loss_div: 0.00045633; loss_ff: 0.00011472] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training: 100%|██████████| 2000/2000 [02:27<00:00, 13.58it/s]\n",
      "[Iteration 002000/002000] [loss: 0.00388143] [loss_bc: 0.00331039; loss_div: 0.00045633; loss_ff: 0.00011472] [w_bc: 1.000000, LR: 0.000050]\n",
      "Runtime --> total: 147.40sec (2.95ms/iter.)\n",
      "Configuration:\n",
      "dim: 256, w_div: 1.000000, w_ff: 1.000000, decay_iterations: None, potential: True, vector_potential: False, \n",
      "Using device: cuda (gpus 1) ['NVIDIA RTX A6000']\n",
      "Potential Boundary: 100%|██████████| 1/1 [00:00<00:00,  1.02it/s]\n",
      "Loaded meta state: /userhome/jeon_mg/workspace/_data/NOAA12673/PINN/20170904_133600/model_final.pt\n",
      "Training:   0%|          | 0/2000 [00:00<?, ?it/s][Iteration 000000/002000] [loss: 0.00371847] [loss_bc: 0.00318485; loss_div: 0.00038418; loss_ff: 0.00014944] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:   5%|▍         | 98/2000 [00:07<02:18, 13.69it/s][Iteration 000100/002000] [loss: 0.00369446] [loss_bc: 0.00315920; loss_div: 0.00037014; loss_ff: 0.00016512] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  10%|▉         | 198/2000 [00:14<02:12, 13.58it/s][Iteration 000200/002000] [loss: 0.00374026] [loss_bc: 0.00333261; loss_div: 0.00029411; loss_ff: 0.00011353] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  15%|█▍        | 298/2000 [00:21<02:05, 13.58it/s][Iteration 000300/002000] [loss: 0.00375149] [loss_bc: 0.00333284; loss_div: 0.00031118; loss_ff: 0.00010747] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  20%|█▉        | 398/2000 [00:29<01:58, 13.54it/s][Iteration 000400/002000] [loss: 0.00362728] [loss_bc: 0.00323304; loss_div: 0.00030205; loss_ff: 0.00009219] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  25%|██▍       | 498/2000 [00:36<01:50, 13.59it/s][Iteration 000500/002000] [loss: 0.00336120] [loss_bc: 0.00295520; loss_div: 0.00028947; loss_ff: 0.00011653] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  30%|██▉       | 598/2000 [00:44<01:43, 13.57it/s][Iteration 000600/002000] [loss: 0.00354751] [loss_bc: 0.00309563; loss_div: 0.00033161; loss_ff: 0.00012026] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  35%|███▍      | 698/2000 [00:51<01:34, 13.73it/s][Iteration 000700/002000] [loss: 0.00358302] [loss_bc: 0.00312997; loss_div: 0.00033104; loss_ff: 0.00012201] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  40%|███▉      | 798/2000 [00:58<01:27, 13.78it/s][Iteration 000800/002000] [loss: 0.00349783] [loss_bc: 0.00305887; loss_div: 0.00031451; loss_ff: 0.00012445] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  45%|████▍     | 898/2000 [01:06<01:21, 13.60it/s][Iteration 000900/002000] [loss: 0.00353111] [loss_bc: 0.00312892; loss_div: 0.00029494; loss_ff: 0.00010725] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  50%|████▉     | 998/2000 [01:13<01:14, 13.50it/s][Iteration 001000/002000] [loss: 0.00345738] [loss_bc: 0.00303745; loss_div: 0.00030486; loss_ff: 0.00011507] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  55%|█████▍    | 1098/2000 [01:20<01:06, 13.52it/s][Iteration 001100/002000] [loss: 0.00378659] [loss_bc: 0.00334722; loss_div: 0.00032616; loss_ff: 0.00011321] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  60%|█████▉    | 1198/2000 [01:28<00:57, 13.88it/s][Iteration 001200/002000] [loss: 0.00335695] [loss_bc: 0.00293617; loss_div: 0.00030883; loss_ff: 0.00011195] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  65%|██████▍   | 1298/2000 [01:35<00:51, 13.51it/s][Iteration 001300/002000] [loss: 0.00344039] [loss_bc: 0.00303264; loss_div: 0.00030408; loss_ff: 0.00010367] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  70%|██████▉   | 1398/2000 [01:43<00:44, 13.58it/s][Iteration 001400/002000] [loss: 0.00370280] [loss_bc: 0.00330532; loss_div: 0.00029244; loss_ff: 0.00010504] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  75%|███████▍  | 1498/2000 [01:50<00:36, 13.59it/s][Iteration 001500/002000] [loss: 0.00347986] [loss_bc: 0.00304646; loss_div: 0.00033104; loss_ff: 0.00010236] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  80%|███████▉  | 1598/2000 [01:57<00:29, 13.49it/s][Iteration 001600/002000] [loss: 0.00336839] [loss_bc: 0.00293482; loss_div: 0.00033556; loss_ff: 0.00009800] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  85%|████████▍ | 1698/2000 [02:05<00:21, 13.79it/s][Iteration 001700/002000] [loss: 0.00344135] [loss_bc: 0.00303319; loss_div: 0.00029530; loss_ff: 0.00011286] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  90%|████████▉ | 1798/2000 [02:12<00:14, 13.94it/s][Iteration 001800/002000] [loss: 0.00368799] [loss_bc: 0.00328950; loss_div: 0.00028568; loss_ff: 0.00011280] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  95%|█████████▍| 1898/2000 [02:19<00:07, 13.56it/s][Iteration 001900/002000] [loss: 0.00372075] [loss_bc: 0.00320539; loss_div: 0.00036850; loss_ff: 0.00014686] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training: 100%|█████████▉| 1998/2000 [02:27<00:00, 13.65it/s][Iteration 002000/002000] [loss: 0.00371477] [loss_bc: 0.00333363; loss_div: 0.00026009; loss_ff: 0.00012105] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training: 100%|██████████| 2000/2000 [02:27<00:00, 13.54it/s]\n",
      "[Iteration 002000/002000] [loss: 0.00371477] [loss_bc: 0.00333363; loss_div: 0.00026009; loss_ff: 0.00012105] [w_bc: 1.000000, LR: 0.000050]\n",
      "Runtime --> total: 147.90sec (2.96ms/iter.)\n",
      "Configuration:\n",
      "dim: 256, w_div: 1.000000, w_ff: 1.000000, decay_iterations: None, potential: True, vector_potential: False, \n",
      "Using device: cuda (gpus 1) ['NVIDIA RTX A6000']\n",
      "Potential Boundary: 100%|██████████| 1/1 [00:01<00:00,  1.08s/it]\n",
      "Loaded meta state: /userhome/jeon_mg/workspace/_data/NOAA12673/PINN/20170904_134800/model_final.pt\n",
      "Training:   0%|          | 0/2000 [00:00<?, ?it/s][Iteration 000000/002000] [loss: 0.00363146] [loss_bc: 0.00320145; loss_div: 0.00029378; loss_ff: 0.00013623] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:   5%|▍         | 98/2000 [00:07<02:19, 13.68it/s][Iteration 000100/002000] [loss: 0.00346170] [loss_bc: 0.00310942; loss_div: 0.00026508; loss_ff: 0.00008719] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  10%|▉         | 198/2000 [00:14<02:10, 13.76it/s][Iteration 000200/002000] [loss: 0.00370395] [loss_bc: 0.00329412; loss_div: 0.00029886; loss_ff: 0.00011097] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  15%|█▍        | 298/2000 [00:21<02:04, 13.64it/s][Iteration 000300/002000] [loss: 0.00361833] [loss_bc: 0.00318575; loss_div: 0.00031206; loss_ff: 0.00012052] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  20%|█▉        | 398/2000 [00:29<01:57, 13.61it/s][Iteration 000400/002000] [loss: 0.00378823] [loss_bc: 0.00328342; loss_div: 0.00033671; loss_ff: 0.00016810] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  25%|██▍       | 498/2000 [00:36<01:50, 13.62it/s][Iteration 000500/002000] [loss: 0.00361268] [loss_bc: 0.00318570; loss_div: 0.00029086; loss_ff: 0.00013612] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  30%|██▉       | 598/2000 [00:44<01:43, 13.57it/s][Iteration 000600/002000] [loss: 0.00365952] [loss_bc: 0.00327903; loss_div: 0.00028249; loss_ff: 0.00009800] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  35%|███▍      | 698/2000 [00:51<01:34, 13.76it/s][Iteration 000700/002000] [loss: 0.00376629] [loss_bc: 0.00327045; loss_div: 0.00033016; loss_ff: 0.00016567] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  40%|███▉      | 798/2000 [00:58<01:28, 13.58it/s][Iteration 000800/002000] [loss: 0.00363514] [loss_bc: 0.00313636; loss_div: 0.00035086; loss_ff: 0.00014792] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  45%|████▍     | 898/2000 [01:06<01:19, 13.78it/s][Iteration 000900/002000] [loss: 0.00362754] [loss_bc: 0.00317492; loss_div: 0.00033718; loss_ff: 0.00011544] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  50%|████▉     | 998/2000 [01:13<01:13, 13.63it/s][Iteration 001000/002000] [loss: 0.00356457] [loss_bc: 0.00312715; loss_div: 0.00031230; loss_ff: 0.00012513] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  55%|█████▍    | 1098/2000 [01:20<01:06, 13.59it/s][Iteration 001100/002000] [loss: 0.00351046] [loss_bc: 0.00316525; loss_div: 0.00025118; loss_ff: 0.00009402] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  60%|█████▉    | 1198/2000 [01:28<00:59, 13.57it/s][Iteration 001200/002000] [loss: 0.00362990] [loss_bc: 0.00317470; loss_div: 0.00033849; loss_ff: 0.00011671] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  65%|██████▍   | 1298/2000 [01:35<00:50, 13.83it/s][Iteration 001300/002000] [loss: 0.00365947] [loss_bc: 0.00326145; loss_div: 0.00028393; loss_ff: 0.00011409] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  70%|██████▉   | 1398/2000 [01:42<00:44, 13.59it/s][Iteration 001400/002000] [loss: 0.00370972] [loss_bc: 0.00326984; loss_div: 0.00031041; loss_ff: 0.00012947] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  75%|███████▍  | 1498/2000 [01:50<00:36, 13.78it/s][Iteration 001500/002000] [loss: 0.00349581] [loss_bc: 0.00308803; loss_div: 0.00029379; loss_ff: 0.00011398] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  80%|███████▉  | 1598/2000 [01:57<00:28, 13.86it/s][Iteration 001600/002000] [loss: 0.00363661] [loss_bc: 0.00317192; loss_div: 0.00032424; loss_ff: 0.00014044] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  85%|████████▍ | 1698/2000 [02:04<00:22, 13.58it/s][Iteration 001700/002000] [loss: 0.00351057] [loss_bc: 0.00308432; loss_div: 0.00031128; loss_ff: 0.00011498] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  90%|████████▉ | 1798/2000 [02:12<00:14, 13.63it/s][Iteration 001800/002000] [loss: 0.00363911] [loss_bc: 0.00315213; loss_div: 0.00037014; loss_ff: 0.00011684] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  95%|█████████▍| 1898/2000 [02:19<00:07, 13.54it/s][Iteration 001900/002000] [loss: 0.00355381] [loss_bc: 0.00312009; loss_div: 0.00031100; loss_ff: 0.00012271] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training: 100%|█████████▉| 1998/2000 [02:26<00:00, 13.58it/s][Iteration 002000/002000] [loss: 0.00363477] [loss_bc: 0.00316286; loss_div: 0.00035578; loss_ff: 0.00011613] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training: 100%|██████████| 2000/2000 [02:27<00:00, 13.58it/s]\n",
      "[Iteration 002000/002000] [loss: 0.00363477] [loss_bc: 0.00316286; loss_div: 0.00035578; loss_ff: 0.00011613] [w_bc: 1.000000, LR: 0.000050]\n",
      "Runtime --> total: 147.43sec (2.95ms/iter.)\n",
      "Configuration:\n",
      "dim: 256, w_div: 1.000000, w_ff: 1.000000, decay_iterations: None, potential: True, vector_potential: False, \n",
      "Using device: cuda (gpus 1) ['NVIDIA RTX A6000']\n",
      "Potential Boundary: 100%|██████████| 1/1 [00:01<00:00,  1.04s/it]\n",
      "Loaded meta state: /userhome/jeon_mg/workspace/_data/NOAA12673/PINN/20170904_140000/model_final.pt\n",
      "Training:   0%|          | 0/2000 [00:00<?, ?it/s][Iteration 000000/002000] [loss: 0.00357316] [loss_bc: 0.00310515; loss_div: 0.00035891; loss_ff: 0.00010910] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:   5%|▍         | 98/2000 [00:07<02:19, 13.67it/s][Iteration 000100/002000] [loss: 0.00350261] [loss_bc: 0.00307979; loss_div: 0.00031123; loss_ff: 0.00011160] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  10%|▉         | 198/2000 [00:14<02:12, 13.58it/s][Iteration 000200/002000] [loss: 0.00334678] [loss_bc: 0.00291522; loss_div: 0.00032222; loss_ff: 0.00010934] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  15%|█▍        | 298/2000 [00:21<02:05, 13.58it/s][Iteration 000300/002000] [loss: 0.00369550] [loss_bc: 0.00312058; loss_div: 0.00040695; loss_ff: 0.00016797] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  20%|█▉        | 398/2000 [00:29<01:58, 13.55it/s][Iteration 000400/002000] [loss: 0.00364022] [loss_bc: 0.00316153; loss_div: 0.00033399; loss_ff: 0.00014470] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  25%|██▍       | 498/2000 [00:36<01:50, 13.62it/s][Iteration 000500/002000] [loss: 0.00362096] [loss_bc: 0.00310851; loss_div: 0.00038078; loss_ff: 0.00013167] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  30%|██▉       | 598/2000 [00:44<01:41, 13.85it/s][Iteration 000600/002000] [loss: 0.00352431] [loss_bc: 0.00308250; loss_div: 0.00032180; loss_ff: 0.00012001] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  35%|███▍      | 698/2000 [00:51<01:35, 13.63it/s][Iteration 000700/002000] [loss: 0.00372595] [loss_bc: 0.00320277; loss_div: 0.00038919; loss_ff: 0.00013400] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  40%|███▉      | 798/2000 [00:58<01:28, 13.63it/s][Iteration 000800/002000] [loss: 0.00362586] [loss_bc: 0.00319960; loss_div: 0.00031237; loss_ff: 0.00011389] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  45%|████▍     | 898/2000 [01:06<01:22, 13.43it/s][Iteration 000900/002000] [loss: 0.00357043] [loss_bc: 0.00313222; loss_div: 0.00029801; loss_ff: 0.00014021] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  50%|████▉     | 998/2000 [01:13<01:13, 13.62it/s][Iteration 001000/002000] [loss: 0.00363092] [loss_bc: 0.00310622; loss_div: 0.00037888; loss_ff: 0.00014581] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  55%|█████▍    | 1098/2000 [01:20<01:06, 13.61it/s][Iteration 001100/002000] [loss: 0.00332855] [loss_bc: 0.00290208; loss_div: 0.00031954; loss_ff: 0.00010694] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  60%|█████▉    | 1198/2000 [01:28<00:58, 13.61it/s][Iteration 001200/002000] [loss: 0.00348997] [loss_bc: 0.00307306; loss_div: 0.00028922; loss_ff: 0.00012769] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  65%|██████▍   | 1298/2000 [01:35<00:51, 13.67it/s][Iteration 001300/002000] [loss: 0.00371226] [loss_bc: 0.00327098; loss_div: 0.00033509; loss_ff: 0.00010619] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  70%|██████▉   | 1398/2000 [01:42<00:44, 13.64it/s][Iteration 001400/002000] [loss: 0.00372325] [loss_bc: 0.00327821; loss_div: 0.00032402; loss_ff: 0.00012102] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  75%|███████▍  | 1498/2000 [01:50<00:36, 13.65it/s][Iteration 001500/002000] [loss: 0.00336267] [loss_bc: 0.00289147; loss_div: 0.00033865; loss_ff: 0.00013255] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  80%|███████▉  | 1598/2000 [01:57<00:28, 13.94it/s][Iteration 001600/002000] [loss: 0.00353639] [loss_bc: 0.00311025; loss_div: 0.00030300; loss_ff: 0.00012313] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  85%|████████▍ | 1698/2000 [02:04<00:21, 13.95it/s][Iteration 001700/002000] [loss: 0.00353241] [loss_bc: 0.00308465; loss_div: 0.00032221; loss_ff: 0.00012556] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  90%|████████▉ | 1798/2000 [02:11<00:14, 13.59it/s][Iteration 001800/002000] [loss: 0.00356576] [loss_bc: 0.00317541; loss_div: 0.00024905; loss_ff: 0.00014130] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  95%|█████████▍| 1898/2000 [02:19<00:07, 13.78it/s][Iteration 001900/002000] [loss: 0.00358788] [loss_bc: 0.00318724; loss_div: 0.00028922; loss_ff: 0.00011142] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training: 100%|█████████▉| 1998/2000 [02:26<00:00, 13.60it/s][Iteration 002000/002000] [loss: 0.00364411] [loss_bc: 0.00316183; loss_div: 0.00033483; loss_ff: 0.00014745] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training: 100%|██████████| 2000/2000 [02:27<00:00, 13.60it/s]\n",
      "[Iteration 002000/002000] [loss: 0.00364411] [loss_bc: 0.00316183; loss_div: 0.00033483; loss_ff: 0.00014745] [w_bc: 1.000000, LR: 0.000050]\n",
      "Runtime --> total: 147.31sec (2.95ms/iter.)\n",
      "Configuration:\n",
      "dim: 256, w_div: 1.000000, w_ff: 1.000000, decay_iterations: None, potential: True, vector_potential: False, \n",
      "Using device: cuda (gpus 1) ['NVIDIA RTX A6000']\n",
      "Potential Boundary: 100%|██████████| 1/1 [00:01<00:00,  1.01s/it]\n",
      "Loaded meta state: /userhome/jeon_mg/workspace/_data/NOAA12673/PINN/20170904_141200/model_final.pt\n",
      "Training:   0%|          | 0/2000 [00:00<?, ?it/s][Iteration 000000/002000] [loss: 0.00356191] [loss_bc: 0.00313776; loss_div: 0.00029605; loss_ff: 0.00012810] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:   5%|▍         | 98/2000 [00:07<02:19, 13.64it/s][Iteration 000100/002000] [loss: 0.00362512] [loss_bc: 0.00319819; loss_div: 0.00030520; loss_ff: 0.00012173] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  10%|▉         | 198/2000 [00:14<02:12, 13.60it/s][Iteration 000200/002000] [loss: 0.00358791] [loss_bc: 0.00316712; loss_div: 0.00028783; loss_ff: 0.00013296] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  15%|█▍        | 298/2000 [00:21<02:05, 13.56it/s][Iteration 000300/002000] [loss: 0.00347893] [loss_bc: 0.00311908; loss_div: 0.00027567; loss_ff: 0.00008418] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  20%|█▉        | 398/2000 [00:29<01:57, 13.59it/s][Iteration 000400/002000] [loss: 0.00347729] [loss_bc: 0.00307818; loss_div: 0.00028788; loss_ff: 0.00011123] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  25%|██▍       | 498/2000 [00:36<01:48, 13.83it/s][Iteration 000500/002000] [loss: 0.00354301] [loss_bc: 0.00315403; loss_div: 0.00029961; loss_ff: 0.00008937] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  30%|██▉       | 598/2000 [00:43<01:43, 13.61it/s][Iteration 000600/002000] [loss: 0.00359940] [loss_bc: 0.00314458; loss_div: 0.00032099; loss_ff: 0.00013383] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  35%|███▍      | 698/2000 [00:51<01:36, 13.53it/s][Iteration 000700/002000] [loss: 0.00352661] [loss_bc: 0.00306874; loss_div: 0.00033786; loss_ff: 0.00012001] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  40%|███▉      | 798/2000 [00:58<01:27, 13.70it/s][Iteration 000800/002000] [loss: 0.00369668] [loss_bc: 0.00318192; loss_div: 0.00039248; loss_ff: 0.00012228] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  45%|████▍     | 898/2000 [01:06<01:20, 13.61it/s][Iteration 000900/002000] [loss: 0.00374383] [loss_bc: 0.00330814; loss_div: 0.00031372; loss_ff: 0.00012196] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  50%|████▉     | 998/2000 [01:13<01:13, 13.65it/s][Iteration 001000/002000] [loss: 0.00346382] [loss_bc: 0.00306291; loss_div: 0.00027986; loss_ff: 0.00012104] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  55%|█████▍    | 1098/2000 [01:20<01:05, 13.73it/s][Iteration 001100/002000] [loss: 0.00361695] [loss_bc: 0.00317552; loss_div: 0.00030303; loss_ff: 0.00013840] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  60%|█████▉    | 1198/2000 [01:28<00:59, 13.57it/s][Iteration 001200/002000] [loss: 0.00353603] [loss_bc: 0.00306927; loss_div: 0.00034299; loss_ff: 0.00012377] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  65%|██████▍   | 1298/2000 [01:35<00:51, 13.58it/s][Iteration 001300/002000] [loss: 0.00361679] [loss_bc: 0.00326084; loss_div: 0.00025400; loss_ff: 0.00010195] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  70%|██████▉   | 1398/2000 [01:42<00:44, 13.67it/s][Iteration 001400/002000] [loss: 0.00364088] [loss_bc: 0.00317609; loss_div: 0.00034370; loss_ff: 0.00012109] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  75%|███████▍  | 1498/2000 [01:50<00:36, 13.65it/s][Iteration 001500/002000] [loss: 0.00377210] [loss_bc: 0.00325853; loss_div: 0.00037247; loss_ff: 0.00014110] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  80%|███████▉  | 1598/2000 [01:57<00:29, 13.55it/s][Iteration 001600/002000] [loss: 0.00359295] [loss_bc: 0.00312650; loss_div: 0.00033045; loss_ff: 0.00013599] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  85%|████████▍ | 1698/2000 [02:05<00:22, 13.20it/s][Iteration 001700/002000] [loss: 0.00367452] [loss_bc: 0.00325928; loss_div: 0.00030534; loss_ff: 0.00010990] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  90%|████████▉ | 1798/2000 [02:12<00:14, 13.54it/s][Iteration 001800/002000] [loss: 0.00375925] [loss_bc: 0.00324522; loss_div: 0.00034775; loss_ff: 0.00016628] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  95%|█████████▍| 1898/2000 [02:19<00:07, 13.58it/s][Iteration 001900/002000] [loss: 0.00343769] [loss_bc: 0.00305686; loss_div: 0.00027403; loss_ff: 0.00010680] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training: 100%|█████████▉| 1998/2000 [02:27<00:00, 13.90it/s][Iteration 002000/002000] [loss: 0.00374458] [loss_bc: 0.00324313; loss_div: 0.00034284; loss_ff: 0.00015861] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training: 100%|██████████| 2000/2000 [02:27<00:00, 13.56it/s]\n",
      "[Iteration 002000/002000] [loss: 0.00374458] [loss_bc: 0.00324313; loss_div: 0.00034284; loss_ff: 0.00015861] [w_bc: 1.000000, LR: 0.000050]\n",
      "Runtime --> total: 147.72sec (2.95ms/iter.)\n",
      "Configuration:\n",
      "dim: 256, w_div: 1.000000, w_ff: 1.000000, decay_iterations: None, potential: True, vector_potential: False, \n",
      "Using device: cuda (gpus 1) ['NVIDIA RTX A6000']\n",
      "Potential Boundary: 100%|██████████| 1/1 [00:00<00:00,  1.02it/s]\n",
      "Loaded meta state: /userhome/jeon_mg/workspace/_data/NOAA12673/PINN/20170904_142400/model_final.pt\n",
      "Training:   0%|          | 0/2000 [00:00<?, ?it/s][Iteration 000000/002000] [loss: 0.00369381] [loss_bc: 0.00330036; loss_div: 0.00028433; loss_ff: 0.00010912] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:   5%|▍         | 98/2000 [00:07<02:18, 13.77it/s][Iteration 000100/002000] [loss: 0.00347645] [loss_bc: 0.00309285; loss_div: 0.00028690; loss_ff: 0.00009669] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  10%|▉         | 198/2000 [00:14<02:12, 13.60it/s][Iteration 000200/002000] [loss: 0.00379749] [loss_bc: 0.00331231; loss_div: 0.00037748; loss_ff: 0.00010770] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  15%|█▍        | 298/2000 [00:21<02:05, 13.56it/s][Iteration 000300/002000] [loss: 0.00353078] [loss_bc: 0.00314294; loss_div: 0.00028643; loss_ff: 0.00010141] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  20%|█▉        | 398/2000 [00:29<01:58, 13.51it/s][Iteration 000400/002000] [loss: 0.00359292] [loss_bc: 0.00313338; loss_div: 0.00035123; loss_ff: 0.00010830] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  25%|██▍       | 498/2000 [00:36<01:50, 13.55it/s][Iteration 000500/002000] [loss: 0.00359327] [loss_bc: 0.00315456; loss_div: 0.00031106; loss_ff: 0.00012765] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  30%|██▉       | 598/2000 [00:43<01:43, 13.60it/s][Iteration 000600/002000] [loss: 0.00350137] [loss_bc: 0.00313053; loss_div: 0.00027285; loss_ff: 0.00009798] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  35%|███▍      | 698/2000 [00:51<01:35, 13.58it/s][Iteration 000700/002000] [loss: 0.00338074] [loss_bc: 0.00295107; loss_div: 0.00029515; loss_ff: 0.00013451] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  40%|███▉      | 798/2000 [00:58<01:28, 13.59it/s][Iteration 000800/002000] [loss: 0.00344877] [loss_bc: 0.00295704; loss_div: 0.00034360; loss_ff: 0.00014813] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  45%|████▍     | 898/2000 [01:06<01:21, 13.60it/s][Iteration 000900/002000] [loss: 0.00336185] [loss_bc: 0.00289220; loss_div: 0.00035571; loss_ff: 0.00011394] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  50%|████▉     | 998/2000 [01:13<01:13, 13.60it/s][Iteration 001000/002000] [loss: 0.00363167] [loss_bc: 0.00312933; loss_div: 0.00039185; loss_ff: 0.00011049] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  55%|█████▍    | 1098/2000 [01:20<01:06, 13.60it/s][Iteration 001100/002000] [loss: 0.00370900] [loss_bc: 0.00329449; loss_div: 0.00031714; loss_ff: 0.00009737] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  60%|█████▉    | 1198/2000 [01:28<00:58, 13.61it/s][Iteration 001200/002000] [loss: 0.00353624] [loss_bc: 0.00305511; loss_div: 0.00034763; loss_ff: 0.00013350] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  65%|██████▍   | 1298/2000 [01:35<00:51, 13.60it/s][Iteration 001300/002000] [loss: 0.00340224] [loss_bc: 0.00294363; loss_div: 0.00033434; loss_ff: 0.00012427] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  70%|██████▉   | 1398/2000 [01:43<00:43, 13.91it/s][Iteration 001400/002000] [loss: 0.00362668] [loss_bc: 0.00314482; loss_div: 0.00035234; loss_ff: 0.00012952] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  75%|███████▍  | 1498/2000 [01:50<00:36, 13.70it/s][Iteration 001500/002000] [loss: 0.00354235] [loss_bc: 0.00311275; loss_div: 0.00032138; loss_ff: 0.00010823] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  80%|███████▉  | 1598/2000 [01:57<00:29, 13.59it/s][Iteration 001600/002000] [loss: 0.00331981] [loss_bc: 0.00294047; loss_div: 0.00028084; loss_ff: 0.00009850] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  85%|████████▍ | 1698/2000 [02:05<00:22, 13.65it/s][Iteration 001700/002000] [loss: 0.00361309] [loss_bc: 0.00315557; loss_div: 0.00031013; loss_ff: 0.00014739] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  90%|████████▉ | 1798/2000 [02:12<00:14, 13.53it/s][Iteration 001800/002000] [loss: 0.00367890] [loss_bc: 0.00322614; loss_div: 0.00033035; loss_ff: 0.00012241] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  95%|█████████▍| 1898/2000 [02:19<00:07, 13.60it/s][Iteration 001900/002000] [loss: 0.00369629] [loss_bc: 0.00322922; loss_div: 0.00031174; loss_ff: 0.00015533] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training: 100%|█████████▉| 1998/2000 [02:27<00:00, 13.73it/s][Iteration 002000/002000] [loss: 0.00339023] [loss_bc: 0.00293472; loss_div: 0.00033810; loss_ff: 0.00011741] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training: 100%|██████████| 2000/2000 [02:27<00:00, 13.56it/s]\n",
      "[Iteration 002000/002000] [loss: 0.00339023] [loss_bc: 0.00293472; loss_div: 0.00033810; loss_ff: 0.00011741] [w_bc: 1.000000, LR: 0.000050]\n",
      "Runtime --> total: 147.72sec (2.95ms/iter.)\n",
      "Configuration:\n",
      "dim: 256, w_div: 1.000000, w_ff: 1.000000, decay_iterations: None, potential: True, vector_potential: False, \n",
      "Using device: cuda (gpus 1) ['NVIDIA RTX A6000']\n",
      "Potential Boundary: 100%|██████████| 1/1 [00:01<00:00,  1.04s/it]\n",
      "Loaded meta state: /userhome/jeon_mg/workspace/_data/NOAA12673/PINN/20170904_143600/model_final.pt\n",
      "Training:   0%|          | 0/2000 [00:00<?, ?it/s][Iteration 000000/002000] [loss: 0.00346252] [loss_bc: 0.00304359; loss_div: 0.00031995; loss_ff: 0.00009898] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:   5%|▍         | 98/2000 [00:07<02:18, 13.77it/s][Iteration 000100/002000] [loss: 0.00361374] [loss_bc: 0.00318326; loss_div: 0.00031753; loss_ff: 0.00011295] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  10%|▉         | 198/2000 [00:14<02:12, 13.59it/s][Iteration 000200/002000] [loss: 0.00353101] [loss_bc: 0.00317639; loss_div: 0.00025409; loss_ff: 0.00010053] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  15%|█▍        | 298/2000 [00:21<02:02, 13.94it/s][Iteration 000300/002000] [loss: 0.00359774] [loss_bc: 0.00317504; loss_div: 0.00029756; loss_ff: 0.00012515] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  20%|█▉        | 398/2000 [00:29<01:58, 13.56it/s][Iteration 000400/002000] [loss: 0.00370933] [loss_bc: 0.00320600; loss_div: 0.00034028; loss_ff: 0.00016304] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  25%|██▍       | 498/2000 [00:36<01:50, 13.65it/s][Iteration 000500/002000] [loss: 0.00343763] [loss_bc: 0.00299055; loss_div: 0.00033838; loss_ff: 0.00010870] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  30%|██▉       | 598/2000 [00:43<01:41, 13.87it/s][Iteration 000600/002000] [loss: 0.00373913] [loss_bc: 0.00323964; loss_div: 0.00038815; loss_ff: 0.00011135] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  35%|███▍      | 698/2000 [00:51<01:35, 13.70it/s][Iteration 000700/002000] [loss: 0.00376271] [loss_bc: 0.00319289; loss_div: 0.00041940; loss_ff: 0.00015042] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  40%|███▉      | 798/2000 [00:58<01:28, 13.63it/s][Iteration 000800/002000] [loss: 0.00352969] [loss_bc: 0.00313239; loss_div: 0.00029998; loss_ff: 0.00009732] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  45%|████▍     | 898/2000 [01:05<01:20, 13.61it/s][Iteration 000900/002000] [loss: 0.00364095] [loss_bc: 0.00318515; loss_div: 0.00032661; loss_ff: 0.00012919] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  50%|████▉     | 998/2000 [01:13<01:13, 13.70it/s][Iteration 001000/002000] [loss: 0.00369878] [loss_bc: 0.00320898; loss_div: 0.00035733; loss_ff: 0.00013248] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  55%|█████▍    | 1098/2000 [01:20<01:06, 13.51it/s][Iteration 001100/002000] [loss: 0.00364426] [loss_bc: 0.00318820; loss_div: 0.00031473; loss_ff: 0.00014133] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  60%|█████▉    | 1198/2000 [01:28<00:59, 13.50it/s][Iteration 001200/002000] [loss: 0.00365000] [loss_bc: 0.00319775; loss_div: 0.00034149; loss_ff: 0.00011076] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  65%|██████▍   | 1298/2000 [01:35<00:51, 13.56it/s][Iteration 001300/002000] [loss: 0.00354811] [loss_bc: 0.00301225; loss_div: 0.00039871; loss_ff: 0.00013715] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  70%|██████▉   | 1398/2000 [01:42<00:44, 13.55it/s][Iteration 001400/002000] [loss: 0.00358677] [loss_bc: 0.00317600; loss_div: 0.00029368; loss_ff: 0.00011709] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  75%|███████▍  | 1498/2000 [01:50<00:36, 13.78it/s][Iteration 001500/002000] [loss: 0.00354191] [loss_bc: 0.00312413; loss_div: 0.00030231; loss_ff: 0.00011547] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  80%|███████▉  | 1598/2000 [01:57<00:29, 13.73it/s][Iteration 001600/002000] [loss: 0.00361197] [loss_bc: 0.00314521; loss_div: 0.00034577; loss_ff: 0.00012099] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  85%|████████▍ | 1698/2000 [02:04<00:22, 13.58it/s][Iteration 001700/002000] [loss: 0.00368604] [loss_bc: 0.00318056; loss_div: 0.00039405; loss_ff: 0.00011144] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  90%|████████▉ | 1798/2000 [02:12<00:14, 13.59it/s][Iteration 001800/002000] [loss: 0.00354820] [loss_bc: 0.00317655; loss_div: 0.00028099; loss_ff: 0.00009065] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  95%|█████████▍| 1898/2000 [02:19<00:07, 13.57it/s][Iteration 001900/002000] [loss: 0.00360399] [loss_bc: 0.00310777; loss_div: 0.00036669; loss_ff: 0.00012952] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training: 100%|█████████▉| 1998/2000 [02:26<00:00, 13.94it/s][Iteration 002000/002000] [loss: 0.00357592] [loss_bc: 0.00316278; loss_div: 0.00032051; loss_ff: 0.00009263] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training: 100%|██████████| 2000/2000 [02:27<00:00, 13.57it/s]\n",
      "[Iteration 002000/002000] [loss: 0.00357592] [loss_bc: 0.00316278; loss_div: 0.00032051; loss_ff: 0.00009263] [w_bc: 1.000000, LR: 0.000050]\n",
      "Runtime --> total: 147.52sec (2.95ms/iter.)\n",
      "Configuration:\n",
      "dim: 256, w_div: 1.000000, w_ff: 1.000000, decay_iterations: None, potential: True, vector_potential: False, \n",
      "Using device: cuda (gpus 1) ['NVIDIA RTX A6000']\n",
      "Potential Boundary: 100%|██████████| 1/1 [00:00<00:00,  1.62it/s]\n",
      "Loaded meta state: /userhome/jeon_mg/workspace/_data/NOAA12673/PINN/20170904_144800/model_final.pt\n",
      "Training:   0%|          | 0/2000 [00:00<?, ?it/s][Iteration 000000/002000] [loss: 0.00348791] [loss_bc: 0.00308886; loss_div: 0.00029183; loss_ff: 0.00010723] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:   5%|▍         | 98/2000 [00:07<02:20, 13.54it/s][Iteration 000100/002000] [loss: 0.00379926] [loss_bc: 0.00333756; loss_div: 0.00035177; loss_ff: 0.00010992] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  10%|▉         | 198/2000 [00:14<02:12, 13.61it/s][Iteration 000200/002000] [loss: 0.00378335] [loss_bc: 0.00331473; loss_div: 0.00032903; loss_ff: 0.00013959] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  15%|█▍        | 298/2000 [00:22<02:04, 13.62it/s][Iteration 000300/002000] [loss: 0.00365293] [loss_bc: 0.00318171; loss_div: 0.00034577; loss_ff: 0.00012545] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  20%|█▉        | 398/2000 [00:29<01:58, 13.56it/s][Iteration 000400/002000] [loss: 0.00383133] [loss_bc: 0.00334321; loss_div: 0.00035589; loss_ff: 0.00013222] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  25%|██▍       | 498/2000 [00:36<01:50, 13.64it/s][Iteration 000500/002000] [loss: 0.00365127] [loss_bc: 0.00317733; loss_div: 0.00031374; loss_ff: 0.00016020] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  30%|██▉       | 598/2000 [00:44<01:43, 13.57it/s][Iteration 000600/002000] [loss: 0.00350352] [loss_bc: 0.00306045; loss_div: 0.00031162; loss_ff: 0.00013145] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  35%|███▍      | 698/2000 [00:51<01:36, 13.53it/s][Iteration 000700/002000] [loss: 0.00377403] [loss_bc: 0.00333099; loss_div: 0.00032595; loss_ff: 0.00011709] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  40%|███▉      | 798/2000 [00:58<01:28, 13.56it/s][Iteration 000800/002000] [loss: 0.00360738] [loss_bc: 0.00316829; loss_div: 0.00034305; loss_ff: 0.00009604] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  45%|████▍     | 898/2000 [01:06<01:19, 13.84it/s][Iteration 000900/002000] [loss: 0.00375657] [loss_bc: 0.00332621; loss_div: 0.00031967; loss_ff: 0.00011070] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  50%|████▉     | 998/2000 [01:13<01:13, 13.66it/s][Iteration 001000/002000] [loss: 0.00342651] [loss_bc: 0.00304452; loss_div: 0.00027954; loss_ff: 0.00010244] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  55%|█████▍    | 1098/2000 [01:20<01:06, 13.55it/s][Iteration 001100/002000] [loss: 0.00323497] [loss_bc: 0.00283499; loss_div: 0.00025633; loss_ff: 0.00014365] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  60%|█████▉    | 1198/2000 [01:28<00:58, 13.80it/s][Iteration 001200/002000] [loss: 0.00377830] [loss_bc: 0.00331059; loss_div: 0.00033506; loss_ff: 0.00013264] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  65%|██████▍   | 1298/2000 [01:35<00:51, 13.72it/s][Iteration 001300/002000] [loss: 0.00355422] [loss_bc: 0.00304068; loss_div: 0.00039968; loss_ff: 0.00011385] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  70%|██████▉   | 1398/2000 [01:43<00:43, 13.78it/s][Iteration 001400/002000] [loss: 0.00378922] [loss_bc: 0.00342744; loss_div: 0.00025407; loss_ff: 0.00010770] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  75%|███████▍  | 1498/2000 [01:50<00:36, 13.58it/s][Iteration 001500/002000] [loss: 0.00355310] [loss_bc: 0.00304234; loss_div: 0.00038699; loss_ff: 0.00012377] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  80%|███████▉  | 1598/2000 [01:57<00:29, 13.51it/s][Iteration 001600/002000] [loss: 0.00375895] [loss_bc: 0.00328551; loss_div: 0.00035823; loss_ff: 0.00011521] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  85%|████████▍ | 1698/2000 [02:05<00:21, 13.73it/s][Iteration 001700/002000] [loss: 0.00355320] [loss_bc: 0.00317575; loss_div: 0.00027630; loss_ff: 0.00010115] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  90%|████████▉ | 1798/2000 [02:12<00:14, 13.53it/s][Iteration 001800/002000] [loss: 0.00359282] [loss_bc: 0.00315177; loss_div: 0.00029264; loss_ff: 0.00014842] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  95%|█████████▍| 1898/2000 [02:19<00:07, 13.90it/s][Iteration 001900/002000] [loss: 0.00339223] [loss_bc: 0.00303172; loss_div: 0.00026626; loss_ff: 0.00009425] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training: 100%|█████████▉| 1998/2000 [02:27<00:00, 13.53it/s][Iteration 002000/002000] [loss: 0.00361905] [loss_bc: 0.00317543; loss_div: 0.00032367; loss_ff: 0.00011995] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training: 100%|██████████| 2000/2000 [02:27<00:00, 13.54it/s]\n",
      "[Iteration 002000/002000] [loss: 0.00361905] [loss_bc: 0.00317543; loss_div: 0.00032367; loss_ff: 0.00011995] [w_bc: 1.000000, LR: 0.000050]\n",
      "Runtime --> total: 147.90sec (2.96ms/iter.)\n",
      "Configuration:\n",
      "dim: 256, w_div: 1.000000, w_ff: 1.000000, decay_iterations: None, potential: True, vector_potential: False, \n",
      "Using device: cuda (gpus 1) ['NVIDIA RTX A6000']\n",
      "Potential Boundary: 100%|██████████| 1/1 [00:00<00:00,  1.78it/s]\n",
      "Loaded meta state: /userhome/jeon_mg/workspace/_data/NOAA12673/PINN/20170904_150000/model_final.pt\n",
      "Training:   0%|          | 0/2000 [00:00<?, ?it/s][Iteration 000000/002000] [loss: 0.00359767] [loss_bc: 0.00316697; loss_div: 0.00030028; loss_ff: 0.00013042] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:   5%|▍         | 98/2000 [00:07<02:19, 13.59it/s][Iteration 000100/002000] [loss: 0.00378601] [loss_bc: 0.00332602; loss_div: 0.00033397; loss_ff: 0.00012603] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  10%|▉         | 198/2000 [00:14<02:12, 13.56it/s][Iteration 000200/002000] [loss: 0.00357754] [loss_bc: 0.00321326; loss_div: 0.00027365; loss_ff: 0.00009063] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  15%|█▍        | 298/2000 [00:21<02:04, 13.63it/s][Iteration 000300/002000] [loss: 0.00347047] [loss_bc: 0.00307167; loss_div: 0.00030353; loss_ff: 0.00009528] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  20%|█▉        | 398/2000 [00:29<01:57, 13.62it/s][Iteration 000400/002000] [loss: 0.00358960] [loss_bc: 0.00312354; loss_div: 0.00035035; loss_ff: 0.00011571] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  25%|██▍       | 498/2000 [00:36<01:51, 13.51it/s][Iteration 000500/002000] [loss: 0.00342091] [loss_bc: 0.00298801; loss_div: 0.00032172; loss_ff: 0.00011117] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  30%|██▉       | 598/2000 [00:44<01:43, 13.59it/s][Iteration 000600/002000] [loss: 0.00337076] [loss_bc: 0.00298164; loss_div: 0.00027203; loss_ff: 0.00011708] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  35%|███▍      | 698/2000 [00:51<01:36, 13.56it/s][Iteration 000700/002000] [loss: 0.00353483] [loss_bc: 0.00311545; loss_div: 0.00030581; loss_ff: 0.00011357] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  40%|███▉      | 798/2000 [00:58<01:27, 13.67it/s][Iteration 000800/002000] [loss: 0.00358630] [loss_bc: 0.00311386; loss_div: 0.00035018; loss_ff: 0.00012226] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  45%|████▍     | 898/2000 [01:06<01:20, 13.61it/s][Iteration 000900/002000] [loss: 0.00361181] [loss_bc: 0.00315150; loss_div: 0.00034360; loss_ff: 0.00011671] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  50%|████▉     | 998/2000 [01:13<01:14, 13.51it/s][Iteration 001000/002000] [loss: 0.00370359] [loss_bc: 0.00329265; loss_div: 0.00029851; loss_ff: 0.00011242] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  55%|█████▍    | 1098/2000 [01:20<01:06, 13.64it/s][Iteration 001100/002000] [loss: 0.00376716] [loss_bc: 0.00333945; loss_div: 0.00031358; loss_ff: 0.00011414] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  60%|█████▉    | 1198/2000 [01:28<00:59, 13.52it/s][Iteration 001200/002000] [loss: 0.00378906] [loss_bc: 0.00333395; loss_div: 0.00033229; loss_ff: 0.00012282] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  65%|██████▍   | 1298/2000 [01:35<00:51, 13.59it/s][Iteration 001300/002000] [loss: 0.00345800] [loss_bc: 0.00301789; loss_div: 0.00033513; loss_ff: 0.00010499] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  70%|██████▉   | 1398/2000 [01:43<00:44, 13.64it/s][Iteration 001400/002000] [loss: 0.00364568] [loss_bc: 0.00314911; loss_div: 0.00035620; loss_ff: 0.00014037] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  75%|███████▍  | 1498/2000 [01:50<00:37, 13.55it/s][Iteration 001500/002000] [loss: 0.00352800] [loss_bc: 0.00310339; loss_div: 0.00029565; loss_ff: 0.00012896] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  80%|███████▉  | 1598/2000 [01:57<00:29, 13.57it/s][Iteration 001600/002000] [loss: 0.00335016] [loss_bc: 0.00297266; loss_div: 0.00027719; loss_ff: 0.00010031] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  85%|████████▍ | 1698/2000 [02:05<00:22, 13.58it/s][Iteration 001700/002000] [loss: 0.00377494] [loss_bc: 0.00333468; loss_div: 0.00033278; loss_ff: 0.00010748] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  90%|████████▉ | 1798/2000 [02:12<00:14, 13.60it/s][Iteration 001800/002000] [loss: 0.00342697] [loss_bc: 0.00297435; loss_div: 0.00031892; loss_ff: 0.00013370] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  95%|█████████▍| 1898/2000 [02:19<00:07, 13.58it/s][Iteration 001900/002000] [loss: 0.00352215] [loss_bc: 0.00309641; loss_div: 0.00029932; loss_ff: 0.00012642] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training: 100%|█████████▉| 1998/2000 [02:27<00:00, 13.64it/s][Iteration 002000/002000] [loss: 0.00352278] [loss_bc: 0.00305273; loss_div: 0.00034238; loss_ff: 0.00012767] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training: 100%|██████████| 2000/2000 [02:27<00:00, 13.54it/s]\n",
      "[Iteration 002000/002000] [loss: 0.00352278] [loss_bc: 0.00305273; loss_div: 0.00034238; loss_ff: 0.00012767] [w_bc: 1.000000, LR: 0.000050]\n",
      "Runtime --> total: 147.84sec (2.96ms/iter.)\n",
      "Configuration:\n",
      "dim: 256, w_div: 1.000000, w_ff: 1.000000, decay_iterations: None, potential: True, vector_potential: False, \n",
      "Using device: cuda (gpus 1) ['NVIDIA RTX A6000']\n",
      "Potential Boundary: 100%|██████████| 1/1 [00:00<00:00,  1.50it/s]\n",
      "Loaded meta state: /userhome/jeon_mg/workspace/_data/NOAA12673/PINN/20170904_151200/model_final.pt\n",
      "Training:   0%|          | 0/2000 [00:00<?, ?it/s][Iteration 000000/002000] [loss: 0.00353224] [loss_bc: 0.00306560; loss_div: 0.00035269; loss_ff: 0.00011396] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:   5%|▍         | 98/2000 [00:07<02:20, 13.58it/s][Iteration 000100/002000] [loss: 0.00336758] [loss_bc: 0.00297166; loss_div: 0.00028265; loss_ff: 0.00011327] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  10%|▉         | 198/2000 [00:14<02:13, 13.55it/s][Iteration 000200/002000] [loss: 0.00331310] [loss_bc: 0.00293386; loss_div: 0.00027965; loss_ff: 0.00009960] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  15%|█▍        | 298/2000 [00:21<02:05, 13.55it/s][Iteration 000300/002000] [loss: 0.00355895] [loss_bc: 0.00308371; loss_div: 0.00035003; loss_ff: 0.00012521] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  20%|█▉        | 398/2000 [00:29<01:57, 13.61it/s][Iteration 000400/002000] [loss: 0.00349169] [loss_bc: 0.00307608; loss_div: 0.00030797; loss_ff: 0.00010764] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  25%|██▍       | 498/2000 [00:36<01:49, 13.71it/s][Iteration 000500/002000] [loss: 0.00351209] [loss_bc: 0.00304993; loss_div: 0.00035223; loss_ff: 0.00010993] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  30%|██▉       | 598/2000 [00:44<01:43, 13.52it/s][Iteration 000600/002000] [loss: 0.00372170] [loss_bc: 0.00330285; loss_div: 0.00031415; loss_ff: 0.00010471] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  35%|███▍      | 698/2000 [00:51<01:35, 13.60it/s][Iteration 000700/002000] [loss: 0.00358167] [loss_bc: 0.00311038; loss_div: 0.00033311; loss_ff: 0.00013818] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  40%|███▉      | 798/2000 [00:58<01:28, 13.54it/s][Iteration 000800/002000] [loss: 0.00351226] [loss_bc: 0.00310599; loss_div: 0.00028862; loss_ff: 0.00011765] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  45%|████▍     | 898/2000 [01:06<01:20, 13.64it/s][Iteration 000900/002000] [loss: 0.00357209] [loss_bc: 0.00304949; loss_div: 0.00034450; loss_ff: 0.00017809] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  50%|████▉     | 998/2000 [01:13<01:14, 13.53it/s][Iteration 001000/002000] [loss: 0.00349750] [loss_bc: 0.00309049; loss_div: 0.00028472; loss_ff: 0.00012230] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  55%|█████▍    | 1098/2000 [01:21<01:06, 13.59it/s][Iteration 001100/002000] [loss: 0.00352637] [loss_bc: 0.00306367; loss_div: 0.00032760; loss_ff: 0.00013511] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  60%|█████▉    | 1198/2000 [01:28<00:59, 13.57it/s][Iteration 001200/002000] [loss: 0.00331052] [loss_bc: 0.00294505; loss_div: 0.00028140; loss_ff: 0.00008407] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  65%|██████▍   | 1298/2000 [01:35<00:51, 13.55it/s][Iteration 001300/002000] [loss: 0.00349588] [loss_bc: 0.00304249; loss_div: 0.00030466; loss_ff: 0.00014873] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  70%|██████▉   | 1398/2000 [01:43<00:43, 13.80it/s][Iteration 001400/002000] [loss: 0.00353712] [loss_bc: 0.00308905; loss_div: 0.00035076; loss_ff: 0.00009731] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  75%|███████▍  | 1498/2000 [01:50<00:36, 13.90it/s][Iteration 001500/002000] [loss: 0.00358514] [loss_bc: 0.00309113; loss_div: 0.00037578; loss_ff: 0.00011824] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  80%|███████▉  | 1598/2000 [01:57<00:29, 13.52it/s][Iteration 001600/002000] [loss: 0.00355216] [loss_bc: 0.00308050; loss_div: 0.00034132; loss_ff: 0.00013034] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  85%|████████▍ | 1698/2000 [02:05<00:22, 13.60it/s][Iteration 001700/002000] [loss: 0.00347862] [loss_bc: 0.00305953; loss_div: 0.00030487; loss_ff: 0.00011422] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  90%|████████▉ | 1798/2000 [02:12<00:14, 13.78it/s][Iteration 001800/002000] [loss: 0.00352908] [loss_bc: 0.00308722; loss_div: 0.00032953; loss_ff: 0.00011233] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  95%|█████████▍| 1898/2000 [02:19<00:07, 13.53it/s][Iteration 001900/002000] [loss: 0.00329200] [loss_bc: 0.00293432; loss_div: 0.00026660; loss_ff: 0.00009108] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training: 100%|█████████▉| 1998/2000 [02:27<00:00, 13.87it/s][Iteration 002000/002000] [loss: 0.00355459] [loss_bc: 0.00308174; loss_div: 0.00033271; loss_ff: 0.00014014] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training: 100%|██████████| 2000/2000 [02:27<00:00, 13.55it/s]\n",
      "[Iteration 002000/002000] [loss: 0.00355459] [loss_bc: 0.00308174; loss_div: 0.00033271; loss_ff: 0.00014014] [w_bc: 1.000000, LR: 0.000050]\n",
      "Runtime --> total: 147.73sec (2.95ms/iter.)\n",
      "Configuration:\n",
      "dim: 256, w_div: 1.000000, w_ff: 1.000000, decay_iterations: None, potential: True, vector_potential: False, \n",
      "Using device: cuda (gpus 1) ['NVIDIA RTX A6000']\n",
      "Potential Boundary: 100%|██████████| 1/1 [00:00<00:00,  1.76it/s]\n",
      "Loaded meta state: /userhome/jeon_mg/workspace/_data/NOAA12673/PINN/20170904_152400/model_final.pt\n",
      "Training:   0%|          | 0/2000 [00:00<?, ?it/s][Iteration 000000/002000] [loss: 0.00360815] [loss_bc: 0.00316904; loss_div: 0.00033216; loss_ff: 0.00010695] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:   5%|▍         | 98/2000 [00:07<02:19, 13.64it/s][Iteration 000100/002000] [loss: 0.00356706] [loss_bc: 0.00303735; loss_div: 0.00035498; loss_ff: 0.00017473] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  10%|▉         | 198/2000 [00:14<02:12, 13.63it/s][Iteration 000200/002000] [loss: 0.00378119] [loss_bc: 0.00334866; loss_div: 0.00031891; loss_ff: 0.00011361] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  15%|█▍        | 298/2000 [00:21<02:05, 13.55it/s][Iteration 000300/002000] [loss: 0.00349429] [loss_bc: 0.00303095; loss_div: 0.00030369; loss_ff: 0.00015965] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  20%|█▉        | 398/2000 [00:29<01:56, 13.80it/s][Iteration 000400/002000] [loss: 0.00352695] [loss_bc: 0.00312881; loss_div: 0.00028635; loss_ff: 0.00011179] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  25%|██▍       | 498/2000 [00:36<01:50, 13.55it/s][Iteration 000500/002000] [loss: 0.00374254] [loss_bc: 0.00328963; loss_div: 0.00031616; loss_ff: 0.00013675] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  30%|██▉       | 598/2000 [00:43<01:43, 13.58it/s][Iteration 000600/002000] [loss: 0.00374735] [loss_bc: 0.00333078; loss_div: 0.00030661; loss_ff: 0.00010997] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  35%|███▍      | 698/2000 [00:51<01:36, 13.47it/s][Iteration 000700/002000] [loss: 0.00375428] [loss_bc: 0.00329522; loss_div: 0.00031005; loss_ff: 0.00014902] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  40%|███▉      | 798/2000 [00:58<01:29, 13.50it/s][Iteration 000800/002000] [loss: 0.00373026] [loss_bc: 0.00326786; loss_div: 0.00034528; loss_ff: 0.00011712] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  45%|████▍     | 898/2000 [01:06<01:20, 13.61it/s][Iteration 000900/002000] [loss: 0.00356963] [loss_bc: 0.00312679; loss_div: 0.00030696; loss_ff: 0.00013588] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  50%|████▉     | 998/2000 [01:13<01:12, 13.75it/s][Iteration 001000/002000] [loss: 0.00330362] [loss_bc: 0.00286974; loss_div: 0.00029183; loss_ff: 0.00014206] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  55%|█████▍    | 1098/2000 [01:20<01:06, 13.59it/s][Iteration 001100/002000] [loss: 0.00362164] [loss_bc: 0.00327273; loss_div: 0.00025669; loss_ff: 0.00009221] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  60%|█████▉    | 1198/2000 [01:28<00:59, 13.59it/s][Iteration 001200/002000] [loss: 0.00348572] [loss_bc: 0.00305648; loss_div: 0.00032010; loss_ff: 0.00010913] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  65%|██████▍   | 1298/2000 [01:35<00:51, 13.65it/s][Iteration 001300/002000] [loss: 0.00354561] [loss_bc: 0.00313119; loss_div: 0.00029926; loss_ff: 0.00011516] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  70%|██████▉   | 1398/2000 [01:43<00:44, 13.57it/s][Iteration 001400/002000] [loss: 0.00367136] [loss_bc: 0.00327854; loss_div: 0.00028713; loss_ff: 0.00010568] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  75%|███████▍  | 1498/2000 [01:50<00:36, 13.88it/s][Iteration 001500/002000] [loss: 0.00374362] [loss_bc: 0.00325876; loss_div: 0.00036201; loss_ff: 0.00012285] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  80%|███████▉  | 1598/2000 [01:57<00:29, 13.61it/s][Iteration 001600/002000] [loss: 0.00375754] [loss_bc: 0.00325894; loss_div: 0.00037717; loss_ff: 0.00012143] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  85%|████████▍ | 1698/2000 [02:05<00:22, 13.61it/s][Iteration 001700/002000] [loss: 0.00373318] [loss_bc: 0.00331339; loss_div: 0.00030611; loss_ff: 0.00011367] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  90%|████████▉ | 1798/2000 [02:12<00:14, 13.55it/s][Iteration 001800/002000] [loss: 0.00367373] [loss_bc: 0.00325348; loss_div: 0.00028169; loss_ff: 0.00013856] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  95%|█████████▍| 1898/2000 [02:19<00:07, 13.60it/s][Iteration 001900/002000] [loss: 0.00372661] [loss_bc: 0.00330749; loss_div: 0.00031953; loss_ff: 0.00009959] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training: 100%|█████████▉| 1998/2000 [02:27<00:00, 13.62it/s][Iteration 002000/002000] [loss: 0.00336827] [loss_bc: 0.00294048; loss_div: 0.00030250; loss_ff: 0.00012529] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training: 100%|██████████| 2000/2000 [02:27<00:00, 13.56it/s]\n",
      "[Iteration 002000/002000] [loss: 0.00336827] [loss_bc: 0.00294048; loss_div: 0.00030250; loss_ff: 0.00012529] [w_bc: 1.000000, LR: 0.000050]\n",
      "Runtime --> total: 147.72sec (2.95ms/iter.)\n",
      "Configuration:\n",
      "dim: 256, w_div: 1.000000, w_ff: 1.000000, decay_iterations: None, potential: True, vector_potential: False, \n",
      "Using device: cuda (gpus 1) ['NVIDIA RTX A6000']\n",
      "Potential Boundary: 100%|██████████| 1/1 [00:00<00:00,  1.49it/s]\n",
      "Loaded meta state: /userhome/jeon_mg/workspace/_data/NOAA12673/PINN/20170904_153600/model_final.pt\n",
      "Training:   0%|          | 0/2000 [00:00<?, ?it/s][Iteration 000000/002000] [loss: 0.00334892] [loss_bc: 0.00297818; loss_div: 0.00027605; loss_ff: 0.00009468] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:   5%|▍         | 98/2000 [00:07<02:20, 13.51it/s][Iteration 000100/002000] [loss: 0.00360787] [loss_bc: 0.00320108; loss_div: 0.00029469; loss_ff: 0.00011211] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  10%|▉         | 198/2000 [00:14<02:12, 13.59it/s][Iteration 000200/002000] [loss: 0.00375798] [loss_bc: 0.00324364; loss_div: 0.00040226; loss_ff: 0.00011207] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  15%|█▍        | 298/2000 [00:21<02:05, 13.60it/s][Iteration 000300/002000] [loss: 0.00334610] [loss_bc: 0.00293249; loss_div: 0.00030836; loss_ff: 0.00010525] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  20%|█▉        | 398/2000 [00:29<01:57, 13.63it/s][Iteration 000400/002000] [loss: 0.00369251] [loss_bc: 0.00323017; loss_div: 0.00032597; loss_ff: 0.00013637] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  25%|██▍       | 498/2000 [00:36<01:50, 13.61it/s][Iteration 000500/002000] [loss: 0.00353192] [loss_bc: 0.00306099; loss_div: 0.00030893; loss_ff: 0.00016200] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  30%|██▉       | 598/2000 [00:44<01:42, 13.68it/s][Iteration 000600/002000] [loss: 0.00329858] [loss_bc: 0.00292276; loss_div: 0.00025579; loss_ff: 0.00012003] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  35%|███▍      | 698/2000 [00:51<01:35, 13.58it/s][Iteration 000700/002000] [loss: 0.00367492] [loss_bc: 0.00318635; loss_div: 0.00036913; loss_ff: 0.00011945] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  40%|███▉      | 798/2000 [00:58<01:28, 13.53it/s][Iteration 000800/002000] [loss: 0.00360254] [loss_bc: 0.00318948; loss_div: 0.00031465; loss_ff: 0.00009840] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  45%|████▍     | 898/2000 [01:06<01:19, 13.78it/s][Iteration 000900/002000] [loss: 0.00363192] [loss_bc: 0.00318063; loss_div: 0.00031915; loss_ff: 0.00013213] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  50%|████▉     | 998/2000 [01:13<01:13, 13.54it/s][Iteration 001000/002000] [loss: 0.00358531] [loss_bc: 0.00318515; loss_div: 0.00028751; loss_ff: 0.00011264] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  55%|█████▍    | 1098/2000 [01:21<01:06, 13.61it/s][Iteration 001100/002000] [loss: 0.00355269] [loss_bc: 0.00317485; loss_div: 0.00027210; loss_ff: 0.00010574] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  60%|█████▉    | 1198/2000 [01:28<00:57, 13.94it/s][Iteration 001200/002000] [loss: 0.00357344] [loss_bc: 0.00317733; loss_div: 0.00029144; loss_ff: 0.00010467] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  65%|██████▍   | 1298/2000 [01:35<00:51, 13.64it/s][Iteration 001300/002000] [loss: 0.00360336] [loss_bc: 0.00318383; loss_div: 0.00031119; loss_ff: 0.00010833] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  70%|██████▉   | 1398/2000 [01:42<00:43, 13.82it/s][Iteration 001400/002000] [loss: 0.00371729] [loss_bc: 0.00320905; loss_div: 0.00038169; loss_ff: 0.00012654] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  75%|███████▍  | 1498/2000 [01:50<00:36, 13.59it/s][Iteration 001500/002000] [loss: 0.00360691] [loss_bc: 0.00312591; loss_div: 0.00035385; loss_ff: 0.00012715] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  80%|███████▉  | 1598/2000 [01:57<00:29, 13.85it/s][Iteration 001600/002000] [loss: 0.00334077] [loss_bc: 0.00291335; loss_div: 0.00031450; loss_ff: 0.00011292] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  85%|████████▍ | 1698/2000 [02:04<00:22, 13.58it/s][Iteration 001700/002000] [loss: 0.00367314] [loss_bc: 0.00320427; loss_div: 0.00035550; loss_ff: 0.00011337] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  90%|████████▉ | 1798/2000 [02:12<00:14, 13.56it/s][Iteration 001800/002000] [loss: 0.00344325] [loss_bc: 0.00303697; loss_div: 0.00029278; loss_ff: 0.00011349] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  95%|█████████▍| 1898/2000 [02:19<00:07, 13.68it/s][Iteration 001900/002000] [loss: 0.00360588] [loss_bc: 0.00316446; loss_div: 0.00032740; loss_ff: 0.00011402] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training: 100%|█████████▉| 1998/2000 [02:27<00:00, 13.60it/s][Iteration 002000/002000] [loss: 0.00337398] [loss_bc: 0.00294683; loss_div: 0.00031609; loss_ff: 0.00011106] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training: 100%|██████████| 2000/2000 [02:27<00:00, 13.56it/s]\n",
      "[Iteration 002000/002000] [loss: 0.00337398] [loss_bc: 0.00294683; loss_div: 0.00031609; loss_ff: 0.00011106] [w_bc: 1.000000, LR: 0.000050]\n",
      "Runtime --> total: 147.71sec (2.95ms/iter.)\n",
      "Configuration:\n",
      "dim: 256, w_div: 1.000000, w_ff: 1.000000, decay_iterations: None, potential: True, vector_potential: False, \n",
      "Using device: cuda (gpus 1) ['NVIDIA RTX A6000']\n",
      "Potential Boundary: 100%|██████████| 1/1 [00:00<00:00,  1.78it/s]\n",
      "Loaded meta state: /userhome/jeon_mg/workspace/_data/NOAA12673/PINN/20170904_154800/model_final.pt\n",
      "Training:   0%|          | 0/2000 [00:00<?, ?it/s][Iteration 000000/002000] [loss: 0.00364430] [loss_bc: 0.00310730; loss_div: 0.00038151; loss_ff: 0.00015549] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:   5%|▍         | 98/2000 [00:07<02:19, 13.64it/s][Iteration 000100/002000] [loss: 0.00351189] [loss_bc: 0.00308655; loss_div: 0.00031541; loss_ff: 0.00010992] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  10%|▉         | 198/2000 [00:14<02:10, 13.80it/s][Iteration 000200/002000] [loss: 0.00369456] [loss_bc: 0.00316373; loss_div: 0.00036428; loss_ff: 0.00016655] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  15%|█▍        | 298/2000 [00:21<02:05, 13.53it/s][Iteration 000300/002000] [loss: 0.00342201] [loss_bc: 0.00301359; loss_div: 0.00031097; loss_ff: 0.00009745] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  20%|█▉        | 398/2000 [00:29<01:57, 13.61it/s][Iteration 000400/002000] [loss: 0.00354636] [loss_bc: 0.00306770; loss_div: 0.00033213; loss_ff: 0.00014653] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  25%|██▍       | 498/2000 [00:36<01:50, 13.59it/s][Iteration 000500/002000] [loss: 0.00363734] [loss_bc: 0.00323140; loss_div: 0.00027855; loss_ff: 0.00012739] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  30%|██▉       | 598/2000 [00:44<01:42, 13.62it/s][Iteration 000600/002000] [loss: 0.00368256] [loss_bc: 0.00320799; loss_div: 0.00036211; loss_ff: 0.00011246] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  35%|███▍      | 698/2000 [00:51<01:34, 13.80it/s][Iteration 000700/002000] [loss: 0.00354783] [loss_bc: 0.00309670; loss_div: 0.00031611; loss_ff: 0.00013501] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  40%|███▉      | 798/2000 [00:58<01:28, 13.65it/s][Iteration 000800/002000] [loss: 0.00350729] [loss_bc: 0.00309606; loss_div: 0.00027829; loss_ff: 0.00013294] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  45%|████▍     | 898/2000 [01:06<01:20, 13.61it/s][Iteration 000900/002000] [loss: 0.00345839] [loss_bc: 0.00299522; loss_div: 0.00032109; loss_ff: 0.00014208] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  50%|████▉     | 998/2000 [01:13<01:13, 13.64it/s][Iteration 001000/002000] [loss: 0.00361072] [loss_bc: 0.00314552; loss_div: 0.00034159; loss_ff: 0.00012361] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  55%|█████▍    | 1098/2000 [01:20<01:06, 13.58it/s][Iteration 001100/002000] [loss: 0.00373907] [loss_bc: 0.00322211; loss_div: 0.00034724; loss_ff: 0.00016973] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  60%|█████▉    | 1198/2000 [01:28<00:59, 13.58it/s][Iteration 001200/002000] [loss: 0.00361137] [loss_bc: 0.00306531; loss_div: 0.00042090; loss_ff: 0.00012516] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  65%|██████▍   | 1298/2000 [01:35<00:51, 13.58it/s][Iteration 001300/002000] [loss: 0.00353122] [loss_bc: 0.00313667; loss_div: 0.00029128; loss_ff: 0.00010327] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  70%|██████▉   | 1398/2000 [01:43<00:44, 13.67it/s][Iteration 001400/002000] [loss: 0.00365152] [loss_bc: 0.00319302; loss_div: 0.00032632; loss_ff: 0.00013219] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  75%|███████▍  | 1498/2000 [01:50<00:36, 13.87it/s][Iteration 001500/002000] [loss: 0.00341302] [loss_bc: 0.00306390; loss_div: 0.00026279; loss_ff: 0.00008634] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  80%|███████▉  | 1598/2000 [01:57<00:29, 13.63it/s][Iteration 001600/002000] [loss: 0.00365768] [loss_bc: 0.00320422; loss_div: 0.00032841; loss_ff: 0.00012506] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  85%|████████▍ | 1698/2000 [02:05<00:22, 13.72it/s][Iteration 001700/002000] [loss: 0.00348183] [loss_bc: 0.00305997; loss_div: 0.00028661; loss_ff: 0.00013525] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  90%|████████▉ | 1798/2000 [02:12<00:14, 13.59it/s][Iteration 001800/002000] [loss: 0.00362184] [loss_bc: 0.00308339; loss_div: 0.00036588; loss_ff: 0.00017257] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  95%|█████████▍| 1898/2000 [02:19<00:07, 13.59it/s][Iteration 001900/002000] [loss: 0.00350168] [loss_bc: 0.00305148; loss_div: 0.00030636; loss_ff: 0.00014384] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training: 100%|█████████▉| 1998/2000 [02:27<00:00, 13.48it/s][Iteration 002000/002000] [loss: 0.00357833] [loss_bc: 0.00307739; loss_div: 0.00037631; loss_ff: 0.00012463] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training: 100%|██████████| 2000/2000 [02:27<00:00, 13.54it/s]\n",
      "[Iteration 002000/002000] [loss: 0.00357833] [loss_bc: 0.00307739; loss_div: 0.00037631; loss_ff: 0.00012463] [w_bc: 1.000000, LR: 0.000050]\n",
      "Runtime --> total: 147.88sec (2.96ms/iter.)\n",
      "Configuration:\n",
      "dim: 256, w_div: 1.000000, w_ff: 1.000000, decay_iterations: None, potential: True, vector_potential: False, \n",
      "Using device: cuda (gpus 1) ['NVIDIA RTX A6000']\n",
      "Potential Boundary: 100%|██████████| 1/1 [00:01<00:00,  1.15s/it]\n",
      "Loaded meta state: /userhome/jeon_mg/workspace/_data/NOAA12673/PINN/20170904_160000/model_final.pt\n",
      "Training:   0%|          | 0/2000 [00:00<?, ?it/s][Iteration 000000/002000] [loss: 0.00344374] [loss_bc: 0.00304437; loss_div: 0.00029994; loss_ff: 0.00009943] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:   5%|▍         | 98/2000 [00:07<02:19, 13.62it/s][Iteration 000100/002000] [loss: 0.00344569] [loss_bc: 0.00302057; loss_div: 0.00030671; loss_ff: 0.00011842] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  10%|▉         | 198/2000 [00:14<02:12, 13.60it/s][Iteration 000200/002000] [loss: 0.00346383] [loss_bc: 0.00302013; loss_div: 0.00034752; loss_ff: 0.00009618] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  15%|█▍        | 298/2000 [00:21<02:04, 13.62it/s][Iteration 000300/002000] [loss: 0.00347632] [loss_bc: 0.00309427; loss_div: 0.00027746; loss_ff: 0.00010459] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  20%|█▉        | 398/2000 [00:29<01:57, 13.60it/s][Iteration 000400/002000] [loss: 0.00359298] [loss_bc: 0.00315041; loss_div: 0.00032073; loss_ff: 0.00012185] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  25%|██▍       | 498/2000 [00:36<01:50, 13.63it/s][Iteration 000500/002000] [loss: 0.00370887] [loss_bc: 0.00333084; loss_div: 0.00027038; loss_ff: 0.00010766] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  30%|██▉       | 598/2000 [00:43<01:40, 13.89it/s][Iteration 000600/002000] [loss: 0.00344657] [loss_bc: 0.00303371; loss_div: 0.00030919; loss_ff: 0.00010367] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  35%|███▍      | 698/2000 [00:51<01:36, 13.46it/s][Iteration 000700/002000] [loss: 0.00355057] [loss_bc: 0.00309319; loss_div: 0.00033682; loss_ff: 0.00012057] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  40%|███▉      | 798/2000 [00:58<01:27, 13.69it/s][Iteration 000800/002000] [loss: 0.00370642] [loss_bc: 0.00328179; loss_div: 0.00030097; loss_ff: 0.00012365] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  45%|████▍     | 898/2000 [01:06<01:21, 13.52it/s][Iteration 000900/002000] [loss: 0.00348956] [loss_bc: 0.00303483; loss_div: 0.00030669; loss_ff: 0.00014804] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  50%|████▉     | 998/2000 [01:13<01:12, 13.88it/s][Iteration 001000/002000] [loss: 0.00345846] [loss_bc: 0.00300508; loss_div: 0.00033211; loss_ff: 0.00012127] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  55%|█████▍    | 1098/2000 [01:20<01:06, 13.55it/s][Iteration 001100/002000] [loss: 0.00346374] [loss_bc: 0.00300605; loss_div: 0.00029645; loss_ff: 0.00016123] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  60%|█████▉    | 1198/2000 [01:28<00:58, 13.64it/s][Iteration 001200/002000] [loss: 0.00341178] [loss_bc: 0.00300154; loss_div: 0.00028362; loss_ff: 0.00012662] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  65%|██████▍   | 1298/2000 [01:35<00:51, 13.60it/s][Iteration 001300/002000] [loss: 0.00355055] [loss_bc: 0.00302647; loss_div: 0.00034797; loss_ff: 0.00017612] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  70%|██████▉   | 1398/2000 [01:42<00:44, 13.43it/s][Iteration 001400/002000] [loss: 0.00350805] [loss_bc: 0.00308809; loss_div: 0.00030098; loss_ff: 0.00011898] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  75%|███████▍  | 1498/2000 [01:50<00:36, 13.57it/s][Iteration 001500/002000] [loss: 0.00338241] [loss_bc: 0.00288622; loss_div: 0.00032310; loss_ff: 0.00017309] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  80%|███████▉  | 1598/2000 [01:57<00:29, 13.61it/s][Iteration 001600/002000] [loss: 0.00371336] [loss_bc: 0.00330987; loss_div: 0.00029286; loss_ff: 0.00011064] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  85%|████████▍ | 1698/2000 [02:04<00:22, 13.59it/s][Iteration 001700/002000] [loss: 0.00387225] [loss_bc: 0.00343665; loss_div: 0.00032080; loss_ff: 0.00011480] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  90%|████████▉ | 1798/2000 [02:12<00:14, 13.63it/s][Iteration 001800/002000] [loss: 0.00338425] [loss_bc: 0.00299210; loss_div: 0.00026817; loss_ff: 0.00012398] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  95%|█████████▍| 1898/2000 [02:19<00:07, 13.57it/s][Iteration 001900/002000] [loss: 0.00369128] [loss_bc: 0.00326539; loss_div: 0.00028915; loss_ff: 0.00013674] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training: 100%|█████████▉| 1998/2000 [02:26<00:00, 13.94it/s][Iteration 002000/002000] [loss: 0.00360115] [loss_bc: 0.00308033; loss_div: 0.00035049; loss_ff: 0.00017033] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training: 100%|██████████| 2000/2000 [02:27<00:00, 13.57it/s]\n",
      "[Iteration 002000/002000] [loss: 0.00360115] [loss_bc: 0.00308033; loss_div: 0.00035049; loss_ff: 0.00017033] [w_bc: 1.000000, LR: 0.000050]\n",
      "Runtime --> total: 147.51sec (2.95ms/iter.)\n",
      "Configuration:\n",
      "dim: 256, w_div: 1.000000, w_ff: 1.000000, decay_iterations: None, potential: True, vector_potential: False, \n",
      "Using device: cuda (gpus 1) ['NVIDIA RTX A6000']\n",
      "Potential Boundary: 100%|██████████| 1/1 [00:01<00:00,  1.18s/it]\n",
      "Loaded meta state: /userhome/jeon_mg/workspace/_data/NOAA12673/PINN/20170904_161200/model_final.pt\n",
      "Training:   0%|          | 0/2000 [00:00<?, ?it/s][Iteration 000000/002000] [loss: 0.00350037] [loss_bc: 0.00304417; loss_div: 0.00031903; loss_ff: 0.00013717] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:   5%|▍         | 98/2000 [00:07<02:19, 13.60it/s][Iteration 000100/002000] [loss: 0.00362108] [loss_bc: 0.00321009; loss_div: 0.00029931; loss_ff: 0.00011168] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  10%|▉         | 198/2000 [00:14<02:12, 13.58it/s][Iteration 000200/002000] [loss: 0.00334986] [loss_bc: 0.00288632; loss_div: 0.00034157; loss_ff: 0.00012197] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  15%|█▍        | 298/2000 [00:21<02:05, 13.60it/s][Iteration 000300/002000] [loss: 0.00354126] [loss_bc: 0.00310615; loss_div: 0.00031476; loss_ff: 0.00012035] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  20%|█▉        | 398/2000 [00:29<01:55, 13.89it/s][Iteration 000400/002000] [loss: 0.00340027] [loss_bc: 0.00298171; loss_div: 0.00031020; loss_ff: 0.00010836] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  25%|██▍       | 498/2000 [00:36<01:49, 13.76it/s][Iteration 000500/002000] [loss: 0.00353934] [loss_bc: 0.00308823; loss_div: 0.00032600; loss_ff: 0.00012510] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  30%|██▉       | 598/2000 [00:43<01:42, 13.65it/s][Iteration 000600/002000] [loss: 0.00373143] [loss_bc: 0.00326552; loss_div: 0.00034010; loss_ff: 0.00012581] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  35%|███▍      | 698/2000 [00:51<01:35, 13.62it/s][Iteration 000700/002000] [loss: 0.00343292] [loss_bc: 0.00302252; loss_div: 0.00030618; loss_ff: 0.00010421] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  40%|███▉      | 798/2000 [00:58<01:28, 13.59it/s][Iteration 000800/002000] [loss: 0.00367305] [loss_bc: 0.00318086; loss_div: 0.00037193; loss_ff: 0.00012027] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  45%|████▍     | 898/2000 [01:06<01:21, 13.59it/s][Iteration 000900/002000] [loss: 0.00353178] [loss_bc: 0.00309482; loss_div: 0.00033503; loss_ff: 0.00010192] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  50%|████▉     | 998/2000 [01:13<01:14, 13.44it/s][Iteration 001000/002000] [loss: 0.00374510] [loss_bc: 0.00326415; loss_div: 0.00037038; loss_ff: 0.00011057] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  55%|█████▍    | 1098/2000 [01:20<01:05, 13.72it/s][Iteration 001100/002000] [loss: 0.00368942] [loss_bc: 0.00325745; loss_div: 0.00034305; loss_ff: 0.00008892] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  60%|█████▉    | 1198/2000 [01:28<00:58, 13.60it/s][Iteration 001200/002000] [loss: 0.00329126] [loss_bc: 0.00287325; loss_div: 0.00029724; loss_ff: 0.00012076] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  65%|██████▍   | 1298/2000 [01:35<00:51, 13.58it/s][Iteration 001300/002000] [loss: 0.00342131] [loss_bc: 0.00297522; loss_div: 0.00034948; loss_ff: 0.00009660] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  70%|██████▉   | 1398/2000 [01:42<00:43, 13.92it/s][Iteration 001400/002000] [loss: 0.00328687] [loss_bc: 0.00286704; loss_div: 0.00031345; loss_ff: 0.00010638] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  75%|███████▍  | 1498/2000 [01:50<00:36, 13.70it/s][Iteration 001500/002000] [loss: 0.00352635] [loss_bc: 0.00303279; loss_div: 0.00037097; loss_ff: 0.00012258] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  80%|███████▉  | 1598/2000 [01:57<00:30, 13.21it/s][Iteration 001600/002000] [loss: 0.00373180] [loss_bc: 0.00316369; loss_div: 0.00046190; loss_ff: 0.00010621] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  85%|████████▍ | 1698/2000 [02:04<00:22, 13.63it/s][Iteration 001700/002000] [loss: 0.00356328] [loss_bc: 0.00318160; loss_div: 0.00027805; loss_ff: 0.00010363] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  90%|████████▉ | 1798/2000 [02:12<00:14, 13.55it/s][Iteration 001800/002000] [loss: 0.00365406] [loss_bc: 0.00325330; loss_div: 0.00027336; loss_ff: 0.00012740] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  95%|█████████▍| 1898/2000 [02:19<00:07, 13.62it/s][Iteration 001900/002000] [loss: 0.00350381] [loss_bc: 0.00317614; loss_div: 0.00024674; loss_ff: 0.00008094] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training: 100%|█████████▉| 1998/2000 [02:27<00:00, 13.68it/s][Iteration 002000/002000] [loss: 0.00340125] [loss_bc: 0.00302574; loss_div: 0.00027344; loss_ff: 0.00010207] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training: 100%|██████████| 2000/2000 [02:27<00:00, 13.57it/s]\n",
      "[Iteration 002000/002000] [loss: 0.00340125] [loss_bc: 0.00302574; loss_div: 0.00027344; loss_ff: 0.00010207] [w_bc: 1.000000, LR: 0.000050]\n",
      "Runtime --> total: 147.55sec (2.95ms/iter.)\n",
      "Configuration:\n",
      "dim: 256, w_div: 1.000000, w_ff: 1.000000, decay_iterations: None, potential: True, vector_potential: False, \n",
      "Using device: cuda (gpus 1) ['NVIDIA RTX A6000']\n",
      "Potential Boundary: 100%|██████████| 1/1 [00:01<00:00,  1.04s/it]\n",
      "Loaded meta state: /userhome/jeon_mg/workspace/_data/NOAA12673/PINN/20170904_162400/model_final.pt\n",
      "Training:   0%|          | 0/2000 [00:00<?, ?it/s][Iteration 000000/002000] [loss: 0.00374405] [loss_bc: 0.00317827; loss_div: 0.00039683; loss_ff: 0.00016895] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:   5%|▍         | 98/2000 [00:07<02:17, 13.82it/s][Iteration 000100/002000] [loss: 0.00361965] [loss_bc: 0.00316591; loss_div: 0.00032435; loss_ff: 0.00012939] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  10%|▉         | 198/2000 [00:14<02:13, 13.54it/s][Iteration 000200/002000] [loss: 0.00357072] [loss_bc: 0.00312645; loss_div: 0.00032326; loss_ff: 0.00012102] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  15%|█▍        | 298/2000 [00:21<02:05, 13.59it/s][Iteration 000300/002000] [loss: 0.00349615] [loss_bc: 0.00313377; loss_div: 0.00026497; loss_ff: 0.00009742] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  20%|█▉        | 398/2000 [00:29<01:55, 13.91it/s][Iteration 000400/002000] [loss: 0.00361194] [loss_bc: 0.00320739; loss_div: 0.00027174; loss_ff: 0.00013281] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  25%|██▍       | 498/2000 [00:36<01:50, 13.55it/s][Iteration 000500/002000] [loss: 0.00355903] [loss_bc: 0.00313722; loss_div: 0.00030862; loss_ff: 0.00011319] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  30%|██▉       | 598/2000 [00:43<01:43, 13.59it/s][Iteration 000600/002000] [loss: 0.00358361] [loss_bc: 0.00313256; loss_div: 0.00032425; loss_ff: 0.00012680] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  35%|███▍      | 698/2000 [00:51<01:36, 13.56it/s][Iteration 000700/002000] [loss: 0.00367268] [loss_bc: 0.00331837; loss_div: 0.00025591; loss_ff: 0.00009840] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  40%|███▉      | 798/2000 [00:58<01:27, 13.69it/s][Iteration 000800/002000] [loss: 0.00352871] [loss_bc: 0.00311674; loss_div: 0.00029428; loss_ff: 0.00011769] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  45%|████▍     | 898/2000 [01:06<01:20, 13.71it/s][Iteration 000900/002000] [loss: 0.00354325] [loss_bc: 0.00311841; loss_div: 0.00032259; loss_ff: 0.00010225] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  50%|████▉     | 998/2000 [01:13<01:13, 13.56it/s][Iteration 001000/002000] [loss: 0.00354671] [loss_bc: 0.00309919; loss_div: 0.00032655; loss_ff: 0.00012096] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  55%|█████▍    | 1098/2000 [01:20<01:06, 13.49it/s][Iteration 001100/002000] [loss: 0.00377580] [loss_bc: 0.00331132; loss_div: 0.00034196; loss_ff: 0.00012253] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  60%|█████▉    | 1198/2000 [01:28<00:59, 13.48it/s][Iteration 001200/002000] [loss: 0.00373294] [loss_bc: 0.00331019; loss_div: 0.00029667; loss_ff: 0.00012608] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  65%|██████▍   | 1298/2000 [01:35<00:51, 13.52it/s][Iteration 001300/002000] [loss: 0.00365309] [loss_bc: 0.00320970; loss_div: 0.00034161; loss_ff: 0.00010178] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  70%|██████▉   | 1398/2000 [01:43<00:44, 13.56it/s][Iteration 001400/002000] [loss: 0.00353082] [loss_bc: 0.00314395; loss_div: 0.00029637; loss_ff: 0.00009049] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  75%|███████▍  | 1498/2000 [01:50<00:36, 13.58it/s][Iteration 001500/002000] [loss: 0.00360411] [loss_bc: 0.00320421; loss_div: 0.00029484; loss_ff: 0.00010506] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  80%|███████▉  | 1598/2000 [01:57<00:29, 13.54it/s][Iteration 001600/002000] [loss: 0.00340111] [loss_bc: 0.00301759; loss_div: 0.00027978; loss_ff: 0.00010375] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  85%|████████▍ | 1698/2000 [02:05<00:22, 13.61it/s][Iteration 001700/002000] [loss: 0.00372541] [loss_bc: 0.00330005; loss_div: 0.00031448; loss_ff: 0.00011088] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  90%|████████▉ | 1798/2000 [02:12<00:14, 13.93it/s][Iteration 001800/002000] [loss: 0.00361909] [loss_bc: 0.00310434; loss_div: 0.00037696; loss_ff: 0.00013779] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  95%|█████████▍| 1898/2000 [02:19<00:07, 13.89it/s][Iteration 001900/002000] [loss: 0.00369070] [loss_bc: 0.00319505; loss_div: 0.00034509; loss_ff: 0.00015056] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training: 100%|█████████▉| 1998/2000 [02:27<00:00, 13.56it/s][Iteration 002000/002000] [loss: 0.00351960] [loss_bc: 0.00314310; loss_div: 0.00028471; loss_ff: 0.00009179] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training: 100%|██████████| 2000/2000 [02:27<00:00, 13.56it/s]\n",
      "[Iteration 002000/002000] [loss: 0.00351960] [loss_bc: 0.00314310; loss_div: 0.00028471; loss_ff: 0.00009179] [w_bc: 1.000000, LR: 0.000050]\n",
      "Runtime --> total: 147.70sec (2.95ms/iter.)\n",
      "Configuration:\n",
      "dim: 256, w_div: 1.000000, w_ff: 1.000000, decay_iterations: None, potential: True, vector_potential: False, \n",
      "Using device: cuda (gpus 1) ['NVIDIA RTX A6000']\n",
      "Potential Boundary: 100%|██████████| 1/1 [00:01<00:00,  1.05s/it]\n",
      "Loaded meta state: /userhome/jeon_mg/workspace/_data/NOAA12673/PINN/20170904_163600/model_final.pt\n",
      "Training:   0%|          | 0/2000 [00:00<?, ?it/s][Iteration 000000/002000] [loss: 0.00331876] [loss_bc: 0.00296971; loss_div: 0.00026125; loss_ff: 0.00008780] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:   5%|▍         | 98/2000 [00:07<02:19, 13.59it/s][Iteration 000100/002000] [loss: 0.00346990] [loss_bc: 0.00305096; loss_div: 0.00028821; loss_ff: 0.00013073] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  10%|▉         | 198/2000 [00:14<02:11, 13.72it/s][Iteration 000200/002000] [loss: 0.00339220] [loss_bc: 0.00304345; loss_div: 0.00026157; loss_ff: 0.00008719] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  15%|█▍        | 298/2000 [00:21<02:03, 13.83it/s][Iteration 000300/002000] [loss: 0.00336256] [loss_bc: 0.00294542; loss_div: 0.00029986; loss_ff: 0.00011729] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  20%|█▉        | 398/2000 [00:29<01:57, 13.62it/s][Iteration 000400/002000] [loss: 0.00343784] [loss_bc: 0.00303947; loss_div: 0.00028381; loss_ff: 0.00011456] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  25%|██▍       | 498/2000 [00:36<01:50, 13.60it/s][Iteration 000500/002000] [loss: 0.00376584] [loss_bc: 0.00333828; loss_div: 0.00029978; loss_ff: 0.00012777] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  30%|██▉       | 598/2000 [00:43<01:40, 13.92it/s][Iteration 000600/002000] [loss: 0.00334501] [loss_bc: 0.00293898; loss_div: 0.00029118; loss_ff: 0.00011485] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  35%|███▍      | 698/2000 [00:51<01:35, 13.59it/s][Iteration 000700/002000] [loss: 0.00335829] [loss_bc: 0.00294110; loss_div: 0.00028356; loss_ff: 0.00013363] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  40%|███▉      | 798/2000 [00:58<01:28, 13.57it/s][Iteration 000800/002000] [loss: 0.00383937] [loss_bc: 0.00338035; loss_div: 0.00033681; loss_ff: 0.00012220] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  45%|████▍     | 898/2000 [01:05<01:20, 13.64it/s][Iteration 000900/002000] [loss: 0.00374443] [loss_bc: 0.00324214; loss_div: 0.00035788; loss_ff: 0.00014441] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  50%|████▉     | 998/2000 [01:13<01:14, 13.52it/s][Iteration 001000/002000] [loss: 0.00339452] [loss_bc: 0.00302429; loss_div: 0.00026536; loss_ff: 0.00010487] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  55%|█████▍    | 1098/2000 [01:20<01:06, 13.55it/s][Iteration 001100/002000] [loss: 0.00383396] [loss_bc: 0.00337738; loss_div: 0.00033411; loss_ff: 0.00012247] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  60%|█████▉    | 1198/2000 [01:28<00:59, 13.58it/s][Iteration 001200/002000] [loss: 0.00342566] [loss_bc: 0.00302635; loss_div: 0.00027811; loss_ff: 0.00012120] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  65%|██████▍   | 1298/2000 [01:35<00:51, 13.53it/s][Iteration 001300/002000] [loss: 0.00337435] [loss_bc: 0.00292984; loss_div: 0.00031075; loss_ff: 0.00013376] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  70%|██████▉   | 1398/2000 [01:42<00:44, 13.56it/s][Iteration 001400/002000] [loss: 0.00345833] [loss_bc: 0.00300308; loss_div: 0.00030754; loss_ff: 0.00014772] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  75%|███████▍  | 1498/2000 [01:50<00:36, 13.58it/s][Iteration 001500/002000] [loss: 0.00360156] [loss_bc: 0.00308560; loss_div: 0.00038789; loss_ff: 0.00012807] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  80%|███████▉  | 1598/2000 [01:57<00:29, 13.62it/s][Iteration 001600/002000] [loss: 0.00342249] [loss_bc: 0.00301707; loss_div: 0.00028505; loss_ff: 0.00012038] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  85%|████████▍ | 1698/2000 [02:04<00:21, 13.88it/s][Iteration 001700/002000] [loss: 0.00399876] [loss_bc: 0.00344267; loss_div: 0.00037902; loss_ff: 0.00017707] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  90%|████████▉ | 1798/2000 [02:12<00:14, 13.61it/s][Iteration 001800/002000] [loss: 0.00356070] [loss_bc: 0.00312392; loss_div: 0.00030984; loss_ff: 0.00012694] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  95%|█████████▍| 1898/2000 [02:19<00:07, 13.62it/s][Iteration 001900/002000] [loss: 0.00375442] [loss_bc: 0.00323880; loss_div: 0.00037799; loss_ff: 0.00013764] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training: 100%|█████████▉| 1998/2000 [02:26<00:00, 13.58it/s][Iteration 002000/002000] [loss: 0.00348942] [loss_bc: 0.00306296; loss_div: 0.00030098; loss_ff: 0.00012548] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training: 100%|██████████| 2000/2000 [02:27<00:00, 13.57it/s]\n",
      "[Iteration 002000/002000] [loss: 0.00348942] [loss_bc: 0.00306296; loss_div: 0.00030098; loss_ff: 0.00012548] [w_bc: 1.000000, LR: 0.000050]\n",
      "Runtime --> total: 147.58sec (2.95ms/iter.)\n",
      "Configuration:\n",
      "dim: 256, w_div: 1.000000, w_ff: 1.000000, decay_iterations: None, potential: True, vector_potential: False, \n",
      "Using device: cuda (gpus 1) ['NVIDIA RTX A6000']\n",
      "Potential Boundary: 100%|██████████| 1/1 [00:01<00:00,  1.04s/it]\n",
      "Loaded meta state: /userhome/jeon_mg/workspace/_data/NOAA12673/PINN/20170904_164800/model_final.pt\n",
      "Training:   0%|          | 0/2000 [00:00<?, ?it/s][Iteration 000000/002000] [loss: 0.00357146] [loss_bc: 0.00314004; loss_div: 0.00031947; loss_ff: 0.00011195] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:   5%|▍         | 98/2000 [00:07<02:19, 13.62it/s][Iteration 000100/002000] [loss: 0.00383741] [loss_bc: 0.00339958; loss_div: 0.00030291; loss_ff: 0.00013491] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  10%|▉         | 198/2000 [00:14<02:09, 13.92it/s][Iteration 000200/002000] [loss: 0.00354873] [loss_bc: 0.00312376; loss_div: 0.00030386; loss_ff: 0.00012111] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  15%|█▍        | 298/2000 [00:21<02:05, 13.54it/s][Iteration 000300/002000] [loss: 0.00373545] [loss_bc: 0.00323505; loss_div: 0.00036538; loss_ff: 0.00013502] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  20%|█▉        | 398/2000 [00:29<01:58, 13.56it/s][Iteration 000400/002000] [loss: 0.00376595] [loss_bc: 0.00338246; loss_div: 0.00028060; loss_ff: 0.00010290] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  25%|██▍       | 498/2000 [00:36<01:50, 13.64it/s][Iteration 000500/002000] [loss: 0.00366194] [loss_bc: 0.00325732; loss_div: 0.00030226; loss_ff: 0.00010236] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  30%|██▉       | 598/2000 [00:43<01:43, 13.58it/s][Iteration 000600/002000] [loss: 0.00384370] [loss_bc: 0.00338243; loss_div: 0.00032283; loss_ff: 0.00013844] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  35%|███▍      | 698/2000 [00:51<01:34, 13.82it/s][Iteration 000700/002000] [loss: 0.00364432] [loss_bc: 0.00321973; loss_div: 0.00031963; loss_ff: 0.00010497] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  40%|███▉      | 798/2000 [00:58<01:28, 13.63it/s][Iteration 000800/002000] [loss: 0.00352315] [loss_bc: 0.00311148; loss_div: 0.00028672; loss_ff: 0.00012495] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  45%|████▍     | 898/2000 [01:05<01:20, 13.62it/s][Iteration 000900/002000] [loss: 0.00380474] [loss_bc: 0.00336042; loss_div: 0.00032530; loss_ff: 0.00011901] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  50%|████▉     | 998/2000 [01:13<01:13, 13.60it/s][Iteration 001000/002000] [loss: 0.00377501] [loss_bc: 0.00337773; loss_div: 0.00029052; loss_ff: 0.00010676] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  55%|█████▍    | 1098/2000 [01:20<01:06, 13.54it/s][Iteration 001100/002000] [loss: 0.00367648] [loss_bc: 0.00325102; loss_div: 0.00030239; loss_ff: 0.00012307] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  60%|█████▉    | 1198/2000 [01:28<00:58, 13.63it/s][Iteration 001200/002000] [loss: 0.00350579] [loss_bc: 0.00305149; loss_div: 0.00034545; loss_ff: 0.00010885] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  65%|██████▍   | 1298/2000 [01:35<00:50, 13.84it/s][Iteration 001300/002000] [loss: 0.00366552] [loss_bc: 0.00326489; loss_div: 0.00029757; loss_ff: 0.00010306] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  70%|██████▉   | 1398/2000 [01:42<00:44, 13.52it/s][Iteration 001400/002000] [loss: 0.00370366] [loss_bc: 0.00322259; loss_div: 0.00036142; loss_ff: 0.00011965] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  75%|███████▍  | 1498/2000 [01:50<00:36, 13.60it/s][Iteration 001500/002000] [loss: 0.00349716] [loss_bc: 0.00305569; loss_div: 0.00031836; loss_ff: 0.00012311] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  80%|███████▉  | 1598/2000 [01:57<00:29, 13.58it/s][Iteration 001600/002000] [loss: 0.00370251] [loss_bc: 0.00321405; loss_div: 0.00034231; loss_ff: 0.00014615] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  85%|████████▍ | 1698/2000 [02:04<00:22, 13.55it/s][Iteration 001700/002000] [loss: 0.00359849] [loss_bc: 0.00319979; loss_div: 0.00028904; loss_ff: 0.00010966] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  90%|████████▉ | 1798/2000 [02:12<00:14, 13.54it/s][Iteration 001800/002000] [loss: 0.00364295] [loss_bc: 0.00323857; loss_div: 0.00029278; loss_ff: 0.00011160] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  95%|█████████▍| 1898/2000 [02:19<00:07, 13.52it/s][Iteration 001900/002000] [loss: 0.00383209] [loss_bc: 0.00334509; loss_div: 0.00033914; loss_ff: 0.00014786] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training: 100%|█████████▉| 1998/2000 [02:27<00:00, 13.50it/s][Iteration 002000/002000] [loss: 0.00365482] [loss_bc: 0.00323257; loss_div: 0.00032413; loss_ff: 0.00009812] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training: 100%|██████████| 2000/2000 [02:27<00:00, 13.57it/s]\n",
      "[Iteration 002000/002000] [loss: 0.00365482] [loss_bc: 0.00323257; loss_div: 0.00032413; loss_ff: 0.00009812] [w_bc: 1.000000, LR: 0.000050]\n",
      "Runtime --> total: 147.59sec (2.95ms/iter.)\n",
      "Configuration:\n",
      "dim: 256, w_div: 1.000000, w_ff: 1.000000, decay_iterations: None, potential: True, vector_potential: False, \n",
      "Using device: cuda (gpus 1) ['NVIDIA RTX A6000']\n",
      "Potential Boundary: 100%|██████████| 1/1 [00:01<00:00,  1.07s/it]\n",
      "Loaded meta state: /userhome/jeon_mg/workspace/_data/NOAA12673/PINN/20170904_170000/model_final.pt\n",
      "Training:   0%|          | 0/2000 [00:00<?, ?it/s][Iteration 000000/002000] [loss: 0.00370612] [loss_bc: 0.00325742; loss_div: 0.00033575; loss_ff: 0.00011295] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:   5%|▍         | 98/2000 [00:07<02:19, 13.64it/s][Iteration 000100/002000] [loss: 0.00394453] [loss_bc: 0.00345843; loss_div: 0.00035131; loss_ff: 0.00013479] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  10%|▉         | 198/2000 [00:14<02:10, 13.79it/s][Iteration 000200/002000] [loss: 0.00379432] [loss_bc: 0.00335996; loss_div: 0.00030828; loss_ff: 0.00012608] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  15%|█▍        | 298/2000 [00:21<02:04, 13.63it/s][Iteration 000300/002000] [loss: 0.00374520] [loss_bc: 0.00329149; loss_div: 0.00032622; loss_ff: 0.00012750] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  20%|█▉        | 398/2000 [00:29<01:59, 13.45it/s][Iteration 000400/002000] [loss: 0.00381402] [loss_bc: 0.00340925; loss_div: 0.00027579; loss_ff: 0.00012898] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  25%|██▍       | 498/2000 [00:36<01:50, 13.62it/s][Iteration 000500/002000] [loss: 0.00369779] [loss_bc: 0.00327210; loss_div: 0.00029063; loss_ff: 0.00013506] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  30%|██▉       | 598/2000 [00:44<01:43, 13.56it/s][Iteration 000600/002000] [loss: 0.00392192] [loss_bc: 0.00344940; loss_div: 0.00033262; loss_ff: 0.00013989] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  35%|███▍      | 698/2000 [00:51<01:35, 13.59it/s][Iteration 000700/002000] [loss: 0.00369416] [loss_bc: 0.00327127; loss_div: 0.00029171; loss_ff: 0.00013118] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  40%|███▉      | 798/2000 [00:58<01:26, 13.96it/s][Iteration 000800/002000] [loss: 0.00379642] [loss_bc: 0.00326475; loss_div: 0.00038343; loss_ff: 0.00014825] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  45%|████▍     | 898/2000 [01:05<01:21, 13.58it/s][Iteration 000900/002000] [loss: 0.00391421] [loss_bc: 0.00342486; loss_div: 0.00035403; loss_ff: 0.00013532] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  50%|████▉     | 998/2000 [01:13<01:13, 13.58it/s][Iteration 001000/002000] [loss: 0.00364276] [loss_bc: 0.00319945; loss_div: 0.00032810; loss_ff: 0.00011521] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  55%|█████▍    | 1098/2000 [01:20<01:06, 13.62it/s][Iteration 001100/002000] [loss: 0.00384552] [loss_bc: 0.00340864; loss_div: 0.00032263; loss_ff: 0.00011425] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  60%|█████▉    | 1198/2000 [01:28<00:58, 13.66it/s][Iteration 001200/002000] [loss: 0.00386540] [loss_bc: 0.00339193; loss_div: 0.00035823; loss_ff: 0.00011523] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  65%|██████▍   | 1298/2000 [01:35<00:50, 13.84it/s][Iteration 001300/002000] [loss: 0.00377120] [loss_bc: 0.00332908; loss_div: 0.00031490; loss_ff: 0.00012722] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  70%|██████▉   | 1398/2000 [01:42<00:44, 13.58it/s][Iteration 001400/002000] [loss: 0.00385288] [loss_bc: 0.00342294; loss_div: 0.00030985; loss_ff: 0.00012008] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  75%|███████▍  | 1498/2000 [01:50<00:37, 13.51it/s][Iteration 001500/002000] [loss: 0.00370215] [loss_bc: 0.00321660; loss_div: 0.00035173; loss_ff: 0.00013382] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  80%|███████▉  | 1598/2000 [01:57<00:29, 13.59it/s][Iteration 001600/002000] [loss: 0.00378529] [loss_bc: 0.00333055; loss_div: 0.00032947; loss_ff: 0.00012528] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  85%|████████▍ | 1698/2000 [02:04<00:22, 13.41it/s][Iteration 001700/002000] [loss: 0.00355411] [loss_bc: 0.00308789; loss_div: 0.00033117; loss_ff: 0.00013505] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  90%|████████▉ | 1798/2000 [02:12<00:14, 13.61it/s][Iteration 001800/002000] [loss: 0.00366651] [loss_bc: 0.00320345; loss_div: 0.00034411; loss_ff: 0.00011894] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  95%|█████████▍| 1898/2000 [02:19<00:07, 13.62it/s][Iteration 001900/002000] [loss: 0.00374762] [loss_bc: 0.00326799; loss_div: 0.00034133; loss_ff: 0.00013830] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training: 100%|█████████▉| 1998/2000 [02:27<00:00, 13.83it/s][Iteration 002000/002000] [loss: 0.00389798] [loss_bc: 0.00340983; loss_div: 0.00034942; loss_ff: 0.00013874] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training: 100%|██████████| 2000/2000 [02:27<00:00, 13.56it/s]\n",
      "[Iteration 002000/002000] [loss: 0.00389798] [loss_bc: 0.00340983; loss_div: 0.00034942; loss_ff: 0.00013874] [w_bc: 1.000000, LR: 0.000050]\n",
      "Runtime --> total: 147.64sec (2.95ms/iter.)\n",
      "Configuration:\n",
      "dim: 256, w_div: 1.000000, w_ff: 1.000000, decay_iterations: None, potential: True, vector_potential: False, \n",
      "Using device: cuda (gpus 1) ['NVIDIA RTX A6000']\n",
      "Potential Boundary: 100%|██████████| 1/1 [00:01<00:00,  1.28s/it]\n",
      "Loaded meta state: /userhome/jeon_mg/workspace/_data/NOAA12673/PINN/20170904_171200/model_final.pt\n",
      "Training:   0%|          | 0/2000 [00:00<?, ?it/s][Iteration 000000/002000] [loss: 0.00372525] [loss_bc: 0.00322488; loss_div: 0.00036905; loss_ff: 0.00013132] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:   5%|▍         | 98/2000 [00:07<02:19, 13.60it/s][Iteration 000100/002000] [loss: 0.00388865] [loss_bc: 0.00347776; loss_div: 0.00029776; loss_ff: 0.00011314] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  10%|▉         | 198/2000 [00:14<02:12, 13.64it/s][Iteration 000200/002000] [loss: 0.00359361] [loss_bc: 0.00319675; loss_div: 0.00029821; loss_ff: 0.00009865] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  15%|█▍        | 298/2000 [00:21<02:04, 13.65it/s][Iteration 000300/002000] [loss: 0.00372772] [loss_bc: 0.00328565; loss_div: 0.00031437; loss_ff: 0.00012769] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  20%|█▉        | 398/2000 [00:29<01:57, 13.60it/s][Iteration 000400/002000] [loss: 0.00371442] [loss_bc: 0.00319690; loss_div: 0.00036033; loss_ff: 0.00015720] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  25%|██▍       | 498/2000 [00:36<01:50, 13.62it/s][Iteration 000500/002000] [loss: 0.00369265] [loss_bc: 0.00331098; loss_div: 0.00027424; loss_ff: 0.00010743] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  30%|██▉       | 598/2000 [00:43<01:41, 13.78it/s][Iteration 000600/002000] [loss: 0.00384687] [loss_bc: 0.00338194; loss_div: 0.00034982; loss_ff: 0.00011510] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  35%|███▍      | 698/2000 [00:51<01:33, 13.87it/s][Iteration 000700/002000] [loss: 0.00387452] [loss_bc: 0.00343572; loss_div: 0.00031777; loss_ff: 0.00012103] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  40%|███▉      | 798/2000 [00:58<01:28, 13.60it/s][Iteration 000800/002000] [loss: 0.00370561] [loss_bc: 0.00327525; loss_div: 0.00032902; loss_ff: 0.00010134] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  45%|████▍     | 898/2000 [01:05<01:20, 13.62it/s][Iteration 000900/002000] [loss: 0.00387691] [loss_bc: 0.00344702; loss_div: 0.00032375; loss_ff: 0.00010613] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  50%|████▉     | 998/2000 [01:13<01:12, 13.75it/s][Iteration 001000/002000] [loss: 0.00386296] [loss_bc: 0.00337711; loss_div: 0.00034982; loss_ff: 0.00013603] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  55%|█████▍    | 1098/2000 [01:20<01:06, 13.62it/s][Iteration 001100/002000] [loss: 0.00377138] [loss_bc: 0.00329766; loss_div: 0.00031872; loss_ff: 0.00015500] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  60%|█████▉    | 1198/2000 [01:27<00:59, 13.57it/s][Iteration 001200/002000] [loss: 0.00376495] [loss_bc: 0.00331331; loss_div: 0.00031382; loss_ff: 0.00013782] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  65%|██████▍   | 1298/2000 [01:35<00:51, 13.55it/s][Iteration 001300/002000] [loss: 0.00351676] [loss_bc: 0.00311122; loss_div: 0.00029532; loss_ff: 0.00011022] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  70%|██████▉   | 1398/2000 [01:42<00:44, 13.51it/s][Iteration 001400/002000] [loss: 0.00382382] [loss_bc: 0.00331287; loss_div: 0.00036315; loss_ff: 0.00014780] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  75%|███████▍  | 1498/2000 [01:50<00:36, 13.58it/s][Iteration 001500/002000] [loss: 0.00378054] [loss_bc: 0.00325358; loss_div: 0.00035785; loss_ff: 0.00016910] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  80%|███████▉  | 1598/2000 [01:57<00:29, 13.66it/s][Iteration 001600/002000] [loss: 0.00396499] [loss_bc: 0.00349558; loss_div: 0.00036353; loss_ff: 0.00010588] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  85%|████████▍ | 1698/2000 [02:04<00:22, 13.62it/s][Iteration 001700/002000] [loss: 0.00386528] [loss_bc: 0.00335932; loss_div: 0.00035572; loss_ff: 0.00015024] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  90%|████████▉ | 1798/2000 [02:12<00:14, 13.66it/s][Iteration 001800/002000] [loss: 0.00390989] [loss_bc: 0.00343720; loss_div: 0.00036256; loss_ff: 0.00011013] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  95%|█████████▍| 1898/2000 [02:19<00:07, 13.97it/s][Iteration 001900/002000] [loss: 0.00365995] [loss_bc: 0.00323325; loss_div: 0.00032154; loss_ff: 0.00010516] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training: 100%|█████████▉| 1998/2000 [02:26<00:00, 13.59it/s][Iteration 002000/002000] [loss: 0.00397512] [loss_bc: 0.00350386; loss_div: 0.00032401; loss_ff: 0.00014725] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training: 100%|██████████| 2000/2000 [02:27<00:00, 13.59it/s]\n",
      "[Iteration 002000/002000] [loss: 0.00397512] [loss_bc: 0.00350386; loss_div: 0.00032401; loss_ff: 0.00014725] [w_bc: 1.000000, LR: 0.000050]\n",
      "Runtime --> total: 147.36sec (2.95ms/iter.)\n",
      "Configuration:\n",
      "dim: 256, w_div: 1.000000, w_ff: 1.000000, decay_iterations: None, potential: True, vector_potential: False, \n",
      "Using device: cuda (gpus 1) ['NVIDIA RTX A6000']\n",
      "Potential Boundary: 100%|██████████| 1/1 [00:01<00:00,  1.17s/it]\n",
      "Loaded meta state: /userhome/jeon_mg/workspace/_data/NOAA12673/PINN/20170904_172400/model_final.pt\n",
      "Training:   0%|          | 0/2000 [00:00<?, ?it/s][Iteration 000000/002000] [loss: 0.00415273] [loss_bc: 0.00372195; loss_div: 0.00031388; loss_ff: 0.00011690] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:   5%|▍         | 98/2000 [00:07<02:18, 13.78it/s][Iteration 000100/002000] [loss: 0.00397863] [loss_bc: 0.00351401; loss_div: 0.00034852; loss_ff: 0.00011610] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  10%|▉         | 198/2000 [00:14<02:11, 13.71it/s][Iteration 000200/002000] [loss: 0.00418778] [loss_bc: 0.00369838; loss_div: 0.00037274; loss_ff: 0.00011666] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  15%|█▍        | 298/2000 [00:21<02:03, 13.75it/s][Iteration 000300/002000] [loss: 0.00390195] [loss_bc: 0.00334003; loss_div: 0.00043037; loss_ff: 0.00013155] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  20%|█▉        | 398/2000 [00:29<01:57, 13.66it/s][Iteration 000400/002000] [loss: 0.00388017] [loss_bc: 0.00341181; loss_div: 0.00035727; loss_ff: 0.00011108] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  25%|██▍       | 498/2000 [00:36<01:49, 13.66it/s][Iteration 000500/002000] [loss: 0.00394866] [loss_bc: 0.00348729; loss_div: 0.00035586; loss_ff: 0.00010551] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  30%|██▉       | 598/2000 [00:43<01:42, 13.63it/s][Iteration 000600/002000] [loss: 0.00393314] [loss_bc: 0.00346855; loss_div: 0.00033565; loss_ff: 0.00012894] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  35%|███▍      | 698/2000 [00:51<01:37, 13.32it/s][Iteration 000700/002000] [loss: 0.00390207] [loss_bc: 0.00347389; loss_div: 0.00031332; loss_ff: 0.00011486] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  40%|███▉      | 798/2000 [00:58<01:28, 13.53it/s][Iteration 000800/002000] [loss: 0.00390510] [loss_bc: 0.00346900; loss_div: 0.00031679; loss_ff: 0.00011931] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  45%|████▍     | 898/2000 [01:06<01:20, 13.61it/s][Iteration 000900/002000] [loss: 0.00393029] [loss_bc: 0.00339016; loss_div: 0.00039345; loss_ff: 0.00014668] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  50%|████▉     | 998/2000 [01:13<01:13, 13.63it/s][Iteration 001000/002000] [loss: 0.00395566] [loss_bc: 0.00347375; loss_div: 0.00037905; loss_ff: 0.00010286] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  55%|█████▍    | 1098/2000 [01:20<01:06, 13.65it/s][Iteration 001100/002000] [loss: 0.00390552] [loss_bc: 0.00346187; loss_div: 0.00032093; loss_ff: 0.00012272] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  60%|█████▉    | 1198/2000 [01:28<00:58, 13.64it/s][Iteration 001200/002000] [loss: 0.00379248] [loss_bc: 0.00338101; loss_div: 0.00031791; loss_ff: 0.00009356] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  65%|██████▍   | 1298/2000 [01:35<00:51, 13.58it/s][Iteration 001300/002000] [loss: 0.00379369] [loss_bc: 0.00335708; loss_div: 0.00033025; loss_ff: 0.00010636] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  70%|██████▉   | 1398/2000 [01:42<00:44, 13.59it/s][Iteration 001400/002000] [loss: 0.00379305] [loss_bc: 0.00332071; loss_div: 0.00035095; loss_ff: 0.00012139] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  75%|███████▍  | 1498/2000 [01:50<00:36, 13.64it/s][Iteration 001500/002000] [loss: 0.00378734] [loss_bc: 0.00327579; loss_div: 0.00035484; loss_ff: 0.00015671] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  80%|███████▉  | 1598/2000 [01:57<00:29, 13.63it/s][Iteration 001600/002000] [loss: 0.00385797] [loss_bc: 0.00338998; loss_div: 0.00031575; loss_ff: 0.00015224] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  85%|████████▍ | 1698/2000 [02:05<00:22, 13.59it/s][Iteration 001700/002000] [loss: 0.00394822] [loss_bc: 0.00346500; loss_div: 0.00031680; loss_ff: 0.00016641] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  90%|████████▉ | 1798/2000 [02:12<00:14, 13.52it/s][Iteration 001800/002000] [loss: 0.00386836] [loss_bc: 0.00337419; loss_div: 0.00036029; loss_ff: 0.00013388] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  95%|█████████▍| 1898/2000 [02:19<00:07, 13.63it/s][Iteration 001900/002000] [loss: 0.00395348] [loss_bc: 0.00334444; loss_div: 0.00039782; loss_ff: 0.00021122] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training: 100%|█████████▉| 1998/2000 [02:27<00:00, 13.58it/s][Iteration 002000/002000] [loss: 0.00371555] [loss_bc: 0.00331397; loss_div: 0.00028755; loss_ff: 0.00011403] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training: 100%|██████████| 2000/2000 [02:27<00:00, 13.56it/s]\n",
      "[Iteration 002000/002000] [loss: 0.00371555] [loss_bc: 0.00331397; loss_div: 0.00028755; loss_ff: 0.00011403] [w_bc: 1.000000, LR: 0.000050]\n",
      "Runtime --> total: 147.64sec (2.95ms/iter.)\n",
      "Configuration:\n",
      "dim: 256, w_div: 1.000000, w_ff: 1.000000, decay_iterations: None, potential: True, vector_potential: False, \n",
      "Using device: cuda (gpus 1) ['NVIDIA RTX A6000']\n",
      "Potential Boundary: 100%|██████████| 1/1 [00:01<00:00,  1.07s/it]\n",
      "Loaded meta state: /userhome/jeon_mg/workspace/_data/NOAA12673/PINN/20170904_173600/model_final.pt\n",
      "Training:   0%|          | 0/2000 [00:00<?, ?it/s][Iteration 000000/002000] [loss: 0.00406749] [loss_bc: 0.00356254; loss_div: 0.00034338; loss_ff: 0.00016158] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:   5%|▍         | 98/2000 [00:07<02:20, 13.56it/s][Iteration 000100/002000] [loss: 0.00381670] [loss_bc: 0.00340624; loss_div: 0.00029034; loss_ff: 0.00012012] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  10%|▉         | 198/2000 [00:14<02:12, 13.65it/s][Iteration 000200/002000] [loss: 0.00397866] [loss_bc: 0.00348415; loss_div: 0.00036759; loss_ff: 0.00012692] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  15%|█▍        | 298/2000 [00:21<02:06, 13.50it/s][Iteration 000300/002000] [loss: 0.00392312] [loss_bc: 0.00351295; loss_div: 0.00028715; loss_ff: 0.00012303] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  20%|█▉        | 398/2000 [00:29<01:58, 13.54it/s][Iteration 000400/002000] [loss: 0.00390315] [loss_bc: 0.00347197; loss_div: 0.00033399; loss_ff: 0.00009719] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  25%|██▍       | 498/2000 [00:36<01:53, 13.25it/s][Iteration 000500/002000] [loss: 0.00413100] [loss_bc: 0.00362754; loss_div: 0.00035503; loss_ff: 0.00014843] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  30%|██▉       | 598/2000 [00:44<01:43, 13.60it/s][Iteration 000600/002000] [loss: 0.00384525] [loss_bc: 0.00338235; loss_div: 0.00034006; loss_ff: 0.00012284] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  35%|███▍      | 698/2000 [00:51<01:33, 13.86it/s][Iteration 000700/002000] [loss: 0.00383737] [loss_bc: 0.00336485; loss_div: 0.00032653; loss_ff: 0.00014599] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  40%|███▉      | 798/2000 [00:58<01:26, 13.91it/s][Iteration 000800/002000] [loss: 0.00405591] [loss_bc: 0.00361946; loss_div: 0.00030984; loss_ff: 0.00012661] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  45%|████▍     | 898/2000 [01:05<01:19, 13.94it/s][Iteration 000900/002000] [loss: 0.00404602] [loss_bc: 0.00360955; loss_div: 0.00032615; loss_ff: 0.00011032] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  50%|████▉     | 998/2000 [01:13<01:12, 13.78it/s][Iteration 001000/002000] [loss: 0.00389268] [loss_bc: 0.00349047; loss_div: 0.00028292; loss_ff: 0.00011930] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  55%|█████▍    | 1098/2000 [01:20<01:06, 13.56it/s][Iteration 001100/002000] [loss: 0.00378603] [loss_bc: 0.00339244; loss_div: 0.00027675; loss_ff: 0.00011684] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  60%|█████▉    | 1198/2000 [01:28<00:58, 13.62it/s][Iteration 001200/002000] [loss: 0.00387012] [loss_bc: 0.00337543; loss_div: 0.00038432; loss_ff: 0.00011036] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  65%|██████▍   | 1298/2000 [01:35<00:50, 13.83it/s][Iteration 001300/002000] [loss: 0.00416514] [loss_bc: 0.00360930; loss_div: 0.00038597; loss_ff: 0.00016987] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  70%|██████▉   | 1398/2000 [01:42<00:43, 13.83it/s][Iteration 001400/002000] [loss: 0.00384420] [loss_bc: 0.00339731; loss_div: 0.00033177; loss_ff: 0.00011512] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  75%|███████▍  | 1498/2000 [01:50<00:36, 13.79it/s][Iteration 001500/002000] [loss: 0.00387363] [loss_bc: 0.00344965; loss_div: 0.00029982; loss_ff: 0.00012415] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  80%|███████▉  | 1598/2000 [01:57<00:29, 13.72it/s][Iteration 001600/002000] [loss: 0.00376987] [loss_bc: 0.00334966; loss_div: 0.00030630; loss_ff: 0.00011392] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  85%|████████▍ | 1698/2000 [02:04<00:22, 13.54it/s][Iteration 001700/002000] [loss: 0.00384186] [loss_bc: 0.00338773; loss_div: 0.00034859; loss_ff: 0.00010554] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  90%|████████▉ | 1798/2000 [02:12<00:14, 13.58it/s][Iteration 001800/002000] [loss: 0.00389502] [loss_bc: 0.00344579; loss_div: 0.00031845; loss_ff: 0.00013078] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  95%|█████████▍| 1898/2000 [02:19<00:07, 13.52it/s][Iteration 001900/002000] [loss: 0.00382176] [loss_bc: 0.00335172; loss_div: 0.00031571; loss_ff: 0.00015433] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training: 100%|█████████▉| 1998/2000 [02:27<00:00, 13.54it/s][Iteration 002000/002000] [loss: 0.00395657] [loss_bc: 0.00348362; loss_div: 0.00034827; loss_ff: 0.00012468] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training: 100%|██████████| 2000/2000 [02:27<00:00, 13.58it/s]\n",
      "[Iteration 002000/002000] [loss: 0.00395657] [loss_bc: 0.00348362; loss_div: 0.00034827; loss_ff: 0.00012468] [w_bc: 1.000000, LR: 0.000050]\n",
      "Runtime --> total: 147.51sec (2.95ms/iter.)\n",
      "Configuration:\n",
      "dim: 256, w_div: 1.000000, w_ff: 1.000000, decay_iterations: None, potential: True, vector_potential: False, \n",
      "Using device: cuda (gpus 1) ['NVIDIA RTX A6000']\n",
      "Potential Boundary: 100%|██████████| 1/1 [00:01<00:00,  1.13s/it]\n",
      "Loaded meta state: /userhome/jeon_mg/workspace/_data/NOAA12673/PINN/20170904_174800/model_final.pt\n",
      "Training:   0%|          | 0/2000 [00:00<?, ?it/s][Iteration 000000/002000] [loss: 0.00417858] [loss_bc: 0.00373193; loss_div: 0.00032479; loss_ff: 0.00012186] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:   5%|▍         | 98/2000 [00:07<02:19, 13.61it/s][Iteration 000100/002000] [loss: 0.00406649] [loss_bc: 0.00354833; loss_div: 0.00036743; loss_ff: 0.00015073] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  10%|▉         | 198/2000 [00:14<02:10, 13.79it/s][Iteration 000200/002000] [loss: 0.00402361] [loss_bc: 0.00347407; loss_div: 0.00042638; loss_ff: 0.00012315] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  15%|█▍        | 298/2000 [00:21<02:06, 13.49it/s][Iteration 000300/002000] [loss: 0.00424747] [loss_bc: 0.00370359; loss_div: 0.00039899; loss_ff: 0.00014490] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  20%|█▉        | 398/2000 [00:29<01:57, 13.60it/s][Iteration 000400/002000] [loss: 0.00409472] [loss_bc: 0.00361536; loss_div: 0.00033988; loss_ff: 0.00013948] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  25%|██▍       | 498/2000 [00:36<01:48, 13.84it/s][Iteration 000500/002000] [loss: 0.00387212] [loss_bc: 0.00338404; loss_div: 0.00032602; loss_ff: 0.00016205] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  30%|██▉       | 598/2000 [00:44<01:43, 13.59it/s][Iteration 000600/002000] [loss: 0.00397097] [loss_bc: 0.00343087; loss_div: 0.00038483; loss_ff: 0.00015527] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  35%|███▍      | 698/2000 [00:51<01:35, 13.61it/s][Iteration 000700/002000] [loss: 0.00408710] [loss_bc: 0.00360657; loss_div: 0.00032835; loss_ff: 0.00015218] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  40%|███▉      | 798/2000 [00:58<01:28, 13.57it/s][Iteration 000800/002000] [loss: 0.00426327] [loss_bc: 0.00369688; loss_div: 0.00039211; loss_ff: 0.00017428] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  45%|████▍     | 898/2000 [01:06<01:21, 13.56it/s][Iteration 000900/002000] [loss: 0.00407317] [loss_bc: 0.00360220; loss_div: 0.00034706; loss_ff: 0.00012390] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  50%|████▉     | 998/2000 [01:13<01:13, 13.57it/s][Iteration 001000/002000] [loss: 0.00409459] [loss_bc: 0.00359703; loss_div: 0.00034718; loss_ff: 0.00015038] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  55%|█████▍    | 1098/2000 [01:20<01:05, 13.73it/s][Iteration 001100/002000] [loss: 0.00397944] [loss_bc: 0.00345431; loss_div: 0.00036366; loss_ff: 0.00016147] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  60%|█████▉    | 1198/2000 [01:28<00:59, 13.56it/s][Iteration 001200/002000] [loss: 0.00371839] [loss_bc: 0.00328545; loss_div: 0.00032374; loss_ff: 0.00010920] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  65%|██████▍   | 1298/2000 [01:35<00:50, 13.78it/s][Iteration 001300/002000] [loss: 0.00384373] [loss_bc: 0.00345330; loss_div: 0.00029545; loss_ff: 0.00009498] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  70%|██████▉   | 1398/2000 [01:43<00:44, 13.60it/s][Iteration 001400/002000] [loss: 0.00397091] [loss_bc: 0.00341628; loss_div: 0.00041325; loss_ff: 0.00014139] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  75%|███████▍  | 1498/2000 [01:50<00:36, 13.65it/s][Iteration 001500/002000] [loss: 0.00397873] [loss_bc: 0.00352008; loss_div: 0.00034716; loss_ff: 0.00011149] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  80%|███████▉  | 1598/2000 [01:57<00:29, 13.58it/s][Iteration 001600/002000] [loss: 0.00400352] [loss_bc: 0.00352080; loss_div: 0.00035060; loss_ff: 0.00013211] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  85%|████████▍ | 1698/2000 [02:05<00:22, 13.58it/s][Iteration 001700/002000] [loss: 0.00392100] [loss_bc: 0.00345456; loss_div: 0.00033730; loss_ff: 0.00012913] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  90%|████████▉ | 1798/2000 [02:12<00:14, 13.61it/s][Iteration 001800/002000] [loss: 0.00377713] [loss_bc: 0.00335443; loss_div: 0.00030971; loss_ff: 0.00011298] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  95%|█████████▍| 1898/2000 [02:19<00:07, 13.60it/s][Iteration 001900/002000] [loss: 0.00408111] [loss_bc: 0.00365431; loss_div: 0.00028756; loss_ff: 0.00013923] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training: 100%|█████████▉| 1998/2000 [02:27<00:00, 13.46it/s][Iteration 002000/002000] [loss: 0.00394434] [loss_bc: 0.00344159; loss_div: 0.00037717; loss_ff: 0.00012558] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training: 100%|██████████| 2000/2000 [02:27<00:00, 13.55it/s]\n",
      "[Iteration 002000/002000] [loss: 0.00394434] [loss_bc: 0.00344159; loss_div: 0.00037717; loss_ff: 0.00012558] [w_bc: 1.000000, LR: 0.000050]\n",
      "Runtime --> total: 147.82sec (2.96ms/iter.)\n",
      "Configuration:\n",
      "dim: 256, w_div: 1.000000, w_ff: 1.000000, decay_iterations: None, potential: True, vector_potential: False, \n",
      "Using device: cuda (gpus 1) ['NVIDIA RTX A6000']\n",
      "Potential Boundary: 100%|██████████| 1/1 [00:01<00:00,  1.11s/it]\n",
      "Loaded meta state: /userhome/jeon_mg/workspace/_data/NOAA12673/PINN/20170904_180000/model_final.pt\n",
      "Training:   0%|          | 0/2000 [00:00<?, ?it/s][Iteration 000000/002000] [loss: 0.00421815] [loss_bc: 0.00374878; loss_div: 0.00034168; loss_ff: 0.00012769] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:   5%|▍         | 98/2000 [00:07<02:20, 13.58it/s][Iteration 000100/002000] [loss: 0.00398601] [loss_bc: 0.00350026; loss_div: 0.00034939; loss_ff: 0.00013636] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  10%|▉         | 198/2000 [00:14<02:12, 13.63it/s][Iteration 000200/002000] [loss: 0.00409605] [loss_bc: 0.00360532; loss_div: 0.00034692; loss_ff: 0.00014381] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  15%|█▍        | 298/2000 [00:21<02:02, 13.93it/s][Iteration 000300/002000] [loss: 0.00380798] [loss_bc: 0.00336988; loss_div: 0.00031048; loss_ff: 0.00012761] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  20%|█▉        | 398/2000 [00:29<01:57, 13.66it/s][Iteration 000400/002000] [loss: 0.00390915] [loss_bc: 0.00348929; loss_div: 0.00029829; loss_ff: 0.00012157] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  25%|██▍       | 498/2000 [00:36<01:49, 13.69it/s][Iteration 000500/002000] [loss: 0.00375897] [loss_bc: 0.00331487; loss_div: 0.00033522; loss_ff: 0.00010888] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  30%|██▉       | 598/2000 [00:43<01:43, 13.54it/s][Iteration 000600/002000] [loss: 0.00374595] [loss_bc: 0.00331553; loss_div: 0.00032011; loss_ff: 0.00011031] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  35%|███▍      | 698/2000 [00:51<01:34, 13.71it/s][Iteration 000700/002000] [loss: 0.00418650] [loss_bc: 0.00368253; loss_div: 0.00036080; loss_ff: 0.00014317] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  40%|███▉      | 798/2000 [00:58<01:27, 13.81it/s][Iteration 000800/002000] [loss: 0.00390035] [loss_bc: 0.00348877; loss_div: 0.00031507; loss_ff: 0.00009652] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  45%|████▍     | 898/2000 [01:05<01:21, 13.59it/s][Iteration 000900/002000] [loss: 0.00415371] [loss_bc: 0.00372110; loss_div: 0.00030478; loss_ff: 0.00012783] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  50%|████▉     | 998/2000 [01:13<01:13, 13.61it/s][Iteration 001000/002000] [loss: 0.00398030] [loss_bc: 0.00347636; loss_div: 0.00036132; loss_ff: 0.00014262] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  55%|█████▍    | 1098/2000 [01:20<01:06, 13.59it/s][Iteration 001100/002000] [loss: 0.00409709] [loss_bc: 0.00359592; loss_div: 0.00037734; loss_ff: 0.00012384] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  60%|█████▉    | 1198/2000 [01:28<00:58, 13.64it/s][Iteration 001200/002000] [loss: 0.00389731] [loss_bc: 0.00345996; loss_div: 0.00030770; loss_ff: 0.00012965] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  65%|██████▍   | 1298/2000 [01:35<00:50, 13.79it/s][Iteration 001300/002000] [loss: 0.00416300] [loss_bc: 0.00371452; loss_div: 0.00032062; loss_ff: 0.00012786] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  70%|██████▉   | 1398/2000 [01:42<00:44, 13.62it/s][Iteration 001400/002000] [loss: 0.00373717] [loss_bc: 0.00329989; loss_div: 0.00031367; loss_ff: 0.00012361] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  75%|███████▍  | 1498/2000 [01:50<00:36, 13.63it/s][Iteration 001500/002000] [loss: 0.00416111] [loss_bc: 0.00366292; loss_div: 0.00036207; loss_ff: 0.00013613] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  80%|███████▉  | 1598/2000 [01:57<00:29, 13.60it/s][Iteration 001600/002000] [loss: 0.00402009] [loss_bc: 0.00343337; loss_div: 0.00039308; loss_ff: 0.00019364] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  85%|████████▍ | 1698/2000 [02:04<00:22, 13.60it/s][Iteration 001700/002000] [loss: 0.00374382] [loss_bc: 0.00331821; loss_div: 0.00032171; loss_ff: 0.00010389] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  90%|████████▉ | 1798/2000 [02:12<00:14, 13.64it/s][Iteration 001800/002000] [loss: 0.00377693] [loss_bc: 0.00332295; loss_div: 0.00030590; loss_ff: 0.00014808] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  95%|█████████▍| 1898/2000 [02:19<00:07, 13.64it/s][Iteration 001900/002000] [loss: 0.00379458] [loss_bc: 0.00331171; loss_div: 0.00034942; loss_ff: 0.00013345] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training: 100%|█████████▉| 1998/2000 [02:27<00:00, 13.78it/s][Iteration 002000/002000] [loss: 0.00410764] [loss_bc: 0.00359004; loss_div: 0.00036588; loss_ff: 0.00015173] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training: 100%|██████████| 2000/2000 [02:27<00:00, 13.57it/s]\n",
      "[Iteration 002000/002000] [loss: 0.00410764] [loss_bc: 0.00359004; loss_div: 0.00036588; loss_ff: 0.00015173] [w_bc: 1.000000, LR: 0.000050]\n",
      "Runtime --> total: 147.57sec (2.95ms/iter.)\n",
      "Configuration:\n",
      "dim: 256, w_div: 1.000000, w_ff: 1.000000, decay_iterations: None, potential: True, vector_potential: False, \n",
      "Using device: cuda (gpus 1) ['NVIDIA RTX A6000']\n",
      "Potential Boundary: 100%|██████████| 1/1 [00:01<00:00,  1.20s/it]\n",
      "Loaded meta state: /userhome/jeon_mg/workspace/_data/NOAA12673/PINN/20170904_181200/model_final.pt\n",
      "Training:   0%|          | 0/2000 [00:00<?, ?it/s][Iteration 000000/002000] [loss: 0.00392296] [loss_bc: 0.00340938; loss_div: 0.00037734; loss_ff: 0.00013623] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:   5%|▍         | 98/2000 [00:07<02:17, 13.85it/s][Iteration 000100/002000] [loss: 0.00409317] [loss_bc: 0.00363118; loss_div: 0.00032483; loss_ff: 0.00013716] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  10%|▉         | 198/2000 [00:14<02:12, 13.56it/s][Iteration 000200/002000] [loss: 0.00401970] [loss_bc: 0.00357153; loss_div: 0.00032140; loss_ff: 0.00012676] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  15%|█▍        | 298/2000 [00:21<02:06, 13.44it/s][Iteration 000300/002000] [loss: 0.00417523] [loss_bc: 0.00369433; loss_div: 0.00035096; loss_ff: 0.00012994] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  20%|█▉        | 398/2000 [00:29<02:02, 13.13it/s][Iteration 000400/002000] [loss: 0.00404195] [loss_bc: 0.00356223; loss_div: 0.00034326; loss_ff: 0.00013646] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  25%|██▍       | 498/2000 [00:37<01:50, 13.60it/s][Iteration 000500/002000] [loss: 0.00412127] [loss_bc: 0.00370526; loss_div: 0.00030896; loss_ff: 0.00010705] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  30%|██▉       | 598/2000 [00:44<01:43, 13.59it/s][Iteration 000600/002000] [loss: 0.00423462] [loss_bc: 0.00371535; loss_div: 0.00034757; loss_ff: 0.00017171] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  35%|███▍      | 698/2000 [00:52<01:37, 13.40it/s][Iteration 000700/002000] [loss: 0.00410850] [loss_bc: 0.00368776; loss_div: 0.00029976; loss_ff: 0.00012098] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  40%|███▉      | 798/2000 [00:59<01:28, 13.58it/s][Iteration 000800/002000] [loss: 0.00392514] [loss_bc: 0.00355276; loss_div: 0.00027392; loss_ff: 0.00009846] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  45%|████▍     | 898/2000 [01:07<01:20, 13.62it/s][Iteration 000900/002000] [loss: 0.00384181] [loss_bc: 0.00333793; loss_div: 0.00036558; loss_ff: 0.00013831] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  50%|████▉     | 998/2000 [01:14<01:13, 13.58it/s][Iteration 001000/002000] [loss: 0.00411301] [loss_bc: 0.00361617; loss_div: 0.00035759; loss_ff: 0.00013925] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  55%|█████▍    | 1098/2000 [01:21<01:06, 13.52it/s][Iteration 001100/002000] [loss: 0.00386923] [loss_bc: 0.00341108; loss_div: 0.00030169; loss_ff: 0.00015646] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  60%|█████▉    | 1198/2000 [01:29<00:59, 13.46it/s][Iteration 001200/002000] [loss: 0.00365995] [loss_bc: 0.00316297; loss_div: 0.00035662; loss_ff: 0.00014036] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  65%|██████▍   | 1298/2000 [01:36<00:51, 13.53it/s][Iteration 001300/002000] [loss: 0.00399459] [loss_bc: 0.00354211; loss_div: 0.00031920; loss_ff: 0.00013328] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  70%|██████▉   | 1398/2000 [01:44<00:44, 13.51it/s][Iteration 001400/002000] [loss: 0.00403644] [loss_bc: 0.00359952; loss_div: 0.00030227; loss_ff: 0.00013465] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  75%|███████▍  | 1498/2000 [01:51<00:36, 13.60it/s][Iteration 001500/002000] [loss: 0.00410188] [loss_bc: 0.00353955; loss_div: 0.00044179; loss_ff: 0.00012053] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  80%|███████▉  | 1598/2000 [01:58<00:29, 13.71it/s][Iteration 001600/002000] [loss: 0.00404567] [loss_bc: 0.00360110; loss_div: 0.00032542; loss_ff: 0.00011915] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  85%|████████▍ | 1698/2000 [02:06<00:22, 13.58it/s][Iteration 001700/002000] [loss: 0.00411039] [loss_bc: 0.00360165; loss_div: 0.00036930; loss_ff: 0.00013944] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  90%|████████▉ | 1798/2000 [02:13<00:14, 13.54it/s][Iteration 001800/002000] [loss: 0.00416271] [loss_bc: 0.00366666; loss_div: 0.00038113; loss_ff: 0.00011491] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  95%|█████████▍| 1898/2000 [02:21<00:07, 13.60it/s][Iteration 001900/002000] [loss: 0.00380246] [loss_bc: 0.00314320; loss_div: 0.00042186; loss_ff: 0.00023741] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training: 100%|█████████▉| 1998/2000 [02:28<00:00, 13.53it/s][Iteration 002000/002000] [loss: 0.00414480] [loss_bc: 0.00359730; loss_div: 0.00036862; loss_ff: 0.00017888] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training: 100%|██████████| 2000/2000 [02:28<00:00, 13.45it/s]\n",
      "[Iteration 002000/002000] [loss: 0.00414480] [loss_bc: 0.00359730; loss_div: 0.00036862; loss_ff: 0.00017888] [w_bc: 1.000000, LR: 0.000050]\n",
      "Runtime --> total: 148.99sec (2.98ms/iter.)\n",
      "Configuration:\n",
      "dim: 256, w_div: 1.000000, w_ff: 1.000000, decay_iterations: None, potential: True, vector_potential: False, \n",
      "Using device: cuda (gpus 1) ['NVIDIA RTX A6000']\n",
      "Potential Boundary: 100%|██████████| 1/1 [00:00<00:00,  1.65it/s]\n",
      "Loaded meta state: /userhome/jeon_mg/workspace/_data/NOAA12673/PINN/20170904_182400/model_final.pt\n",
      "Training:   0%|          | 0/2000 [00:00<?, ?it/s][Iteration 000000/002000] [loss: 0.00394358] [loss_bc: 0.00341947; loss_div: 0.00036052; loss_ff: 0.00016359] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:   5%|▍         | 98/2000 [00:07<02:20, 13.57it/s][Iteration 000100/002000] [loss: 0.00397080] [loss_bc: 0.00342082; loss_div: 0.00040367; loss_ff: 0.00014631] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  10%|▉         | 198/2000 [00:14<02:13, 13.49it/s][Iteration 000200/002000] [loss: 0.00396875] [loss_bc: 0.00351364; loss_div: 0.00034648; loss_ff: 0.00010864] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  15%|█▍        | 298/2000 [00:21<02:05, 13.56it/s][Iteration 000300/002000] [loss: 0.00388665] [loss_bc: 0.00340795; loss_div: 0.00035862; loss_ff: 0.00012009] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  20%|█▉        | 398/2000 [00:29<01:57, 13.58it/s][Iteration 000400/002000] [loss: 0.00409368] [loss_bc: 0.00355508; loss_div: 0.00038105; loss_ff: 0.00015756] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  25%|██▍       | 498/2000 [00:36<01:50, 13.56it/s][Iteration 000500/002000] [loss: 0.00396473] [loss_bc: 0.00339729; loss_div: 0.00043788; loss_ff: 0.00012957] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  30%|██▉       | 598/2000 [00:44<01:43, 13.50it/s][Iteration 000600/002000] [loss: 0.00389513] [loss_bc: 0.00347687; loss_div: 0.00031584; loss_ff: 0.00010243] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  35%|███▍      | 698/2000 [00:51<01:36, 13.54it/s][Iteration 000700/002000] [loss: 0.00434354] [loss_bc: 0.00383062; loss_div: 0.00031788; loss_ff: 0.00019504] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  40%|███▉      | 798/2000 [00:58<01:28, 13.62it/s][Iteration 000800/002000] [loss: 0.00384114] [loss_bc: 0.00340817; loss_div: 0.00029979; loss_ff: 0.00013318] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  45%|████▍     | 898/2000 [01:06<01:21, 13.58it/s][Iteration 000900/002000] [loss: 0.00402861] [loss_bc: 0.00353613; loss_div: 0.00035141; loss_ff: 0.00014107] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  50%|████▉     | 998/2000 [01:13<01:14, 13.52it/s][Iteration 001000/002000] [loss: 0.00405270] [loss_bc: 0.00353607; loss_div: 0.00038095; loss_ff: 0.00013568] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  55%|█████▍    | 1098/2000 [01:21<01:06, 13.55it/s][Iteration 001100/002000] [loss: 0.00392843] [loss_bc: 0.00345765; loss_div: 0.00032522; loss_ff: 0.00014556] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  60%|█████▉    | 1198/2000 [01:28<00:58, 13.59it/s][Iteration 001200/002000] [loss: 0.00382330] [loss_bc: 0.00339930; loss_div: 0.00028296; loss_ff: 0.00014105] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  65%|██████▍   | 1298/2000 [01:35<00:51, 13.53it/s][Iteration 001300/002000] [loss: 0.00395207] [loss_bc: 0.00344825; loss_div: 0.00037089; loss_ff: 0.00013293] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  70%|██████▉   | 1398/2000 [01:43<00:44, 13.61it/s][Iteration 001400/002000] [loss: 0.00385872] [loss_bc: 0.00345952; loss_div: 0.00028480; loss_ff: 0.00011440] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  75%|███████▍  | 1498/2000 [01:50<00:36, 13.82it/s][Iteration 001500/002000] [loss: 0.00409934] [loss_bc: 0.00357276; loss_div: 0.00038444; loss_ff: 0.00014214] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  80%|███████▉  | 1598/2000 [01:57<00:28, 13.88it/s][Iteration 001600/002000] [loss: 0.00429362] [loss_bc: 0.00381662; loss_div: 0.00035457; loss_ff: 0.00012242] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  85%|████████▍ | 1698/2000 [02:05<00:22, 13.52it/s][Iteration 001700/002000] [loss: 0.00401921] [loss_bc: 0.00356271; loss_div: 0.00032809; loss_ff: 0.00012841] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  90%|████████▉ | 1798/2000 [02:12<00:14, 13.51it/s][Iteration 001800/002000] [loss: 0.00416367] [loss_bc: 0.00363404; loss_div: 0.00031931; loss_ff: 0.00021031] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  95%|█████████▍| 1898/2000 [02:19<00:07, 13.51it/s][Iteration 001900/002000] [loss: 0.00395860] [loss_bc: 0.00339618; loss_div: 0.00038101; loss_ff: 0.00018141] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training: 100%|█████████▉| 1998/2000 [02:27<00:00, 13.69it/s][Iteration 002000/002000] [loss: 0.00387540] [loss_bc: 0.00348948; loss_div: 0.00029268; loss_ff: 0.00009324] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training: 100%|██████████| 2000/2000 [02:27<00:00, 13.56it/s]\n",
      "[Iteration 002000/002000] [loss: 0.00387540] [loss_bc: 0.00348948; loss_div: 0.00029268; loss_ff: 0.00009324] [w_bc: 1.000000, LR: 0.000050]\n",
      "Runtime --> total: 147.71sec (2.95ms/iter.)\n",
      "Configuration:\n",
      "dim: 256, w_div: 1.000000, w_ff: 1.000000, decay_iterations: None, potential: True, vector_potential: False, \n",
      "Using device: cuda (gpus 1) ['NVIDIA RTX A6000']\n",
      "Potential Boundary: 100%|██████████| 1/1 [00:00<00:00,  1.55it/s]\n",
      "Loaded meta state: /userhome/jeon_mg/workspace/_data/NOAA12673/PINN/20170904_183600/model_final.pt\n",
      "Training:   0%|          | 0/2000 [00:00<?, ?it/s][Iteration 000000/002000] [loss: 0.00404206] [loss_bc: 0.00359693; loss_div: 0.00032006; loss_ff: 0.00012507] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:   5%|▍         | 98/2000 [00:07<02:21, 13.45it/s][Iteration 000100/002000] [loss: 0.00410408] [loss_bc: 0.00358825; loss_div: 0.00037771; loss_ff: 0.00013812] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  10%|▉         | 198/2000 [00:14<02:13, 13.53it/s][Iteration 000200/002000] [loss: 0.00407462] [loss_bc: 0.00368396; loss_div: 0.00028305; loss_ff: 0.00010761] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  15%|█▍        | 298/2000 [00:21<02:05, 13.59it/s][Iteration 000300/002000] [loss: 0.00373609] [loss_bc: 0.00332135; loss_div: 0.00029872; loss_ff: 0.00011603] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  20%|█▉        | 398/2000 [00:29<01:58, 13.56it/s][Iteration 000400/002000] [loss: 0.00406365] [loss_bc: 0.00357310; loss_div: 0.00030627; loss_ff: 0.00018429] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  25%|██▍       | 498/2000 [00:36<01:50, 13.59it/s][Iteration 000500/002000] [loss: 0.00407550] [loss_bc: 0.00366145; loss_div: 0.00030424; loss_ff: 0.00010982] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  30%|██▉       | 598/2000 [00:44<01:42, 13.64it/s][Iteration 000600/002000] [loss: 0.00411638] [loss_bc: 0.00361880; loss_div: 0.00035120; loss_ff: 0.00014638] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  35%|███▍      | 698/2000 [00:51<01:34, 13.71it/s][Iteration 000700/002000] [loss: 0.00417075] [loss_bc: 0.00361723; loss_div: 0.00039865; loss_ff: 0.00015486] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  40%|███▉      | 798/2000 [00:58<01:26, 13.93it/s][Iteration 000800/002000] [loss: 0.00389189] [loss_bc: 0.00341351; loss_div: 0.00034750; loss_ff: 0.00013088] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  45%|████▍     | 898/2000 [01:06<01:21, 13.60it/s][Iteration 000900/002000] [loss: 0.00408570] [loss_bc: 0.00360695; loss_div: 0.00033474; loss_ff: 0.00014402] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  50%|████▉     | 998/2000 [01:13<01:14, 13.53it/s][Iteration 001000/002000] [loss: 0.00422283] [loss_bc: 0.00368759; loss_div: 0.00038918; loss_ff: 0.00014606] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  55%|█████▍    | 1098/2000 [01:20<01:06, 13.56it/s][Iteration 001100/002000] [loss: 0.00371055] [loss_bc: 0.00330962; loss_div: 0.00030490; loss_ff: 0.00009604] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  60%|█████▉    | 1198/2000 [01:28<00:59, 13.57it/s][Iteration 001200/002000] [loss: 0.00410148] [loss_bc: 0.00360849; loss_div: 0.00037246; loss_ff: 0.00012052] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  65%|██████▍   | 1298/2000 [01:35<00:51, 13.55it/s][Iteration 001300/002000] [loss: 0.00405795] [loss_bc: 0.00359876; loss_div: 0.00034634; loss_ff: 0.00011285] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  70%|██████▉   | 1398/2000 [01:43<00:44, 13.63it/s][Iteration 001400/002000] [loss: 0.00402491] [loss_bc: 0.00360520; loss_div: 0.00030570; loss_ff: 0.00011401] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  75%|███████▍  | 1498/2000 [01:50<00:36, 13.62it/s][Iteration 001500/002000] [loss: 0.00417838] [loss_bc: 0.00367583; loss_div: 0.00032185; loss_ff: 0.00018070] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  80%|███████▉  | 1598/2000 [01:57<00:29, 13.62it/s][Iteration 001600/002000] [loss: 0.00411107] [loss_bc: 0.00360214; loss_div: 0.00037917; loss_ff: 0.00012975] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  85%|████████▍ | 1698/2000 [02:05<00:22, 13.58it/s][Iteration 001700/002000] [loss: 0.00388442] [loss_bc: 0.00338405; loss_div: 0.00035576; loss_ff: 0.00014461] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  90%|████████▉ | 1798/2000 [02:12<00:14, 13.91it/s][Iteration 001800/002000] [loss: 0.00419774] [loss_bc: 0.00366039; loss_div: 0.00040672; loss_ff: 0.00013063] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  95%|█████████▍| 1898/2000 [02:19<00:07, 13.54it/s][Iteration 001900/002000] [loss: 0.00393879] [loss_bc: 0.00348013; loss_div: 0.00032655; loss_ff: 0.00013211] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training: 100%|█████████▉| 1998/2000 [02:27<00:00, 13.57it/s][Iteration 002000/002000] [loss: 0.00413098] [loss_bc: 0.00360648; loss_div: 0.00038692; loss_ff: 0.00013757] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training: 100%|██████████| 2000/2000 [02:27<00:00, 13.55it/s]\n",
      "[Iteration 002000/002000] [loss: 0.00413098] [loss_bc: 0.00360648; loss_div: 0.00038692; loss_ff: 0.00013757] [w_bc: 1.000000, LR: 0.000050]\n",
      "Runtime --> total: 147.74sec (2.95ms/iter.)\n",
      "Configuration:\n",
      "dim: 256, w_div: 1.000000, w_ff: 1.000000, decay_iterations: None, potential: True, vector_potential: False, \n",
      "Using device: cuda (gpus 1) ['NVIDIA RTX A6000']\n",
      "Potential Boundary: 100%|██████████| 1/1 [00:00<00:00,  1.28it/s]\n",
      "Loaded meta state: /userhome/jeon_mg/workspace/_data/NOAA12673/PINN/20170904_184800/model_final.pt\n",
      "Training:   0%|          | 0/2000 [00:00<?, ?it/s][Iteration 000000/002000] [loss: 0.00421918] [loss_bc: 0.00373703; loss_div: 0.00035862; loss_ff: 0.00012353] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:   5%|▍         | 98/2000 [00:07<02:19, 13.61it/s][Iteration 000100/002000] [loss: 0.00394502] [loss_bc: 0.00348557; loss_div: 0.00033779; loss_ff: 0.00012166] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  10%|▉         | 198/2000 [00:14<02:13, 13.52it/s][Iteration 000200/002000] [loss: 0.00425240] [loss_bc: 0.00370853; loss_div: 0.00039262; loss_ff: 0.00015125] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  15%|█▍        | 298/2000 [00:21<02:05, 13.51it/s][Iteration 000300/002000] [loss: 0.00375256] [loss_bc: 0.00321692; loss_div: 0.00039926; loss_ff: 0.00013638] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  20%|█▉        | 398/2000 [00:29<01:57, 13.64it/s][Iteration 000400/002000] [loss: 0.00388872] [loss_bc: 0.00345244; loss_div: 0.00032224; loss_ff: 0.00011404] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  25%|██▍       | 498/2000 [00:36<01:51, 13.51it/s][Iteration 000500/002000] [loss: 0.00408684] [loss_bc: 0.00365834; loss_div: 0.00030270; loss_ff: 0.00012580] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  30%|██▉       | 598/2000 [00:44<01:42, 13.62it/s][Iteration 000600/002000] [loss: 0.00386083] [loss_bc: 0.00335544; loss_div: 0.00035244; loss_ff: 0.00015294] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  35%|███▍      | 698/2000 [00:51<01:33, 13.88it/s][Iteration 000700/002000] [loss: 0.00423586] [loss_bc: 0.00369940; loss_div: 0.00038494; loss_ff: 0.00015152] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  40%|███▉      | 798/2000 [00:58<01:26, 13.90it/s][Iteration 000800/002000] [loss: 0.00411868] [loss_bc: 0.00365461; loss_div: 0.00033744; loss_ff: 0.00012663] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  45%|████▍     | 898/2000 [01:05<01:21, 13.56it/s][Iteration 000900/002000] [loss: 0.00420376] [loss_bc: 0.00371032; loss_div: 0.00037647; loss_ff: 0.00011696] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  50%|████▉     | 998/2000 [01:13<01:13, 13.61it/s][Iteration 001000/002000] [loss: 0.00388798] [loss_bc: 0.00333826; loss_div: 0.00042335; loss_ff: 0.00012638] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  55%|█████▍    | 1098/2000 [01:20<01:05, 13.81it/s][Iteration 001100/002000] [loss: 0.00418269] [loss_bc: 0.00369986; loss_div: 0.00034846; loss_ff: 0.00013438] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  60%|█████▉    | 1198/2000 [01:28<00:59, 13.57it/s][Iteration 001200/002000] [loss: 0.00382215] [loss_bc: 0.00343805; loss_div: 0.00026000; loss_ff: 0.00012411] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  65%|██████▍   | 1298/2000 [01:35<00:50, 13.78it/s][Iteration 001300/002000] [loss: 0.00413232] [loss_bc: 0.00368480; loss_div: 0.00032531; loss_ff: 0.00012221] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  70%|██████▉   | 1398/2000 [01:42<00:44, 13.65it/s][Iteration 001400/002000] [loss: 0.00411760] [loss_bc: 0.00370245; loss_div: 0.00032132; loss_ff: 0.00009383] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  75%|███████▍  | 1498/2000 [01:50<00:36, 13.62it/s][Iteration 001500/002000] [loss: 0.00410755] [loss_bc: 0.00368219; loss_div: 0.00030372; loss_ff: 0.00012163] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  80%|███████▉  | 1598/2000 [01:57<00:29, 13.57it/s][Iteration 001600/002000] [loss: 0.00369069] [loss_bc: 0.00317673; loss_div: 0.00035125; loss_ff: 0.00016270] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  85%|████████▍ | 1698/2000 [02:04<00:21, 13.79it/s][Iteration 001700/002000] [loss: 0.00397492] [loss_bc: 0.00346002; loss_div: 0.00038093; loss_ff: 0.00013398] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  90%|████████▉ | 1798/2000 [02:12<00:14, 13.56it/s][Iteration 001800/002000] [loss: 0.00387896] [loss_bc: 0.00343830; loss_div: 0.00031119; loss_ff: 0.00012947] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  95%|█████████▍| 1898/2000 [02:19<00:07, 13.61it/s][Iteration 001900/002000] [loss: 0.00392105] [loss_bc: 0.00346244; loss_div: 0.00035607; loss_ff: 0.00010254] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training: 100%|█████████▉| 1998/2000 [02:27<00:00, 13.55it/s][Iteration 002000/002000] [loss: 0.00401810] [loss_bc: 0.00345508; loss_div: 0.00034313; loss_ff: 0.00021988] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training: 100%|██████████| 2000/2000 [02:27<00:00, 13.57it/s]\n",
      "[Iteration 002000/002000] [loss: 0.00401810] [loss_bc: 0.00345508; loss_div: 0.00034313; loss_ff: 0.00021988] [w_bc: 1.000000, LR: 0.000050]\n",
      "Runtime --> total: 147.54sec (2.95ms/iter.)\n",
      "Configuration:\n",
      "dim: 256, w_div: 1.000000, w_ff: 1.000000, decay_iterations: None, potential: True, vector_potential: False, \n",
      "Using device: cuda (gpus 1) ['NVIDIA RTX A6000']\n",
      "Potential Boundary: 100%|██████████| 1/1 [00:00<00:00,  1.65it/s]\n",
      "Loaded meta state: /userhome/jeon_mg/workspace/_data/NOAA12673/PINN/20170904_190000/model_final.pt\n",
      "Training:   0%|          | 0/2000 [00:00<?, ?it/s][Iteration 000000/002000] [loss: 0.00397113] [loss_bc: 0.00354896; loss_div: 0.00029827; loss_ff: 0.00012389] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:   5%|▍         | 98/2000 [00:07<02:19, 13.63it/s][Iteration 000100/002000] [loss: 0.00412472] [loss_bc: 0.00355492; loss_div: 0.00036150; loss_ff: 0.00020830] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  10%|▉         | 198/2000 [00:14<02:12, 13.57it/s][Iteration 000200/002000] [loss: 0.00402217] [loss_bc: 0.00353264; loss_div: 0.00037109; loss_ff: 0.00011845] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  15%|█▍        | 298/2000 [00:21<02:05, 13.58it/s][Iteration 000300/002000] [loss: 0.00434129] [loss_bc: 0.00388301; loss_div: 0.00034672; loss_ff: 0.00011157] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  20%|█▉        | 398/2000 [00:29<01:58, 13.47it/s][Iteration 000400/002000] [loss: 0.00392316] [loss_bc: 0.00353938; loss_div: 0.00026368; loss_ff: 0.00012010] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  25%|██▍       | 498/2000 [00:36<01:50, 13.61it/s][Iteration 000500/002000] [loss: 0.00415760] [loss_bc: 0.00362564; loss_div: 0.00037733; loss_ff: 0.00015464] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  30%|██▉       | 598/2000 [00:44<01:43, 13.56it/s][Iteration 000600/002000] [loss: 0.00399270] [loss_bc: 0.00353933; loss_div: 0.00032067; loss_ff: 0.00013270] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  35%|███▍      | 698/2000 [00:51<01:35, 13.61it/s][Iteration 000700/002000] [loss: 0.00393426] [loss_bc: 0.00348290; loss_div: 0.00033297; loss_ff: 0.00011839] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  40%|███▉      | 798/2000 [00:58<01:28, 13.65it/s][Iteration 000800/002000] [loss: 0.00405341] [loss_bc: 0.00361054; loss_div: 0.00034356; loss_ff: 0.00009931] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  45%|████▍     | 898/2000 [01:06<01:20, 13.63it/s][Iteration 000900/002000] [loss: 0.00401361] [loss_bc: 0.00348692; loss_div: 0.00037651; loss_ff: 0.00015017] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  50%|████▉     | 998/2000 [01:13<01:12, 13.85it/s][Iteration 001000/002000] [loss: 0.00423530] [loss_bc: 0.00360965; loss_div: 0.00045809; loss_ff: 0.00016756] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  55%|█████▍    | 1098/2000 [01:20<01:06, 13.62it/s][Iteration 001100/002000] [loss: 0.00400210] [loss_bc: 0.00352420; loss_div: 0.00035976; loss_ff: 0.00011814] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  60%|█████▉    | 1198/2000 [01:28<00:57, 13.97it/s][Iteration 001200/002000] [loss: 0.00415799] [loss_bc: 0.00362347; loss_div: 0.00039033; loss_ff: 0.00014419] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  65%|██████▍   | 1298/2000 [01:35<00:50, 13.92it/s][Iteration 001300/002000] [loss: 0.00408886] [loss_bc: 0.00361306; loss_div: 0.00034681; loss_ff: 0.00012900] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  70%|██████▉   | 1398/2000 [01:42<00:44, 13.55it/s][Iteration 001400/002000] [loss: 0.00433979] [loss_bc: 0.00386939; loss_div: 0.00033186; loss_ff: 0.00013854] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  75%|███████▍  | 1498/2000 [01:50<00:37, 13.52it/s][Iteration 001500/002000] [loss: 0.00400505] [loss_bc: 0.00350096; loss_div: 0.00036128; loss_ff: 0.00014281] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  80%|███████▉  | 1598/2000 [01:57<00:29, 13.84it/s][Iteration 001600/002000] [loss: 0.00407617] [loss_bc: 0.00350386; loss_div: 0.00040033; loss_ff: 0.00017198] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  85%|████████▍ | 1698/2000 [02:04<00:22, 13.68it/s][Iteration 001700/002000] [loss: 0.00413100] [loss_bc: 0.00360347; loss_div: 0.00039689; loss_ff: 0.00013064] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  90%|████████▉ | 1798/2000 [02:12<00:14, 13.66it/s][Iteration 001800/002000] [loss: 0.00392206] [loss_bc: 0.00349503; loss_div: 0.00032426; loss_ff: 0.00010276] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  95%|█████████▍| 1898/2000 [02:19<00:07, 13.61it/s][Iteration 001900/002000] [loss: 0.00388381] [loss_bc: 0.00346721; loss_div: 0.00031071; loss_ff: 0.00010588] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training: 100%|█████████▉| 1998/2000 [02:27<00:00, 13.62it/s][Iteration 002000/002000] [loss: 0.00394820] [loss_bc: 0.00349209; loss_div: 0.00034851; loss_ff: 0.00010760] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training: 100%|██████████| 2000/2000 [02:27<00:00, 13.56it/s]\n",
      "[Iteration 002000/002000] [loss: 0.00394820] [loss_bc: 0.00349209; loss_div: 0.00034851; loss_ff: 0.00010760] [w_bc: 1.000000, LR: 0.000050]\n",
      "Runtime --> total: 147.65sec (2.95ms/iter.)\n",
      "Configuration:\n",
      "dim: 256, w_div: 1.000000, w_ff: 1.000000, decay_iterations: None, potential: True, vector_potential: False, \n",
      "Using device: cuda (gpus 1) ['NVIDIA RTX A6000']\n",
      "Potential Boundary: 100%|██████████| 1/1 [00:00<00:00,  1.44it/s]\n",
      "Loaded meta state: /userhome/jeon_mg/workspace/_data/NOAA12673/PINN/20170904_191200/model_final.pt\n",
      "Training:   0%|          | 0/2000 [00:00<?, ?it/s][Iteration 000000/002000] [loss: 0.00407492] [loss_bc: 0.00368163; loss_div: 0.00028817; loss_ff: 0.00010511] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:   5%|▍         | 98/2000 [00:07<02:18, 13.75it/s][Iteration 000100/002000] [loss: 0.00413293] [loss_bc: 0.00374024; loss_div: 0.00027458; loss_ff: 0.00011811] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  10%|▉         | 198/2000 [00:14<02:10, 13.83it/s][Iteration 000200/002000] [loss: 0.00381261] [loss_bc: 0.00340344; loss_div: 0.00029183; loss_ff: 0.00011734] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  15%|█▍        | 298/2000 [00:21<02:05, 13.61it/s][Iteration 000300/002000] [loss: 0.00426896] [loss_bc: 0.00376618; loss_div: 0.00039605; loss_ff: 0.00010673] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  20%|█▉        | 398/2000 [00:29<01:58, 13.47it/s][Iteration 000400/002000] [loss: 0.00371386] [loss_bc: 0.00331341; loss_div: 0.00028773; loss_ff: 0.00011272] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  25%|██▍       | 498/2000 [00:36<01:49, 13.68it/s][Iteration 000500/002000] [loss: 0.00418687] [loss_bc: 0.00366355; loss_div: 0.00036871; loss_ff: 0.00015461] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  30%|██▉       | 598/2000 [00:44<01:43, 13.60it/s][Iteration 000600/002000] [loss: 0.00419535] [loss_bc: 0.00373353; loss_div: 0.00032183; loss_ff: 0.00013998] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  35%|███▍      | 698/2000 [00:51<01:35, 13.57it/s][Iteration 000700/002000] [loss: 0.00396023] [loss_bc: 0.00339322; loss_div: 0.00038819; loss_ff: 0.00017882] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  40%|███▉      | 798/2000 [00:58<01:28, 13.57it/s][Iteration 000800/002000] [loss: 0.00404295] [loss_bc: 0.00354697; loss_div: 0.00035764; loss_ff: 0.00013833] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  45%|████▍     | 898/2000 [01:06<01:21, 13.48it/s][Iteration 000900/002000] [loss: 0.00419995] [loss_bc: 0.00371593; loss_div: 0.00036450; loss_ff: 0.00011951] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  50%|████▉     | 998/2000 [01:13<01:13, 13.65it/s][Iteration 001000/002000] [loss: 0.00397375] [loss_bc: 0.00354267; loss_div: 0.00031917; loss_ff: 0.00011191] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  55%|█████▍    | 1098/2000 [01:21<01:06, 13.58it/s][Iteration 001100/002000] [loss: 0.00388763] [loss_bc: 0.00338789; loss_div: 0.00034851; loss_ff: 0.00015124] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  60%|█████▉    | 1198/2000 [01:28<00:57, 13.92it/s][Iteration 001200/002000] [loss: 0.00398659] [loss_bc: 0.00355091; loss_div: 0.00032475; loss_ff: 0.00011093] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  65%|██████▍   | 1298/2000 [01:35<00:51, 13.60it/s][Iteration 001300/002000] [loss: 0.00378453] [loss_bc: 0.00338210; loss_div: 0.00027706; loss_ff: 0.00012537] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  70%|██████▉   | 1398/2000 [01:42<00:44, 13.59it/s][Iteration 001400/002000] [loss: 0.00412905] [loss_bc: 0.00369325; loss_div: 0.00031501; loss_ff: 0.00012079] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  75%|███████▍  | 1498/2000 [01:50<00:36, 13.58it/s][Iteration 001500/002000] [loss: 0.00419475] [loss_bc: 0.00363547; loss_div: 0.00043587; loss_ff: 0.00012341] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  80%|███████▉  | 1598/2000 [01:57<00:29, 13.69it/s][Iteration 001600/002000] [loss: 0.00425312] [loss_bc: 0.00370678; loss_div: 0.00042016; loss_ff: 0.00012618] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  85%|████████▍ | 1698/2000 [02:04<00:21, 13.82it/s][Iteration 001700/002000] [loss: 0.00420652] [loss_bc: 0.00369183; loss_div: 0.00039338; loss_ff: 0.00012132] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  90%|████████▉ | 1798/2000 [02:12<00:14, 13.91it/s][Iteration 001800/002000] [loss: 0.00420087] [loss_bc: 0.00363553; loss_div: 0.00039052; loss_ff: 0.00017483] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  95%|█████████▍| 1898/2000 [02:19<00:07, 13.58it/s][Iteration 001900/002000] [loss: 0.00422095] [loss_bc: 0.00370540; loss_div: 0.00036573; loss_ff: 0.00014981] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training: 100%|█████████▉| 1998/2000 [02:26<00:00, 13.95it/s][Iteration 002000/002000] [loss: 0.00379311] [loss_bc: 0.00328611; loss_div: 0.00036720; loss_ff: 0.00013980] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training: 100%|██████████| 2000/2000 [02:27<00:00, 13.60it/s]\n",
      "[Iteration 002000/002000] [loss: 0.00379311] [loss_bc: 0.00328611; loss_div: 0.00036720; loss_ff: 0.00013980] [w_bc: 1.000000, LR: 0.000050]\n",
      "Runtime --> total: 147.24sec (2.94ms/iter.)\n",
      "Configuration:\n",
      "dim: 256, w_div: 1.000000, w_ff: 1.000000, decay_iterations: None, potential: True, vector_potential: False, \n",
      "Using device: cuda (gpus 1) ['NVIDIA RTX A6000']\n",
      "Potential Boundary: 100%|██████████| 1/1 [00:00<00:00,  1.25it/s]\n",
      "Loaded meta state: /userhome/jeon_mg/workspace/_data/NOAA12673/PINN/20170904_192400/model_final.pt\n",
      "Training:   0%|          | 0/2000 [00:00<?, ?it/s][Iteration 000000/002000] [loss: 0.00410887] [loss_bc: 0.00358968; loss_div: 0.00035437; loss_ff: 0.00016481] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:   5%|▍         | 98/2000 [00:07<02:19, 13.67it/s][Iteration 000100/002000] [loss: 0.00406179] [loss_bc: 0.00356056; loss_div: 0.00033476; loss_ff: 0.00016647] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  10%|▉         | 198/2000 [00:14<02:13, 13.45it/s][Iteration 000200/002000] [loss: 0.00406258] [loss_bc: 0.00354950; loss_div: 0.00036338; loss_ff: 0.00014970] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  15%|█▍        | 298/2000 [00:21<02:06, 13.49it/s][Iteration 000300/002000] [loss: 0.00403069] [loss_bc: 0.00355336; loss_div: 0.00037472; loss_ff: 0.00010262] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  20%|█▉        | 398/2000 [00:29<01:58, 13.51it/s][Iteration 000400/002000] [loss: 0.00429175] [loss_bc: 0.00372632; loss_div: 0.00041730; loss_ff: 0.00014813] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  25%|██▍       | 498/2000 [00:36<01:49, 13.66it/s][Iteration 000500/002000] [loss: 0.00412261] [loss_bc: 0.00374224; loss_div: 0.00028290; loss_ff: 0.00009747] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  30%|██▉       | 598/2000 [00:44<01:43, 13.55it/s][Iteration 000600/002000] [loss: 0.00407673] [loss_bc: 0.00357723; loss_div: 0.00036307; loss_ff: 0.00013643] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  35%|███▍      | 698/2000 [00:51<01:34, 13.76it/s][Iteration 000700/002000] [loss: 0.00395342] [loss_bc: 0.00353611; loss_div: 0.00028443; loss_ff: 0.00013289] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  40%|███▉      | 798/2000 [00:58<01:28, 13.59it/s][Iteration 000800/002000] [loss: 0.00433265] [loss_bc: 0.00377726; loss_div: 0.00042254; loss_ff: 0.00013284] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  45%|████▍     | 898/2000 [01:06<01:21, 13.55it/s][Iteration 000900/002000] [loss: 0.00419655] [loss_bc: 0.00372454; loss_div: 0.00035730; loss_ff: 0.00011471] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  50%|████▉     | 998/2000 [01:13<01:13, 13.57it/s][Iteration 001000/002000] [loss: 0.00428734] [loss_bc: 0.00373001; loss_div: 0.00041811; loss_ff: 0.00013923] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  55%|█████▍    | 1098/2000 [01:20<01:06, 13.49it/s][Iteration 001100/002000] [loss: 0.00379089] [loss_bc: 0.00333490; loss_div: 0.00033697; loss_ff: 0.00011901] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  60%|█████▉    | 1198/2000 [01:28<00:57, 13.96it/s][Iteration 001200/002000] [loss: 0.00395558] [loss_bc: 0.00352017; loss_div: 0.00032427; loss_ff: 0.00011114] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  65%|██████▍   | 1298/2000 [01:35<00:51, 13.62it/s][Iteration 001300/002000] [loss: 0.00406101] [loss_bc: 0.00357653; loss_div: 0.00033162; loss_ff: 0.00015286] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  70%|██████▉   | 1398/2000 [01:42<00:44, 13.59it/s][Iteration 001400/002000] [loss: 0.00384205] [loss_bc: 0.00337323; loss_div: 0.00034551; loss_ff: 0.00012332] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  75%|███████▍  | 1498/2000 [01:50<00:36, 13.60it/s][Iteration 001500/002000] [loss: 0.00394914] [loss_bc: 0.00351070; loss_div: 0.00031067; loss_ff: 0.00012777] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  80%|███████▉  | 1598/2000 [01:57<00:29, 13.61it/s][Iteration 001600/002000] [loss: 0.00431251] [loss_bc: 0.00374459; loss_div: 0.00042005; loss_ff: 0.00014787] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  85%|████████▍ | 1698/2000 [02:05<00:22, 13.57it/s][Iteration 001700/002000] [loss: 0.00379975] [loss_bc: 0.00332370; loss_div: 0.00035407; loss_ff: 0.00012198] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  90%|████████▉ | 1798/2000 [02:12<00:14, 13.91it/s][Iteration 001800/002000] [loss: 0.00404877] [loss_bc: 0.00351560; loss_div: 0.00037127; loss_ff: 0.00016191] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  95%|█████████▍| 1898/2000 [02:19<00:07, 13.57it/s][Iteration 001900/002000] [loss: 0.00419014] [loss_bc: 0.00370662; loss_div: 0.00036250; loss_ff: 0.00012102] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training: 100%|█████████▉| 1998/2000 [02:27<00:00, 13.62it/s][Iteration 002000/002000] [loss: 0.00415790] [loss_bc: 0.00373884; loss_div: 0.00030428; loss_ff: 0.00011478] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training: 100%|██████████| 2000/2000 [02:27<00:00, 13.55it/s]\n",
      "[Iteration 002000/002000] [loss: 0.00415790] [loss_bc: 0.00373884; loss_div: 0.00030428; loss_ff: 0.00011478] [w_bc: 1.000000, LR: 0.000050]\n",
      "Runtime --> total: 147.72sec (2.95ms/iter.)\n",
      "Configuration:\n",
      "dim: 256, w_div: 1.000000, w_ff: 1.000000, decay_iterations: None, potential: True, vector_potential: False, \n",
      "Using device: cuda (gpus 1) ['NVIDIA RTX A6000']\n",
      "Potential Boundary: 100%|██████████| 1/1 [00:00<00:00,  1.58it/s]\n",
      "Loaded meta state: /userhome/jeon_mg/workspace/_data/NOAA12673/PINN/20170904_193600/model_final.pt\n",
      "Training:   0%|          | 0/2000 [00:00<?, ?it/s][Iteration 000000/002000] [loss: 0.00401586] [loss_bc: 0.00358697; loss_div: 0.00031272; loss_ff: 0.00011616] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:   5%|▍         | 98/2000 [00:07<02:18, 13.71it/s][Iteration 000100/002000] [loss: 0.00421360] [loss_bc: 0.00358601; loss_div: 0.00047311; loss_ff: 0.00015448] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  10%|▉         | 198/2000 [00:14<02:09, 13.89it/s][Iteration 000200/002000] [loss: 0.00407649] [loss_bc: 0.00357395; loss_div: 0.00036329; loss_ff: 0.00013925] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  15%|█▍        | 298/2000 [00:21<02:05, 13.60it/s][Iteration 000300/002000] [loss: 0.00398553] [loss_bc: 0.00351273; loss_div: 0.00032782; loss_ff: 0.00014498] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  20%|█▉        | 398/2000 [00:29<01:56, 13.77it/s][Iteration 000400/002000] [loss: 0.00417478] [loss_bc: 0.00377201; loss_div: 0.00030688; loss_ff: 0.00009590] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  25%|██▍       | 498/2000 [00:36<01:50, 13.56it/s][Iteration 000500/002000] [loss: 0.00380925] [loss_bc: 0.00335624; loss_div: 0.00032955; loss_ff: 0.00012346] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  30%|██▉       | 598/2000 [00:44<01:44, 13.47it/s][Iteration 000600/002000] [loss: 0.00385344] [loss_bc: 0.00334921; loss_div: 0.00035491; loss_ff: 0.00014931] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  35%|███▍      | 698/2000 [00:51<01:34, 13.75it/s][Iteration 000700/002000] [loss: 0.00432832] [loss_bc: 0.00372300; loss_div: 0.00042253; loss_ff: 0.00018279] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  40%|███▉      | 798/2000 [00:58<01:28, 13.54it/s][Iteration 000800/002000] [loss: 0.00397919] [loss_bc: 0.00349765; loss_div: 0.00035944; loss_ff: 0.00012211] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  45%|████▍     | 898/2000 [01:06<01:21, 13.56it/s][Iteration 000900/002000] [loss: 0.00425350] [loss_bc: 0.00376392; loss_div: 0.00037697; loss_ff: 0.00011261] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  50%|████▉     | 998/2000 [01:13<01:13, 13.61it/s][Iteration 001000/002000] [loss: 0.00435698] [loss_bc: 0.00377545; loss_div: 0.00040649; loss_ff: 0.00017504] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  55%|█████▍    | 1098/2000 [01:20<01:06, 13.63it/s][Iteration 001100/002000] [loss: 0.00383064] [loss_bc: 0.00335015; loss_div: 0.00035028; loss_ff: 0.00013021] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  60%|█████▉    | 1198/2000 [01:28<00:58, 13.60it/s][Iteration 001200/002000] [loss: 0.00392471] [loss_bc: 0.00334212; loss_div: 0.00041949; loss_ff: 0.00016311] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  65%|██████▍   | 1298/2000 [01:35<00:52, 13.49it/s][Iteration 001300/002000] [loss: 0.00428232] [loss_bc: 0.00375239; loss_div: 0.00038810; loss_ff: 0.00014183] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  70%|██████▉   | 1398/2000 [01:43<00:44, 13.63it/s][Iteration 001400/002000] [loss: 0.00404350] [loss_bc: 0.00355508; loss_div: 0.00034349; loss_ff: 0.00014493] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  75%|███████▍  | 1498/2000 [01:50<00:37, 13.56it/s][Iteration 001500/002000] [loss: 0.00379255] [loss_bc: 0.00333509; loss_div: 0.00034085; loss_ff: 0.00011661] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  80%|███████▉  | 1598/2000 [01:57<00:29, 13.65it/s][Iteration 001600/002000] [loss: 0.00389163] [loss_bc: 0.00333465; loss_div: 0.00042369; loss_ff: 0.00013329] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  85%|████████▍ | 1698/2000 [02:05<00:22, 13.63it/s][Iteration 001700/002000] [loss: 0.00423987] [loss_bc: 0.00372356; loss_div: 0.00035289; loss_ff: 0.00016342] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  90%|████████▉ | 1798/2000 [02:12<00:14, 13.62it/s][Iteration 001800/002000] [loss: 0.00417622] [loss_bc: 0.00371723; loss_div: 0.00032645; loss_ff: 0.00013254] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  95%|█████████▍| 1898/2000 [02:19<00:07, 13.54it/s][Iteration 001900/002000] [loss: 0.00419700] [loss_bc: 0.00371600; loss_div: 0.00033451; loss_ff: 0.00014649] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training: 100%|█████████▉| 1998/2000 [02:27<00:00, 13.64it/s][Iteration 002000/002000] [loss: 0.00404417] [loss_bc: 0.00352970; loss_div: 0.00035482; loss_ff: 0.00015964] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training: 100%|██████████| 2000/2000 [02:27<00:00, 13.54it/s]\n",
      "[Iteration 002000/002000] [loss: 0.00404417] [loss_bc: 0.00352970; loss_div: 0.00035482; loss_ff: 0.00015964] [w_bc: 1.000000, LR: 0.000050]\n",
      "Runtime --> total: 147.88sec (2.96ms/iter.)\n",
      "Configuration:\n",
      "dim: 256, w_div: 1.000000, w_ff: 1.000000, decay_iterations: None, potential: True, vector_potential: False, \n",
      "Using device: cuda (gpus 1) ['NVIDIA RTX A6000']\n",
      "Potential Boundary: 100%|██████████| 1/1 [00:00<00:00,  1.78it/s]\n",
      "Loaded meta state: /userhome/jeon_mg/workspace/_data/NOAA12673/PINN/20170904_194800/model_final.pt\n",
      "Training:   0%|          | 0/2000 [00:00<?, ?it/s][Iteration 000000/002000] [loss: 0.00377555] [loss_bc: 0.00330898; loss_div: 0.00033496; loss_ff: 0.00013161] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:   5%|▍         | 98/2000 [00:07<02:20, 13.54it/s][Iteration 000100/002000] [loss: 0.00379658] [loss_bc: 0.00330519; loss_div: 0.00036174; loss_ff: 0.00012964] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  10%|▉         | 198/2000 [00:14<02:12, 13.56it/s][Iteration 000200/002000] [loss: 0.00423501] [loss_bc: 0.00374915; loss_div: 0.00033860; loss_ff: 0.00014726] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  15%|█▍        | 298/2000 [00:21<02:05, 13.58it/s][Iteration 000300/002000] [loss: 0.00428400] [loss_bc: 0.00372041; loss_div: 0.00037503; loss_ff: 0.00018856] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  20%|█▉        | 398/2000 [00:29<01:55, 13.93it/s][Iteration 000400/002000] [loss: 0.00407696] [loss_bc: 0.00356162; loss_div: 0.00036676; loss_ff: 0.00014857] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  25%|██▍       | 498/2000 [00:36<01:50, 13.58it/s][Iteration 000500/002000] [loss: 0.00378902] [loss_bc: 0.00330132; loss_div: 0.00036052; loss_ff: 0.00012719] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  30%|██▉       | 598/2000 [00:43<01:42, 13.62it/s][Iteration 000600/002000] [loss: 0.00427500] [loss_bc: 0.00375528; loss_div: 0.00040161; loss_ff: 0.00011811] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  35%|███▍      | 698/2000 [00:51<01:35, 13.58it/s][Iteration 000700/002000] [loss: 0.00370958] [loss_bc: 0.00329320; loss_div: 0.00030037; loss_ff: 0.00011602] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  40%|███▉      | 798/2000 [00:58<01:27, 13.66it/s][Iteration 000800/002000] [loss: 0.00375185] [loss_bc: 0.00329005; loss_div: 0.00033950; loss_ff: 0.00012230] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  45%|████▍     | 898/2000 [01:06<01:20, 13.69it/s][Iteration 000900/002000] [loss: 0.00407171] [loss_bc: 0.00362878; loss_div: 0.00030673; loss_ff: 0.00013619] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  50%|████▉     | 998/2000 [01:13<01:13, 13.71it/s][Iteration 001000/002000] [loss: 0.00425762] [loss_bc: 0.00370267; loss_div: 0.00041300; loss_ff: 0.00014196] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  55%|█████▍    | 1098/2000 [01:20<01:05, 13.72it/s][Iteration 001100/002000] [loss: 0.00376366] [loss_bc: 0.00328612; loss_div: 0.00034482; loss_ff: 0.00013271] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  60%|█████▉    | 1198/2000 [01:28<00:58, 13.61it/s][Iteration 001200/002000] [loss: 0.00414498] [loss_bc: 0.00372099; loss_div: 0.00031092; loss_ff: 0.00011307] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  65%|██████▍   | 1298/2000 [01:35<00:51, 13.58it/s][Iteration 001300/002000] [loss: 0.00407490] [loss_bc: 0.00369619; loss_div: 0.00028734; loss_ff: 0.00009137] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  70%|██████▉   | 1398/2000 [01:43<00:44, 13.64it/s][Iteration 001400/002000] [loss: 0.00391744] [loss_bc: 0.00348443; loss_div: 0.00033985; loss_ff: 0.00009316] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  75%|███████▍  | 1498/2000 [01:50<00:36, 13.61it/s][Iteration 001500/002000] [loss: 0.00420670] [loss_bc: 0.00369655; loss_div: 0.00040593; loss_ff: 0.00010422] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  80%|███████▉  | 1598/2000 [01:57<00:29, 13.65it/s][Iteration 001600/002000] [loss: 0.00372311] [loss_bc: 0.00328221; loss_div: 0.00031293; loss_ff: 0.00012798] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  85%|████████▍ | 1698/2000 [02:05<00:22, 13.68it/s][Iteration 001700/002000] [loss: 0.00403396] [loss_bc: 0.00359446; loss_div: 0.00032262; loss_ff: 0.00011688] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  90%|████████▉ | 1798/2000 [02:12<00:14, 13.63it/s][Iteration 001800/002000] [loss: 0.00399687] [loss_bc: 0.00354234; loss_div: 0.00034427; loss_ff: 0.00011027] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  95%|█████████▍| 1898/2000 [02:19<00:07, 13.58it/s][Iteration 001900/002000] [loss: 0.00411589] [loss_bc: 0.00358404; loss_div: 0.00039092; loss_ff: 0.00014094] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training: 100%|█████████▉| 1998/2000 [02:27<00:00, 13.58it/s][Iteration 002000/002000] [loss: 0.00381504] [loss_bc: 0.00327203; loss_div: 0.00037377; loss_ff: 0.00016925] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training: 100%|██████████| 2000/2000 [02:27<00:00, 13.54it/s]\n",
      "[Iteration 002000/002000] [loss: 0.00381504] [loss_bc: 0.00327203; loss_div: 0.00037377; loss_ff: 0.00016925] [w_bc: 1.000000, LR: 0.000050]\n",
      "Runtime --> total: 147.84sec (2.96ms/iter.)\n",
      "Configuration:\n",
      "dim: 256, w_div: 1.000000, w_ff: 1.000000, decay_iterations: None, potential: True, vector_potential: False, \n",
      "Using device: cuda (gpus 1) ['NVIDIA RTX A6000']\n",
      "Potential Boundary: 100%|██████████| 1/1 [00:00<00:00,  1.67it/s]\n",
      "Loaded meta state: /userhome/jeon_mg/workspace/_data/NOAA12673/PINN/20170904_200000/model_final.pt\n",
      "Training:   0%|          | 0/2000 [00:00<?, ?it/s][Iteration 000000/002000] [loss: 0.00424752] [loss_bc: 0.00374161; loss_div: 0.00038140; loss_ff: 0.00012451] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:   5%|▍         | 98/2000 [00:07<02:19, 13.65it/s][Iteration 000100/002000] [loss: 0.00405640] [loss_bc: 0.00366267; loss_div: 0.00029794; loss_ff: 0.00009579] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  10%|▉         | 198/2000 [00:14<02:12, 13.64it/s][Iteration 000200/002000] [loss: 0.00412151] [loss_bc: 0.00367828; loss_div: 0.00032470; loss_ff: 0.00011853] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  15%|█▍        | 298/2000 [00:21<02:05, 13.55it/s][Iteration 000300/002000] [loss: 0.00420101] [loss_bc: 0.00372387; loss_div: 0.00034750; loss_ff: 0.00012964] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  20%|█▉        | 398/2000 [00:29<01:58, 13.56it/s][Iteration 000400/002000] [loss: 0.00410168] [loss_bc: 0.00367307; loss_div: 0.00032802; loss_ff: 0.00010059] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  25%|██▍       | 498/2000 [00:36<01:50, 13.58it/s][Iteration 000500/002000] [loss: 0.00389277] [loss_bc: 0.00340570; loss_div: 0.00035230; loss_ff: 0.00013477] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  30%|██▉       | 598/2000 [00:43<01:40, 13.93it/s][Iteration 000600/002000] [loss: 0.00394530] [loss_bc: 0.00336569; loss_div: 0.00040237; loss_ff: 0.00017724] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  35%|███▍      | 698/2000 [00:51<01:34, 13.72it/s][Iteration 000700/002000] [loss: 0.00405712] [loss_bc: 0.00340783; loss_div: 0.00042059; loss_ff: 0.00022871] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  40%|███▉      | 798/2000 [00:58<01:28, 13.62it/s][Iteration 000800/002000] [loss: 0.00412290] [loss_bc: 0.00361970; loss_div: 0.00036109; loss_ff: 0.00014211] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  45%|████▍     | 898/2000 [01:05<01:21, 13.56it/s][Iteration 000900/002000] [loss: 0.00404512] [loss_bc: 0.00352429; loss_div: 0.00037194; loss_ff: 0.00014890] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  50%|████▉     | 998/2000 [01:13<01:13, 13.55it/s][Iteration 001000/002000] [loss: 0.00404587] [loss_bc: 0.00364204; loss_div: 0.00030033; loss_ff: 0.00010349] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  55%|█████▍    | 1098/2000 [01:20<01:06, 13.54it/s][Iteration 001100/002000] [loss: 0.00410223] [loss_bc: 0.00361293; loss_div: 0.00036729; loss_ff: 0.00012200] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  60%|█████▉    | 1198/2000 [01:28<00:59, 13.59it/s][Iteration 001200/002000] [loss: 0.00387312] [loss_bc: 0.00334727; loss_div: 0.00038121; loss_ff: 0.00014465] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  65%|██████▍   | 1298/2000 [01:35<00:51, 13.62it/s][Iteration 001300/002000] [loss: 0.00411082] [loss_bc: 0.00364348; loss_div: 0.00033185; loss_ff: 0.00013549] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  70%|██████▉   | 1398/2000 [01:42<00:44, 13.57it/s][Iteration 001400/002000] [loss: 0.00389356] [loss_bc: 0.00339289; loss_div: 0.00036904; loss_ff: 0.00013163] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  75%|███████▍  | 1498/2000 [01:50<00:37, 13.48it/s][Iteration 001500/002000] [loss: 0.00408563] [loss_bc: 0.00356149; loss_div: 0.00037066; loss_ff: 0.00015349] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  80%|███████▉  | 1598/2000 [01:57<00:29, 13.48it/s][Iteration 001600/002000] [loss: 0.00373082] [loss_bc: 0.00333814; loss_div: 0.00028809; loss_ff: 0.00010458] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  85%|████████▍ | 1698/2000 [02:05<00:22, 13.72it/s][Iteration 001700/002000] [loss: 0.00424584] [loss_bc: 0.00363692; loss_div: 0.00042310; loss_ff: 0.00018583] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  90%|████████▉ | 1798/2000 [02:12<00:14, 13.61it/s][Iteration 001800/002000] [loss: 0.00402412] [loss_bc: 0.00360553; loss_div: 0.00029566; loss_ff: 0.00012294] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  95%|█████████▍| 1898/2000 [02:19<00:07, 13.62it/s][Iteration 001900/002000] [loss: 0.00404848] [loss_bc: 0.00358678; loss_div: 0.00031104; loss_ff: 0.00015066] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training: 100%|█████████▉| 1998/2000 [02:27<00:00, 13.60it/s][Iteration 002000/002000] [loss: 0.00415780] [loss_bc: 0.00368094; loss_div: 0.00035482; loss_ff: 0.00012203] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training: 100%|██████████| 2000/2000 [02:27<00:00, 13.56it/s]\n",
      "[Iteration 002000/002000] [loss: 0.00415780] [loss_bc: 0.00368094; loss_div: 0.00035482; loss_ff: 0.00012203] [w_bc: 1.000000, LR: 0.000050]\n",
      "Runtime --> total: 147.70sec (2.95ms/iter.)\n",
      "Configuration:\n",
      "dim: 256, w_div: 1.000000, w_ff: 1.000000, decay_iterations: None, potential: True, vector_potential: False, \n",
      "Using device: cuda (gpus 1) ['NVIDIA RTX A6000']\n",
      "Potential Boundary: 100%|██████████| 1/1 [00:00<00:00,  1.33it/s]\n",
      "Loaded meta state: /userhome/jeon_mg/workspace/_data/NOAA12673/PINN/20170904_201200/model_final.pt\n",
      "Training:   0%|          | 0/2000 [00:00<?, ?it/s][Iteration 000000/002000] [loss: 0.00409982] [loss_bc: 0.00362215; loss_div: 0.00036101; loss_ff: 0.00011666] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:   5%|▍         | 98/2000 [00:07<02:20, 13.53it/s][Iteration 000100/002000] [loss: 0.00387116] [loss_bc: 0.00340565; loss_div: 0.00035072; loss_ff: 0.00011479] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  10%|▉         | 198/2000 [00:14<02:12, 13.59it/s][Iteration 000200/002000] [loss: 0.00388327] [loss_bc: 0.00340718; loss_div: 0.00036671; loss_ff: 0.00010938] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  15%|█▍        | 298/2000 [00:21<02:06, 13.50it/s][Iteration 000300/002000] [loss: 0.00376112] [loss_bc: 0.00340272; loss_div: 0.00024510; loss_ff: 0.00011330] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  20%|█▉        | 398/2000 [00:29<01:56, 13.76it/s][Iteration 000400/002000] [loss: 0.00390106] [loss_bc: 0.00347132; loss_div: 0.00031218; loss_ff: 0.00011756] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  25%|██▍       | 498/2000 [00:36<01:50, 13.57it/s][Iteration 000500/002000] [loss: 0.00388636] [loss_bc: 0.00343198; loss_div: 0.00031570; loss_ff: 0.00013869] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  30%|██▉       | 598/2000 [00:44<01:41, 13.86it/s][Iteration 000600/002000] [loss: 0.00365161] [loss_bc: 0.00317807; loss_div: 0.00034721; loss_ff: 0.00012634] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  35%|███▍      | 698/2000 [00:51<01:33, 13.93it/s][Iteration 000700/002000] [loss: 0.00387994] [loss_bc: 0.00344360; loss_div: 0.00033204; loss_ff: 0.00010430] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  40%|███▉      | 798/2000 [00:58<01:26, 13.93it/s][Iteration 000800/002000] [loss: 0.00409208] [loss_bc: 0.00360737; loss_div: 0.00036971; loss_ff: 0.00011500] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  45%|████▍     | 898/2000 [01:05<01:21, 13.49it/s][Iteration 000900/002000] [loss: 0.00388414] [loss_bc: 0.00339317; loss_div: 0.00037549; loss_ff: 0.00011549] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  50%|████▉     | 998/2000 [01:13<01:13, 13.60it/s][Iteration 001000/002000] [loss: 0.00414338] [loss_bc: 0.00370752; loss_div: 0.00031782; loss_ff: 0.00011804] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  55%|█████▍    | 1098/2000 [01:20<01:04, 13.90it/s][Iteration 001100/002000] [loss: 0.00387364] [loss_bc: 0.00343251; loss_div: 0.00029489; loss_ff: 0.00014624] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  60%|█████▉    | 1198/2000 [01:27<00:59, 13.52it/s][Iteration 001200/002000] [loss: 0.00401371] [loss_bc: 0.00361017; loss_div: 0.00028717; loss_ff: 0.00011637] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  65%|██████▍   | 1298/2000 [01:35<00:50, 13.87it/s][Iteration 001300/002000] [loss: 0.00388624] [loss_bc: 0.00338084; loss_div: 0.00035585; loss_ff: 0.00014955] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  70%|██████▉   | 1398/2000 [01:42<00:43, 13.85it/s][Iteration 001400/002000] [loss: 0.00413399] [loss_bc: 0.00359740; loss_div: 0.00039646; loss_ff: 0.00014014] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  75%|███████▍  | 1498/2000 [01:49<00:36, 13.58it/s][Iteration 001500/002000] [loss: 0.00398232] [loss_bc: 0.00342545; loss_div: 0.00034500; loss_ff: 0.00021187] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  80%|███████▉  | 1598/2000 [01:57<00:29, 13.78it/s][Iteration 001600/002000] [loss: 0.00387982] [loss_bc: 0.00342786; loss_div: 0.00029728; loss_ff: 0.00015468] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  85%|████████▍ | 1698/2000 [02:04<00:22, 13.57it/s][Iteration 001700/002000] [loss: 0.00366085] [loss_bc: 0.00316114; loss_div: 0.00037789; loss_ff: 0.00012183] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  90%|████████▉ | 1798/2000 [02:12<00:14, 13.91it/s][Iteration 001800/002000] [loss: 0.00358117] [loss_bc: 0.00316861; loss_div: 0.00030922; loss_ff: 0.00010334] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  95%|█████████▍| 1898/2000 [02:19<00:07, 13.62it/s][Iteration 001900/002000] [loss: 0.00388189] [loss_bc: 0.00344336; loss_div: 0.00032575; loss_ff: 0.00011278] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training: 100%|█████████▉| 1998/2000 [02:26<00:00, 13.65it/s][Iteration 002000/002000] [loss: 0.00388594] [loss_bc: 0.00340267; loss_div: 0.00035721; loss_ff: 0.00012605] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training: 100%|██████████| 2000/2000 [02:27<00:00, 13.59it/s]\n",
      "[Iteration 002000/002000] [loss: 0.00388594] [loss_bc: 0.00340267; loss_div: 0.00035721; loss_ff: 0.00012605] [w_bc: 1.000000, LR: 0.000050]\n",
      "Runtime --> total: 147.38sec (2.95ms/iter.)\n",
      "Configuration:\n",
      "dim: 256, w_div: 1.000000, w_ff: 1.000000, decay_iterations: None, potential: True, vector_potential: False, \n",
      "Using device: cuda (gpus 1) ['NVIDIA RTX A6000']\n",
      "Potential Boundary: 100%|██████████| 1/1 [00:01<00:00,  1.24s/it]\n",
      "Loaded meta state: /userhome/jeon_mg/workspace/_data/NOAA12673/PINN/20170904_202400/model_final.pt\n",
      "Training:   0%|          | 0/2000 [00:00<?, ?it/s][Iteration 000000/002000] [loss: 0.00405477] [loss_bc: 0.00356449; loss_div: 0.00037343; loss_ff: 0.00011685] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:   5%|▍         | 98/2000 [00:07<02:16, 13.89it/s][Iteration 000100/002000] [loss: 0.00378510] [loss_bc: 0.00338669; loss_div: 0.00028252; loss_ff: 0.00011589] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  10%|▉         | 198/2000 [00:14<02:11, 13.73it/s][Iteration 000200/002000] [loss: 0.00403052] [loss_bc: 0.00358904; loss_div: 0.00032081; loss_ff: 0.00012067] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  15%|█▍        | 298/2000 [00:21<02:05, 13.60it/s][Iteration 000300/002000] [loss: 0.00401446] [loss_bc: 0.00360430; loss_div: 0.00030289; loss_ff: 0.00010727] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  20%|█▉        | 398/2000 [00:29<01:57, 13.59it/s][Iteration 000400/002000] [loss: 0.00374103] [loss_bc: 0.00334517; loss_div: 0.00029500; loss_ff: 0.00010086] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  25%|██▍       | 498/2000 [00:36<01:50, 13.65it/s][Iteration 000500/002000] [loss: 0.00400276] [loss_bc: 0.00358319; loss_div: 0.00028559; loss_ff: 0.00013398] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  30%|██▉       | 598/2000 [00:43<01:40, 13.91it/s][Iteration 000600/002000] [loss: 0.00394978] [loss_bc: 0.00354065; loss_div: 0.00032307; loss_ff: 0.00008606] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  35%|███▍      | 698/2000 [00:51<01:35, 13.58it/s][Iteration 000700/002000] [loss: 0.00369523] [loss_bc: 0.00333242; loss_div: 0.00025348; loss_ff: 0.00010933] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  40%|███▉      | 798/2000 [00:58<01:27, 13.70it/s][Iteration 000800/002000] [loss: 0.00371297] [loss_bc: 0.00328924; loss_div: 0.00030800; loss_ff: 0.00011574] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  45%|████▍     | 898/2000 [01:05<01:19, 13.94it/s][Iteration 000900/002000] [loss: 0.00383427] [loss_bc: 0.00343710; loss_div: 0.00029500; loss_ff: 0.00010217] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  50%|████▉     | 998/2000 [01:13<01:13, 13.63it/s][Iteration 001000/002000] [loss: 0.00399065] [loss_bc: 0.00357586; loss_div: 0.00031418; loss_ff: 0.00010061] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  55%|█████▍    | 1098/2000 [01:20<01:06, 13.51it/s][Iteration 001100/002000] [loss: 0.00396077] [loss_bc: 0.00356903; loss_div: 0.00028468; loss_ff: 0.00010706] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  60%|█████▉    | 1198/2000 [01:27<00:58, 13.77it/s][Iteration 001200/002000] [loss: 0.00388734] [loss_bc: 0.00342774; loss_div: 0.00032020; loss_ff: 0.00013941] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  65%|██████▍   | 1298/2000 [01:35<00:51, 13.61it/s][Iteration 001300/002000] [loss: 0.00385647] [loss_bc: 0.00333086; loss_div: 0.00035623; loss_ff: 0.00016938] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  70%|██████▉   | 1398/2000 [01:42<00:44, 13.66it/s][Iteration 001400/002000] [loss: 0.00384295] [loss_bc: 0.00342657; loss_div: 0.00030148; loss_ff: 0.00011490] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  75%|███████▍  | 1498/2000 [01:50<00:37, 13.56it/s][Iteration 001500/002000] [loss: 0.00375060] [loss_bc: 0.00327970; loss_div: 0.00034663; loss_ff: 0.00012427] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  80%|███████▉  | 1598/2000 [01:57<00:29, 13.52it/s][Iteration 001600/002000] [loss: 0.00407137] [loss_bc: 0.00355932; loss_div: 0.00039367; loss_ff: 0.00011838] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  85%|████████▍ | 1698/2000 [02:04<00:22, 13.58it/s][Iteration 001700/002000] [loss: 0.00384610] [loss_bc: 0.00332611; loss_div: 0.00041152; loss_ff: 0.00010847] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  90%|████████▉ | 1798/2000 [02:12<00:14, 13.80it/s][Iteration 001800/002000] [loss: 0.00410349] [loss_bc: 0.00351669; loss_div: 0.00044385; loss_ff: 0.00014295] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  95%|█████████▍| 1898/2000 [02:19<00:07, 13.57it/s][Iteration 001900/002000] [loss: 0.00395333] [loss_bc: 0.00342360; loss_div: 0.00038504; loss_ff: 0.00014470] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training: 100%|█████████▉| 1998/2000 [02:26<00:00, 13.56it/s][Iteration 002000/002000] [loss: 0.00406171] [loss_bc: 0.00353029; loss_div: 0.00039525; loss_ff: 0.00013617] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training: 100%|██████████| 2000/2000 [02:27<00:00, 13.59it/s]\n",
      "[Iteration 002000/002000] [loss: 0.00406171] [loss_bc: 0.00353029; loss_div: 0.00039525; loss_ff: 0.00013617] [w_bc: 1.000000, LR: 0.000050]\n",
      "Runtime --> total: 147.35sec (2.95ms/iter.)\n",
      "Configuration:\n",
      "dim: 256, w_div: 1.000000, w_ff: 1.000000, decay_iterations: None, potential: True, vector_potential: False, \n",
      "Using device: cuda (gpus 1) ['NVIDIA RTX A6000']\n",
      "Potential Boundary: 100%|██████████| 1/1 [00:01<00:00,  1.33s/it]\n",
      "Loaded meta state: /userhome/jeon_mg/workspace/_data/NOAA12673/PINN/20170904_203600/model_final.pt\n",
      "Training:   0%|          | 0/2000 [00:00<?, ?it/s][Iteration 000000/002000] [loss: 0.00407784] [loss_bc: 0.00353791; loss_div: 0.00041029; loss_ff: 0.00012965] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:   5%|▍         | 98/2000 [00:07<02:19, 13.63it/s][Iteration 000100/002000] [loss: 0.00394017] [loss_bc: 0.00354793; loss_div: 0.00027805; loss_ff: 0.00011420] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  10%|▉         | 198/2000 [00:14<02:13, 13.50it/s][Iteration 000200/002000] [loss: 0.00403423] [loss_bc: 0.00359373; loss_div: 0.00029990; loss_ff: 0.00014060] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  15%|█▍        | 298/2000 [00:21<02:04, 13.69it/s][Iteration 000300/002000] [loss: 0.00383447] [loss_bc: 0.00342756; loss_div: 0.00031073; loss_ff: 0.00009618] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  20%|█▉        | 398/2000 [00:29<01:57, 13.58it/s][Iteration 000400/002000] [loss: 0.00381401] [loss_bc: 0.00328192; loss_div: 0.00040417; loss_ff: 0.00012792] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  25%|██▍       | 498/2000 [00:36<01:49, 13.77it/s][Iteration 000500/002000] [loss: 0.00385280] [loss_bc: 0.00335152; loss_div: 0.00034741; loss_ff: 0.00015387] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  30%|██▉       | 598/2000 [00:44<01:42, 13.62it/s][Iteration 000600/002000] [loss: 0.00402511] [loss_bc: 0.00359672; loss_div: 0.00029915; loss_ff: 0.00012924] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  35%|███▍      | 698/2000 [00:51<01:35, 13.65it/s][Iteration 000700/002000] [loss: 0.00391626] [loss_bc: 0.00348122; loss_div: 0.00032265; loss_ff: 0.00011239] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  40%|███▉      | 798/2000 [00:58<01:27, 13.81it/s][Iteration 000800/002000] [loss: 0.00404949] [loss_bc: 0.00351479; loss_div: 0.00038529; loss_ff: 0.00014941] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  45%|████▍     | 898/2000 [01:06<01:21, 13.53it/s][Iteration 000900/002000] [loss: 0.00406052] [loss_bc: 0.00358359; loss_div: 0.00032687; loss_ff: 0.00015006] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  50%|████▉     | 998/2000 [01:13<01:13, 13.61it/s][Iteration 001000/002000] [loss: 0.00411401] [loss_bc: 0.00356877; loss_div: 0.00039354; loss_ff: 0.00015170] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  55%|█████▍    | 1098/2000 [01:20<01:05, 13.82it/s][Iteration 001100/002000] [loss: 0.00370588] [loss_bc: 0.00326964; loss_div: 0.00030467; loss_ff: 0.00013157] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  60%|█████▉    | 1198/2000 [01:28<00:59, 13.54it/s][Iteration 001200/002000] [loss: 0.00375353] [loss_bc: 0.00333896; loss_div: 0.00027608; loss_ff: 0.00013850] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  65%|██████▍   | 1298/2000 [01:35<00:51, 13.56it/s][Iteration 001300/002000] [loss: 0.00401555] [loss_bc: 0.00357136; loss_div: 0.00032704; loss_ff: 0.00011715] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  70%|██████▉   | 1398/2000 [01:42<00:43, 13.95it/s][Iteration 001400/002000] [loss: 0.00414474] [loss_bc: 0.00367470; loss_div: 0.00034905; loss_ff: 0.00012099] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  75%|███████▍  | 1498/2000 [01:50<00:37, 13.39it/s][Iteration 001500/002000] [loss: 0.00415094] [loss_bc: 0.00356038; loss_div: 0.00043177; loss_ff: 0.00015879] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  80%|███████▉  | 1598/2000 [01:57<00:29, 13.62it/s][Iteration 001600/002000] [loss: 0.00377193] [loss_bc: 0.00334234; loss_div: 0.00031934; loss_ff: 0.00011026] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  85%|████████▍ | 1698/2000 [02:04<00:22, 13.63it/s][Iteration 001700/002000] [loss: 0.00386751] [loss_bc: 0.00346109; loss_div: 0.00030904; loss_ff: 0.00009738] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  90%|████████▉ | 1798/2000 [02:12<00:14, 13.63it/s][Iteration 001800/002000] [loss: 0.00394557] [loss_bc: 0.00357390; loss_div: 0.00027202; loss_ff: 0.00009965] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  95%|█████████▍| 1898/2000 [02:19<00:07, 13.61it/s][Iteration 001900/002000] [loss: 0.00374142] [loss_bc: 0.00325671; loss_div: 0.00035604; loss_ff: 0.00012867] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training: 100%|█████████▉| 1998/2000 [02:27<00:00, 13.67it/s][Iteration 002000/002000] [loss: 0.00407125] [loss_bc: 0.00355764; loss_div: 0.00039345; loss_ff: 0.00012015] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training: 100%|██████████| 2000/2000 [02:27<00:00, 13.56it/s]\n",
      "[Iteration 002000/002000] [loss: 0.00407125] [loss_bc: 0.00355764; loss_div: 0.00039345; loss_ff: 0.00012015] [w_bc: 1.000000, LR: 0.000050]\n",
      "Runtime --> total: 147.62sec (2.95ms/iter.)\n",
      "Configuration:\n",
      "dim: 256, w_div: 1.000000, w_ff: 1.000000, decay_iterations: None, potential: True, vector_potential: False, \n",
      "Using device: cuda (gpus 1) ['NVIDIA RTX A6000']\n",
      "Potential Boundary: 100%|██████████| 1/1 [00:01<00:00,  1.16s/it]\n",
      "Loaded meta state: /userhome/jeon_mg/workspace/_data/NOAA12673/PINN/20170904_204800/model_final.pt\n",
      "Training:   0%|          | 0/2000 [00:00<?, ?it/s][Iteration 000000/002000] [loss: 0.00417314] [loss_bc: 0.00364714; loss_div: 0.00041415; loss_ff: 0.00011185] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:   5%|▍         | 98/2000 [00:07<02:17, 13.83it/s][Iteration 000100/002000] [loss: 0.00369181] [loss_bc: 0.00334196; loss_div: 0.00025180; loss_ff: 0.00009805] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  10%|▉         | 198/2000 [00:14<02:10, 13.76it/s][Iteration 000200/002000] [loss: 0.00393122] [loss_bc: 0.00343803; loss_div: 0.00033071; loss_ff: 0.00016248] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  15%|█▍        | 298/2000 [00:21<02:05, 13.58it/s][Iteration 000300/002000] [loss: 0.00402973] [loss_bc: 0.00365046; loss_div: 0.00026052; loss_ff: 0.00011874] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  20%|█▉        | 398/2000 [00:29<01:56, 13.81it/s][Iteration 000400/002000] [loss: 0.00374102] [loss_bc: 0.00321326; loss_div: 0.00039378; loss_ff: 0.00013397] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  25%|██▍       | 498/2000 [00:36<01:50, 13.63it/s][Iteration 000500/002000] [loss: 0.00386926] [loss_bc: 0.00336502; loss_div: 0.00037148; loss_ff: 0.00013275] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  30%|██▉       | 598/2000 [00:43<01:42, 13.70it/s][Iteration 000600/002000] [loss: 0.00391716] [loss_bc: 0.00341149; loss_div: 0.00034733; loss_ff: 0.00015833] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  35%|███▍      | 698/2000 [00:51<01:35, 13.70it/s][Iteration 000700/002000] [loss: 0.00414355] [loss_bc: 0.00364707; loss_div: 0.00036285; loss_ff: 0.00013363] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  40%|███▉      | 798/2000 [00:58<01:28, 13.64it/s][Iteration 000800/002000] [loss: 0.00389453] [loss_bc: 0.00339903; loss_div: 0.00038125; loss_ff: 0.00011424] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  45%|████▍     | 898/2000 [01:06<01:21, 13.60it/s][Iteration 000900/002000] [loss: 0.00403559] [loss_bc: 0.00340786; loss_div: 0.00047198; loss_ff: 0.00015575] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  50%|████▉     | 998/2000 [01:13<01:13, 13.64it/s][Iteration 001000/002000] [loss: 0.00380936] [loss_bc: 0.00335004; loss_div: 0.00028186; loss_ff: 0.00017746] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  55%|█████▍    | 1098/2000 [01:20<01:06, 13.64it/s][Iteration 001100/002000] [loss: 0.00372905] [loss_bc: 0.00328565; loss_div: 0.00032815; loss_ff: 0.00011525] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  60%|█████▉    | 1198/2000 [01:28<00:58, 13.67it/s][Iteration 001200/002000] [loss: 0.00362274] [loss_bc: 0.00319964; loss_div: 0.00030661; loss_ff: 0.00011648] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  65%|██████▍   | 1298/2000 [01:35<00:51, 13.63it/s][Iteration 001300/002000] [loss: 0.00379313] [loss_bc: 0.00328871; loss_div: 0.00039359; loss_ff: 0.00011083] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  70%|██████▉   | 1398/2000 [01:42<00:44, 13.56it/s][Iteration 001400/002000] [loss: 0.00408203] [loss_bc: 0.00362709; loss_div: 0.00033980; loss_ff: 0.00011514] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  75%|███████▍  | 1498/2000 [01:50<00:36, 13.70it/s][Iteration 001500/002000] [loss: 0.00358594] [loss_bc: 0.00319993; loss_div: 0.00028930; loss_ff: 0.00009671] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  80%|███████▉  | 1598/2000 [01:57<00:29, 13.68it/s][Iteration 001600/002000] [loss: 0.00411208] [loss_bc: 0.00363020; loss_div: 0.00034078; loss_ff: 0.00014110] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  85%|████████▍ | 1698/2000 [02:04<00:22, 13.53it/s][Iteration 001700/002000] [loss: 0.00365012] [loss_bc: 0.00327772; loss_div: 0.00028082; loss_ff: 0.00009158] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  90%|████████▉ | 1798/2000 [02:12<00:14, 13.82it/s][Iteration 001800/002000] [loss: 0.00365359] [loss_bc: 0.00327593; loss_div: 0.00028915; loss_ff: 0.00008850] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  95%|█████████▍| 1898/2000 [02:19<00:07, 13.50it/s][Iteration 001900/002000] [loss: 0.00405093] [loss_bc: 0.00362259; loss_div: 0.00030830; loss_ff: 0.00012005] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training: 100%|█████████▉| 1998/2000 [02:26<00:00, 13.81it/s][Iteration 002000/002000] [loss: 0.00391402] [loss_bc: 0.00347469; loss_div: 0.00031556; loss_ff: 0.00012377] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training: 100%|██████████| 2000/2000 [02:27<00:00, 13.59it/s]\n",
      "[Iteration 002000/002000] [loss: 0.00391402] [loss_bc: 0.00347469; loss_div: 0.00031556; loss_ff: 0.00012377] [w_bc: 1.000000, LR: 0.000050]\n",
      "Runtime --> total: 147.39sec (2.95ms/iter.)\n",
      "Configuration:\n",
      "dim: 256, w_div: 1.000000, w_ff: 1.000000, decay_iterations: None, potential: True, vector_potential: False, \n",
      "Using device: cuda (gpus 1) ['NVIDIA RTX A6000']\n",
      "Potential Boundary: 100%|██████████| 1/1 [00:01<00:00,  1.11s/it]\n",
      "Loaded meta state: /userhome/jeon_mg/workspace/_data/NOAA12673/PINN/20170904_210000/model_final.pt\n",
      "Training:   0%|          | 0/2000 [00:00<?, ?it/s][Iteration 000000/002000] [loss: 0.00382863] [loss_bc: 0.00339595; loss_div: 0.00029509; loss_ff: 0.00013759] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:   5%|▍         | 98/2000 [00:07<02:18, 13.71it/s][Iteration 000100/002000] [loss: 0.00389745] [loss_bc: 0.00351781; loss_div: 0.00028814; loss_ff: 0.00009151] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  10%|▉         | 198/2000 [00:14<02:11, 13.70it/s][Iteration 000200/002000] [loss: 0.00398436] [loss_bc: 0.00350060; loss_div: 0.00036177; loss_ff: 0.00012199] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  15%|█▍        | 298/2000 [00:21<02:04, 13.63it/s][Iteration 000300/002000] [loss: 0.00403256] [loss_bc: 0.00355744; loss_div: 0.00036199; loss_ff: 0.00011313] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  20%|█▉        | 398/2000 [00:29<01:58, 13.54it/s][Iteration 000400/002000] [loss: 0.00408368] [loss_bc: 0.00350991; loss_div: 0.00043040; loss_ff: 0.00014336] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  25%|██▍       | 498/2000 [00:36<01:49, 13.71it/s][Iteration 000500/002000] [loss: 0.00374372] [loss_bc: 0.00328578; loss_div: 0.00035138; loss_ff: 0.00010656] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  30%|██▉       | 598/2000 [00:43<01:42, 13.66it/s][Iteration 000600/002000] [loss: 0.00405737] [loss_bc: 0.00355251; loss_div: 0.00038509; loss_ff: 0.00011976] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  35%|███▍      | 698/2000 [00:51<01:33, 13.99it/s][Iteration 000700/002000] [loss: 0.00380986] [loss_bc: 0.00329459; loss_div: 0.00038791; loss_ff: 0.00012735] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  40%|███▉      | 798/2000 [00:58<01:29, 13.38it/s][Iteration 000800/002000] [loss: 0.00387400] [loss_bc: 0.00342204; loss_div: 0.00032499; loss_ff: 0.00012698] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  45%|████▍     | 898/2000 [01:05<01:18, 13.96it/s][Iteration 000900/002000] [loss: 0.00391977] [loss_bc: 0.00342239; loss_div: 0.00035372; loss_ff: 0.00014367] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  50%|████▉     | 998/2000 [01:13<01:13, 13.65it/s][Iteration 001000/002000] [loss: 0.00401245] [loss_bc: 0.00349193; loss_div: 0.00041176; loss_ff: 0.00010876] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  55%|█████▍    | 1098/2000 [01:20<01:05, 13.73it/s][Iteration 001100/002000] [loss: 0.00416527] [loss_bc: 0.00371953; loss_div: 0.00032226; loss_ff: 0.00012347] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  60%|█████▉    | 1198/2000 [01:27<00:58, 13.63it/s][Iteration 001200/002000] [loss: 0.00377789] [loss_bc: 0.00337100; loss_div: 0.00028867; loss_ff: 0.00011822] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  65%|██████▍   | 1298/2000 [01:35<00:51, 13.63it/s][Iteration 001300/002000] [loss: 0.00377257] [loss_bc: 0.00326932; loss_div: 0.00034574; loss_ff: 0.00015750] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  70%|██████▉   | 1398/2000 [01:42<00:43, 13.70it/s][Iteration 001400/002000] [loss: 0.00396776] [loss_bc: 0.00351593; loss_div: 0.00032164; loss_ff: 0.00013019] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  75%|███████▍  | 1498/2000 [01:49<00:36, 13.85it/s][Iteration 001500/002000] [loss: 0.00386122] [loss_bc: 0.00338685; loss_div: 0.00034971; loss_ff: 0.00012466] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  80%|███████▉  | 1598/2000 [01:57<00:29, 13.68it/s][Iteration 001600/002000] [loss: 0.00424587] [loss_bc: 0.00371265; loss_div: 0.00035940; loss_ff: 0.00017382] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  85%|████████▍ | 1698/2000 [02:04<00:22, 13.38it/s][Iteration 001700/002000] [loss: 0.00416167] [loss_bc: 0.00369454; loss_div: 0.00033583; loss_ff: 0.00013130] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  90%|████████▉ | 1798/2000 [02:11<00:14, 13.62it/s][Iteration 001800/002000] [loss: 0.00384642] [loss_bc: 0.00339692; loss_div: 0.00031744; loss_ff: 0.00013206] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  95%|█████████▍| 1898/2000 [02:19<00:07, 13.67it/s][Iteration 001900/002000] [loss: 0.00391852] [loss_bc: 0.00346835; loss_div: 0.00033761; loss_ff: 0.00011256] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training: 100%|█████████▉| 1998/2000 [02:26<00:00, 13.66it/s][Iteration 002000/002000] [loss: 0.00381842] [loss_bc: 0.00336975; loss_div: 0.00031244; loss_ff: 0.00013622] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training: 100%|██████████| 2000/2000 [02:26<00:00, 13.62it/s]\n",
      "[Iteration 002000/002000] [loss: 0.00381842] [loss_bc: 0.00336975; loss_div: 0.00031244; loss_ff: 0.00013622] [w_bc: 1.000000, LR: 0.000050]\n",
      "Runtime --> total: 147.01sec (2.94ms/iter.)\n",
      "Configuration:\n",
      "dim: 256, w_div: 1.000000, w_ff: 1.000000, decay_iterations: None, potential: True, vector_potential: False, \n",
      "Using device: cuda (gpus 1) ['NVIDIA RTX A6000']\n",
      "Potential Boundary: 100%|██████████| 1/1 [00:01<00:00,  1.39s/it]\n",
      "Loaded meta state: /userhome/jeon_mg/workspace/_data/NOAA12673/PINN/20170904_211200/model_final.pt\n",
      "Training:   0%|          | 0/2000 [00:00<?, ?it/s][Iteration 000000/002000] [loss: 0.00363872] [loss_bc: 0.00324171; loss_div: 0.00026942; loss_ff: 0.00012759] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:   5%|▍         | 98/2000 [00:07<02:19, 13.64it/s][Iteration 000100/002000] [loss: 0.00400475] [loss_bc: 0.00356133; loss_div: 0.00029816; loss_ff: 0.00014526] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  10%|▉         | 198/2000 [00:14<02:12, 13.62it/s][Iteration 000200/002000] [loss: 0.00369366] [loss_bc: 0.00324012; loss_div: 0.00028295; loss_ff: 0.00017060] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  15%|█▍        | 298/2000 [00:21<02:04, 13.67it/s][Iteration 000300/002000] [loss: 0.00372151] [loss_bc: 0.00328264; loss_div: 0.00028148; loss_ff: 0.00015739] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  20%|█▉        | 398/2000 [00:29<01:57, 13.66it/s][Iteration 000400/002000] [loss: 0.00404058] [loss_bc: 0.00352534; loss_div: 0.00036181; loss_ff: 0.00015343] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  25%|██▍       | 498/2000 [00:36<01:49, 13.65it/s][Iteration 000500/002000] [loss: 0.00399972] [loss_bc: 0.00352354; loss_div: 0.00033647; loss_ff: 0.00013971] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  30%|██▉       | 598/2000 [00:43<01:43, 13.55it/s][Iteration 000600/002000] [loss: 0.00390887] [loss_bc: 0.00340581; loss_div: 0.00038366; loss_ff: 0.00011941] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  35%|███▍      | 698/2000 [00:51<01:35, 13.62it/s][Iteration 000700/002000] [loss: 0.00385017] [loss_bc: 0.00340900; loss_div: 0.00030494; loss_ff: 0.00013622] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  40%|███▉      | 798/2000 [00:58<01:28, 13.65it/s][Iteration 000800/002000] [loss: 0.00402992] [loss_bc: 0.00352867; loss_div: 0.00035658; loss_ff: 0.00014467] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  45%|████▍     | 898/2000 [01:06<01:20, 13.69it/s][Iteration 000900/002000] [loss: 0.00395104] [loss_bc: 0.00354291; loss_div: 0.00030840; loss_ff: 0.00009972] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  50%|████▉     | 998/2000 [01:13<01:11, 14.00it/s][Iteration 001000/002000] [loss: 0.00408162] [loss_bc: 0.00367530; loss_div: 0.00029273; loss_ff: 0.00011358] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  55%|█████▍    | 1098/2000 [01:20<01:05, 13.67it/s][Iteration 001100/002000] [loss: 0.00399464] [loss_bc: 0.00351478; loss_div: 0.00031460; loss_ff: 0.00016526] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  60%|█████▉    | 1198/2000 [01:27<00:58, 13.66it/s][Iteration 001200/002000] [loss: 0.00369345] [loss_bc: 0.00321892; loss_div: 0.00032882; loss_ff: 0.00014571] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  65%|██████▍   | 1298/2000 [01:35<00:51, 13.72it/s][Iteration 001300/002000] [loss: 0.00403412] [loss_bc: 0.00353690; loss_div: 0.00036777; loss_ff: 0.00012944] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  70%|██████▉   | 1398/2000 [01:42<00:44, 13.62it/s][Iteration 001400/002000] [loss: 0.00384756] [loss_bc: 0.00339514; loss_div: 0.00034649; loss_ff: 0.00010593] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  75%|███████▍  | 1498/2000 [01:50<00:36, 13.58it/s][Iteration 001500/002000] [loss: 0.00400872] [loss_bc: 0.00351266; loss_div: 0.00036152; loss_ff: 0.00013454] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  80%|███████▉  | 1598/2000 [01:57<00:29, 13.68it/s][Iteration 001600/002000] [loss: 0.00377095] [loss_bc: 0.00326304; loss_div: 0.00035946; loss_ff: 0.00014845] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  85%|████████▍ | 1698/2000 [02:04<00:22, 13.69it/s][Iteration 001700/002000] [loss: 0.00397647] [loss_bc: 0.00353379; loss_div: 0.00029970; loss_ff: 0.00014298] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  90%|████████▉ | 1798/2000 [02:12<00:14, 13.66it/s][Iteration 001800/002000] [loss: 0.00390830] [loss_bc: 0.00338281; loss_div: 0.00036804; loss_ff: 0.00015744] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  95%|█████████▍| 1898/2000 [02:19<00:07, 13.55it/s][Iteration 001900/002000] [loss: 0.00410054] [loss_bc: 0.00365220; loss_div: 0.00034028; loss_ff: 0.00010805] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training: 100%|█████████▉| 1998/2000 [02:26<00:00, 13.62it/s][Iteration 002000/002000] [loss: 0.00381676] [loss_bc: 0.00340456; loss_div: 0.00029674; loss_ff: 0.00011546] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training: 100%|██████████| 2000/2000 [02:27<00:00, 13.60it/s]\n",
      "[Iteration 002000/002000] [loss: 0.00381676] [loss_bc: 0.00340456; loss_div: 0.00029674; loss_ff: 0.00011546] [w_bc: 1.000000, LR: 0.000050]\n",
      "Runtime --> total: 147.29sec (2.95ms/iter.)\n",
      "Configuration:\n",
      "dim: 256, w_div: 1.000000, w_ff: 1.000000, decay_iterations: None, potential: True, vector_potential: False, \n",
      "Using device: cuda (gpus 1) ['NVIDIA RTX A6000']\n",
      "Potential Boundary: 100%|██████████| 1/1 [00:01<00:00,  1.29s/it]\n",
      "Loaded meta state: /userhome/jeon_mg/workspace/_data/NOAA12673/PINN/20170904_212400/model_final.pt\n",
      "Training:   0%|          | 0/2000 [00:00<?, ?it/s][Iteration 000000/002000] [loss: 0.00386725] [loss_bc: 0.00344793; loss_div: 0.00030433; loss_ff: 0.00011499] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:   5%|▍         | 98/2000 [00:07<02:17, 13.87it/s][Iteration 000100/002000] [loss: 0.00393515] [loss_bc: 0.00350474; loss_div: 0.00030415; loss_ff: 0.00012625] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  10%|▉         | 198/2000 [00:14<02:11, 13.67it/s][Iteration 000200/002000] [loss: 0.00383274] [loss_bc: 0.00336050; loss_div: 0.00034688; loss_ff: 0.00012536] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  15%|█▍        | 298/2000 [00:21<02:04, 13.65it/s][Iteration 000300/002000] [loss: 0.00387508] [loss_bc: 0.00340248; loss_div: 0.00033566; loss_ff: 0.00013693] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  20%|█▉        | 398/2000 [00:29<01:57, 13.63it/s][Iteration 000400/002000] [loss: 0.00390124] [loss_bc: 0.00340353; loss_div: 0.00035675; loss_ff: 0.00014096] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  25%|██▍       | 498/2000 [00:36<01:50, 13.57it/s][Iteration 000500/002000] [loss: 0.00402242] [loss_bc: 0.00349531; loss_div: 0.00040606; loss_ff: 0.00012105] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  30%|██▉       | 598/2000 [00:43<01:43, 13.57it/s][Iteration 000600/002000] [loss: 0.00369796] [loss_bc: 0.00325102; loss_div: 0.00032333; loss_ff: 0.00012361] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  35%|███▍      | 698/2000 [00:51<01:35, 13.63it/s][Iteration 000700/002000] [loss: 0.00391053] [loss_bc: 0.00341839; loss_div: 0.00034454; loss_ff: 0.00014760] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  40%|███▉      | 798/2000 [00:58<01:29, 13.46it/s][Iteration 000800/002000] [loss: 0.00382847] [loss_bc: 0.00334398; loss_div: 0.00037097; loss_ff: 0.00011351] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  45%|████▍     | 898/2000 [01:06<01:20, 13.72it/s][Iteration 000900/002000] [loss: 0.00386566] [loss_bc: 0.00339786; loss_div: 0.00033225; loss_ff: 0.00013555] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  50%|████▉     | 998/2000 [01:13<01:13, 13.66it/s][Iteration 001000/002000] [loss: 0.00400170] [loss_bc: 0.00352474; loss_div: 0.00030956; loss_ff: 0.00016740] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  55%|█████▍    | 1098/2000 [01:20<01:05, 13.73it/s][Iteration 001100/002000] [loss: 0.00420884] [loss_bc: 0.00372504; loss_div: 0.00035018; loss_ff: 0.00013361] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  60%|█████▉    | 1198/2000 [01:28<00:57, 13.97it/s][Iteration 001200/002000] [loss: 0.00423480] [loss_bc: 0.00371903; loss_div: 0.00039653; loss_ff: 0.00011924] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  65%|██████▍   | 1298/2000 [01:35<00:52, 13.46it/s][Iteration 001300/002000] [loss: 0.00387508] [loss_bc: 0.00345768; loss_div: 0.00030689; loss_ff: 0.00011051] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  70%|██████▉   | 1398/2000 [01:42<00:43, 13.69it/s][Iteration 001400/002000] [loss: 0.00420699] [loss_bc: 0.00372374; loss_div: 0.00036034; loss_ff: 0.00012292] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  75%|███████▍  | 1498/2000 [01:50<00:36, 13.63it/s][Iteration 001500/002000] [loss: 0.00391443] [loss_bc: 0.00343739; loss_div: 0.00035544; loss_ff: 0.00012159] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  80%|███████▉  | 1598/2000 [01:57<00:29, 13.60it/s][Iteration 001600/002000] [loss: 0.00408809] [loss_bc: 0.00370789; loss_div: 0.00028175; loss_ff: 0.00009845] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  85%|████████▍ | 1698/2000 [02:04<00:22, 13.63it/s][Iteration 001700/002000] [loss: 0.00390455] [loss_bc: 0.00349251; loss_div: 0.00029070; loss_ff: 0.00012135] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  90%|████████▉ | 1798/2000 [02:12<00:14, 13.57it/s][Iteration 001800/002000] [loss: 0.00384739] [loss_bc: 0.00337451; loss_div: 0.00029463; loss_ff: 0.00017825] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  95%|█████████▍| 1898/2000 [02:19<00:07, 13.63it/s][Iteration 001900/002000] [loss: 0.00392807] [loss_bc: 0.00337873; loss_div: 0.00043003; loss_ff: 0.00011931] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training: 100%|█████████▉| 1998/2000 [02:26<00:00, 13.60it/s][Iteration 002000/002000] [loss: 0.00376516] [loss_bc: 0.00332860; loss_div: 0.00033265; loss_ff: 0.00010390] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training: 100%|██████████| 2000/2000 [02:27<00:00, 13.59it/s]\n",
      "[Iteration 002000/002000] [loss: 0.00376516] [loss_bc: 0.00332860; loss_div: 0.00033265; loss_ff: 0.00010390] [w_bc: 1.000000, LR: 0.000050]\n",
      "Runtime --> total: 147.36sec (2.95ms/iter.)\n",
      "Configuration:\n",
      "dim: 256, w_div: 1.000000, w_ff: 1.000000, decay_iterations: None, potential: True, vector_potential: False, \n",
      "Using device: cuda (gpus 1) ['NVIDIA RTX A6000']\n",
      "Potential Boundary: 100%|██████████| 1/1 [00:01<00:00,  1.26s/it]\n",
      "Loaded meta state: /userhome/jeon_mg/workspace/_data/NOAA12673/PINN/20170904_213600/model_final.pt\n",
      "Training:   0%|          | 0/2000 [00:00<?, ?it/s][Iteration 000000/002000] [loss: 0.00409826] [loss_bc: 0.00358782; loss_div: 0.00039027; loss_ff: 0.00012017] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:   5%|▍         | 98/2000 [00:07<02:19, 13.66it/s][Iteration 000100/002000] [loss: 0.00408544] [loss_bc: 0.00364742; loss_div: 0.00031255; loss_ff: 0.00012547] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  10%|▉         | 198/2000 [00:14<02:10, 13.83it/s][Iteration 000200/002000] [loss: 0.00396053] [loss_bc: 0.00343117; loss_div: 0.00038181; loss_ff: 0.00014755] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  15%|█▍        | 298/2000 [00:21<02:04, 13.66it/s][Iteration 000300/002000] [loss: 0.00389869] [loss_bc: 0.00342173; loss_div: 0.00035748; loss_ff: 0.00011947] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  20%|█▉        | 398/2000 [00:29<01:57, 13.61it/s][Iteration 000400/002000] [loss: 0.00393508] [loss_bc: 0.00342186; loss_div: 0.00038318; loss_ff: 0.00013004] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  25%|██▍       | 498/2000 [00:36<01:50, 13.65it/s][Iteration 000500/002000] [loss: 0.00394399] [loss_bc: 0.00347213; loss_div: 0.00035990; loss_ff: 0.00011196] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  30%|██▉       | 598/2000 [00:43<01:42, 13.64it/s][Iteration 000600/002000] [loss: 0.00395374] [loss_bc: 0.00355825; loss_div: 0.00029729; loss_ff: 0.00009821] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  35%|███▍      | 698/2000 [00:51<01:35, 13.60it/s][Iteration 000700/002000] [loss: 0.00395448] [loss_bc: 0.00343440; loss_div: 0.00035394; loss_ff: 0.00016614] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  40%|███▉      | 798/2000 [00:58<01:28, 13.63it/s][Iteration 000800/002000] [loss: 0.00408709] [loss_bc: 0.00362885; loss_div: 0.00032501; loss_ff: 0.00013323] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  45%|████▍     | 898/2000 [01:05<01:19, 13.90it/s][Iteration 000900/002000] [loss: 0.00404433] [loss_bc: 0.00355808; loss_div: 0.00036580; loss_ff: 0.00012044] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  50%|████▉     | 998/2000 [01:13<01:13, 13.67it/s][Iteration 001000/002000] [loss: 0.00398924] [loss_bc: 0.00354726; loss_div: 0.00033293; loss_ff: 0.00010905] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  55%|█████▍    | 1098/2000 [01:20<01:06, 13.63it/s][Iteration 001100/002000] [loss: 0.00414439] [loss_bc: 0.00355459; loss_div: 0.00037607; loss_ff: 0.00021373] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  60%|█████▉    | 1198/2000 [01:27<00:58, 13.69it/s][Iteration 001200/002000] [loss: 0.00399212] [loss_bc: 0.00354665; loss_div: 0.00033208; loss_ff: 0.00011339] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  65%|██████▍   | 1298/2000 [01:35<00:51, 13.66it/s][Iteration 001300/002000] [loss: 0.00395162] [loss_bc: 0.00347696; loss_div: 0.00034028; loss_ff: 0.00013438] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  70%|██████▉   | 1398/2000 [01:42<00:43, 13.91it/s][Iteration 001400/002000] [loss: 0.00389752] [loss_bc: 0.00340760; loss_div: 0.00035957; loss_ff: 0.00013035] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  75%|███████▍  | 1498/2000 [01:49<00:36, 13.71it/s][Iteration 001500/002000] [loss: 0.00393975] [loss_bc: 0.00341300; loss_div: 0.00034058; loss_ff: 0.00018616] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  80%|███████▉  | 1598/2000 [01:57<00:29, 13.70it/s][Iteration 001600/002000] [loss: 0.00403255] [loss_bc: 0.00361089; loss_div: 0.00030912; loss_ff: 0.00011254] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  85%|████████▍ | 1698/2000 [02:04<00:22, 13.58it/s][Iteration 001700/002000] [loss: 0.00419787] [loss_bc: 0.00360191; loss_div: 0.00046944; loss_ff: 0.00012652] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  90%|████████▉ | 1798/2000 [02:12<00:14, 13.64it/s][Iteration 001800/002000] [loss: 0.00401216] [loss_bc: 0.00353788; loss_div: 0.00034145; loss_ff: 0.00013283] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  95%|█████████▍| 1898/2000 [02:19<00:07, 13.64it/s][Iteration 001900/002000] [loss: 0.00402856] [loss_bc: 0.00349165; loss_div: 0.00035901; loss_ff: 0.00017790] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training: 100%|█████████▉| 1998/2000 [02:26<00:00, 13.60it/s][Iteration 002000/002000] [loss: 0.00397602] [loss_bc: 0.00353859; loss_div: 0.00031555; loss_ff: 0.00012188] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training: 100%|██████████| 2000/2000 [02:27<00:00, 13.59it/s]\n",
      "[Iteration 002000/002000] [loss: 0.00397602] [loss_bc: 0.00353859; loss_div: 0.00031555; loss_ff: 0.00012188] [w_bc: 1.000000, LR: 0.000050]\n",
      "Runtime --> total: 147.29sec (2.95ms/iter.)\n",
      "Configuration:\n",
      "dim: 256, w_div: 1.000000, w_ff: 1.000000, decay_iterations: None, potential: True, vector_potential: False, \n",
      "Using device: cuda (gpus 1) ['NVIDIA RTX A6000']\n",
      "Potential Boundary: 100%|██████████| 1/1 [00:01<00:00,  1.17s/it]\n",
      "Loaded meta state: /userhome/jeon_mg/workspace/_data/NOAA12673/PINN/20170904_214800/model_final.pt\n",
      "Training:   0%|          | 0/2000 [00:00<?, ?it/s][Iteration 000000/002000] [loss: 0.00424119] [loss_bc: 0.00368700; loss_div: 0.00039800; loss_ff: 0.00015619] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:   5%|▍         | 98/2000 [00:07<02:20, 13.54it/s][Iteration 000100/002000] [loss: 0.00417232] [loss_bc: 0.00366822; loss_div: 0.00035020; loss_ff: 0.00015390] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  10%|▉         | 198/2000 [00:14<02:09, 13.88it/s][Iteration 000200/002000] [loss: 0.00422496] [loss_bc: 0.00371170; loss_div: 0.00037500; loss_ff: 0.00013825] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  15%|█▍        | 298/2000 [00:21<02:04, 13.68it/s][Iteration 000300/002000] [loss: 0.00388873] [loss_bc: 0.00345952; loss_div: 0.00033201; loss_ff: 0.00009720] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  20%|█▉        | 398/2000 [00:29<01:57, 13.65it/s][Iteration 000400/002000] [loss: 0.00423909] [loss_bc: 0.00370433; loss_div: 0.00035455; loss_ff: 0.00018021] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  25%|██▍       | 498/2000 [00:36<01:49, 13.73it/s][Iteration 000500/002000] [loss: 0.00373367] [loss_bc: 0.00332575; loss_div: 0.00029928; loss_ff: 0.00010863] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  30%|██▉       | 598/2000 [00:43<01:42, 13.67it/s][Iteration 000600/002000] [loss: 0.00375344] [loss_bc: 0.00328405; loss_div: 0.00033862; loss_ff: 0.00013077] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  35%|███▍      | 698/2000 [00:51<01:36, 13.55it/s][Iteration 000700/002000] [loss: 0.00427341] [loss_bc: 0.00376180; loss_div: 0.00037909; loss_ff: 0.00013252] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  40%|███▉      | 798/2000 [00:58<01:28, 13.60it/s][Iteration 000800/002000] [loss: 0.00376549] [loss_bc: 0.00328601; loss_div: 0.00035830; loss_ff: 0.00012118] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  45%|████▍     | 898/2000 [01:05<01:21, 13.50it/s][Iteration 000900/002000] [loss: 0.00390248] [loss_bc: 0.00339145; loss_div: 0.00037492; loss_ff: 0.00013612] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  50%|████▉     | 998/2000 [01:13<01:12, 13.91it/s][Iteration 001000/002000] [loss: 0.00395884] [loss_bc: 0.00344286; loss_div: 0.00038950; loss_ff: 0.00012648] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  55%|█████▍    | 1098/2000 [01:20<01:05, 13.68it/s][Iteration 001100/002000] [loss: 0.00393503] [loss_bc: 0.00344266; loss_div: 0.00036505; loss_ff: 0.00012732] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  60%|█████▉    | 1198/2000 [01:27<00:58, 13.71it/s][Iteration 001200/002000] [loss: 0.00421029] [loss_bc: 0.00363258; loss_div: 0.00035116; loss_ff: 0.00022655] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  65%|██████▍   | 1298/2000 [01:35<00:51, 13.59it/s][Iteration 001300/002000] [loss: 0.00415897] [loss_bc: 0.00366707; loss_div: 0.00034136; loss_ff: 0.00015054] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  70%|██████▉   | 1398/2000 [01:42<00:44, 13.61it/s][Iteration 001400/002000] [loss: 0.00376197] [loss_bc: 0.00330673; loss_div: 0.00031922; loss_ff: 0.00013602] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  75%|███████▍  | 1498/2000 [01:49<00:36, 13.58it/s][Iteration 001500/002000] [loss: 0.00388052] [loss_bc: 0.00344410; loss_div: 0.00032374; loss_ff: 0.00011268] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  80%|███████▉  | 1598/2000 [01:57<00:29, 13.66it/s][Iteration 001600/002000] [loss: 0.00415310] [loss_bc: 0.00365002; loss_div: 0.00035218; loss_ff: 0.00015090] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  85%|████████▍ | 1698/2000 [02:04<00:22, 13.67it/s][Iteration 001700/002000] [loss: 0.00397557] [loss_bc: 0.00344256; loss_div: 0.00041579; loss_ff: 0.00011722] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  90%|████████▉ | 1798/2000 [02:11<00:14, 13.68it/s][Iteration 001800/002000] [loss: 0.00400375] [loss_bc: 0.00344046; loss_div: 0.00037565; loss_ff: 0.00018764] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  95%|█████████▍| 1898/2000 [02:19<00:07, 13.76it/s][Iteration 001900/002000] [loss: 0.00369922] [loss_bc: 0.00326997; loss_div: 0.00032861; loss_ff: 0.00010064] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training: 100%|█████████▉| 1998/2000 [02:26<00:00, 13.59it/s][Iteration 002000/002000] [loss: 0.00414093] [loss_bc: 0.00362821; loss_div: 0.00036981; loss_ff: 0.00014290] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training: 100%|██████████| 2000/2000 [02:26<00:00, 13.61it/s]\n",
      "[Iteration 002000/002000] [loss: 0.00414093] [loss_bc: 0.00362821; loss_div: 0.00036981; loss_ff: 0.00014290] [w_bc: 1.000000, LR: 0.000050]\n",
      "Runtime --> total: 147.10sec (2.94ms/iter.)\n",
      "Configuration:\n",
      "dim: 256, w_div: 1.000000, w_ff: 1.000000, decay_iterations: None, potential: True, vector_potential: False, \n",
      "Using device: cuda (gpus 1) ['NVIDIA RTX A6000']\n",
      "Potential Boundary: 100%|██████████| 1/1 [00:01<00:00,  1.28s/it]\n",
      "Loaded meta state: /userhome/jeon_mg/workspace/_data/NOAA12673/PINN/20170904_220000/model_final.pt\n",
      "Training:   0%|          | 0/2000 [00:00<?, ?it/s][Iteration 000000/002000] [loss: 0.00420887] [loss_bc: 0.00372154; loss_div: 0.00037054; loss_ff: 0.00011678] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:   5%|▍         | 98/2000 [00:07<02:18, 13.73it/s][Iteration 000100/002000] [loss: 0.00384337] [loss_bc: 0.00341940; loss_div: 0.00028370; loss_ff: 0.00014027] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  10%|▉         | 198/2000 [00:14<02:11, 13.75it/s][Iteration 000200/002000] [loss: 0.00408135] [loss_bc: 0.00362618; loss_div: 0.00033741; loss_ff: 0.00011776] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  15%|█▍        | 298/2000 [00:21<02:05, 13.60it/s][Iteration 000300/002000] [loss: 0.00421829] [loss_bc: 0.00371388; loss_div: 0.00035278; loss_ff: 0.00015163] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  20%|█▉        | 398/2000 [00:29<01:57, 13.65it/s][Iteration 000400/002000] [loss: 0.00419019] [loss_bc: 0.00370897; loss_div: 0.00034594; loss_ff: 0.00013528] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  25%|██▍       | 498/2000 [00:36<01:50, 13.63it/s][Iteration 000500/002000] [loss: 0.00384506] [loss_bc: 0.00339786; loss_div: 0.00031179; loss_ff: 0.00013541] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  30%|██▉       | 598/2000 [00:43<01:42, 13.64it/s][Iteration 000600/002000] [loss: 0.00414517] [loss_bc: 0.00366290; loss_div: 0.00035741; loss_ff: 0.00012486] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  35%|███▍      | 698/2000 [00:51<01:35, 13.60it/s][Iteration 000700/002000] [loss: 0.00426429] [loss_bc: 0.00365608; loss_div: 0.00044125; loss_ff: 0.00016696] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  40%|███▉      | 798/2000 [00:58<01:27, 13.66it/s][Iteration 000800/002000] [loss: 0.00416861] [loss_bc: 0.00366050; loss_div: 0.00038389; loss_ff: 0.00012423] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  45%|████▍     | 898/2000 [01:05<01:20, 13.67it/s][Iteration 000900/002000] [loss: 0.00409129] [loss_bc: 0.00365949; loss_div: 0.00031947; loss_ff: 0.00011233] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  50%|████▉     | 998/2000 [01:13<01:14, 13.44it/s][Iteration 001000/002000] [loss: 0.00413655] [loss_bc: 0.00369499; loss_div: 0.00032034; loss_ff: 0.00012122] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  55%|█████▍    | 1098/2000 [01:20<01:06, 13.58it/s][Iteration 001100/002000] [loss: 0.00416490] [loss_bc: 0.00368140; loss_div: 0.00034901; loss_ff: 0.00013450] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  60%|█████▉    | 1198/2000 [01:28<00:58, 13.70it/s][Iteration 001200/002000] [loss: 0.00409298] [loss_bc: 0.00362600; loss_div: 0.00031797; loss_ff: 0.00014901] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  65%|██████▍   | 1298/2000 [01:35<00:51, 13.63it/s][Iteration 001300/002000] [loss: 0.00426873] [loss_bc: 0.00367757; loss_div: 0.00041323; loss_ff: 0.00017793] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  70%|██████▉   | 1398/2000 [01:42<00:44, 13.65it/s][Iteration 001400/002000] [loss: 0.00384858] [loss_bc: 0.00338788; loss_div: 0.00033267; loss_ff: 0.00012804] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  75%|███████▍  | 1498/2000 [01:50<00:36, 13.83it/s][Iteration 001500/002000] [loss: 0.00416740] [loss_bc: 0.00363722; loss_div: 0.00037327; loss_ff: 0.00015690] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  80%|███████▉  | 1598/2000 [01:57<00:29, 13.56it/s][Iteration 001600/002000] [loss: 0.00411823] [loss_bc: 0.00364707; loss_div: 0.00032402; loss_ff: 0.00014714] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  85%|████████▍ | 1698/2000 [02:04<00:21, 13.90it/s][Iteration 001700/002000] [loss: 0.00406055] [loss_bc: 0.00361401; loss_div: 0.00032615; loss_ff: 0.00012040] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  90%|████████▉ | 1798/2000 [02:11<00:14, 13.92it/s][Iteration 001800/002000] [loss: 0.00380159] [loss_bc: 0.00338686; loss_div: 0.00031885; loss_ff: 0.00009587] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  95%|█████████▍| 1898/2000 [02:19<00:07, 13.59it/s][Iteration 001900/002000] [loss: 0.00382725] [loss_bc: 0.00342219; loss_div: 0.00030745; loss_ff: 0.00009761] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training: 100%|█████████▉| 1998/2000 [02:26<00:00, 13.67it/s][Iteration 002000/002000] [loss: 0.00383413] [loss_bc: 0.00340509; loss_div: 0.00031302; loss_ff: 0.00011602] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training: 100%|██████████| 2000/2000 [02:26<00:00, 13.61it/s]\n",
      "[Iteration 002000/002000] [loss: 0.00383413] [loss_bc: 0.00340509; loss_div: 0.00031302; loss_ff: 0.00011602] [w_bc: 1.000000, LR: 0.000050]\n",
      "Runtime --> total: 147.08sec (2.94ms/iter.)\n",
      "Configuration:\n",
      "dim: 256, w_div: 1.000000, w_ff: 1.000000, decay_iterations: None, potential: True, vector_potential: False, \n",
      "Using device: cuda (gpus 1) ['NVIDIA RTX A6000']\n",
      "Potential Boundary: 100%|██████████| 1/1 [00:01<00:00,  1.46s/it]\n",
      "Loaded meta state: /userhome/jeon_mg/workspace/_data/NOAA12673/PINN/20170904_221200/model_final.pt\n",
      "Training:   0%|          | 0/2000 [00:00<?, ?it/s][Iteration 000000/002000] [loss: 0.00411786] [loss_bc: 0.00369586; loss_div: 0.00029994; loss_ff: 0.00012207] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:   5%|▍         | 98/2000 [00:07<02:18, 13.77it/s][Iteration 000100/002000] [loss: 0.00397416] [loss_bc: 0.00353004; loss_div: 0.00032769; loss_ff: 0.00011642] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  10%|▉         | 198/2000 [00:14<02:12, 13.60it/s][Iteration 000200/002000] [loss: 0.00416219] [loss_bc: 0.00363129; loss_div: 0.00037143; loss_ff: 0.00015947] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  15%|█▍        | 298/2000 [00:21<02:05, 13.60it/s][Iteration 000300/002000] [loss: 0.00405254] [loss_bc: 0.00362993; loss_div: 0.00031517; loss_ff: 0.00010744] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  20%|█▉        | 398/2000 [00:29<01:57, 13.62it/s][Iteration 000400/002000] [loss: 0.00404707] [loss_bc: 0.00360186; loss_div: 0.00034215; loss_ff: 0.00010306] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  25%|██▍       | 498/2000 [00:36<01:50, 13.65it/s][Iteration 000500/002000] [loss: 0.00387040] [loss_bc: 0.00340929; loss_div: 0.00033481; loss_ff: 0.00012631] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  30%|██▉       | 598/2000 [00:43<01:42, 13.72it/s][Iteration 000600/002000] [loss: 0.00410688] [loss_bc: 0.00358689; loss_div: 0.00038230; loss_ff: 0.00013769] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  35%|███▍      | 698/2000 [00:51<01:35, 13.62it/s][Iteration 000700/002000] [loss: 0.00404222] [loss_bc: 0.00361239; loss_div: 0.00030422; loss_ff: 0.00012561] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  40%|███▉      | 798/2000 [00:58<01:28, 13.64it/s][Iteration 000800/002000] [loss: 0.00405730] [loss_bc: 0.00361179; loss_div: 0.00030065; loss_ff: 0.00014486] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  45%|████▍     | 898/2000 [01:05<01:20, 13.64it/s][Iteration 000900/002000] [loss: 0.00435627] [loss_bc: 0.00385748; loss_div: 0.00034168; loss_ff: 0.00015711] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  50%|████▉     | 998/2000 [01:13<01:13, 13.67it/s][Iteration 001000/002000] [loss: 0.00399854] [loss_bc: 0.00350434; loss_div: 0.00037412; loss_ff: 0.00012008] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  55%|█████▍    | 1098/2000 [01:20<01:04, 13.95it/s][Iteration 001100/002000] [loss: 0.00416741] [loss_bc: 0.00365654; loss_div: 0.00037515; loss_ff: 0.00013572] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  60%|█████▉    | 1198/2000 [01:27<00:57, 13.94it/s][Iteration 001200/002000] [loss: 0.00394795] [loss_bc: 0.00346420; loss_div: 0.00030952; loss_ff: 0.00017422] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  65%|██████▍   | 1298/2000 [01:35<00:51, 13.71it/s][Iteration 001300/002000] [loss: 0.00439003] [loss_bc: 0.00383838; loss_div: 0.00041951; loss_ff: 0.00013214] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  70%|██████▉   | 1398/2000 [01:42<00:44, 13.42it/s][Iteration 001400/002000] [loss: 0.00421007] [loss_bc: 0.00365359; loss_div: 0.00038586; loss_ff: 0.00017062] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  75%|███████▍  | 1498/2000 [01:49<00:36, 13.63it/s][Iteration 001500/002000] [loss: 0.00405877] [loss_bc: 0.00357617; loss_div: 0.00036003; loss_ff: 0.00012257] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  80%|███████▉  | 1598/2000 [01:57<00:29, 13.67it/s][Iteration 001600/002000] [loss: 0.00388264] [loss_bc: 0.00338287; loss_div: 0.00037075; loss_ff: 0.00012903] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  85%|████████▍ | 1698/2000 [02:04<00:22, 13.56it/s][Iteration 001700/002000] [loss: 0.00396575] [loss_bc: 0.00344625; loss_div: 0.00032477; loss_ff: 0.00019473] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  90%|████████▉ | 1798/2000 [02:11<00:14, 13.64it/s][Iteration 001800/002000] [loss: 0.00407956] [loss_bc: 0.00358183; loss_div: 0.00038439; loss_ff: 0.00011334] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  95%|█████████▍| 1898/2000 [02:19<00:07, 13.68it/s][Iteration 001900/002000] [loss: 0.00433178] [loss_bc: 0.00384303; loss_div: 0.00037738; loss_ff: 0.00011137] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training: 100%|█████████▉| 1998/2000 [02:26<00:00, 13.64it/s][Iteration 002000/002000] [loss: 0.00439058] [loss_bc: 0.00383641; loss_div: 0.00041286; loss_ff: 0.00014131] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training: 100%|██████████| 2000/2000 [02:26<00:00, 13.63it/s]\n",
      "[Iteration 002000/002000] [loss: 0.00439058] [loss_bc: 0.00383641; loss_div: 0.00041286; loss_ff: 0.00014131] [w_bc: 1.000000, LR: 0.000050]\n",
      "Runtime --> total: 146.93sec (2.94ms/iter.)\n",
      "Configuration:\n",
      "dim: 256, w_div: 1.000000, w_ff: 1.000000, decay_iterations: None, potential: True, vector_potential: False, \n",
      "Using device: cuda (gpus 1) ['NVIDIA RTX A6000']\n",
      "Potential Boundary: 100%|██████████| 1/1 [00:01<00:00,  1.18s/it]\n",
      "Loaded meta state: /userhome/jeon_mg/workspace/_data/NOAA12673/PINN/20170904_222400/model_final.pt\n",
      "Training:   0%|          | 0/2000 [00:00<?, ?it/s][Iteration 000000/002000] [loss: 0.00405157] [loss_bc: 0.00359534; loss_div: 0.00031138; loss_ff: 0.00014485] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:   5%|▍         | 98/2000 [00:07<02:19, 13.62it/s][Iteration 000100/002000] [loss: 0.00413725] [loss_bc: 0.00358957; loss_div: 0.00042648; loss_ff: 0.00012121] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  10%|▉         | 198/2000 [00:14<02:09, 13.96it/s][Iteration 000200/002000] [loss: 0.00397164] [loss_bc: 0.00347221; loss_div: 0.00034928; loss_ff: 0.00015015] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  15%|█▍        | 298/2000 [00:21<02:05, 13.56it/s][Iteration 000300/002000] [loss: 0.00422892] [loss_bc: 0.00370699; loss_div: 0.00036598; loss_ff: 0.00015595] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  20%|█▉        | 398/2000 [00:29<02:01, 13.18it/s][Iteration 000400/002000] [loss: 0.00424981] [loss_bc: 0.00375345; loss_div: 0.00037960; loss_ff: 0.00011676] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  25%|██▍       | 498/2000 [00:36<01:56, 12.87it/s][Iteration 000500/002000] [loss: 0.00425881] [loss_bc: 0.00368241; loss_div: 0.00042566; loss_ff: 0.00015074] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  30%|██▉       | 598/2000 [00:43<01:42, 13.68it/s][Iteration 000600/002000] [loss: 0.00416743] [loss_bc: 0.00368013; loss_div: 0.00035284; loss_ff: 0.00013447] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  35%|███▍      | 698/2000 [00:51<01:36, 13.56it/s][Iteration 000700/002000] [loss: 0.00411848] [loss_bc: 0.00363501; loss_div: 0.00035862; loss_ff: 0.00012484] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  40%|███▉      | 798/2000 [00:58<01:29, 13.37it/s][Iteration 000800/002000] [loss: 0.00422254] [loss_bc: 0.00375264; loss_div: 0.00033116; loss_ff: 0.00013873] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  45%|████▍     | 898/2000 [01:06<01:22, 13.41it/s][Iteration 000900/002000] [loss: 0.00419295] [loss_bc: 0.00369703; loss_div: 0.00038796; loss_ff: 0.00010796] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  50%|████▉     | 998/2000 [01:13<01:13, 13.59it/s][Iteration 001000/002000] [loss: 0.00408277] [loss_bc: 0.00374191; loss_div: 0.00022322; loss_ff: 0.00011764] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  55%|█████▍    | 1098/2000 [01:21<01:09, 13.05it/s][Iteration 001100/002000] [loss: 0.00400307] [loss_bc: 0.00354578; loss_div: 0.00034378; loss_ff: 0.00011351] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  60%|█████▉    | 1198/2000 [01:28<00:58, 13.59it/s][Iteration 001200/002000] [loss: 0.00413224] [loss_bc: 0.00362774; loss_div: 0.00037808; loss_ff: 0.00012642] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  65%|██████▍   | 1298/2000 [01:35<00:50, 13.77it/s][Iteration 001300/002000] [loss: 0.00409005] [loss_bc: 0.00362351; loss_div: 0.00035700; loss_ff: 0.00010955] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  70%|██████▉   | 1398/2000 [01:43<00:44, 13.59it/s][Iteration 001400/002000] [loss: 0.00398303] [loss_bc: 0.00351332; loss_div: 0.00033772; loss_ff: 0.00013199] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  75%|███████▍  | 1498/2000 [01:50<00:37, 13.23it/s][Iteration 001500/002000] [loss: 0.00401432] [loss_bc: 0.00354632; loss_div: 0.00031925; loss_ff: 0.00014874] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  80%|███████▉  | 1598/2000 [01:58<00:29, 13.67it/s][Iteration 001600/002000] [loss: 0.00409407] [loss_bc: 0.00349503; loss_div: 0.00043918; loss_ff: 0.00015986] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  85%|████████▍ | 1698/2000 [02:05<00:22, 13.46it/s][Iteration 001700/002000] [loss: 0.00414492] [loss_bc: 0.00362712; loss_div: 0.00034336; loss_ff: 0.00017444] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  90%|████████▉ | 1798/2000 [02:13<00:14, 13.60it/s][Iteration 001800/002000] [loss: 0.00383195] [loss_bc: 0.00344453; loss_div: 0.00027433; loss_ff: 0.00011309] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  95%|█████████▍| 1898/2000 [02:20<00:07, 13.49it/s][Iteration 001900/002000] [loss: 0.00412908] [loss_bc: 0.00361697; loss_div: 0.00035528; loss_ff: 0.00015682] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training: 100%|█████████▉| 1998/2000 [02:28<00:00, 13.71it/s][Iteration 002000/002000] [loss: 0.00408397] [loss_bc: 0.00352443; loss_div: 0.00040539; loss_ff: 0.00015415] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training: 100%|██████████| 2000/2000 [02:28<00:00, 13.47it/s]\n",
      "[Iteration 002000/002000] [loss: 0.00408397] [loss_bc: 0.00352443; loss_div: 0.00040539; loss_ff: 0.00015415] [w_bc: 1.000000, LR: 0.000050]\n",
      "Runtime --> total: 148.62sec (2.97ms/iter.)\n",
      "Configuration:\n",
      "dim: 256, w_div: 1.000000, w_ff: 1.000000, decay_iterations: None, potential: True, vector_potential: False, \n",
      "Using device: cuda (gpus 1) ['NVIDIA RTX A6000']\n",
      "Potential Boundary: 100%|██████████| 1/1 [00:01<00:00,  1.39s/it]\n",
      "Loaded meta state: /userhome/jeon_mg/workspace/_data/NOAA12673/PINN/20170904_223600/model_final.pt\n",
      "Training:   0%|          | 0/2000 [00:00<?, ?it/s][Iteration 000000/002000] [loss: 0.00402633] [loss_bc: 0.00352835; loss_div: 0.00033243; loss_ff: 0.00016556] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:   5%|▍         | 98/2000 [00:07<02:25, 13.09it/s][Iteration 000100/002000] [loss: 0.00380474] [loss_bc: 0.00339379; loss_div: 0.00031570; loss_ff: 0.00009524] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  10%|▉         | 198/2000 [00:14<02:22, 12.69it/s][Iteration 000200/002000] [loss: 0.00388849] [loss_bc: 0.00350309; loss_div: 0.00027799; loss_ff: 0.00010741] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  15%|█▍        | 298/2000 [00:22<02:05, 13.60it/s][Iteration 000300/002000] [loss: 0.00398774] [loss_bc: 0.00352714; loss_div: 0.00031275; loss_ff: 0.00014785] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  20%|█▉        | 398/2000 [00:29<01:57, 13.64it/s][Iteration 000400/002000] [loss: 0.00416496] [loss_bc: 0.00372470; loss_div: 0.00033194; loss_ff: 0.00010832] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  25%|██▍       | 498/2000 [00:36<01:50, 13.56it/s][Iteration 000500/002000] [loss: 0.00426984] [loss_bc: 0.00385189; loss_div: 0.00030567; loss_ff: 0.00011228] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  30%|██▉       | 598/2000 [00:44<01:47, 13.07it/s][Iteration 000600/002000] [loss: 0.00420395] [loss_bc: 0.00372885; loss_div: 0.00036091; loss_ff: 0.00011419] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  35%|███▍      | 698/2000 [00:51<01:35, 13.61it/s][Iteration 000700/002000] [loss: 0.00396662] [loss_bc: 0.00351214; loss_div: 0.00033235; loss_ff: 0.00012212] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  40%|███▉      | 798/2000 [00:59<01:27, 13.74it/s][Iteration 000800/002000] [loss: 0.00410674] [loss_bc: 0.00357838; loss_div: 0.00039695; loss_ff: 0.00013140] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  45%|████▍     | 898/2000 [01:06<01:23, 13.21it/s][Iteration 000900/002000] [loss: 0.00425541] [loss_bc: 0.00370539; loss_div: 0.00043646; loss_ff: 0.00011355] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  50%|████▉     | 998/2000 [01:14<01:15, 13.23it/s][Iteration 001000/002000] [loss: 0.00427179] [loss_bc: 0.00368997; loss_div: 0.00045885; loss_ff: 0.00012296] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  55%|█████▍    | 1098/2000 [01:21<01:05, 13.76it/s][Iteration 001100/002000] [loss: 0.00419182] [loss_bc: 0.00364762; loss_div: 0.00037253; loss_ff: 0.00017167] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  60%|█████▉    | 1198/2000 [01:29<00:59, 13.54it/s][Iteration 001200/002000] [loss: 0.00397159] [loss_bc: 0.00356911; loss_div: 0.00028953; loss_ff: 0.00011295] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  65%|██████▍   | 1298/2000 [01:36<00:52, 13.47it/s][Iteration 001300/002000] [loss: 0.00411798] [loss_bc: 0.00364245; loss_div: 0.00032989; loss_ff: 0.00014563] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  70%|██████▉   | 1398/2000 [01:43<00:44, 13.51it/s][Iteration 001400/002000] [loss: 0.00435160] [loss_bc: 0.00384154; loss_div: 0.00034758; loss_ff: 0.00016248] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  75%|███████▍  | 1498/2000 [01:51<00:37, 13.56it/s][Iteration 001500/002000] [loss: 0.00383549] [loss_bc: 0.00333847; loss_div: 0.00038078; loss_ff: 0.00011624] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  80%|███████▉  | 1598/2000 [01:58<00:29, 13.53it/s][Iteration 001600/002000] [loss: 0.00419198] [loss_bc: 0.00368606; loss_div: 0.00035560; loss_ff: 0.00015032] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  85%|████████▍ | 1698/2000 [02:06<00:22, 13.52it/s][Iteration 001700/002000] [loss: 0.00376822] [loss_bc: 0.00333592; loss_div: 0.00030189; loss_ff: 0.00013041] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  90%|████████▉ | 1798/2000 [02:13<00:15, 13.46it/s][Iteration 001800/002000] [loss: 0.00396437] [loss_bc: 0.00345977; loss_div: 0.00037852; loss_ff: 0.00012608] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  95%|█████████▍| 1898/2000 [02:21<00:07, 13.64it/s][Iteration 001900/002000] [loss: 0.00414012] [loss_bc: 0.00370532; loss_div: 0.00029591; loss_ff: 0.00013889] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training: 100%|█████████▉| 1998/2000 [02:28<00:00, 13.40it/s][Iteration 002000/002000] [loss: 0.00384937] [loss_bc: 0.00345847; loss_div: 0.00029016; loss_ff: 0.00010073] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training: 100%|██████████| 2000/2000 [02:29<00:00, 13.41it/s]\n",
      "[Iteration 002000/002000] [loss: 0.00384937] [loss_bc: 0.00345847; loss_div: 0.00029016; loss_ff: 0.00010073] [w_bc: 1.000000, LR: 0.000050]\n",
      "Runtime --> total: 149.34sec (2.99ms/iter.)\n",
      "Configuration:\n",
      "dim: 256, w_div: 1.000000, w_ff: 1.000000, decay_iterations: None, potential: True, vector_potential: False, \n",
      "Using device: cuda (gpus 1) ['NVIDIA RTX A6000']\n",
      "Potential Boundary: 100%|██████████| 1/1 [00:00<00:00,  1.29it/s]\n",
      "Loaded meta state: /userhome/jeon_mg/workspace/_data/NOAA12673/PINN/20170904_224800/model_final.pt\n",
      "Training:   0%|          | 0/2000 [00:00<?, ?it/s][Iteration 000000/002000] [loss: 0.00411277] [loss_bc: 0.00366409; loss_div: 0.00032596; loss_ff: 0.00012272] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:   5%|▍         | 98/2000 [00:07<02:20, 13.53it/s][Iteration 000100/002000] [loss: 0.00410148] [loss_bc: 0.00365483; loss_div: 0.00034267; loss_ff: 0.00010398] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  10%|▉         | 198/2000 [00:15<02:13, 13.52it/s][Iteration 000200/002000] [loss: 0.00395990] [loss_bc: 0.00352388; loss_div: 0.00029682; loss_ff: 0.00013921] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  15%|█▍        | 298/2000 [00:22<02:06, 13.44it/s][Iteration 000300/002000] [loss: 0.00394398] [loss_bc: 0.00342363; loss_div: 0.00038798; loss_ff: 0.00013237] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  20%|█▉        | 398/2000 [00:30<01:59, 13.42it/s][Iteration 000400/002000] [loss: 0.00409591] [loss_bc: 0.00357481; loss_div: 0.00040111; loss_ff: 0.00011999] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  25%|██▍       | 498/2000 [00:37<01:54, 13.10it/s][Iteration 000500/002000] [loss: 0.00398742] [loss_bc: 0.00360887; loss_div: 0.00027461; loss_ff: 0.00010394] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  30%|██▉       | 598/2000 [00:45<01:45, 13.31it/s][Iteration 000600/002000] [loss: 0.00407072] [loss_bc: 0.00360632; loss_div: 0.00035530; loss_ff: 0.00010910] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  35%|███▍      | 698/2000 [00:52<01:44, 12.47it/s][Iteration 000700/002000] [loss: 0.00425234] [loss_bc: 0.00369316; loss_div: 0.00036666; loss_ff: 0.00019252] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  40%|███▉      | 798/2000 [01:00<01:27, 13.69it/s][Iteration 000800/002000] [loss: 0.00418826] [loss_bc: 0.00361193; loss_div: 0.00033133; loss_ff: 0.00024499] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  45%|████▍     | 898/2000 [01:07<01:23, 13.27it/s][Iteration 000900/002000] [loss: 0.00419499] [loss_bc: 0.00363085; loss_div: 0.00042919; loss_ff: 0.00013495] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  50%|████▉     | 998/2000 [01:15<01:16, 13.17it/s][Iteration 001000/002000] [loss: 0.00413373] [loss_bc: 0.00363928; loss_div: 0.00036507; loss_ff: 0.00012939] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  55%|█████▍    | 1098/2000 [01:23<01:09, 12.99it/s][Iteration 001100/002000] [loss: 0.00446579] [loss_bc: 0.00394085; loss_div: 0.00038895; loss_ff: 0.00013599] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  60%|█████▉    | 1198/2000 [01:30<00:59, 13.52it/s][Iteration 001200/002000] [loss: 0.00447041] [loss_bc: 0.00394398; loss_div: 0.00035545; loss_ff: 0.00017097] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  65%|██████▍   | 1298/2000 [01:38<00:52, 13.42it/s][Iteration 001300/002000] [loss: 0.00408330] [loss_bc: 0.00363233; loss_div: 0.00032772; loss_ff: 0.00012325] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  70%|██████▉   | 1398/2000 [01:45<00:43, 13.72it/s][Iteration 001400/002000] [loss: 0.00418861] [loss_bc: 0.00366940; loss_div: 0.00036028; loss_ff: 0.00015893] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  75%|███████▍  | 1498/2000 [01:53<00:38, 13.13it/s][Iteration 001500/002000] [loss: 0.00395830] [loss_bc: 0.00349301; loss_div: 0.00034431; loss_ff: 0.00012098] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  80%|███████▉  | 1598/2000 [02:00<00:30, 13.29it/s][Iteration 001600/002000] [loss: 0.00402948] [loss_bc: 0.00349494; loss_div: 0.00039105; loss_ff: 0.00014348] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  85%|████████▍ | 1698/2000 [02:08<00:22, 13.45it/s][Iteration 001700/002000] [loss: 0.00404323] [loss_bc: 0.00348508; loss_div: 0.00034521; loss_ff: 0.00021295] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  90%|████████▉ | 1798/2000 [02:15<00:15, 13.24it/s][Iteration 001800/002000] [loss: 0.00422133] [loss_bc: 0.00368696; loss_div: 0.00040454; loss_ff: 0.00012984] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  95%|█████████▍| 1898/2000 [02:23<00:07, 13.30it/s][Iteration 001900/002000] [loss: 0.00417127] [loss_bc: 0.00367178; loss_div: 0.00034626; loss_ff: 0.00015323] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training: 100%|█████████▉| 1998/2000 [02:31<00:00, 13.23it/s][Iteration 002000/002000] [loss: 0.00413412] [loss_bc: 0.00360715; loss_div: 0.00038120; loss_ff: 0.00014577] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training: 100%|██████████| 2000/2000 [02:31<00:00, 13.20it/s]\n",
      "[Iteration 002000/002000] [loss: 0.00413412] [loss_bc: 0.00360715; loss_div: 0.00038120; loss_ff: 0.00014577] [w_bc: 1.000000, LR: 0.000050]\n",
      "Runtime --> total: 151.71sec (3.03ms/iter.)\n",
      "Configuration:\n",
      "dim: 256, w_div: 1.000000, w_ff: 1.000000, decay_iterations: None, potential: True, vector_potential: False, \n",
      "Using device: cuda (gpus 1) ['NVIDIA RTX A6000']\n",
      "Potential Boundary: 100%|██████████| 1/1 [00:00<00:00,  1.31it/s]\n",
      "Loaded meta state: /userhome/jeon_mg/workspace/_data/NOAA12673/PINN/20170904_230000/model_final.pt\n",
      "Training:   0%|          | 0/2000 [00:00<?, ?it/s][Iteration 000000/002000] [loss: 0.00410830] [loss_bc: 0.00367348; loss_div: 0.00031952; loss_ff: 0.00011530] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:   5%|▍         | 98/2000 [00:07<02:19, 13.64it/s][Iteration 000100/002000] [loss: 0.00377201] [loss_bc: 0.00333981; loss_div: 0.00030481; loss_ff: 0.00012739] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  10%|▉         | 198/2000 [00:14<02:20, 12.83it/s][Iteration 000200/002000] [loss: 0.00401386] [loss_bc: 0.00360953; loss_div: 0.00029279; loss_ff: 0.00011154] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  15%|█▍        | 298/2000 [00:22<02:05, 13.55it/s][Iteration 000300/002000] [loss: 0.00377620] [loss_bc: 0.00332738; loss_div: 0.00033908; loss_ff: 0.00010974] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  20%|█▉        | 398/2000 [00:30<01:59, 13.43it/s][Iteration 000400/002000] [loss: 0.00435301] [loss_bc: 0.00390167; loss_div: 0.00033299; loss_ff: 0.00011835] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  25%|██▍       | 498/2000 [00:37<01:51, 13.47it/s][Iteration 000500/002000] [loss: 0.00411235] [loss_bc: 0.00360387; loss_div: 0.00033647; loss_ff: 0.00017202] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  30%|██▉       | 598/2000 [00:45<01:43, 13.55it/s][Iteration 000600/002000] [loss: 0.00421050] [loss_bc: 0.00373458; loss_div: 0.00034433; loss_ff: 0.00013159] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  35%|███▍      | 698/2000 [00:52<01:37, 13.29it/s][Iteration 000700/002000] [loss: 0.00436112] [loss_bc: 0.00390849; loss_div: 0.00030512; loss_ff: 0.00014750] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  40%|███▉      | 798/2000 [01:00<01:27, 13.69it/s][Iteration 000800/002000] [loss: 0.00450017] [loss_bc: 0.00390376; loss_div: 0.00043685; loss_ff: 0.00015955] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  45%|████▍     | 898/2000 [01:07<01:21, 13.53it/s][Iteration 000900/002000] [loss: 0.00403700] [loss_bc: 0.00358912; loss_div: 0.00033652; loss_ff: 0.00011136] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  50%|████▉     | 998/2000 [01:15<01:16, 13.13it/s][Iteration 001000/002000] [loss: 0.00391014] [loss_bc: 0.00350381; loss_div: 0.00030145; loss_ff: 0.00010489] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  55%|█████▍    | 1098/2000 [01:23<01:06, 13.54it/s][Iteration 001100/002000] [loss: 0.00408162] [loss_bc: 0.00365783; loss_div: 0.00031017; loss_ff: 0.00011363] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  60%|█████▉    | 1198/2000 [01:30<00:59, 13.43it/s][Iteration 001200/002000] [loss: 0.00420609] [loss_bc: 0.00370849; loss_div: 0.00031423; loss_ff: 0.00018337] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  65%|██████▍   | 1298/2000 [01:38<00:52, 13.42it/s][Iteration 001300/002000] [loss: 0.00408843] [loss_bc: 0.00358236; loss_div: 0.00036250; loss_ff: 0.00014356] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  70%|██████▉   | 1398/2000 [01:45<00:44, 13.44it/s][Iteration 001400/002000] [loss: 0.00401705] [loss_bc: 0.00350442; loss_div: 0.00038714; loss_ff: 0.00012549] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  75%|███████▍  | 1498/2000 [01:53<00:36, 13.65it/s][Iteration 001500/002000] [loss: 0.00403048] [loss_bc: 0.00357869; loss_div: 0.00035375; loss_ff: 0.00009804] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  80%|███████▉  | 1598/2000 [02:00<00:30, 13.22it/s][Iteration 001600/002000] [loss: 0.00371103] [loss_bc: 0.00330805; loss_div: 0.00030264; loss_ff: 0.00010034] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  85%|████████▍ | 1698/2000 [02:08<00:22, 13.40it/s][Iteration 001700/002000] [loss: 0.00394045] [loss_bc: 0.00349438; loss_div: 0.00035908; loss_ff: 0.00008699] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  90%|████████▉ | 1798/2000 [02:16<00:16, 12.23it/s][Iteration 001800/002000] [loss: 0.00417912] [loss_bc: 0.00371300; loss_div: 0.00034216; loss_ff: 0.00012396] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  95%|█████████▍| 1898/2000 [02:23<00:07, 13.01it/s][Iteration 001900/002000] [loss: 0.00399567] [loss_bc: 0.00349622; loss_div: 0.00039557; loss_ff: 0.00010388] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training: 100%|█████████▉| 1998/2000 [02:31<00:00, 12.63it/s][Iteration 002000/002000] [loss: 0.00387640] [loss_bc: 0.00349322; loss_div: 0.00027502; loss_ff: 0.00010817] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training: 100%|██████████| 2000/2000 [02:31<00:00, 13.17it/s]\n",
      "[Iteration 002000/002000] [loss: 0.00387640] [loss_bc: 0.00349322; loss_div: 0.00027502; loss_ff: 0.00010817] [w_bc: 1.000000, LR: 0.000050]\n",
      "Runtime --> total: 152.13sec (3.04ms/iter.)\n",
      "Configuration:\n",
      "dim: 256, w_div: 1.000000, w_ff: 1.000000, decay_iterations: None, potential: True, vector_potential: False, \n",
      "Using device: cuda (gpus 1) ['NVIDIA RTX A6000']\n",
      "Potential Boundary: 100%|██████████| 1/1 [00:00<00:00,  1.40it/s]\n",
      "Loaded meta state: /userhome/jeon_mg/workspace/_data/NOAA12673/PINN/20170904_231200/model_final.pt\n",
      "Training:   0%|          | 0/2000 [00:00<?, ?it/s][Iteration 000000/002000] [loss: 0.00397636] [loss_bc: 0.00343041; loss_div: 0.00042938; loss_ff: 0.00011657] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:   5%|▍         | 98/2000 [00:07<02:23, 13.29it/s][Iteration 000100/002000] [loss: 0.00394206] [loss_bc: 0.00342945; loss_div: 0.00038178; loss_ff: 0.00013082] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  10%|▉         | 198/2000 [00:14<02:17, 13.12it/s][Iteration 000200/002000] [loss: 0.00430279] [loss_bc: 0.00378981; loss_div: 0.00031516; loss_ff: 0.00019783] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  15%|█▍        | 298/2000 [00:22<02:16, 12.46it/s][Iteration 000300/002000] [loss: 0.00405490] [loss_bc: 0.00356733; loss_div: 0.00035960; loss_ff: 0.00012797] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  20%|█▉        | 398/2000 [00:30<01:57, 13.59it/s][Iteration 000400/002000] [loss: 0.00429637] [loss_bc: 0.00379049; loss_div: 0.00035120; loss_ff: 0.00015468] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  25%|██▍       | 498/2000 [00:37<01:50, 13.59it/s][Iteration 000500/002000] [loss: 0.00407775] [loss_bc: 0.00359751; loss_div: 0.00034054; loss_ff: 0.00013970] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  30%|██▉       | 598/2000 [00:45<01:47, 13.06it/s][Iteration 000600/002000] [loss: 0.00424288] [loss_bc: 0.00370761; loss_div: 0.00032364; loss_ff: 0.00021163] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  35%|███▍      | 698/2000 [00:52<01:39, 13.11it/s][Iteration 000700/002000] [loss: 0.00400223] [loss_bc: 0.00352794; loss_div: 0.00035468; loss_ff: 0.00011961] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  40%|███▉      | 798/2000 [01:00<01:31, 13.09it/s][Iteration 000800/002000] [loss: 0.00404564] [loss_bc: 0.00358888; loss_div: 0.00033263; loss_ff: 0.00012413] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  45%|████▍     | 898/2000 [01:07<01:19, 13.83it/s][Iteration 000900/002000] [loss: 0.00400674] [loss_bc: 0.00351216; loss_div: 0.00036496; loss_ff: 0.00012962] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  50%|████▉     | 998/2000 [01:15<01:15, 13.29it/s][Iteration 001000/002000] [loss: 0.00408011] [loss_bc: 0.00355034; loss_div: 0.00040213; loss_ff: 0.00012763] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  55%|█████▍    | 1098/2000 [01:23<01:07, 13.37it/s][Iteration 001100/002000] [loss: 0.00417999] [loss_bc: 0.00368989; loss_div: 0.00037996; loss_ff: 0.00011014] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  60%|█████▉    | 1198/2000 [01:30<01:00, 13.36it/s][Iteration 001200/002000] [loss: 0.00399898] [loss_bc: 0.00349864; loss_div: 0.00038594; loss_ff: 0.00011439] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  65%|██████▍   | 1298/2000 [01:38<00:51, 13.69it/s][Iteration 001300/002000] [loss: 0.00421992] [loss_bc: 0.00371026; loss_div: 0.00035113; loss_ff: 0.00015853] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  70%|██████▉   | 1398/2000 [01:45<00:45, 13.16it/s][Iteration 001400/002000] [loss: 0.00400792] [loss_bc: 0.00354173; loss_div: 0.00029621; loss_ff: 0.00016997] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  75%|███████▍  | 1498/2000 [01:53<00:38, 13.19it/s][Iteration 001500/002000] [loss: 0.00405923] [loss_bc: 0.00360550; loss_div: 0.00031029; loss_ff: 0.00014344] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  80%|███████▉  | 1598/2000 [02:00<00:30, 13.22it/s][Iteration 001600/002000] [loss: 0.00420412] [loss_bc: 0.00368184; loss_div: 0.00035447; loss_ff: 0.00016782] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  85%|████████▍ | 1698/2000 [02:08<00:23, 13.06it/s][Iteration 001700/002000] [loss: 0.00401688] [loss_bc: 0.00352901; loss_div: 0.00035803; loss_ff: 0.00012984] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  90%|████████▉ | 1798/2000 [02:16<00:15, 13.16it/s][Iteration 001800/002000] [loss: 0.00408751] [loss_bc: 0.00357301; loss_div: 0.00040110; loss_ff: 0.00011339] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  95%|█████████▍| 1898/2000 [02:23<00:07, 13.24it/s][Iteration 001900/002000] [loss: 0.00402543] [loss_bc: 0.00349487; loss_div: 0.00033764; loss_ff: 0.00019292] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training: 100%|█████████▉| 1998/2000 [02:31<00:00, 13.08it/s][Iteration 002000/002000] [loss: 0.00407386] [loss_bc: 0.00370448; loss_div: 0.00025810; loss_ff: 0.00011128] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training: 100%|██████████| 2000/2000 [02:31<00:00, 13.20it/s]\n",
      "[Iteration 002000/002000] [loss: 0.00407386] [loss_bc: 0.00370448; loss_div: 0.00025810; loss_ff: 0.00011128] [w_bc: 1.000000, LR: 0.000050]\n",
      "Runtime --> total: 151.83sec (3.04ms/iter.)\n",
      "Configuration:\n",
      "dim: 256, w_div: 1.000000, w_ff: 1.000000, decay_iterations: None, potential: True, vector_potential: False, \n",
      "Using device: cuda (gpus 1) ['NVIDIA RTX A6000']\n",
      "Potential Boundary: 100%|██████████| 1/1 [00:00<00:00,  1.40it/s]\n",
      "Loaded meta state: /userhome/jeon_mg/workspace/_data/NOAA12673/PINN/20170904_232400/model_final.pt\n",
      "Training:   0%|          | 0/2000 [00:00<?, ?it/s][Iteration 000000/002000] [loss: 0.00391941] [loss_bc: 0.00352377; loss_div: 0.00028272; loss_ff: 0.00011292] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:   5%|▍         | 98/2000 [00:07<02:22, 13.31it/s][Iteration 000100/002000] [loss: 0.00413799] [loss_bc: 0.00368288; loss_div: 0.00031774; loss_ff: 0.00013738] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  10%|▉         | 198/2000 [00:14<02:18, 13.03it/s][Iteration 000200/002000] [loss: 0.00413287] [loss_bc: 0.00364430; loss_div: 0.00035675; loss_ff: 0.00013182] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  15%|█▍        | 298/2000 [00:22<02:05, 13.54it/s][Iteration 000300/002000] [loss: 0.00422927] [loss_bc: 0.00380336; loss_div: 0.00029673; loss_ff: 0.00012918] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  20%|█▉        | 398/2000 [00:30<02:02, 13.07it/s][Iteration 000400/002000] [loss: 0.00412043] [loss_bc: 0.00366457; loss_div: 0.00033881; loss_ff: 0.00011704] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  25%|██▍       | 498/2000 [00:37<01:53, 13.26it/s][Iteration 000500/002000] [loss: 0.00390672] [loss_bc: 0.00351630; loss_div: 0.00029931; loss_ff: 0.00009110] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  30%|██▉       | 598/2000 [00:45<01:47, 13.03it/s][Iteration 000600/002000] [loss: 0.00392269] [loss_bc: 0.00350412; loss_div: 0.00030312; loss_ff: 0.00011545] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  35%|███▍      | 698/2000 [00:52<01:37, 13.33it/s][Iteration 000700/002000] [loss: 0.00405215] [loss_bc: 0.00362658; loss_div: 0.00032862; loss_ff: 0.00009695] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  40%|███▉      | 798/2000 [01:00<01:33, 12.83it/s][Iteration 000800/002000] [loss: 0.00402804] [loss_bc: 0.00351446; loss_div: 0.00034260; loss_ff: 0.00017098] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  45%|████▍     | 898/2000 [01:07<01:23, 13.16it/s][Iteration 000900/002000] [loss: 0.00420318] [loss_bc: 0.00379968; loss_div: 0.00030829; loss_ff: 0.00009521] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  50%|████▉     | 998/2000 [01:15<01:14, 13.49it/s][Iteration 001000/002000] [loss: 0.00403254] [loss_bc: 0.00362946; loss_div: 0.00028638; loss_ff: 0.00011670] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  55%|█████▍    | 1098/2000 [01:22<01:09, 13.06it/s][Iteration 001100/002000] [loss: 0.00400520] [loss_bc: 0.00358734; loss_div: 0.00032065; loss_ff: 0.00009722] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  60%|█████▉    | 1198/2000 [01:30<00:59, 13.42it/s][Iteration 001200/002000] [loss: 0.00409935] [loss_bc: 0.00366014; loss_div: 0.00031372; loss_ff: 0.00012549] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  65%|██████▍   | 1298/2000 [01:38<00:52, 13.27it/s][Iteration 001300/002000] [loss: 0.00398200] [loss_bc: 0.00361815; loss_div: 0.00027350; loss_ff: 0.00009035] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  70%|██████▉   | 1398/2000 [01:45<00:45, 13.21it/s][Iteration 001400/002000] [loss: 0.00405801] [loss_bc: 0.00362266; loss_div: 0.00032203; loss_ff: 0.00011332] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  75%|███████▍  | 1498/2000 [01:53<00:38, 13.10it/s][Iteration 001500/002000] [loss: 0.00389238] [loss_bc: 0.00350061; loss_div: 0.00027655; loss_ff: 0.00011522] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  80%|███████▉  | 1598/2000 [02:00<00:31, 12.60it/s][Iteration 001600/002000] [loss: 0.00429529] [loss_bc: 0.00378862; loss_div: 0.00037583; loss_ff: 0.00013085] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  85%|████████▍ | 1698/2000 [02:08<00:22, 13.27it/s][Iteration 001700/002000] [loss: 0.00398783] [loss_bc: 0.00349961; loss_div: 0.00035812; loss_ff: 0.00013011] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  90%|████████▉ | 1798/2000 [02:15<00:15, 13.42it/s][Iteration 001800/002000] [loss: 0.00425571] [loss_bc: 0.00377071; loss_div: 0.00034319; loss_ff: 0.00014180] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  95%|█████████▍| 1898/2000 [02:23<00:07, 13.31it/s][Iteration 001900/002000] [loss: 0.00389656] [loss_bc: 0.00345725; loss_div: 0.00030107; loss_ff: 0.00013824] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training: 100%|█████████▉| 1998/2000 [02:31<00:00, 13.55it/s][Iteration 002000/002000] [loss: 0.00400799] [loss_bc: 0.00348388; loss_div: 0.00037554; loss_ff: 0.00014857] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training: 100%|██████████| 2000/2000 [02:31<00:00, 13.21it/s]\n",
      "[Iteration 002000/002000] [loss: 0.00400799] [loss_bc: 0.00348388; loss_div: 0.00037554; loss_ff: 0.00014857] [w_bc: 1.000000, LR: 0.000050]\n",
      "Runtime --> total: 151.63sec (3.03ms/iter.)\n",
      "Configuration:\n",
      "dim: 256, w_div: 1.000000, w_ff: 1.000000, decay_iterations: None, potential: True, vector_potential: False, \n",
      "Using device: cuda (gpus 1) ['NVIDIA RTX A6000']\n",
      "Potential Boundary: 100%|██████████| 1/1 [00:00<00:00,  1.30it/s]\n",
      "Loaded meta state: /userhome/jeon_mg/workspace/_data/NOAA12673/PINN/20170904_233600/model_final.pt\n",
      "Training:   0%|          | 0/2000 [00:00<?, ?it/s][Iteration 000000/002000] [loss: 0.00403866] [loss_bc: 0.00359135; loss_div: 0.00031918; loss_ff: 0.00012814] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:   5%|▍         | 98/2000 [00:07<02:24, 13.12it/s][Iteration 000100/002000] [loss: 0.00407758] [loss_bc: 0.00357523; loss_div: 0.00033212; loss_ff: 0.00017024] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  10%|▉         | 198/2000 [00:14<02:15, 13.25it/s][Iteration 000200/002000] [loss: 0.00409801] [loss_bc: 0.00364181; loss_div: 0.00031629; loss_ff: 0.00013991] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  15%|█▍        | 298/2000 [00:22<02:05, 13.60it/s][Iteration 000300/002000] [loss: 0.00409535] [loss_bc: 0.00363365; loss_div: 0.00033816; loss_ff: 0.00012354] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  20%|█▉        | 398/2000 [00:30<01:59, 13.46it/s][Iteration 000400/002000] [loss: 0.00396620] [loss_bc: 0.00356065; loss_div: 0.00027493; loss_ff: 0.00013062] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  25%|██▍       | 498/2000 [00:37<01:50, 13.63it/s][Iteration 000500/002000] [loss: 0.00426732] [loss_bc: 0.00375878; loss_div: 0.00036913; loss_ff: 0.00013941] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  30%|██▉       | 598/2000 [00:45<01:44, 13.38it/s][Iteration 000600/002000] [loss: 0.00407273] [loss_bc: 0.00354264; loss_div: 0.00038324; loss_ff: 0.00014685] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  35%|███▍      | 698/2000 [00:52<01:38, 13.23it/s][Iteration 000700/002000] [loss: 0.00410384] [loss_bc: 0.00356487; loss_div: 0.00039487; loss_ff: 0.00014410] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  40%|███▉      | 798/2000 [01:00<01:28, 13.62it/s][Iteration 000800/002000] [loss: 0.00422602] [loss_bc: 0.00375755; loss_div: 0.00033753; loss_ff: 0.00013094] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  45%|████▍     | 898/2000 [01:07<01:21, 13.59it/s][Iteration 000900/002000] [loss: 0.00405667] [loss_bc: 0.00353579; loss_div: 0.00037071; loss_ff: 0.00015018] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  50%|████▉     | 998/2000 [01:15<01:15, 13.29it/s][Iteration 001000/002000] [loss: 0.00406130] [loss_bc: 0.00355120; loss_div: 0.00033428; loss_ff: 0.00017582] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  55%|█████▍    | 1098/2000 [01:22<01:08, 13.07it/s][Iteration 001100/002000] [loss: 0.00414317] [loss_bc: 0.00362937; loss_div: 0.00039094; loss_ff: 0.00012287] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  60%|█████▉    | 1198/2000 [01:30<01:02, 12.87it/s][Iteration 001200/002000] [loss: 0.00426961] [loss_bc: 0.00373091; loss_div: 0.00039738; loss_ff: 0.00014132] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  65%|██████▍   | 1298/2000 [01:38<00:53, 13.23it/s][Iteration 001300/002000] [loss: 0.00395270] [loss_bc: 0.00355283; loss_div: 0.00029387; loss_ff: 0.00010600] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  70%|██████▉   | 1398/2000 [01:45<00:43, 13.79it/s][Iteration 001400/002000] [loss: 0.00396904] [loss_bc: 0.00354807; loss_div: 0.00029086; loss_ff: 0.00013011] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  75%|███████▍  | 1498/2000 [01:53<00:38, 13.10it/s][Iteration 001500/002000] [loss: 0.00405401] [loss_bc: 0.00361197; loss_div: 0.00029725; loss_ff: 0.00014479] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  80%|███████▉  | 1598/2000 [02:00<00:30, 13.40it/s][Iteration 001600/002000] [loss: 0.00398275] [loss_bc: 0.00351550; loss_div: 0.00037905; loss_ff: 0.00008820] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  85%|████████▍ | 1698/2000 [02:08<00:22, 13.64it/s][Iteration 001700/002000] [loss: 0.00427238] [loss_bc: 0.00373942; loss_div: 0.00039078; loss_ff: 0.00014218] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  90%|████████▉ | 1798/2000 [02:15<00:15, 13.43it/s][Iteration 001800/002000] [loss: 0.00400439] [loss_bc: 0.00351459; loss_div: 0.00035063; loss_ff: 0.00013918] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  95%|█████████▍| 1898/2000 [02:23<00:07, 13.13it/s][Iteration 001900/002000] [loss: 0.00399703] [loss_bc: 0.00352930; loss_div: 0.00029955; loss_ff: 0.00016818] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training: 100%|█████████▉| 1998/2000 [02:31<00:00, 13.51it/s][Iteration 002000/002000] [loss: 0.00400553] [loss_bc: 0.00356769; loss_div: 0.00029817; loss_ff: 0.00013967] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training: 100%|██████████| 2000/2000 [02:31<00:00, 13.20it/s]\n",
      "[Iteration 002000/002000] [loss: 0.00400553] [loss_bc: 0.00356769; loss_div: 0.00029817; loss_ff: 0.00013967] [w_bc: 1.000000, LR: 0.000050]\n",
      "Runtime --> total: 151.81sec (3.04ms/iter.)\n"
     ]
    }
   ],
   "source": [
    "meta_path = None\n",
    "\n",
    "for b_bottom_path in sorted(glob.glob(os.path.join(b_bottom_paths, '*.npy'))):\n",
    "    b_bottom_date = os.path.basename(b_bottom_path)[9:-4]\n",
    "    output_path = os.path.join(Path(b_bottom_path).parent.parent, f'PINN/{b_bottom_date}')\n",
    "    \n",
    "    with open(b_bottom_path, 'rb') as f:\n",
    "        b_bottom = np.load(f)\n",
    "\n",
    "    Nx, Ny, _ = b_bottom.shape\n",
    "    \n",
    "    final_model_path = os.path.join(output_path, 'model_final.pt')\n",
    "    if os.path.exists(final_model_path):\n",
    "        meta_path = final_model_path\n",
    "        continue\n",
    "    \n",
    "    if meta_path is None:\n",
    "        trainer = NF2Trainer(output_path, b_bottom, Nz, spatial_norm, b_norm,\n",
    "                             meta_path=None, dim=num_neurons, w_div=w_div, w_ff=w_ff,\n",
    "                             decay_iterations=decay_iterations)\n",
    "\n",
    "        start = time.time()\n",
    "        trainer.train(total_iterations, batch_size, log_interval, log_interval, num_workers=num_worker)\n",
    "        runtime = time.time() - start\n",
    "        trainer.logger.info(f'Runtime --> total: {runtime:.2f}sec ({(runtime/(total_iterations-1)*1000):.2f}ms/iter.)')\n",
    "        meta_path = os.path.join(output_path, 'model_final.pt')\n",
    "    else:\n",
    "        trainer = NF2Trainer(output_path, b_bottom, Nz, spatial_norm, b_norm,\n",
    "                             meta_path=meta_path, dim=num_neurons, w_div=w_div, w_ff=w_ff)\n",
    "\n",
    "        start = time.time()\n",
    "        trainer.train(series_iteration, batch_size, series_log_interval, series_log_interval, num_workers=num_worker)\n",
    "        runtime = time.time() - start\n",
    "        trainer.logger.info(f'Runtime --> total: {runtime:.2f}sec ({(runtime/(total_iterations-1)*1000):.2f}ms/iter.)')\n",
    "        meta_path = os.path.join(output_path, 'model_final.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
