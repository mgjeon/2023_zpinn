{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PINN (series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from setproctitle import setproctitle\n",
    "setproctitle(\"PINN (series)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]= \"2\"\n",
    "\n",
    "import time\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b_bottom_paths = os.path.expanduser('~/workspace/_data/NOAA12673/b_bottom')\n",
    "Nz = 160\n",
    "spatial_norm = 160\n",
    "b_norm = 2500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_iterations = 50000\n",
    "log_interval = 1000\n",
    "\n",
    "series_iteration = 2000\n",
    "series_log_interval = 100\n",
    "\n",
    "num_neurons = 256\n",
    "num_layers = 8\n",
    "\n",
    "w_ff = 1\n",
    "w_div = 1\n",
    "# w_bc_init = 1000\n",
    "decay_iterations = 25000\n",
    "\n",
    "# lr_init = 5e-4\n",
    "# lr_final = 5e-5\n",
    "# lr_decay_iterations = 50000\n",
    "\n",
    "batch_size = 10000\n",
    "num_worker = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cmspinn.pinn_nf2_old import NF2Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration:\n",
      "dim: 256, w_div: 1.000000, w_ff: 1.000000, decay_iterations: 25000, potential: True, vector_potential: False, \n",
      "Using device: cuda (gpus 1) ['NVIDIA RTX A6000']\n",
      "Potential Boundary: 100%|██████████| 1/1 [00:01<00:00,  1.12s/it]\n",
      "Training:   0%|          | 0/50000 [00:00<?, ?it/s][Iteration 000000/050000] [loss: 35.33539200] [loss_bc: 35.33538437; loss_div: 0.00000456; loss_ff: 0.00000217] [w_bc: 1000.000000, LR: 0.000500]\n",
      "Training:   2%|▏         | 999/50000 [01:14<59:19, 13.77it/s]  [Iteration 001000/050000] [loss: 11.47222042] [loss_bc: 10.69083309; loss_div: 0.55726039; loss_ff: 0.22412676] [w_bc: 758.787207, LR: 0.000478]\n",
      "Training:   4%|▍         | 1999/50000 [02:28<59:51, 13.37it/s]  [Iteration 002000/050000] [loss: 6.37679815] [loss_bc: 5.76758623; loss_div: 0.43113244; loss_ff: 0.17807978] [w_bc: 575.598959, LR: 0.000456]\n",
      "Training:   6%|▌         | 2999/50000 [03:41<57:17, 13.67it/s]  [Iteration 003000/050000] [loss: 4.16826582] [loss_bc: 3.77146983; loss_div: 0.27395976; loss_ff: 0.12283615] [w_bc: 436.636463, LR: 0.000436]\n",
      "Training:   8%|▊         | 3999/50000 [04:55<57:19, 13.38it/s]  [Iteration 004000/050000] [loss: 2.37025094] [loss_bc: 2.10761428; loss_div: 0.18142128; loss_ff: 0.08121531] [w_bc: 331.222629, LR: 0.000416]\n",
      "Training:  10%|▉         | 4999/50000 [06:09<54:08, 13.85it/s]  [Iteration 005000/050000] [loss: 1.59120512] [loss_bc: 1.42997825; loss_div: 0.11286367; loss_ff: 0.04836320] [w_bc: 251.258059, LR: 0.000397]\n",
      "Training:  12%|█▏        | 5999/50000 [07:23<55:09, 13.29it/s][Iteration 006000/050000] [loss: 1.13553131] [loss_bc: 1.01187718; loss_div: 0.08372997; loss_ff: 0.03992418] [w_bc: 190.598729, LR: 0.000379]\n",
      "Training:  14%|█▍        | 6999/50000 [08:37<53:09, 13.48it/s]  [Iteration 007000/050000] [loss: 0.76059210] [loss_bc: 0.65942293; loss_div: 0.06586756; loss_ff: 0.03530165] [w_bc: 144.583922, LR: 0.000362]\n",
      "Training:  16%|█▌        | 7999/50000 [09:51<51:04, 13.71it/s][Iteration 008000/050000] [loss: 0.53891325] [loss_bc: 0.47677782; loss_div: 0.04137344; loss_ff: 0.02076197] [w_bc: 109.678121, LR: 0.000346]\n",
      "Training:  18%|█▊        | 8999/50000 [11:05<49:59, 13.67it/s][Iteration 009000/050000] [loss: 0.42313242] [loss_bc: 0.36422685; loss_div: 0.03523681; loss_ff: 0.02366876] [w_bc: 83.199363, LR: 0.000330]\n",
      "Training:  20%|█▉        | 9999/50000 [12:20<49:08, 13.57it/s][Iteration 010000/050000] [loss: 0.28079885] [loss_bc: 0.23835240; loss_div: 0.02888522; loss_ff: 0.01356123] [w_bc: 63.113171, LR: 0.000315]\n",
      "Training:  22%|██▏       | 10999/50000 [13:34<47:49, 13.59it/s][Iteration 011000/050000] [loss: 0.20549656] [loss_bc: 0.16917399; loss_div: 0.02328689; loss_ff: 0.01303569] [w_bc: 47.876236, LR: 0.000301]\n",
      "Training:  24%|██▍       | 11999/50000 [14:48<46:31, 13.61it/s][Iteration 012000/050000] [loss: 0.18341577] [loss_bc: 0.15229118; loss_div: 0.02014595; loss_ff: 0.01097864] [w_bc: 36.317839, LR: 0.000288]\n",
      "Training:  26%|██▌       | 12999/50000 [16:03<46:03, 13.39it/s][Iteration 013000/050000] [loss: 0.12621929] [loss_bc: 0.10376965; loss_div: 0.01296127; loss_ff: 0.00948836] [w_bc: 27.549898, LR: 0.000275]\n",
      "Training:  28%|██▊       | 13999/50000 [17:16<44:37, 13.44it/s][Iteration 014000/050000] [loss: 0.09745919] [loss_bc: 0.07350639; loss_div: 0.01389349; loss_ff: 0.01005930] [w_bc: 20.898735, LR: 0.000262]\n",
      "Training:  30%|██▉       | 14999/50000 [18:30<42:41, 13.67it/s][Iteration 015000/050000] [loss: 0.08356073] [loss_bc: 0.06802106; loss_div: 0.01033108; loss_ff: 0.00520859] [w_bc: 15.853312, LR: 0.000251]\n",
      "Training:  32%|███▏      | 15999/50000 [19:45<42:14, 13.41it/s][Iteration 016000/050000] [loss: 0.06018099] [loss_bc: 0.04652857; loss_div: 0.00748965; loss_ff: 0.00616277] [w_bc: 12.025967, LR: 0.000239]\n",
      "Training:  34%|███▍      | 16999/50000 [20:59<40:10, 13.69it/s][Iteration 017000/050000] [loss: 0.04892269] [loss_bc: 0.03758379; loss_div: 0.00750839; loss_ff: 0.00383050] [w_bc: 9.122629, LR: 0.000229]\n",
      "Training:  36%|███▌      | 17999/50000 [22:13<39:13, 13.60it/s][Iteration 018000/050000] [loss: 0.03416909] [loss_bc: 0.02628849; loss_div: 0.00489955; loss_ff: 0.00298105] [w_bc: 6.920222, LR: 0.000218]\n",
      "Training:  38%|███▊      | 18999/50000 [23:27<37:53, 13.64it/s][Iteration 019000/050000] [loss: 0.03121019] [loss_bc: 0.02464774; loss_div: 0.00452116; loss_ff: 0.00204129] [w_bc: 5.249525, LR: 0.000208]\n",
      "Training:  40%|███▉      | 19999/50000 [24:41<37:18, 13.40it/s][Iteration 020000/050000] [loss: 0.02521748] [loss_bc: 0.01909634; loss_div: 0.00383838; loss_ff: 0.00228276] [w_bc: 3.982172, LR: 0.000199]\n",
      "Training:  42%|████▏     | 20999/50000 [25:55<35:43, 13.53it/s][Iteration 021000/050000] [loss: 0.01896589] [loss_bc: 0.01386750; loss_div: 0.00267080; loss_ff: 0.00242760] [w_bc: 3.020786, LR: 0.000190]\n",
      "Training:  44%|████▍     | 21999/50000 [27:09<34:50, 13.39it/s][Iteration 022000/050000] [loss: 0.01426249] [loss_bc: 0.01051395; loss_div: 0.00241766; loss_ff: 0.00133088] [w_bc: 2.291501, LR: 0.000182]\n",
      "Training:  46%|████▌     | 22999/50000 [28:24<33:26, 13.46it/s][Iteration 023000/050000] [loss: 0.01142323] [loss_bc: 0.00823872; loss_div: 0.00186303; loss_ff: 0.00132148] [w_bc: 1.738281, LR: 0.000173]\n",
      "Training:  48%|████▊     | 23999/50000 [29:38<32:23, 13.38it/s][Iteration 024000/050000] [loss: 0.00933313] [loss_bc: 0.00688851; loss_div: 0.00156515; loss_ff: 0.00087946] [w_bc: 1.318621, LR: 0.000166]\n",
      "Training:  50%|████▉     | 24999/50000 [30:52<30:39, 13.59it/s][Iteration 025000/050000] [loss: 0.00770441] [loss_bc: 0.00500393; loss_div: 0.00167136; loss_ff: 0.00102913] [w_bc: 1.000276, LR: 0.000158]\n",
      "Training:  52%|█████▏    | 25999/50000 [32:07<28:57, 13.81it/s][Iteration 026000/050000] [loss: 0.00647949] [loss_bc: 0.00498560; loss_div: 0.00098197; loss_ff: 0.00051192] [w_bc: 1.000000, LR: 0.000151]\n",
      "Training:  54%|█████▍    | 26999/50000 [33:21<28:04, 13.65it/s][Iteration 027000/050000] [loss: 0.00662591] [loss_bc: 0.00497685; loss_div: 0.00104531; loss_ff: 0.00060375] [w_bc: 1.000000, LR: 0.000144]\n",
      "Training:  56%|█████▌    | 27999/50000 [34:35<27:17, 13.43it/s][Iteration 028000/050000] [loss: 0.00618525] [loss_bc: 0.00493386; loss_div: 0.00082162; loss_ff: 0.00042977] [w_bc: 1.000000, LR: 0.000138]\n",
      "Training:  58%|█████▊    | 28999/50000 [35:49<25:18, 13.83it/s][Iteration 029000/050000] [loss: 0.00683521] [loss_bc: 0.00530077; loss_div: 0.00101124; loss_ff: 0.00052319] [w_bc: 1.000000, LR: 0.000132]\n",
      "Training:  60%|█████▉    | 29999/50000 [37:03<24:17, 13.72it/s][Iteration 030000/050000] [loss: 0.00668264] [loss_bc: 0.00492837; loss_div: 0.00106689; loss_ff: 0.00068738] [w_bc: 1.000000, LR: 0.000126]\n",
      "Training:  62%|██████▏   | 30999/50000 [38:17<23:21, 13.56it/s][Iteration 031000/050000] [loss: 0.00620800] [loss_bc: 0.00489800; loss_div: 0.00082139; loss_ff: 0.00048862] [w_bc: 1.000000, LR: 0.000120]\n",
      "Training:  64%|██████▍   | 31999/50000 [39:31<21:53, 13.71it/s][Iteration 032000/050000] [loss: 0.00570911] [loss_bc: 0.00490112; loss_div: 0.00056019; loss_ff: 0.00024780] [w_bc: 1.000000, LR: 0.000115]\n",
      "Training:  66%|██████▌   | 32999/50000 [40:45<21:03, 13.45it/s][Iteration 033000/050000] [loss: 0.00593640] [loss_bc: 0.00464795; loss_div: 0.00090741; loss_ff: 0.00038103] [w_bc: 1.000000, LR: 0.000109]\n",
      "Training:  68%|██████▊   | 33999/50000 [41:59<19:34, 13.62it/s][Iteration 034000/050000] [loss: 0.00599714] [loss_bc: 0.00478604; loss_div: 0.00082188; loss_ff: 0.00038922] [w_bc: 1.000000, LR: 0.000104]\n",
      "Training:  70%|██████▉   | 34999/50000 [43:13<19:05, 13.09it/s][Iteration 035000/050000] [loss: 0.00589444] [loss_bc: 0.00484906; loss_div: 0.00069366; loss_ff: 0.00035171] [w_bc: 1.000000, LR: 0.000100]\n",
      "Training:  72%|███████▏  | 35999/50000 [44:27<17:04, 13.67it/s][Iteration 036000/050000] [loss: 0.00561773] [loss_bc: 0.00475114; loss_div: 0.00051461; loss_ff: 0.00035197] [w_bc: 1.000000, LR: 0.000095]\n",
      "Training:  74%|███████▍  | 36999/50000 [45:41<15:49, 13.69it/s][Iteration 037000/050000] [loss: 0.00583232] [loss_bc: 0.00482851; loss_div: 0.00058962; loss_ff: 0.00041419] [w_bc: 1.000000, LR: 0.000091]\n",
      "Training:  76%|███████▌  | 37999/50000 [46:55<15:21, 13.03it/s][Iteration 038000/050000] [loss: 0.00600913] [loss_bc: 0.00508944; loss_div: 0.00066063; loss_ff: 0.00025907] [w_bc: 1.000000, LR: 0.000087]\n",
      "Training:  78%|███████▊  | 38999/50000 [48:09<13:20, 13.74it/s][Iteration 039000/050000] [loss: 0.00588422] [loss_bc: 0.00475483; loss_div: 0.00077260; loss_ff: 0.00035679] [w_bc: 1.000000, LR: 0.000083]\n",
      "Training:  80%|███████▉  | 39999/50000 [49:23<12:21, 13.48it/s][Iteration 040000/050000] [loss: 0.00593483] [loss_bc: 0.00505814; loss_div: 0.00061327; loss_ff: 0.00026342] [w_bc: 1.000000, LR: 0.000079]\n",
      "Training:  82%|████████▏ | 40999/50000 [50:38<11:14, 13.34it/s][Iteration 041000/050000] [loss: 0.00591097] [loss_bc: 0.00505197; loss_div: 0.00061234; loss_ff: 0.00024666] [w_bc: 1.000000, LR: 0.000076]\n",
      "Training:  84%|████████▍ | 41999/50000 [51:52<09:43, 13.72it/s][Iteration 042000/050000] [loss: 0.00595037] [loss_bc: 0.00527363; loss_div: 0.00046199; loss_ff: 0.00021475] [w_bc: 1.000000, LR: 0.000072]\n",
      "Training:  86%|████████▌ | 42999/50000 [53:06<08:34, 13.61it/s][Iteration 043000/050000] [loss: 0.00575674] [loss_bc: 0.00502285; loss_div: 0.00050735; loss_ff: 0.00022653] [w_bc: 1.000000, LR: 0.000069]\n",
      "Training:  88%|████████▊ | 43999/50000 [54:20<07:19, 13.64it/s][Iteration 044000/050000] [loss: 0.00532482] [loss_bc: 0.00471315; loss_div: 0.00040075; loss_ff: 0.00021092] [w_bc: 1.000000, LR: 0.000066]\n",
      "Training:  90%|████████▉ | 44999/50000 [55:34<06:14, 13.36it/s][Iteration 045000/050000] [loss: 0.00543525] [loss_bc: 0.00474824; loss_div: 0.00047741; loss_ff: 0.00020960] [w_bc: 1.000000, LR: 0.000063]\n",
      "Training:  92%|█████████▏| 45999/50000 [56:48<04:54, 13.58it/s][Iteration 046000/050000] [loss: 0.00536090] [loss_bc: 0.00468028; loss_div: 0.00044607; loss_ff: 0.00023455] [w_bc: 1.000000, LR: 0.000060]\n",
      "Training:  94%|█████████▍| 46999/50000 [58:02<03:44, 13.35it/s][Iteration 047000/050000] [loss: 0.00496506] [loss_bc: 0.00439965; loss_div: 0.00040260; loss_ff: 0.00016282] [w_bc: 1.000000, LR: 0.000057]\n",
      "Training:  96%|█████████▌| 47999/50000 [59:16<02:37, 12.68it/s][Iteration 048000/050000] [loss: 0.00586930] [loss_bc: 0.00518686; loss_div: 0.00046782; loss_ff: 0.00021462] [w_bc: 1.000000, LR: 0.000055]\n",
      "Training:  98%|█████████▊| 48999/50000 [1:00:31<01:12, 13.83it/s][Iteration 049000/050000] [loss: 0.00528759] [loss_bc: 0.00470703; loss_div: 0.00042108; loss_ff: 0.00015948] [w_bc: 1.000000, LR: 0.000052]\n",
      "Training: 100%|█████████▉| 49999/50000 [1:01:45<00:00, 13.70it/s][Iteration 050000/050000] [loss: 0.00548254] [loss_bc: 0.00492673; loss_div: 0.00041049; loss_ff: 0.00014532] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training: 100%|██████████| 50000/50000 [1:01:45<00:00, 13.49it/s]\n",
      "[Iteration 050000/050000] [loss: 0.00548254] [loss_bc: 0.00492673; loss_div: 0.00041049; loss_ff: 0.00014532] [w_bc: 1.000000, LR: 0.000050]\n",
      "Runtime --> total: 3706.13sec (74.12ms/iter.)\n",
      "Configuration:\n",
      "dim: 256, w_div: 1.000000, w_ff: 1.000000, decay_iterations: None, potential: True, vector_potential: False, \n",
      "Using device: cuda (gpus 1) ['NVIDIA RTX A6000']\n",
      "Potential Boundary: 100%|██████████| 1/1 [00:00<00:00,  1.07it/s]\n",
      "Loaded meta state: /userhome/jeon_mg/workspace/_data/NOAA12673/PINN/20170906_083600/model_final.pt\n",
      "Training:   0%|          | 0/2000 [00:00<?, ?it/s][Iteration 000000/002000] [loss: 0.00536378] [loss_bc: 0.00477342; loss_div: 0.00042154; loss_ff: 0.00016882] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:   5%|▍         | 98/2000 [00:07<02:18, 13.78it/s][Iteration 000100/002000] [loss: 0.00529638] [loss_bc: 0.00477584; loss_div: 0.00037647; loss_ff: 0.00014407] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  10%|▉         | 198/2000 [00:14<02:12, 13.59it/s][Iteration 000200/002000] [loss: 0.00486206] [loss_bc: 0.00427016; loss_div: 0.00044171; loss_ff: 0.00015020] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  15%|█▍        | 298/2000 [00:21<02:03, 13.75it/s][Iteration 000300/002000] [loss: 0.00509151] [loss_bc: 0.00446475; loss_div: 0.00044607; loss_ff: 0.00018069] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  20%|█▉        | 398/2000 [00:29<01:57, 13.62it/s][Iteration 000400/002000] [loss: 0.00541227] [loss_bc: 0.00476250; loss_div: 0.00047920; loss_ff: 0.00017057] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  25%|██▍       | 498/2000 [00:36<01:49, 13.69it/s][Iteration 000500/002000] [loss: 0.00551560] [loss_bc: 0.00475498; loss_div: 0.00053098; loss_ff: 0.00022965] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  30%|██▉       | 598/2000 [00:44<01:41, 13.83it/s][Iteration 000600/002000] [loss: 0.00547023] [loss_bc: 0.00480594; loss_div: 0.00048253; loss_ff: 0.00018176] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  35%|███▍      | 698/2000 [00:51<01:34, 13.84it/s][Iteration 000700/002000] [loss: 0.00528276] [loss_bc: 0.00475431; loss_div: 0.00039156; loss_ff: 0.00013689] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  40%|███▉      | 798/2000 [00:59<01:27, 13.67it/s][Iteration 000800/002000] [loss: 0.00545346] [loss_bc: 0.00475238; loss_div: 0.00050711; loss_ff: 0.00019397] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  45%|████▍     | 898/2000 [01:06<01:23, 13.20it/s][Iteration 000900/002000] [loss: 0.00564285] [loss_bc: 0.00502932; loss_div: 0.00041492; loss_ff: 0.00019862] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  50%|████▉     | 998/2000 [01:13<01:13, 13.64it/s][Iteration 001000/002000] [loss: 0.00494367] [loss_bc: 0.00427864; loss_div: 0.00045877; loss_ff: 0.00020626] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  55%|█████▍    | 1098/2000 [01:21<01:06, 13.57it/s][Iteration 001100/002000] [loss: 0.00509413] [loss_bc: 0.00446527; loss_div: 0.00047067; loss_ff: 0.00015819] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  60%|█████▉    | 1198/2000 [01:28<00:58, 13.80it/s][Iteration 001200/002000] [loss: 0.00514246] [loss_bc: 0.00459806; loss_div: 0.00039633; loss_ff: 0.00014807] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  65%|██████▍   | 1298/2000 [01:35<00:52, 13.49it/s][Iteration 001300/002000] [loss: 0.00522955] [loss_bc: 0.00463842; loss_div: 0.00043972; loss_ff: 0.00015141] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  70%|██████▉   | 1398/2000 [01:43<00:44, 13.62it/s][Iteration 001400/002000] [loss: 0.00539270] [loss_bc: 0.00478038; loss_div: 0.00045258; loss_ff: 0.00015974] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  75%|███████▍  | 1498/2000 [01:50<00:38, 13.19it/s][Iteration 001500/002000] [loss: 0.00540827] [loss_bc: 0.00482447; loss_div: 0.00039866; loss_ff: 0.00018513] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  80%|███████▉  | 1598/2000 [01:58<00:29, 13.52it/s][Iteration 001600/002000] [loss: 0.00556774] [loss_bc: 0.00499648; loss_div: 0.00042049; loss_ff: 0.00015077] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  85%|████████▍ | 1698/2000 [02:05<00:22, 13.67it/s][Iteration 001700/002000] [loss: 0.00518619] [loss_bc: 0.00459785; loss_div: 0.00041454; loss_ff: 0.00017381] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  90%|████████▉ | 1798/2000 [02:12<00:15, 13.43it/s][Iteration 001800/002000] [loss: 0.00542146] [loss_bc: 0.00481702; loss_div: 0.00041398; loss_ff: 0.00019047] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  95%|█████████▍| 1898/2000 [02:20<00:07, 13.80it/s][Iteration 001900/002000] [loss: 0.00506363] [loss_bc: 0.00443314; loss_div: 0.00045981; loss_ff: 0.00017068] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training: 100%|█████████▉| 1998/2000 [02:27<00:00, 13.22it/s][Iteration 002000/002000] [loss: 0.00477512] [loss_bc: 0.00426055; loss_div: 0.00036107; loss_ff: 0.00015350] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training: 100%|██████████| 2000/2000 [02:27<00:00, 13.51it/s]\n",
      "[Iteration 002000/002000] [loss: 0.00477512] [loss_bc: 0.00426055; loss_div: 0.00036107; loss_ff: 0.00015350] [w_bc: 1.000000, LR: 0.000050]\n",
      "Runtime --> total: 148.15sec (2.96ms/iter.)\n",
      "Configuration:\n",
      "dim: 256, w_div: 1.000000, w_ff: 1.000000, decay_iterations: None, potential: True, vector_potential: False, \n",
      "Using device: cuda (gpus 1) ['NVIDIA RTX A6000']\n",
      "Potential Boundary: 100%|██████████| 1/1 [00:00<00:00,  1.06it/s]\n",
      "Loaded meta state: /userhome/jeon_mg/workspace/_data/NOAA12673/PINN/20170906_084800/model_final.pt\n",
      "Training:   0%|          | 0/2000 [00:00<?, ?it/s][Iteration 000000/002000] [loss: 0.00563576] [loss_bc: 0.00507901; loss_div: 0.00038120; loss_ff: 0.00017554] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:   5%|▍         | 98/2000 [00:07<02:17, 13.79it/s][Iteration 000100/002000] [loss: 0.00594440] [loss_bc: 0.00536719; loss_div: 0.00039187; loss_ff: 0.00018534] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  10%|▉         | 198/2000 [00:14<02:13, 13.50it/s][Iteration 000200/002000] [loss: 0.00557801] [loss_bc: 0.00504645; loss_div: 0.00036872; loss_ff: 0.00016285] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  15%|█▍        | 298/2000 [00:22<02:09, 13.18it/s][Iteration 000300/002000] [loss: 0.00596103] [loss_bc: 0.00535463; loss_div: 0.00040106; loss_ff: 0.00020534] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  20%|█▉        | 398/2000 [00:29<01:57, 13.63it/s][Iteration 000400/002000] [loss: 0.00594719] [loss_bc: 0.00538780; loss_div: 0.00037877; loss_ff: 0.00018063] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  25%|██▍       | 498/2000 [00:36<01:54, 13.07it/s][Iteration 000500/002000] [loss: 0.00560341] [loss_bc: 0.00505971; loss_div: 0.00039166; loss_ff: 0.00015205] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  30%|██▉       | 598/2000 [00:44<01:41, 13.79it/s][Iteration 000600/002000] [loss: 0.00588300] [loss_bc: 0.00534100; loss_div: 0.00037849; loss_ff: 0.00016351] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  35%|███▍      | 698/2000 [00:51<01:36, 13.49it/s][Iteration 000700/002000] [loss: 0.00546438] [loss_bc: 0.00492894; loss_div: 0.00036647; loss_ff: 0.00016897] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  40%|███▉      | 798/2000 [00:59<01:27, 13.74it/s][Iteration 000800/002000] [loss: 0.00547232] [loss_bc: 0.00492269; loss_div: 0.00039265; loss_ff: 0.00015697] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  45%|████▍     | 898/2000 [01:06<01:21, 13.53it/s][Iteration 000900/002000] [loss: 0.00585233] [loss_bc: 0.00528010; loss_div: 0.00041510; loss_ff: 0.00015713] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  50%|████▉     | 998/2000 [01:13<01:14, 13.40it/s][Iteration 001000/002000] [loss: 0.00591243] [loss_bc: 0.00531096; loss_div: 0.00043015; loss_ff: 0.00017131] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  55%|█████▍    | 1098/2000 [01:21<01:06, 13.64it/s][Iteration 001100/002000] [loss: 0.00570388] [loss_bc: 0.00503234; loss_div: 0.00047453; loss_ff: 0.00019701] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  60%|█████▉    | 1198/2000 [01:28<01:00, 13.17it/s][Iteration 001200/002000] [loss: 0.00625118] [loss_bc: 0.00568622; loss_div: 0.00039943; loss_ff: 0.00016552] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  65%|██████▍   | 1298/2000 [01:36<00:51, 13.57it/s][Iteration 001300/002000] [loss: 0.00595348] [loss_bc: 0.00529466; loss_div: 0.00044567; loss_ff: 0.00021315] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  70%|██████▉   | 1398/2000 [01:43<00:44, 13.58it/s][Iteration 001400/002000] [loss: 0.00592073] [loss_bc: 0.00528109; loss_div: 0.00045610; loss_ff: 0.00018354] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  75%|███████▍  | 1498/2000 [01:50<00:37, 13.40it/s][Iteration 001500/002000] [loss: 0.00562728] [loss_bc: 0.00500875; loss_div: 0.00041010; loss_ff: 0.00020843] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  80%|███████▉  | 1598/2000 [01:58<00:29, 13.57it/s][Iteration 001600/002000] [loss: 0.00588570] [loss_bc: 0.00531327; loss_div: 0.00038438; loss_ff: 0.00018806] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  85%|████████▍ | 1698/2000 [02:05<00:22, 13.21it/s][Iteration 001700/002000] [loss: 0.00586287] [loss_bc: 0.00534159; loss_div: 0.00035405; loss_ff: 0.00016724] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  90%|████████▉ | 1798/2000 [02:13<00:14, 13.60it/s][Iteration 001800/002000] [loss: 0.00595757] [loss_bc: 0.00527629; loss_div: 0.00046689; loss_ff: 0.00021439] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  95%|█████████▍| 1898/2000 [02:20<00:07, 13.75it/s][Iteration 001900/002000] [loss: 0.00579102] [loss_bc: 0.00527379; loss_div: 0.00035852; loss_ff: 0.00015871] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training: 100%|█████████▉| 1998/2000 [02:27<00:00, 13.12it/s][Iteration 002000/002000] [loss: 0.00556907] [loss_bc: 0.00489579; loss_div: 0.00049494; loss_ff: 0.00017834] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training: 100%|██████████| 2000/2000 [02:28<00:00, 13.50it/s]\n",
      "[Iteration 002000/002000] [loss: 0.00556907] [loss_bc: 0.00489579; loss_div: 0.00049494; loss_ff: 0.00017834] [w_bc: 1.000000, LR: 0.000050]\n",
      "Runtime --> total: 148.29sec (2.97ms/iter.)\n",
      "Configuration:\n",
      "dim: 256, w_div: 1.000000, w_ff: 1.000000, decay_iterations: None, potential: True, vector_potential: False, \n",
      "Using device: cuda (gpus 1) ['NVIDIA RTX A6000']\n",
      "Potential Boundary: 100%|██████████| 1/1 [00:01<00:00,  1.09s/it]\n",
      "Loaded meta state: /userhome/jeon_mg/workspace/_data/NOAA12673/PINN/20170906_090000/model_final.pt\n",
      "Training:   0%|          | 0/2000 [00:00<?, ?it/s][Iteration 000000/002000] [loss: 0.00804604] [loss_bc: 0.00742887; loss_div: 0.00044074; loss_ff: 0.00017643] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:   5%|▍         | 98/2000 [00:07<02:19, 13.60it/s][Iteration 000100/002000] [loss: 0.00717700] [loss_bc: 0.00669673; loss_div: 0.00033125; loss_ff: 0.00014902] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  10%|▉         | 198/2000 [00:14<02:13, 13.51it/s][Iteration 000200/002000] [loss: 0.00726750] [loss_bc: 0.00661621; loss_div: 0.00045606; loss_ff: 0.00019523] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  15%|█▍        | 298/2000 [00:22<02:05, 13.57it/s][Iteration 000300/002000] [loss: 0.00675886] [loss_bc: 0.00622161; loss_div: 0.00039498; loss_ff: 0.00014226] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  20%|█▉        | 398/2000 [00:29<01:56, 13.73it/s][Iteration 000400/002000] [loss: 0.00924302] [loss_bc: 0.00859311; loss_div: 0.00041775; loss_ff: 0.00023216] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  25%|██▍       | 498/2000 [00:36<01:51, 13.53it/s][Iteration 000500/002000] [loss: 0.00684056] [loss_bc: 0.00619700; loss_div: 0.00044353; loss_ff: 0.00020003] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  30%|██▉       | 598/2000 [00:44<01:46, 13.20it/s][Iteration 000600/002000] [loss: 0.00684266] [loss_bc: 0.00626023; loss_div: 0.00042504; loss_ff: 0.00015740] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  35%|███▍      | 698/2000 [00:51<01:34, 13.75it/s][Iteration 000700/002000] [loss: 0.00708592] [loss_bc: 0.00649987; loss_div: 0.00042972; loss_ff: 0.00015634] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  40%|███▉      | 798/2000 [00:59<01:30, 13.23it/s][Iteration 000800/002000] [loss: 0.00901566] [loss_bc: 0.00839712; loss_div: 0.00044056; loss_ff: 0.00017798] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  45%|████▍     | 898/2000 [01:06<01:20, 13.69it/s][Iteration 000900/002000] [loss: 0.00679508] [loss_bc: 0.00621633; loss_div: 0.00039421; loss_ff: 0.00018455] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  50%|████▉     | 998/2000 [01:14<01:13, 13.57it/s][Iteration 001000/002000] [loss: 0.00683962] [loss_bc: 0.00619805; loss_div: 0.00046543; loss_ff: 0.00017614] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  55%|█████▍    | 1098/2000 [01:21<01:05, 13.71it/s][Iteration 001100/002000] [loss: 0.00702545] [loss_bc: 0.00644331; loss_div: 0.00040032; loss_ff: 0.00018181] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  60%|█████▉    | 1198/2000 [01:28<01:00, 13.16it/s][Iteration 001200/002000] [loss: 0.00696659] [loss_bc: 0.00639811; loss_div: 0.00039208; loss_ff: 0.00017640] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  65%|██████▍   | 1298/2000 [01:36<00:51, 13.58it/s][Iteration 001300/002000] [loss: 0.00668276] [loss_bc: 0.00618560; loss_div: 0.00034732; loss_ff: 0.00014984] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  70%|██████▉   | 1398/2000 [01:43<00:44, 13.63it/s][Iteration 001400/002000] [loss: 0.00682912] [loss_bc: 0.00634134; loss_div: 0.00032448; loss_ff: 0.00016330] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  75%|███████▍  | 1498/2000 [01:51<00:36, 13.72it/s][Iteration 001500/002000] [loss: 0.00694015] [loss_bc: 0.00641171; loss_div: 0.00038603; loss_ff: 0.00014241] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  80%|███████▉  | 1598/2000 [01:58<00:29, 13.84it/s][Iteration 001600/002000] [loss: 0.00689234] [loss_bc: 0.00635833; loss_div: 0.00039465; loss_ff: 0.00013936] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  85%|████████▍ | 1698/2000 [02:05<00:22, 13.39it/s][Iteration 001700/002000] [loss: 0.00692025] [loss_bc: 0.00635023; loss_div: 0.00040352; loss_ff: 0.00016649] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  90%|████████▉ | 1798/2000 [02:13<00:15, 13.32it/s][Iteration 001800/002000] [loss: 0.00876977] [loss_bc: 0.00820396; loss_div: 0.00042055; loss_ff: 0.00014526] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  95%|█████████▍| 1898/2000 [02:20<00:07, 13.69it/s][Iteration 001900/002000] [loss: 0.00690891] [loss_bc: 0.00639369; loss_div: 0.00035893; loss_ff: 0.00015629] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training: 100%|█████████▉| 1998/2000 [02:28<00:00, 13.45it/s][Iteration 002000/002000] [loss: 0.00671958] [loss_bc: 0.00616338; loss_div: 0.00040542; loss_ff: 0.00015077] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training: 100%|██████████| 2000/2000 [02:28<00:00, 13.48it/s]\n",
      "[Iteration 002000/002000] [loss: 0.00671958] [loss_bc: 0.00616338; loss_div: 0.00040542; loss_ff: 0.00015077] [w_bc: 1.000000, LR: 0.000050]\n",
      "Runtime --> total: 148.55sec (2.97ms/iter.)\n",
      "Configuration:\n",
      "dim: 256, w_div: 1.000000, w_ff: 1.000000, decay_iterations: None, potential: True, vector_potential: False, \n",
      "Using device: cuda (gpus 1) ['NVIDIA RTX A6000']\n",
      "Potential Boundary: 100%|██████████| 1/1 [00:00<00:00,  1.05it/s]\n",
      "Loaded meta state: /userhome/jeon_mg/workspace/_data/NOAA12673/PINN/20170906_091200/model_final.pt\n",
      "Training:   0%|          | 0/2000 [00:00<?, ?it/s][Iteration 000000/002000] [loss: 0.00574912] [loss_bc: 0.00522789; loss_div: 0.00037875; loss_ff: 0.00014248] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:   5%|▍         | 98/2000 [00:07<02:19, 13.63it/s][Iteration 000100/002000] [loss: 0.00618319] [loss_bc: 0.00563679; loss_div: 0.00035596; loss_ff: 0.00019045] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  10%|▉         | 198/2000 [00:14<02:15, 13.27it/s][Iteration 000200/002000] [loss: 0.00558953] [loss_bc: 0.00492541; loss_div: 0.00049071; loss_ff: 0.00017342] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  15%|█▍        | 298/2000 [00:21<02:07, 13.34it/s][Iteration 000300/002000] [loss: 0.00613488] [loss_bc: 0.00551013; loss_div: 0.00045315; loss_ff: 0.00017161] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  20%|█▉        | 398/2000 [00:29<01:57, 13.68it/s][Iteration 000400/002000] [loss: 0.00617023] [loss_bc: 0.00548440; loss_div: 0.00050709; loss_ff: 0.00017874] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  25%|██▍       | 498/2000 [00:36<01:49, 13.67it/s][Iteration 000500/002000] [loss: 0.00631427] [loss_bc: 0.00571238; loss_div: 0.00042438; loss_ff: 0.00017750] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  30%|██▉       | 598/2000 [00:44<01:43, 13.61it/s][Iteration 000600/002000] [loss: 0.00641802] [loss_bc: 0.00583987; loss_div: 0.00041270; loss_ff: 0.00016544] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  35%|███▍      | 698/2000 [00:51<01:34, 13.71it/s][Iteration 000700/002000] [loss: 0.00587126] [loss_bc: 0.00528126; loss_div: 0.00042454; loss_ff: 0.00016546] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  40%|███▉      | 798/2000 [00:58<01:27, 13.70it/s][Iteration 000800/002000] [loss: 0.00539016] [loss_bc: 0.00484989; loss_div: 0.00037331; loss_ff: 0.00016696] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  45%|████▍     | 898/2000 [01:06<01:20, 13.76it/s][Iteration 000900/002000] [loss: 0.00583748] [loss_bc: 0.00527422; loss_div: 0.00041498; loss_ff: 0.00014828] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  50%|████▉     | 998/2000 [01:13<01:14, 13.53it/s][Iteration 001000/002000] [loss: 0.00643382] [loss_bc: 0.00581150; loss_div: 0.00045634; loss_ff: 0.00016597] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  55%|█████▍    | 1098/2000 [01:21<01:05, 13.69it/s][Iteration 001100/002000] [loss: 0.00596381] [loss_bc: 0.00540347; loss_div: 0.00040265; loss_ff: 0.00015768] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  60%|█████▉    | 1198/2000 [01:28<00:58, 13.70it/s][Iteration 001200/002000] [loss: 0.00635033] [loss_bc: 0.00569090; loss_div: 0.00046068; loss_ff: 0.00019874] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  65%|██████▍   | 1298/2000 [01:35<00:51, 13.55it/s][Iteration 001300/002000] [loss: 0.00535615] [loss_bc: 0.00482722; loss_div: 0.00037923; loss_ff: 0.00014970] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  70%|██████▉   | 1398/2000 [01:43<00:44, 13.56it/s][Iteration 001400/002000] [loss: 0.00557510] [loss_bc: 0.00502618; loss_div: 0.00039483; loss_ff: 0.00015408] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  75%|███████▍  | 1498/2000 [01:50<00:36, 13.69it/s][Iteration 001500/002000] [loss: 0.00549995] [loss_bc: 0.00488450; loss_div: 0.00043582; loss_ff: 0.00017963] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  80%|███████▉  | 1598/2000 [01:58<00:29, 13.72it/s][Iteration 001600/002000] [loss: 0.00579226] [loss_bc: 0.00524333; loss_div: 0.00039923; loss_ff: 0.00014970] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  85%|████████▍ | 1698/2000 [02:05<00:22, 13.65it/s][Iteration 001700/002000] [loss: 0.00627774] [loss_bc: 0.00568817; loss_div: 0.00041498; loss_ff: 0.00017460] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  90%|████████▉ | 1798/2000 [02:12<00:14, 13.81it/s][Iteration 001800/002000] [loss: 0.00602715] [loss_bc: 0.00548251; loss_div: 0.00040103; loss_ff: 0.00014361] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  95%|█████████▍| 1898/2000 [02:20<00:07, 12.93it/s][Iteration 001900/002000] [loss: 0.00543557] [loss_bc: 0.00486915; loss_div: 0.00040868; loss_ff: 0.00015774] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training: 100%|█████████▉| 1998/2000 [02:27<00:00, 13.34it/s][Iteration 002000/002000] [loss: 0.00630778] [loss_bc: 0.00547182; loss_div: 0.00054120; loss_ff: 0.00029476] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training: 100%|██████████| 2000/2000 [02:28<00:00, 13.51it/s]\n",
      "[Iteration 002000/002000] [loss: 0.00630778] [loss_bc: 0.00547182; loss_div: 0.00054120; loss_ff: 0.00029476] [w_bc: 1.000000, LR: 0.000050]\n",
      "Runtime --> total: 148.24sec (2.96ms/iter.)\n",
      "Configuration:\n",
      "dim: 256, w_div: 1.000000, w_ff: 1.000000, decay_iterations: None, potential: True, vector_potential: False, \n",
      "Using device: cuda (gpus 1) ['NVIDIA RTX A6000']\n",
      "Potential Boundary: 100%|██████████| 1/1 [00:01<00:00,  1.02s/it]\n",
      "Loaded meta state: /userhome/jeon_mg/workspace/_data/NOAA12673/PINN/20170906_092400/model_final.pt\n",
      "Training:   0%|          | 0/2000 [00:00<?, ?it/s][Iteration 000000/002000] [loss: 0.00564885] [loss_bc: 0.00486519; loss_div: 0.00049020; loss_ff: 0.00029346] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:   5%|▍         | 98/2000 [00:07<02:18, 13.75it/s][Iteration 000100/002000] [loss: 0.00559451] [loss_bc: 0.00505479; loss_div: 0.00038096; loss_ff: 0.00015876] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  10%|▉         | 198/2000 [00:14<02:12, 13.64it/s][Iteration 000200/002000] [loss: 0.00573546] [loss_bc: 0.00503375; loss_div: 0.00049106; loss_ff: 0.00021065] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  15%|█▍        | 298/2000 [00:22<02:03, 13.77it/s][Iteration 000300/002000] [loss: 0.00581697] [loss_bc: 0.00520935; loss_div: 0.00042930; loss_ff: 0.00017831] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  20%|█▉        | 398/2000 [00:29<01:56, 13.73it/s][Iteration 000400/002000] [loss: 0.00538411] [loss_bc: 0.00478969; loss_div: 0.00042502; loss_ff: 0.00016941] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  25%|██▍       | 498/2000 [00:36<01:51, 13.52it/s][Iteration 000500/002000] [loss: 0.00588742] [loss_bc: 0.00527889; loss_div: 0.00042551; loss_ff: 0.00018303] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  30%|██▉       | 598/2000 [00:44<01:45, 13.33it/s][Iteration 000600/002000] [loss: 0.00556709] [loss_bc: 0.00496729; loss_div: 0.00041666; loss_ff: 0.00018314] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  35%|███▍      | 698/2000 [00:51<01:34, 13.77it/s][Iteration 000700/002000] [loss: 0.00542779] [loss_bc: 0.00494208; loss_div: 0.00036349; loss_ff: 0.00012222] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  40%|███▉      | 798/2000 [00:59<01:29, 13.47it/s][Iteration 000800/002000] [loss: 0.00575397] [loss_bc: 0.00518033; loss_div: 0.00041038; loss_ff: 0.00016326] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  45%|████▍     | 898/2000 [01:06<01:21, 13.53it/s][Iteration 000900/002000] [loss: 0.00552637] [loss_bc: 0.00491324; loss_div: 0.00043329; loss_ff: 0.00017984] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  50%|████▉     | 998/2000 [01:14<01:13, 13.70it/s][Iteration 001000/002000] [loss: 0.00560538] [loss_bc: 0.00499750; loss_div: 0.00042993; loss_ff: 0.00017795] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  55%|█████▍    | 1098/2000 [01:21<01:06, 13.61it/s][Iteration 001100/002000] [loss: 0.00552445] [loss_bc: 0.00498168; loss_div: 0.00039821; loss_ff: 0.00014455] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  60%|█████▉    | 1198/2000 [01:28<01:00, 13.33it/s][Iteration 001200/002000] [loss: 0.00546738] [loss_bc: 0.00494286; loss_div: 0.00035076; loss_ff: 0.00017376] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  65%|██████▍   | 1298/2000 [01:36<00:51, 13.66it/s][Iteration 001300/002000] [loss: 0.00558898] [loss_bc: 0.00503114; loss_div: 0.00037948; loss_ff: 0.00017837] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  70%|██████▉   | 1398/2000 [01:43<00:43, 13.73it/s][Iteration 001400/002000] [loss: 0.00547934] [loss_bc: 0.00488795; loss_div: 0.00041797; loss_ff: 0.00017342] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  75%|███████▍  | 1498/2000 [01:51<00:36, 13.79it/s][Iteration 001500/002000] [loss: 0.00561955] [loss_bc: 0.00489775; loss_div: 0.00054295; loss_ff: 0.00017885] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  80%|███████▉  | 1598/2000 [01:58<00:29, 13.48it/s][Iteration 001600/002000] [loss: 0.00574459] [loss_bc: 0.00515548; loss_div: 0.00044015; loss_ff: 0.00014896] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  85%|████████▍ | 1698/2000 [02:05<00:22, 13.38it/s][Iteration 001700/002000] [loss: 0.00550276] [loss_bc: 0.00489186; loss_div: 0.00042245; loss_ff: 0.00018845] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  90%|████████▉ | 1798/2000 [02:13<00:14, 13.79it/s][Iteration 001800/002000] [loss: 0.00587231] [loss_bc: 0.00521072; loss_div: 0.00048012; loss_ff: 0.00018146] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  95%|█████████▍| 1898/2000 [02:20<00:07, 13.72it/s][Iteration 001900/002000] [loss: 0.00572201] [loss_bc: 0.00501519; loss_div: 0.00048936; loss_ff: 0.00021745] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training: 100%|█████████▉| 1998/2000 [02:28<00:00, 13.58it/s][Iteration 002000/002000] [loss: 0.00544438] [loss_bc: 0.00487572; loss_div: 0.00041319; loss_ff: 0.00015546] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training: 100%|██████████| 2000/2000 [02:28<00:00, 13.48it/s]\n",
      "[Iteration 002000/002000] [loss: 0.00544438] [loss_bc: 0.00487572; loss_div: 0.00041319; loss_ff: 0.00015546] [w_bc: 1.000000, LR: 0.000050]\n",
      "Runtime --> total: 148.49sec (2.97ms/iter.)\n",
      "Configuration:\n",
      "dim: 256, w_div: 1.000000, w_ff: 1.000000, decay_iterations: None, potential: True, vector_potential: False, \n",
      "Using device: cuda (gpus 1) ['NVIDIA RTX A6000']\n",
      "Potential Boundary: 100%|██████████| 1/1 [00:00<00:00,  1.17it/s]\n",
      "Loaded meta state: /userhome/jeon_mg/workspace/_data/NOAA12673/PINN/20170906_093600/model_final.pt\n",
      "Training:   0%|          | 0/2000 [00:00<?, ?it/s][Iteration 000000/002000] [loss: 0.00552715] [loss_bc: 0.00497735; loss_div: 0.00039675; loss_ff: 0.00015305] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:   5%|▍         | 98/2000 [00:07<02:17, 13.81it/s][Iteration 000100/002000] [loss: 0.00539210] [loss_bc: 0.00473479; loss_div: 0.00048469; loss_ff: 0.00017262] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  10%|▉         | 198/2000 [00:14<02:14, 13.36it/s][Iteration 000200/002000] [loss: 0.00553992] [loss_bc: 0.00488160; loss_div: 0.00048611; loss_ff: 0.00017221] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  15%|█▍        | 298/2000 [00:21<02:05, 13.52it/s][Iteration 000300/002000] [loss: 0.00543854] [loss_bc: 0.00494063; loss_div: 0.00034183; loss_ff: 0.00015607] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  20%|█▉        | 398/2000 [00:29<01:56, 13.76it/s][Iteration 000400/002000] [loss: 0.00547161] [loss_bc: 0.00488378; loss_div: 0.00040989; loss_ff: 0.00017794] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  25%|██▍       | 498/2000 [00:36<01:49, 13.72it/s][Iteration 000500/002000] [loss: 0.00541676] [loss_bc: 0.00484268; loss_div: 0.00038795; loss_ff: 0.00018613] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  30%|██▉       | 598/2000 [00:44<01:44, 13.48it/s][Iteration 000600/002000] [loss: 0.00523160] [loss_bc: 0.00471141; loss_div: 0.00035151; loss_ff: 0.00016867] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  35%|███▍      | 698/2000 [00:51<01:42, 12.73it/s][Iteration 000700/002000] [loss: 0.00544781] [loss_bc: 0.00487506; loss_div: 0.00040573; loss_ff: 0.00016701] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  40%|███▉      | 798/2000 [00:59<01:29, 13.50it/s][Iteration 000800/002000] [loss: 0.00545954] [loss_bc: 0.00482965; loss_div: 0.00044144; loss_ff: 0.00018845] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  45%|████▍     | 898/2000 [01:06<01:22, 13.35it/s][Iteration 000900/002000] [loss: 0.00557767] [loss_bc: 0.00493796; loss_div: 0.00044380; loss_ff: 0.00019591] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  50%|████▉     | 998/2000 [01:13<01:13, 13.55it/s][Iteration 001000/002000] [loss: 0.00534776] [loss_bc: 0.00484309; loss_div: 0.00035955; loss_ff: 0.00014512] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  55%|█████▍    | 1098/2000 [01:21<01:06, 13.49it/s][Iteration 001100/002000] [loss: 0.00541550] [loss_bc: 0.00492236; loss_div: 0.00037343; loss_ff: 0.00011971] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  60%|█████▉    | 1198/2000 [01:28<01:00, 13.28it/s][Iteration 001200/002000] [loss: 0.00548142] [loss_bc: 0.00488561; loss_div: 0.00040464; loss_ff: 0.00019116] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  65%|██████▍   | 1298/2000 [01:36<00:51, 13.70it/s][Iteration 001300/002000] [loss: 0.00536835] [loss_bc: 0.00482903; loss_div: 0.00038438; loss_ff: 0.00015494] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  70%|██████▉   | 1398/2000 [01:43<00:43, 13.70it/s][Iteration 001400/002000] [loss: 0.00540406] [loss_bc: 0.00482059; loss_div: 0.00039782; loss_ff: 0.00018565] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  75%|███████▍  | 1498/2000 [01:50<00:36, 13.81it/s][Iteration 001500/002000] [loss: 0.00567623] [loss_bc: 0.00520608; loss_div: 0.00034681; loss_ff: 0.00012334] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  80%|███████▉  | 1598/2000 [01:58<00:29, 13.61it/s][Iteration 001600/002000] [loss: 0.00536946] [loss_bc: 0.00480321; loss_div: 0.00039238; loss_ff: 0.00017386] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  85%|████████▍ | 1698/2000 [02:05<00:22, 13.60it/s][Iteration 001700/002000] [loss: 0.00541749] [loss_bc: 0.00481134; loss_div: 0.00043354; loss_ff: 0.00017260] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  90%|████████▉ | 1798/2000 [02:12<00:14, 13.70it/s][Iteration 001800/002000] [loss: 0.00556528] [loss_bc: 0.00492704; loss_div: 0.00044171; loss_ff: 0.00019653] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  95%|█████████▍| 1898/2000 [02:20<00:07, 13.62it/s][Iteration 001900/002000] [loss: 0.00541898] [loss_bc: 0.00482455; loss_div: 0.00045886; loss_ff: 0.00013557] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training: 100%|█████████▉| 1998/2000 [02:27<00:00, 13.76it/s][Iteration 002000/002000] [loss: 0.00537029] [loss_bc: 0.00479721; loss_div: 0.00040468; loss_ff: 0.00016840] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training: 100%|██████████| 2000/2000 [02:27<00:00, 13.53it/s]\n",
      "[Iteration 002000/002000] [loss: 0.00537029] [loss_bc: 0.00479721; loss_div: 0.00040468; loss_ff: 0.00016840] [w_bc: 1.000000, LR: 0.000050]\n",
      "Runtime --> total: 148.04sec (2.96ms/iter.)\n",
      "Configuration:\n",
      "dim: 256, w_div: 1.000000, w_ff: 1.000000, decay_iterations: None, potential: True, vector_potential: False, \n",
      "Using device: cuda (gpus 1) ['NVIDIA RTX A6000']\n",
      "Potential Boundary: 100%|██████████| 1/1 [00:00<00:00,  1.22it/s]\n",
      "Loaded meta state: /userhome/jeon_mg/workspace/_data/NOAA12673/PINN/20170906_094800/model_final.pt\n",
      "Training:   0%|          | 0/2000 [00:00<?, ?it/s][Iteration 000000/002000] [loss: 0.00602551] [loss_bc: 0.00543954; loss_div: 0.00040715; loss_ff: 0.00017882] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:   5%|▍         | 98/2000 [00:07<02:19, 13.66it/s][Iteration 000100/002000] [loss: 0.00563767] [loss_bc: 0.00503292; loss_div: 0.00040831; loss_ff: 0.00019644] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  10%|▉         | 198/2000 [00:14<02:10, 13.85it/s][Iteration 000200/002000] [loss: 0.00580283] [loss_bc: 0.00525152; loss_div: 0.00040209; loss_ff: 0.00014922] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  15%|█▍        | 298/2000 [00:22<02:03, 13.79it/s][Iteration 000300/002000] [loss: 0.00562462] [loss_bc: 0.00498300; loss_div: 0.00043703; loss_ff: 0.00020460] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  20%|█▉        | 398/2000 [00:29<01:56, 13.73it/s][Iteration 000400/002000] [loss: 0.00557770] [loss_bc: 0.00501118; loss_div: 0.00040258; loss_ff: 0.00016394] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  25%|██▍       | 498/2000 [00:36<01:48, 13.81it/s][Iteration 000500/002000] [loss: 0.00509558] [loss_bc: 0.00457371; loss_div: 0.00034640; loss_ff: 0.00017547] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  30%|██▉       | 598/2000 [00:44<01:42, 13.62it/s][Iteration 000600/002000] [loss: 0.00581440] [loss_bc: 0.00523944; loss_div: 0.00040626; loss_ff: 0.00016870] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  35%|███▍      | 698/2000 [00:51<01:36, 13.46it/s][Iteration 000700/002000] [loss: 0.00557965] [loss_bc: 0.00502065; loss_div: 0.00038978; loss_ff: 0.00016923] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  40%|███▉      | 798/2000 [00:59<01:28, 13.65it/s][Iteration 000800/002000] [loss: 0.00583800] [loss_bc: 0.00523742; loss_div: 0.00045217; loss_ff: 0.00014841] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  45%|████▍     | 898/2000 [01:06<01:20, 13.64it/s][Iteration 000900/002000] [loss: 0.00537933] [loss_bc: 0.00486808; loss_div: 0.00036544; loss_ff: 0.00014582] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  50%|████▉     | 998/2000 [01:13<01:13, 13.68it/s][Iteration 001000/002000] [loss: 0.00589808] [loss_bc: 0.00523076; loss_div: 0.00043850; loss_ff: 0.00022883] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  55%|█████▍    | 1098/2000 [01:21<01:05, 13.67it/s][Iteration 001100/002000] [loss: 0.00540360] [loss_bc: 0.00485381; loss_div: 0.00038675; loss_ff: 0.00016304] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  60%|█████▉    | 1198/2000 [01:28<00:59, 13.59it/s][Iteration 001200/002000] [loss: 0.00563271] [loss_bc: 0.00499196; loss_div: 0.00045746; loss_ff: 0.00018330] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  65%|██████▍   | 1298/2000 [01:36<00:51, 13.64it/s][Iteration 001300/002000] [loss: 0.00598467] [loss_bc: 0.00535932; loss_div: 0.00044476; loss_ff: 0.00018059] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  70%|██████▉   | 1398/2000 [01:43<00:45, 13.30it/s][Iteration 001400/002000] [loss: 0.00557450] [loss_bc: 0.00494358; loss_div: 0.00045334; loss_ff: 0.00017758] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  75%|███████▍  | 1498/2000 [01:51<00:37, 13.41it/s][Iteration 001500/002000] [loss: 0.00557914] [loss_bc: 0.00496357; loss_div: 0.00043910; loss_ff: 0.00017647] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  80%|███████▉  | 1598/2000 [01:58<00:29, 13.73it/s][Iteration 001600/002000] [loss: 0.00564401] [loss_bc: 0.00508883; loss_div: 0.00038085; loss_ff: 0.00017432] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  85%|████████▍ | 1698/2000 [02:05<00:22, 13.57it/s][Iteration 001700/002000] [loss: 0.00552320] [loss_bc: 0.00493372; loss_div: 0.00040547; loss_ff: 0.00018402] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  90%|████████▉ | 1798/2000 [02:13<00:14, 13.74it/s][Iteration 001800/002000] [loss: 0.00550720] [loss_bc: 0.00491555; loss_div: 0.00042243; loss_ff: 0.00016923] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  95%|█████████▍| 1898/2000 [02:20<00:07, 13.38it/s][Iteration 001900/002000] [loss: 0.00600280] [loss_bc: 0.00534668; loss_div: 0.00046126; loss_ff: 0.00019487] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training: 100%|█████████▉| 1998/2000 [02:28<00:00, 13.59it/s][Iteration 002000/002000] [loss: 0.00557084] [loss_bc: 0.00499745; loss_div: 0.00040425; loss_ff: 0.00016915] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training: 100%|██████████| 2000/2000 [02:28<00:00, 13.47it/s]\n",
      "[Iteration 002000/002000] [loss: 0.00557084] [loss_bc: 0.00499745; loss_div: 0.00040425; loss_ff: 0.00016915] [w_bc: 1.000000, LR: 0.000050]\n",
      "Runtime --> total: 148.55sec (2.97ms/iter.)\n",
      "Configuration:\n",
      "dim: 256, w_div: 1.000000, w_ff: 1.000000, decay_iterations: None, potential: True, vector_potential: False, \n",
      "Using device: cuda (gpus 1) ['NVIDIA RTX A6000']\n",
      "Potential Boundary: 100%|██████████| 1/1 [00:00<00:00,  1.13it/s]\n",
      "Loaded meta state: /userhome/jeon_mg/workspace/_data/NOAA12673/PINN/20170906_100000/model_final.pt\n",
      "Training:   0%|          | 0/2000 [00:00<?, ?it/s][Iteration 000000/002000] [loss: 0.00610845] [loss_bc: 0.00557301; loss_div: 0.00036339; loss_ff: 0.00017204] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:   5%|▍         | 98/2000 [00:07<02:17, 13.82it/s][Iteration 000100/002000] [loss: 0.00553381] [loss_bc: 0.00501117; loss_div: 0.00037561; loss_ff: 0.00014703] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  10%|▉         | 198/2000 [00:14<02:12, 13.61it/s][Iteration 000200/002000] [loss: 0.00560643] [loss_bc: 0.00501707; loss_div: 0.00039517; loss_ff: 0.00019419] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  15%|█▍        | 298/2000 [00:22<02:04, 13.66it/s][Iteration 000300/002000] [loss: 0.00587731] [loss_bc: 0.00543803; loss_div: 0.00032446; loss_ff: 0.00011483] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  20%|█▉        | 398/2000 [00:29<02:04, 12.86it/s][Iteration 000400/002000] [loss: 0.00575777] [loss_bc: 0.00520260; loss_div: 0.00040239; loss_ff: 0.00015279] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  25%|██▍       | 498/2000 [00:36<01:50, 13.56it/s][Iteration 000500/002000] [loss: 0.00601700] [loss_bc: 0.00540539; loss_div: 0.00044847; loss_ff: 0.00016313] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  30%|██▉       | 598/2000 [00:44<01:42, 13.62it/s][Iteration 000600/002000] [loss: 0.00573462] [loss_bc: 0.00518423; loss_div: 0.00038285; loss_ff: 0.00016754] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  35%|███▍      | 698/2000 [00:51<01:37, 13.29it/s][Iteration 000700/002000] [loss: 0.00576843] [loss_bc: 0.00517639; loss_div: 0.00042458; loss_ff: 0.00016746] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  40%|███▉      | 798/2000 [00:59<01:27, 13.81it/s][Iteration 000800/002000] [loss: 0.00572486] [loss_bc: 0.00516508; loss_div: 0.00039528; loss_ff: 0.00016450] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  45%|████▍     | 898/2000 [01:06<01:19, 13.79it/s][Iteration 000900/002000] [loss: 0.00544235] [loss_bc: 0.00486415; loss_div: 0.00040836; loss_ff: 0.00016984] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  50%|████▉     | 998/2000 [01:13<01:12, 13.75it/s][Iteration 001000/002000] [loss: 0.00602146] [loss_bc: 0.00531459; loss_div: 0.00045452; loss_ff: 0.00025235] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  55%|█████▍    | 1098/2000 [01:21<01:06, 13.60it/s][Iteration 001100/002000] [loss: 0.00596261] [loss_bc: 0.00533964; loss_div: 0.00042192; loss_ff: 0.00020105] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  60%|█████▉    | 1198/2000 [01:28<00:58, 13.62it/s][Iteration 001200/002000] [loss: 0.00600011] [loss_bc: 0.00531124; loss_div: 0.00053141; loss_ff: 0.00015746] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  65%|██████▍   | 1298/2000 [01:36<00:51, 13.75it/s][Iteration 001300/002000] [loss: 0.00603249] [loss_bc: 0.00529355; loss_div: 0.00046527; loss_ff: 0.00027367] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  70%|██████▉   | 1398/2000 [01:43<00:43, 13.72it/s][Iteration 001400/002000] [loss: 0.00596913] [loss_bc: 0.00532385; loss_div: 0.00043980; loss_ff: 0.00020547] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  75%|███████▍  | 1498/2000 [01:51<00:36, 13.65it/s][Iteration 001500/002000] [loss: 0.00567566] [loss_bc: 0.00495402; loss_div: 0.00055634; loss_ff: 0.00016530] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  80%|███████▉  | 1598/2000 [01:58<00:29, 13.62it/s][Iteration 001600/002000] [loss: 0.00570817] [loss_bc: 0.00511228; loss_div: 0.00040030; loss_ff: 0.00019559] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  85%|████████▍ | 1698/2000 [02:05<00:22, 13.57it/s][Iteration 001700/002000] [loss: 0.00602625] [loss_bc: 0.00531787; loss_div: 0.00045997; loss_ff: 0.00024842] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  90%|████████▉ | 1798/2000 [02:13<00:15, 13.42it/s][Iteration 001800/002000] [loss: 0.00560611] [loss_bc: 0.00502205; loss_div: 0.00040140; loss_ff: 0.00018267] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  95%|█████████▍| 1898/2000 [02:20<00:07, 13.64it/s][Iteration 001900/002000] [loss: 0.00570404] [loss_bc: 0.00508797; loss_div: 0.00043432; loss_ff: 0.00018174] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training: 100%|█████████▉| 1998/2000 [02:28<00:00, 12.99it/s][Iteration 002000/002000] [loss: 0.00543177] [loss_bc: 0.00494286; loss_div: 0.00034624; loss_ff: 0.00014267] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training: 100%|██████████| 2000/2000 [02:28<00:00, 13.46it/s]\n",
      "[Iteration 002000/002000] [loss: 0.00543177] [loss_bc: 0.00494286; loss_div: 0.00034624; loss_ff: 0.00014267] [w_bc: 1.000000, LR: 0.000050]\n",
      "Runtime --> total: 148.72sec (2.97ms/iter.)\n",
      "Configuration:\n",
      "dim: 256, w_div: 1.000000, w_ff: 1.000000, decay_iterations: None, potential: True, vector_potential: False, \n",
      "Using device: cuda (gpus 1) ['NVIDIA RTX A6000']\n",
      "Potential Boundary: 100%|██████████| 1/1 [00:00<00:00,  1.11it/s]\n",
      "Loaded meta state: /userhome/jeon_mg/workspace/_data/NOAA12673/PINN/20170906_101200/model_final.pt\n",
      "Training:   0%|          | 0/2000 [00:00<?, ?it/s][Iteration 000000/002000] [loss: 0.00537449] [loss_bc: 0.00485597; loss_div: 0.00036477; loss_ff: 0.00015376] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:   5%|▍         | 98/2000 [00:07<02:20, 13.51it/s][Iteration 000100/002000] [loss: 0.00538336] [loss_bc: 0.00482929; loss_div: 0.00039945; loss_ff: 0.00015461] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  10%|▉         | 198/2000 [00:14<02:11, 13.68it/s][Iteration 000200/002000] [loss: 0.00574078] [loss_bc: 0.00519737; loss_div: 0.00038558; loss_ff: 0.00015783] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  15%|█▍        | 298/2000 [00:22<02:04, 13.62it/s][Iteration 000300/002000] [loss: 0.00506376] [loss_bc: 0.00455692; loss_div: 0.00035516; loss_ff: 0.00015168] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  20%|█▉        | 398/2000 [00:29<01:56, 13.80it/s][Iteration 000400/002000] [loss: 0.00546632] [loss_bc: 0.00495349; loss_div: 0.00035683; loss_ff: 0.00015600] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  25%|██▍       | 498/2000 [00:36<01:49, 13.71it/s][Iteration 000500/002000] [loss: 0.00575556] [loss_bc: 0.00517275; loss_div: 0.00039883; loss_ff: 0.00018398] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  30%|██▉       | 598/2000 [00:44<01:44, 13.46it/s][Iteration 000600/002000] [loss: 0.00539742] [loss_bc: 0.00480476; loss_div: 0.00042491; loss_ff: 0.00016774] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  35%|███▍      | 698/2000 [00:51<01:37, 13.30it/s][Iteration 000700/002000] [loss: 0.00562327] [loss_bc: 0.00499966; loss_div: 0.00045031; loss_ff: 0.00017330] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  40%|███▉      | 798/2000 [00:59<01:27, 13.74it/s][Iteration 000800/002000] [loss: 0.00538484] [loss_bc: 0.00483203; loss_div: 0.00039838; loss_ff: 0.00015444] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  45%|████▍     | 898/2000 [01:06<01:19, 13.83it/s][Iteration 000900/002000] [loss: 0.00511047] [loss_bc: 0.00455093; loss_div: 0.00038452; loss_ff: 0.00017503] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  50%|████▉     | 998/2000 [01:13<01:14, 13.44it/s][Iteration 001000/002000] [loss: 0.00551482] [loss_bc: 0.00498265; loss_div: 0.00036633; loss_ff: 0.00016585] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  55%|█████▍    | 1098/2000 [01:21<01:07, 13.38it/s][Iteration 001100/002000] [loss: 0.00529606] [loss_bc: 0.00482461; loss_div: 0.00032924; loss_ff: 0.00014220] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  60%|█████▉    | 1198/2000 [01:28<00:59, 13.53it/s][Iteration 001200/002000] [loss: 0.00570696] [loss_bc: 0.00513282; loss_div: 0.00039738; loss_ff: 0.00017675] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  65%|██████▍   | 1298/2000 [01:36<00:51, 13.74it/s][Iteration 001300/002000] [loss: 0.00578330] [loss_bc: 0.00515466; loss_div: 0.00045262; loss_ff: 0.00017603] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  70%|██████▉   | 1398/2000 [01:43<00:44, 13.59it/s][Iteration 001400/002000] [loss: 0.00520772] [loss_bc: 0.00453268; loss_div: 0.00046996; loss_ff: 0.00020508] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  75%|███████▍  | 1498/2000 [01:50<00:36, 13.73it/s][Iteration 001500/002000] [loss: 0.00531578] [loss_bc: 0.00476715; loss_div: 0.00039558; loss_ff: 0.00015305] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  80%|███████▉  | 1598/2000 [01:58<00:30, 13.29it/s][Iteration 001600/002000] [loss: 0.00541033] [loss_bc: 0.00476725; loss_div: 0.00042850; loss_ff: 0.00021457] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  85%|████████▍ | 1698/2000 [02:05<00:22, 13.60it/s][Iteration 001700/002000] [loss: 0.00509801] [loss_bc: 0.00453227; loss_div: 0.00037482; loss_ff: 0.00019091] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  90%|████████▉ | 1798/2000 [02:13<00:14, 13.56it/s][Iteration 001800/002000] [loss: 0.00539556] [loss_bc: 0.00479602; loss_div: 0.00044427; loss_ff: 0.00015527] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  95%|█████████▍| 1898/2000 [02:20<00:07, 13.75it/s][Iteration 001900/002000] [loss: 0.00557193] [loss_bc: 0.00497070; loss_div: 0.00044494; loss_ff: 0.00015629] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training: 100%|█████████▉| 1998/2000 [02:28<00:00, 13.83it/s][Iteration 002000/002000] [loss: 0.00544883] [loss_bc: 0.00476399; loss_div: 0.00048556; loss_ff: 0.00019928] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training: 100%|██████████| 2000/2000 [02:28<00:00, 13.48it/s]\n",
      "[Iteration 002000/002000] [loss: 0.00544883] [loss_bc: 0.00476399; loss_div: 0.00048556; loss_ff: 0.00019928] [w_bc: 1.000000, LR: 0.000050]\n",
      "Runtime --> total: 148.48sec (2.97ms/iter.)\n",
      "Configuration:\n",
      "dim: 256, w_div: 1.000000, w_ff: 1.000000, decay_iterations: None, potential: True, vector_potential: False, \n",
      "Using device: cuda (gpus 1) ['NVIDIA RTX A6000']\n",
      "Potential Boundary: 100%|██████████| 1/1 [00:00<00:00,  1.06it/s]\n",
      "Loaded meta state: /userhome/jeon_mg/workspace/_data/NOAA12673/PINN/20170906_102400/model_final.pt\n",
      "Training:   0%|          | 0/2000 [00:00<?, ?it/s][Iteration 000000/002000] [loss: 0.00559277] [loss_bc: 0.00498280; loss_div: 0.00043596; loss_ff: 0.00017400] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:   5%|▍         | 98/2000 [00:07<02:25, 13.04it/s][Iteration 000100/002000] [loss: 0.00593288] [loss_bc: 0.00532680; loss_div: 0.00045299; loss_ff: 0.00015309] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  10%|▉         | 198/2000 [00:14<02:12, 13.55it/s][Iteration 000200/002000] [loss: 0.00582445] [loss_bc: 0.00531535; loss_div: 0.00035477; loss_ff: 0.00015433] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  15%|█▍        | 298/2000 [00:22<02:04, 13.68it/s][Iteration 000300/002000] [loss: 0.00579567] [loss_bc: 0.00531415; loss_div: 0.00034251; loss_ff: 0.00013901] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  20%|█▉        | 398/2000 [00:29<01:56, 13.71it/s][Iteration 000400/002000] [loss: 0.00588200] [loss_bc: 0.00531584; loss_div: 0.00038708; loss_ff: 0.00017909] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  25%|██▍       | 498/2000 [00:36<01:48, 13.80it/s][Iteration 000500/002000] [loss: 0.00573518] [loss_bc: 0.00511445; loss_div: 0.00044013; loss_ff: 0.00018060] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  30%|██▉       | 598/2000 [00:44<01:43, 13.54it/s][Iteration 000600/002000] [loss: 0.00586039] [loss_bc: 0.00529222; loss_div: 0.00038696; loss_ff: 0.00018121] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  35%|███▍      | 698/2000 [00:51<01:35, 13.64it/s][Iteration 000700/002000] [loss: 0.00561781] [loss_bc: 0.00493123; loss_div: 0.00051451; loss_ff: 0.00017207] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  40%|███▉      | 798/2000 [00:59<01:28, 13.63it/s][Iteration 000800/002000] [loss: 0.00582644] [loss_bc: 0.00529724; loss_div: 0.00038325; loss_ff: 0.00014596] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  45%|████▍     | 898/2000 [01:06<01:19, 13.80it/s][Iteration 000900/002000] [loss: 0.00568691] [loss_bc: 0.00510615; loss_div: 0.00039593; loss_ff: 0.00018483] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  50%|████▉     | 998/2000 [01:13<01:12, 13.75it/s][Iteration 001000/002000] [loss: 0.00589658] [loss_bc: 0.00527770; loss_div: 0.00045368; loss_ff: 0.00016520] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  55%|█████▍    | 1098/2000 [01:21<01:05, 13.76it/s][Iteration 001100/002000] [loss: 0.00570678] [loss_bc: 0.00514700; loss_div: 0.00039316; loss_ff: 0.00016663] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  60%|█████▉    | 1198/2000 [01:28<00:58, 13.77it/s][Iteration 001200/002000] [loss: 0.00525009] [loss_bc: 0.00465060; loss_div: 0.00045150; loss_ff: 0.00014799] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  65%|██████▍   | 1298/2000 [01:35<00:51, 13.69it/s][Iteration 001300/002000] [loss: 0.00577637] [loss_bc: 0.00516195; loss_div: 0.00044910; loss_ff: 0.00016532] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  70%|██████▉   | 1398/2000 [01:43<00:45, 13.35it/s][Iteration 001400/002000] [loss: 0.00554549] [loss_bc: 0.00491637; loss_div: 0.00041748; loss_ff: 0.00021164] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  75%|███████▍  | 1498/2000 [01:50<00:36, 13.61it/s][Iteration 001500/002000] [loss: 0.00594037] [loss_bc: 0.00527872; loss_div: 0.00047063; loss_ff: 0.00019102] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  80%|███████▉  | 1598/2000 [01:58<00:29, 13.41it/s][Iteration 001600/002000] [loss: 0.00523280] [loss_bc: 0.00463283; loss_div: 0.00045222; loss_ff: 0.00014775] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  85%|████████▍ | 1698/2000 [02:05<00:22, 13.16it/s][Iteration 001700/002000] [loss: 0.00585549] [loss_bc: 0.00526728; loss_div: 0.00040278; loss_ff: 0.00018543] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  90%|████████▉ | 1798/2000 [02:13<00:14, 13.65it/s][Iteration 001800/002000] [loss: 0.00538890] [loss_bc: 0.00491076; loss_div: 0.00033135; loss_ff: 0.00014680] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  95%|█████████▍| 1898/2000 [02:20<00:07, 13.71it/s][Iteration 001900/002000] [loss: 0.00580116] [loss_bc: 0.00504819; loss_div: 0.00053862; loss_ff: 0.00021435] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training: 100%|█████████▉| 1998/2000 [02:27<00:00, 13.39it/s][Iteration 002000/002000] [loss: 0.00578846] [loss_bc: 0.00526249; loss_div: 0.00038015; loss_ff: 0.00014582] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training: 100%|██████████| 2000/2000 [02:28<00:00, 13.51it/s]\n",
      "[Iteration 002000/002000] [loss: 0.00578846] [loss_bc: 0.00526249; loss_div: 0.00038015; loss_ff: 0.00014582] [w_bc: 1.000000, LR: 0.000050]\n",
      "Runtime --> total: 148.23sec (2.96ms/iter.)\n",
      "Configuration:\n",
      "dim: 256, w_div: 1.000000, w_ff: 1.000000, decay_iterations: None, potential: True, vector_potential: False, \n",
      "Using device: cuda (gpus 1) ['NVIDIA RTX A6000']\n",
      "Potential Boundary: 100%|██████████| 1/1 [00:00<00:00,  1.06it/s]\n",
      "Loaded meta state: /userhome/jeon_mg/workspace/_data/NOAA12673/PINN/20170906_103600/model_final.pt\n",
      "Training:   0%|          | 0/2000 [00:00<?, ?it/s][Iteration 000000/002000] [loss: 0.00602346] [loss_bc: 0.00546131; loss_div: 0.00039408; loss_ff: 0.00016807] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:   5%|▍         | 98/2000 [00:07<02:18, 13.76it/s][Iteration 000100/002000] [loss: 0.00593110] [loss_bc: 0.00538049; loss_div: 0.00038535; loss_ff: 0.00016526] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  10%|▉         | 198/2000 [00:14<02:10, 13.79it/s][Iteration 000200/002000] [loss: 0.00575434] [loss_bc: 0.00515497; loss_div: 0.00041625; loss_ff: 0.00018312] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  15%|█▍        | 298/2000 [00:22<02:05, 13.59it/s][Iteration 000300/002000] [loss: 0.00552104] [loss_bc: 0.00497499; loss_div: 0.00039117; loss_ff: 0.00015488] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  20%|█▉        | 398/2000 [00:29<01:58, 13.55it/s][Iteration 000400/002000] [loss: 0.00590118] [loss_bc: 0.00528819; loss_div: 0.00043643; loss_ff: 0.00017657] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  25%|██▍       | 498/2000 [00:36<01:53, 13.28it/s][Iteration 000500/002000] [loss: 0.00569965] [loss_bc: 0.00515869; loss_div: 0.00036295; loss_ff: 0.00017800] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  30%|██▉       | 598/2000 [00:44<01:41, 13.76it/s][Iteration 000600/002000] [loss: 0.00592767] [loss_bc: 0.00539321; loss_div: 0.00037880; loss_ff: 0.00015566] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  35%|███▍      | 698/2000 [00:51<01:34, 13.78it/s][Iteration 000700/002000] [loss: 0.00539683] [loss_bc: 0.00483658; loss_div: 0.00041405; loss_ff: 0.00014619] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  40%|███▉      | 798/2000 [00:59<01:30, 13.29it/s][Iteration 000800/002000] [loss: 0.00537368] [loss_bc: 0.00484066; loss_div: 0.00037582; loss_ff: 0.00015720] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  45%|████▍     | 898/2000 [01:06<01:21, 13.59it/s][Iteration 000900/002000] [loss: 0.00551140] [loss_bc: 0.00495510; loss_div: 0.00038005; loss_ff: 0.00017625] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  50%|████▉     | 998/2000 [01:13<01:15, 13.34it/s][Iteration 001000/002000] [loss: 0.00574822] [loss_bc: 0.00505403; loss_div: 0.00050912; loss_ff: 0.00018506] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  55%|█████▍    | 1098/2000 [01:21<01:06, 13.49it/s][Iteration 001100/002000] [loss: 0.00526215] [loss_bc: 0.00470188; loss_div: 0.00040563; loss_ff: 0.00015465] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  60%|█████▉    | 1198/2000 [01:28<01:00, 13.24it/s][Iteration 001200/002000] [loss: 0.00559583] [loss_bc: 0.00503862; loss_div: 0.00040752; loss_ff: 0.00014969] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  65%|██████▍   | 1298/2000 [01:36<00:52, 13.43it/s][Iteration 001300/002000] [loss: 0.00576638] [loss_bc: 0.00522147; loss_div: 0.00036315; loss_ff: 0.00018175] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  70%|██████▉   | 1398/2000 [01:43<00:44, 13.59it/s][Iteration 001400/002000] [loss: 0.00540905] [loss_bc: 0.00482201; loss_div: 0.00042230; loss_ff: 0.00016474] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  75%|███████▍  | 1498/2000 [01:50<00:36, 13.59it/s][Iteration 001500/002000] [loss: 0.00561352] [loss_bc: 0.00504421; loss_div: 0.00042229; loss_ff: 0.00014703] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  80%|███████▉  | 1598/2000 [01:58<00:30, 13.30it/s][Iteration 001600/002000] [loss: 0.00562799] [loss_bc: 0.00504475; loss_div: 0.00041428; loss_ff: 0.00016895] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  85%|████████▍ | 1698/2000 [02:05<00:23, 12.79it/s][Iteration 001700/002000] [loss: 0.00551849] [loss_bc: 0.00493162; loss_div: 0.00041581; loss_ff: 0.00017107] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  90%|████████▉ | 1798/2000 [02:13<00:15, 13.39it/s][Iteration 001800/002000] [loss: 0.00588653] [loss_bc: 0.00512716; loss_div: 0.00055781; loss_ff: 0.00020155] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  95%|█████████▍| 1898/2000 [02:20<00:07, 13.69it/s][Iteration 001900/002000] [loss: 0.00592317] [loss_bc: 0.00536192; loss_div: 0.00038042; loss_ff: 0.00018084] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training: 100%|█████████▉| 1998/2000 [02:28<00:00, 13.53it/s][Iteration 002000/002000] [loss: 0.00579646] [loss_bc: 0.00520350; loss_div: 0.00039621; loss_ff: 0.00019675] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training: 100%|██████████| 2000/2000 [02:28<00:00, 13.47it/s]\n",
      "[Iteration 002000/002000] [loss: 0.00579646] [loss_bc: 0.00520350; loss_div: 0.00039621; loss_ff: 0.00019675] [w_bc: 1.000000, LR: 0.000050]\n",
      "Runtime --> total: 148.62sec (2.97ms/iter.)\n",
      "Configuration:\n",
      "dim: 256, w_div: 1.000000, w_ff: 1.000000, decay_iterations: None, potential: True, vector_potential: False, \n",
      "Using device: cuda (gpus 1) ['NVIDIA RTX A6000']\n",
      "Potential Boundary: 100%|██████████| 1/1 [00:01<00:00,  1.11s/it]\n",
      "Loaded meta state: /userhome/jeon_mg/workspace/_data/NOAA12673/PINN/20170906_104800/model_final.pt\n",
      "Training:   0%|          | 0/2000 [00:00<?, ?it/s][Iteration 000000/002000] [loss: 0.00549717] [loss_bc: 0.00496857; loss_div: 0.00038572; loss_ff: 0.00014289] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:   5%|▍         | 98/2000 [00:07<02:22, 13.37it/s][Iteration 000100/002000] [loss: 0.00551126] [loss_bc: 0.00489937; loss_div: 0.00044997; loss_ff: 0.00016192] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  10%|▉         | 198/2000 [00:14<02:14, 13.43it/s][Iteration 000200/002000] [loss: 0.00641058] [loss_bc: 0.00574747; loss_div: 0.00043341; loss_ff: 0.00022970] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  15%|█▍        | 298/2000 [00:22<02:03, 13.74it/s][Iteration 000300/002000] [loss: 0.00547579] [loss_bc: 0.00492952; loss_div: 0.00036960; loss_ff: 0.00017667] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  20%|█▉        | 398/2000 [00:29<01:57, 13.68it/s][Iteration 000400/002000] [loss: 0.00548531] [loss_bc: 0.00494604; loss_div: 0.00036520; loss_ff: 0.00017407] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  25%|██▍       | 498/2000 [00:36<01:47, 13.92it/s][Iteration 000500/002000] [loss: 0.00537265] [loss_bc: 0.00474847; loss_div: 0.00046187; loss_ff: 0.00016231] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  30%|██▉       | 598/2000 [00:44<01:44, 13.47it/s][Iteration 000600/002000] [loss: 0.00531220] [loss_bc: 0.00482993; loss_div: 0.00034726; loss_ff: 0.00013501] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  35%|███▍      | 698/2000 [00:51<01:37, 13.40it/s][Iteration 000700/002000] [loss: 0.00527018] [loss_bc: 0.00475621; loss_div: 0.00035669; loss_ff: 0.00015729] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  40%|███▉      | 798/2000 [00:59<01:28, 13.65it/s][Iteration 000800/002000] [loss: 0.00555267] [loss_bc: 0.00486214; loss_div: 0.00047116; loss_ff: 0.00021937] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  45%|████▍     | 898/2000 [01:06<01:21, 13.53it/s][Iteration 000900/002000] [loss: 0.00529848] [loss_bc: 0.00472961; loss_div: 0.00040215; loss_ff: 0.00016672] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  50%|████▉     | 998/2000 [01:14<01:13, 13.70it/s][Iteration 001000/002000] [loss: 0.00550906] [loss_bc: 0.00489583; loss_div: 0.00040936; loss_ff: 0.00020387] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  55%|█████▍    | 1098/2000 [01:21<01:06, 13.60it/s][Iteration 001100/002000] [loss: 0.00585778] [loss_bc: 0.00524451; loss_div: 0.00046634; loss_ff: 0.00014693] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  60%|█████▉    | 1198/2000 [01:29<00:59, 13.49it/s][Iteration 001200/002000] [loss: 0.00580515] [loss_bc: 0.00522689; loss_div: 0.00039515; loss_ff: 0.00018311] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  65%|██████▍   | 1298/2000 [01:36<00:51, 13.56it/s][Iteration 001300/002000] [loss: 0.00639816] [loss_bc: 0.00566474; loss_div: 0.00050446; loss_ff: 0.00022895] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  70%|██████▉   | 1398/2000 [01:44<00:44, 13.61it/s][Iteration 001400/002000] [loss: 0.00569026] [loss_bc: 0.00498625; loss_div: 0.00049490; loss_ff: 0.00020910] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  75%|███████▍  | 1498/2000 [01:51<00:37, 13.45it/s][Iteration 001500/002000] [loss: 0.00540279] [loss_bc: 0.00481395; loss_div: 0.00041593; loss_ff: 0.00017291] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  80%|███████▉  | 1598/2000 [01:58<00:30, 13.16it/s][Iteration 001600/002000] [loss: 0.00535646] [loss_bc: 0.00484409; loss_div: 0.00036775; loss_ff: 0.00014462] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  85%|████████▍ | 1698/2000 [02:06<00:21, 13.84it/s][Iteration 001700/002000] [loss: 0.00559042] [loss_bc: 0.00500873; loss_div: 0.00041766; loss_ff: 0.00016402] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  90%|████████▉ | 1798/2000 [02:13<00:15, 13.15it/s][Iteration 001800/002000] [loss: 0.00627010] [loss_bc: 0.00564076; loss_div: 0.00046456; loss_ff: 0.00016478] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  95%|█████████▍| 1898/2000 [02:21<00:07, 13.70it/s][Iteration 001900/002000] [loss: 0.00586301] [loss_bc: 0.00522828; loss_div: 0.00045813; loss_ff: 0.00017659] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training: 100%|█████████▉| 1998/2000 [02:28<00:00, 13.68it/s][Iteration 002000/002000] [loss: 0.00556822] [loss_bc: 0.00501675; loss_div: 0.00038766; loss_ff: 0.00016382] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training: 100%|██████████| 2000/2000 [02:28<00:00, 13.43it/s]\n",
      "[Iteration 002000/002000] [loss: 0.00556822] [loss_bc: 0.00501675; loss_div: 0.00038766; loss_ff: 0.00016382] [w_bc: 1.000000, LR: 0.000050]\n",
      "Runtime --> total: 149.07sec (2.98ms/iter.)\n",
      "Configuration:\n",
      "dim: 256, w_div: 1.000000, w_ff: 1.000000, decay_iterations: None, potential: True, vector_potential: False, \n",
      "Using device: cuda (gpus 1) ['NVIDIA RTX A6000']\n",
      "Potential Boundary: 100%|██████████| 1/1 [00:00<00:00,  1.10it/s]\n",
      "Loaded meta state: /userhome/jeon_mg/workspace/_data/NOAA12673/PINN/20170906_110000/model_final.pt\n",
      "Training:   0%|          | 0/2000 [00:00<?, ?it/s][Iteration 000000/002000] [loss: 0.00582019] [loss_bc: 0.00526385; loss_div: 0.00039559; loss_ff: 0.00016075] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:   5%|▍         | 98/2000 [00:07<02:18, 13.77it/s][Iteration 000100/002000] [loss: 0.00614278] [loss_bc: 0.00563028; loss_div: 0.00035873; loss_ff: 0.00015377] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  10%|▉         | 198/2000 [00:14<02:11, 13.67it/s][Iteration 000200/002000] [loss: 0.00635654] [loss_bc: 0.00575606; loss_div: 0.00041578; loss_ff: 0.00018469] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  15%|█▍        | 298/2000 [00:21<02:02, 13.85it/s][Iteration 000300/002000] [loss: 0.00580403] [loss_bc: 0.00521331; loss_div: 0.00043283; loss_ff: 0.00015789] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  20%|█▉        | 398/2000 [00:29<01:57, 13.59it/s][Iteration 000400/002000] [loss: 0.00650967] [loss_bc: 0.00599839; loss_div: 0.00035008; loss_ff: 0.00016120] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  25%|██▍       | 498/2000 [00:36<01:49, 13.71it/s][Iteration 000500/002000] [loss: 0.00622514] [loss_bc: 0.00559633; loss_div: 0.00042793; loss_ff: 0.00020088] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  30%|██▉       | 598/2000 [00:44<01:49, 12.82it/s][Iteration 000600/002000] [loss: 0.00574171] [loss_bc: 0.00512845; loss_div: 0.00040954; loss_ff: 0.00020372] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  35%|███▍      | 698/2000 [00:51<01:36, 13.54it/s][Iteration 000700/002000] [loss: 0.00555485] [loss_bc: 0.00501237; loss_div: 0.00037626; loss_ff: 0.00016623] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  40%|███▉      | 798/2000 [00:59<01:29, 13.49it/s][Iteration 000800/002000] [loss: 0.00653159] [loss_bc: 0.00595381; loss_div: 0.00039125; loss_ff: 0.00018653] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  45%|████▍     | 898/2000 [01:06<01:24, 13.05it/s][Iteration 000900/002000] [loss: 0.00616951] [loss_bc: 0.00557182; loss_div: 0.00041244; loss_ff: 0.00018525] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  50%|████▉     | 998/2000 [01:13<01:14, 13.38it/s][Iteration 001000/002000] [loss: 0.00616948] [loss_bc: 0.00556289; loss_div: 0.00042470; loss_ff: 0.00018189] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  55%|█████▍    | 1098/2000 [01:21<01:05, 13.71it/s][Iteration 001100/002000] [loss: 0.00579045] [loss_bc: 0.00519296; loss_div: 0.00043014; loss_ff: 0.00016735] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  60%|█████▉    | 1198/2000 [01:28<00:59, 13.43it/s][Iteration 001200/002000] [loss: 0.00614919] [loss_bc: 0.00555512; loss_div: 0.00042800; loss_ff: 0.00016607] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  65%|██████▍   | 1298/2000 [01:36<00:50, 13.90it/s][Iteration 001300/002000] [loss: 0.00625245] [loss_bc: 0.00568159; loss_div: 0.00041489; loss_ff: 0.00015597] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  70%|██████▉   | 1398/2000 [01:43<00:45, 13.37it/s][Iteration 001400/002000] [loss: 0.00576302] [loss_bc: 0.00517195; loss_div: 0.00043197; loss_ff: 0.00015910] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  75%|███████▍  | 1498/2000 [01:51<00:37, 13.49it/s][Iteration 001500/002000] [loss: 0.00622256] [loss_bc: 0.00567182; loss_div: 0.00040372; loss_ff: 0.00014702] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  80%|███████▉  | 1598/2000 [01:58<00:29, 13.55it/s][Iteration 001600/002000] [loss: 0.00615975] [loss_bc: 0.00557332; loss_div: 0.00044841; loss_ff: 0.00013803] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  85%|████████▍ | 1698/2000 [02:05<00:21, 13.87it/s][Iteration 001700/002000] [loss: 0.00572815] [loss_bc: 0.00516868; loss_div: 0.00042348; loss_ff: 0.00013599] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  90%|████████▉ | 1798/2000 [02:13<00:15, 13.46it/s][Iteration 001800/002000] [loss: 0.00572045] [loss_bc: 0.00516853; loss_div: 0.00040196; loss_ff: 0.00014996] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  95%|█████████▍| 1898/2000 [02:20<00:07, 13.31it/s][Iteration 001900/002000] [loss: 0.00645802] [loss_bc: 0.00588038; loss_div: 0.00040879; loss_ff: 0.00016885] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training: 100%|█████████▉| 1998/2000 [02:28<00:00, 13.44it/s][Iteration 002000/002000] [loss: 0.00607462] [loss_bc: 0.00553562; loss_div: 0.00039568; loss_ff: 0.00014332] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training: 100%|██████████| 2000/2000 [02:28<00:00, 13.48it/s]\n",
      "[Iteration 002000/002000] [loss: 0.00607462] [loss_bc: 0.00553562; loss_div: 0.00039568; loss_ff: 0.00014332] [w_bc: 1.000000, LR: 0.000050]\n",
      "Runtime --> total: 148.55sec (2.97ms/iter.)\n",
      "Configuration:\n",
      "dim: 256, w_div: 1.000000, w_ff: 1.000000, decay_iterations: None, potential: True, vector_potential: False, \n",
      "Using device: cuda (gpus 1) ['NVIDIA RTX A6000']\n",
      "Potential Boundary: 100%|██████████| 1/1 [00:00<00:00,  1.20it/s]\n",
      "Loaded meta state: /userhome/jeon_mg/workspace/_data/NOAA12673/PINN/20170906_111200/model_final.pt\n",
      "Training:   0%|          | 0/2000 [00:00<?, ?it/s][Iteration 000000/002000] [loss: 0.00569696] [loss_bc: 0.00514207; loss_div: 0.00039451; loss_ff: 0.00016039] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:   5%|▍         | 98/2000 [00:07<02:18, 13.69it/s][Iteration 000100/002000] [loss: 0.00571290] [loss_bc: 0.00514970; loss_div: 0.00040662; loss_ff: 0.00015658] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  10%|▉         | 198/2000 [00:14<02:11, 13.67it/s][Iteration 000200/002000] [loss: 0.00568600] [loss_bc: 0.00510392; loss_div: 0.00039491; loss_ff: 0.00018717] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  15%|█▍        | 298/2000 [00:22<02:04, 13.66it/s][Iteration 000300/002000] [loss: 0.00614587] [loss_bc: 0.00545213; loss_div: 0.00047621; loss_ff: 0.00021754] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  20%|█▉        | 398/2000 [00:29<01:57, 13.69it/s][Iteration 000400/002000] [loss: 0.00562799] [loss_bc: 0.00512531; loss_div: 0.00035131; loss_ff: 0.00015137] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  25%|██▍       | 498/2000 [00:36<01:52, 13.36it/s][Iteration 000500/002000] [loss: 0.00568053] [loss_bc: 0.00511884; loss_div: 0.00038824; loss_ff: 0.00017345] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  30%|██▉       | 598/2000 [00:44<01:44, 13.47it/s][Iteration 000600/002000] [loss: 0.00583164] [loss_bc: 0.00509346; loss_div: 0.00056691; loss_ff: 0.00017127] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  35%|███▍      | 698/2000 [00:51<01:35, 13.60it/s][Iteration 000700/002000] [loss: 0.00557796] [loss_bc: 0.00506318; loss_div: 0.00035081; loss_ff: 0.00016397] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  40%|███▉      | 798/2000 [00:59<01:27, 13.73it/s][Iteration 000800/002000] [loss: 0.00571726] [loss_bc: 0.00510470; loss_div: 0.00043913; loss_ff: 0.00017343] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  45%|████▍     | 898/2000 [01:06<01:20, 13.68it/s][Iteration 000900/002000] [loss: 0.00563770] [loss_bc: 0.00510357; loss_div: 0.00038346; loss_ff: 0.00015067] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  50%|████▉     | 998/2000 [01:14<01:14, 13.51it/s][Iteration 001000/002000] [loss: 0.00559724] [loss_bc: 0.00508719; loss_div: 0.00037056; loss_ff: 0.00013949] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  55%|█████▍    | 1098/2000 [01:21<01:05, 13.67it/s][Iteration 001100/002000] [loss: 0.00575205] [loss_bc: 0.00510866; loss_div: 0.00041857; loss_ff: 0.00022482] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  60%|█████▉    | 1198/2000 [01:28<01:04, 12.42it/s][Iteration 001200/002000] [loss: 0.00604319] [loss_bc: 0.00542537; loss_div: 0.00040688; loss_ff: 0.00021094] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  65%|██████▍   | 1298/2000 [01:36<00:52, 13.33it/s][Iteration 001300/002000] [loss: 0.00568620] [loss_bc: 0.00504668; loss_div: 0.00042098; loss_ff: 0.00021853] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  70%|██████▉   | 1398/2000 [01:43<00:44, 13.43it/s][Iteration 001400/002000] [loss: 0.00570035] [loss_bc: 0.00510706; loss_div: 0.00038263; loss_ff: 0.00021067] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  75%|███████▍  | 1498/2000 [01:51<00:36, 13.79it/s][Iteration 001500/002000] [loss: 0.00567771] [loss_bc: 0.00507644; loss_div: 0.00044803; loss_ff: 0.00015324] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  80%|███████▉  | 1598/2000 [01:58<00:29, 13.49it/s][Iteration 001600/002000] [loss: 0.00568541] [loss_bc: 0.00508864; loss_div: 0.00040389; loss_ff: 0.00019288] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  85%|████████▍ | 1698/2000 [02:06<00:22, 13.68it/s][Iteration 001700/002000] [loss: 0.00581125] [loss_bc: 0.00513283; loss_div: 0.00050789; loss_ff: 0.00017053] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  90%|████████▉ | 1798/2000 [02:13<00:14, 13.78it/s][Iteration 001800/002000] [loss: 0.00605058] [loss_bc: 0.00552961; loss_div: 0.00036233; loss_ff: 0.00015864] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  95%|█████████▍| 1898/2000 [02:21<00:07, 13.81it/s][Iteration 001900/002000] [loss: 0.00559250] [loss_bc: 0.00507083; loss_div: 0.00036429; loss_ff: 0.00015738] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training: 100%|█████████▉| 1998/2000 [02:28<00:00, 13.78it/s][Iteration 002000/002000] [loss: 0.00605516] [loss_bc: 0.00540502; loss_div: 0.00043738; loss_ff: 0.00021276] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training: 100%|██████████| 2000/2000 [02:28<00:00, 13.44it/s]\n",
      "[Iteration 002000/002000] [loss: 0.00605516] [loss_bc: 0.00540502; loss_div: 0.00043738; loss_ff: 0.00021276] [w_bc: 1.000000, LR: 0.000050]\n",
      "Runtime --> total: 148.93sec (2.98ms/iter.)\n",
      "Configuration:\n",
      "dim: 256, w_div: 1.000000, w_ff: 1.000000, decay_iterations: None, potential: True, vector_potential: False, \n",
      "Using device: cuda (gpus 1) ['NVIDIA RTX A6000']\n",
      "Potential Boundary: 100%|██████████| 1/1 [00:00<00:00,  1.07it/s]\n",
      "Loaded meta state: /userhome/jeon_mg/workspace/_data/NOAA12673/PINN/20170906_112400/model_final.pt\n",
      "Training:   0%|          | 0/2000 [00:00<?, ?it/s][Iteration 000000/002000] [loss: 0.00609366] [loss_bc: 0.00542316; loss_div: 0.00047791; loss_ff: 0.00019259] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:   5%|▍         | 98/2000 [00:07<02:17, 13.83it/s][Iteration 000100/002000] [loss: 0.00605798] [loss_bc: 0.00550094; loss_div: 0.00038625; loss_ff: 0.00017079] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  10%|▉         | 198/2000 [00:14<02:11, 13.71it/s][Iteration 000200/002000] [loss: 0.00620807] [loss_bc: 0.00558228; loss_div: 0.00044424; loss_ff: 0.00018155] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  15%|█▍        | 298/2000 [00:22<02:06, 13.49it/s][Iteration 000300/002000] [loss: 0.00608958] [loss_bc: 0.00546179; loss_div: 0.00045726; loss_ff: 0.00017053] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  20%|█▉        | 398/2000 [00:29<01:56, 13.71it/s][Iteration 000400/002000] [loss: 0.00589330] [loss_bc: 0.00528217; loss_div: 0.00042549; loss_ff: 0.00018563] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  25%|██▍       | 498/2000 [00:36<01:52, 13.35it/s][Iteration 000500/002000] [loss: 0.00561295] [loss_bc: 0.00500752; loss_div: 0.00042787; loss_ff: 0.00017756] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  30%|██▉       | 598/2000 [00:44<01:44, 13.46it/s][Iteration 000600/002000] [loss: 0.00597917] [loss_bc: 0.00542638; loss_div: 0.00037760; loss_ff: 0.00017520] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  35%|███▍      | 698/2000 [00:51<01:36, 13.47it/s][Iteration 000700/002000] [loss: 0.00588317] [loss_bc: 0.00525362; loss_div: 0.00043087; loss_ff: 0.00019869] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  40%|███▉      | 798/2000 [00:59<01:30, 13.24it/s][Iteration 000800/002000] [loss: 0.00619445] [loss_bc: 0.00552256; loss_div: 0.00047700; loss_ff: 0.00019489] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  45%|████▍     | 898/2000 [01:06<01:21, 13.57it/s][Iteration 000900/002000] [loss: 0.00558370] [loss_bc: 0.00505810; loss_div: 0.00036876; loss_ff: 0.00015684] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  50%|████▉     | 998/2000 [01:13<01:13, 13.58it/s][Iteration 001000/002000] [loss: 0.00541845] [loss_bc: 0.00484900; loss_div: 0.00041914; loss_ff: 0.00015030] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  55%|█████▍    | 1098/2000 [01:21<01:05, 13.74it/s][Iteration 001100/002000] [loss: 0.00609761] [loss_bc: 0.00550749; loss_div: 0.00041569; loss_ff: 0.00017442] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  60%|█████▉    | 1198/2000 [01:28<01:00, 13.33it/s][Iteration 001200/002000] [loss: 0.00589757] [loss_bc: 0.00537796; loss_div: 0.00035923; loss_ff: 0.00016037] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  65%|██████▍   | 1298/2000 [01:36<00:51, 13.64it/s][Iteration 001300/002000] [loss: 0.00572547] [loss_bc: 0.00504670; loss_div: 0.00043411; loss_ff: 0.00024466] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  70%|██████▉   | 1398/2000 [01:43<00:44, 13.41it/s][Iteration 001400/002000] [loss: 0.00597856] [loss_bc: 0.00538923; loss_div: 0.00042803; loss_ff: 0.00016129] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  75%|███████▍  | 1498/2000 [01:51<00:37, 13.50it/s][Iteration 001500/002000] [loss: 0.00627378] [loss_bc: 0.00558862; loss_div: 0.00048482; loss_ff: 0.00020034] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  80%|███████▉  | 1598/2000 [01:58<00:29, 13.65it/s][Iteration 001600/002000] [loss: 0.00573364] [loss_bc: 0.00520668; loss_div: 0.00037643; loss_ff: 0.00015054] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  85%|████████▍ | 1698/2000 [02:05<00:22, 13.23it/s][Iteration 001700/002000] [loss: 0.00556714] [loss_bc: 0.00497421; loss_div: 0.00040287; loss_ff: 0.00019006] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  90%|████████▉ | 1798/2000 [02:13<00:14, 13.74it/s][Iteration 001800/002000] [loss: 0.00556578] [loss_bc: 0.00500336; loss_div: 0.00039362; loss_ff: 0.00016879] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  95%|█████████▍| 1898/2000 [02:20<00:07, 13.19it/s][Iteration 001900/002000] [loss: 0.00615969] [loss_bc: 0.00558796; loss_div: 0.00040697; loss_ff: 0.00016476] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training: 100%|█████████▉| 1998/2000 [02:28<00:00, 13.71it/s][Iteration 002000/002000] [loss: 0.00620168] [loss_bc: 0.00560283; loss_div: 0.00043532; loss_ff: 0.00016353] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training: 100%|██████████| 2000/2000 [02:28<00:00, 13.45it/s]\n",
      "[Iteration 002000/002000] [loss: 0.00620168] [loss_bc: 0.00560283; loss_div: 0.00043532; loss_ff: 0.00016353] [w_bc: 1.000000, LR: 0.000050]\n",
      "Runtime --> total: 148.88sec (2.98ms/iter.)\n",
      "Configuration:\n",
      "dim: 256, w_div: 1.000000, w_ff: 1.000000, decay_iterations: None, potential: True, vector_potential: False, \n",
      "Using device: cuda (gpus 1) ['NVIDIA RTX A6000']\n",
      "Potential Boundary: 100%|██████████| 1/1 [00:00<00:00,  1.05it/s]\n",
      "Loaded meta state: /userhome/jeon_mg/workspace/_data/NOAA12673/PINN/20170906_113600/model_final.pt\n",
      "Training:   0%|          | 0/2000 [00:00<?, ?it/s][Iteration 000000/002000] [loss: 0.00612351] [loss_bc: 0.00549160; loss_div: 0.00043904; loss_ff: 0.00019286] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:   5%|▍         | 98/2000 [00:07<02:16, 13.89it/s][Iteration 000100/002000] [loss: 0.00625651] [loss_bc: 0.00565763; loss_div: 0.00042327; loss_ff: 0.00017561] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  10%|▉         | 198/2000 [00:14<02:11, 13.75it/s][Iteration 000200/002000] [loss: 0.00601596] [loss_bc: 0.00540789; loss_div: 0.00042531; loss_ff: 0.00018276] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  15%|█▍        | 298/2000 [00:21<02:04, 13.69it/s][Iteration 000300/002000] [loss: 0.00640267] [loss_bc: 0.00560772; loss_div: 0.00056912; loss_ff: 0.00022583] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  20%|█▉        | 398/2000 [00:29<01:59, 13.46it/s][Iteration 000400/002000] [loss: 0.00579081] [loss_bc: 0.00510766; loss_div: 0.00049116; loss_ff: 0.00019198] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  25%|██▍       | 498/2000 [00:36<01:49, 13.69it/s][Iteration 000500/002000] [loss: 0.00616372] [loss_bc: 0.00556766; loss_div: 0.00041234; loss_ff: 0.00018372] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  30%|██▉       | 598/2000 [00:44<01:42, 13.66it/s][Iteration 000600/002000] [loss: 0.00570782] [loss_bc: 0.00508996; loss_div: 0.00044261; loss_ff: 0.00017525] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  35%|███▍      | 698/2000 [00:51<01:38, 13.17it/s][Iteration 000700/002000] [loss: 0.00605175] [loss_bc: 0.00535973; loss_div: 0.00051618; loss_ff: 0.00017584] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  40%|███▉      | 798/2000 [00:59<01:28, 13.53it/s][Iteration 000800/002000] [loss: 0.00565670] [loss_bc: 0.00497728; loss_div: 0.00045948; loss_ff: 0.00021994] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  45%|████▍     | 898/2000 [01:06<01:21, 13.55it/s][Iteration 000900/002000] [loss: 0.00572560] [loss_bc: 0.00508082; loss_div: 0.00043718; loss_ff: 0.00020760] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  50%|████▉     | 998/2000 [01:13<01:12, 13.89it/s][Iteration 001000/002000] [loss: 0.00636556] [loss_bc: 0.00558304; loss_div: 0.00057346; loss_ff: 0.00020906] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  55%|█████▍    | 1098/2000 [01:21<01:05, 13.71it/s][Iteration 001100/002000] [loss: 0.00614291] [loss_bc: 0.00551464; loss_div: 0.00045779; loss_ff: 0.00017049] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  60%|█████▉    | 1198/2000 [01:28<00:59, 13.56it/s][Iteration 001200/002000] [loss: 0.00614460] [loss_bc: 0.00547001; loss_div: 0.00047999; loss_ff: 0.00019460] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  65%|██████▍   | 1298/2000 [01:36<00:51, 13.59it/s][Iteration 001300/002000] [loss: 0.00564870] [loss_bc: 0.00505049; loss_div: 0.00041371; loss_ff: 0.00018450] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  70%|██████▉   | 1398/2000 [01:43<00:43, 13.69it/s][Iteration 001400/002000] [loss: 0.00613243] [loss_bc: 0.00553487; loss_div: 0.00043366; loss_ff: 0.00016390] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  75%|███████▍  | 1498/2000 [01:50<00:37, 13.27it/s][Iteration 001500/002000] [loss: 0.00619708] [loss_bc: 0.00547310; loss_div: 0.00048751; loss_ff: 0.00023648] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  80%|███████▉  | 1598/2000 [01:58<00:29, 13.71it/s][Iteration 001600/002000] [loss: 0.00580247] [loss_bc: 0.00514240; loss_div: 0.00044484; loss_ff: 0.00021522] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  85%|████████▍ | 1698/2000 [02:05<00:21, 13.83it/s][Iteration 001700/002000] [loss: 0.00614540] [loss_bc: 0.00552331; loss_div: 0.00043435; loss_ff: 0.00018774] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  90%|████████▉ | 1798/2000 [02:13<00:14, 13.49it/s][Iteration 001800/002000] [loss: 0.00604775] [loss_bc: 0.00547691; loss_div: 0.00038893; loss_ff: 0.00018191] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  95%|█████████▍| 1898/2000 [02:20<00:07, 13.45it/s][Iteration 001900/002000] [loss: 0.00581580] [loss_bc: 0.00506405; loss_div: 0.00052748; loss_ff: 0.00022427] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training: 100%|█████████▉| 1998/2000 [02:27<00:00, 13.46it/s][Iteration 002000/002000] [loss: 0.00575248] [loss_bc: 0.00493703; loss_div: 0.00057140; loss_ff: 0.00024404] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training: 100%|██████████| 2000/2000 [02:28<00:00, 13.49it/s]\n",
      "[Iteration 002000/002000] [loss: 0.00575248] [loss_bc: 0.00493703; loss_div: 0.00057140; loss_ff: 0.00024404] [w_bc: 1.000000, LR: 0.000050]\n",
      "Runtime --> total: 148.42sec (2.97ms/iter.)\n",
      "Configuration:\n",
      "dim: 256, w_div: 1.000000, w_ff: 1.000000, decay_iterations: None, potential: True, vector_potential: False, \n",
      "Using device: cuda (gpus 1) ['NVIDIA RTX A6000']\n",
      "Potential Boundary: 100%|██████████| 1/1 [00:00<00:00,  1.24it/s]\n",
      "Loaded meta state: /userhome/jeon_mg/workspace/_data/NOAA12673/PINN/20170906_114800/model_final.pt\n",
      "Training:   0%|          | 0/2000 [00:00<?, ?it/s][Iteration 000000/002000] [loss: 0.01071533] [loss_bc: 0.01002821; loss_div: 0.00044690; loss_ff: 0.00024023] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:   5%|▍         | 98/2000 [00:07<02:19, 13.60it/s][Iteration 000100/002000] [loss: 0.00832631] [loss_bc: 0.00774610; loss_div: 0.00040313; loss_ff: 0.00017708] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  10%|▉         | 198/2000 [00:14<02:10, 13.80it/s][Iteration 000200/002000] [loss: 0.00979008] [loss_bc: 0.00916973; loss_div: 0.00042685; loss_ff: 0.00019350] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  15%|█▍        | 298/2000 [00:21<02:04, 13.68it/s][Iteration 000300/002000] [loss: 0.00782541] [loss_bc: 0.00724324; loss_div: 0.00038158; loss_ff: 0.00020059] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  20%|█▉        | 398/2000 [00:29<01:58, 13.52it/s][Iteration 000400/002000] [loss: 0.01028090] [loss_bc: 0.00968780; loss_div: 0.00041457; loss_ff: 0.00017853] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  25%|██▍       | 498/2000 [00:36<01:55, 13.04it/s][Iteration 000500/002000] [loss: 0.00946527] [loss_bc: 0.00885529; loss_div: 0.00043788; loss_ff: 0.00017209] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  30%|██▉       | 598/2000 [00:44<01:43, 13.60it/s][Iteration 000600/002000] [loss: 0.00894284] [loss_bc: 0.00835544; loss_div: 0.00040140; loss_ff: 0.00018601] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  35%|███▍      | 698/2000 [00:51<01:35, 13.64it/s][Iteration 000700/002000] [loss: 0.00993465] [loss_bc: 0.00935844; loss_div: 0.00039093; loss_ff: 0.00018528] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  40%|███▉      | 798/2000 [00:59<01:29, 13.40it/s][Iteration 000800/002000] [loss: 0.00949764] [loss_bc: 0.00884221; loss_div: 0.00046133; loss_ff: 0.00019410] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  45%|████▍     | 898/2000 [01:06<01:21, 13.54it/s][Iteration 000900/002000] [loss: 0.00755443] [loss_bc: 0.00698710; loss_div: 0.00037747; loss_ff: 0.00018986] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  50%|████▉     | 998/2000 [01:13<01:14, 13.46it/s][Iteration 001000/002000] [loss: 0.00808355] [loss_bc: 0.00756417; loss_div: 0.00037751; loss_ff: 0.00014187] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  55%|█████▍    | 1098/2000 [01:21<01:07, 13.31it/s][Iteration 001100/002000] [loss: 0.00870695] [loss_bc: 0.00807691; loss_div: 0.00043148; loss_ff: 0.00019856] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  60%|█████▉    | 1198/2000 [01:28<01:00, 13.23it/s][Iteration 001200/002000] [loss: 0.00991752] [loss_bc: 0.00933072; loss_div: 0.00039500; loss_ff: 0.00019181] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  65%|██████▍   | 1298/2000 [01:36<00:52, 13.40it/s][Iteration 001300/002000] [loss: 0.00857770] [loss_bc: 0.00800537; loss_div: 0.00038864; loss_ff: 0.00018368] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  70%|██████▉   | 1398/2000 [01:43<00:44, 13.44it/s][Iteration 001400/002000] [loss: 0.00906287] [loss_bc: 0.00842301; loss_div: 0.00045213; loss_ff: 0.00018773] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  75%|███████▍  | 1498/2000 [01:51<00:37, 13.45it/s][Iteration 001500/002000] [loss: 0.00930864] [loss_bc: 0.00875254; loss_div: 0.00039740; loss_ff: 0.00015871] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  80%|███████▉  | 1598/2000 [01:58<00:30, 13.28it/s][Iteration 001600/002000] [loss: 0.00964617] [loss_bc: 0.00902271; loss_div: 0.00042871; loss_ff: 0.00019475] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  85%|████████▍ | 1698/2000 [02:05<00:22, 13.54it/s][Iteration 001700/002000] [loss: 0.00929047] [loss_bc: 0.00869355; loss_div: 0.00041799; loss_ff: 0.00017893] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  90%|████████▉ | 1798/2000 [02:13<00:14, 13.64it/s][Iteration 001800/002000] [loss: 0.00815624] [loss_bc: 0.00745044; loss_div: 0.00050784; loss_ff: 0.00019796] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  95%|█████████▍| 1898/2000 [02:20<00:07, 13.62it/s][Iteration 001900/002000] [loss: 0.00971182] [loss_bc: 0.00913782; loss_div: 0.00041718; loss_ff: 0.00015683] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training: 100%|█████████▉| 1998/2000 [02:28<00:00, 13.71it/s][Iteration 002000/002000] [loss: 0.00894238] [loss_bc: 0.00828687; loss_div: 0.00048948; loss_ff: 0.00016603] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training: 100%|██████████| 2000/2000 [02:28<00:00, 13.47it/s]\n",
      "[Iteration 002000/002000] [loss: 0.00894238] [loss_bc: 0.00828687; loss_div: 0.00048948; loss_ff: 0.00016603] [w_bc: 1.000000, LR: 0.000050]\n",
      "Runtime --> total: 148.62sec (2.97ms/iter.)\n",
      "Configuration:\n",
      "dim: 256, w_div: 1.000000, w_ff: 1.000000, decay_iterations: None, potential: True, vector_potential: False, \n",
      "Using device: cuda (gpus 1) ['NVIDIA RTX A6000']\n",
      "Potential Boundary: 100%|██████████| 1/1 [00:00<00:00,  1.10it/s]\n",
      "Loaded meta state: /userhome/jeon_mg/workspace/_data/NOAA12673/PINN/20170906_120000/model_final.pt\n",
      "Training:   0%|          | 0/2000 [00:00<?, ?it/s][Iteration 000000/002000] [loss: 0.00749089] [loss_bc: 0.00686357; loss_div: 0.00044223; loss_ff: 0.00018508] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:   5%|▍         | 98/2000 [00:07<02:20, 13.52it/s][Iteration 000100/002000] [loss: 0.00697094] [loss_bc: 0.00621440; loss_div: 0.00053859; loss_ff: 0.00021796] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  10%|▉         | 198/2000 [00:14<02:10, 13.79it/s][Iteration 000200/002000] [loss: 0.00695544] [loss_bc: 0.00637144; loss_div: 0.00041651; loss_ff: 0.00016749] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  15%|█▍        | 298/2000 [00:22<02:06, 13.43it/s][Iteration 000300/002000] [loss: 0.00690060] [loss_bc: 0.00628088; loss_div: 0.00044657; loss_ff: 0.00017315] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  20%|█▉        | 398/2000 [00:29<01:57, 13.60it/s][Iteration 000400/002000] [loss: 0.00653650] [loss_bc: 0.00585001; loss_div: 0.00051797; loss_ff: 0.00016852] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  25%|██▍       | 498/2000 [00:37<01:50, 13.54it/s][Iteration 000500/002000] [loss: 0.00644655] [loss_bc: 0.00582330; loss_div: 0.00045723; loss_ff: 0.00016602] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  30%|██▉       | 598/2000 [00:44<01:42, 13.70it/s][Iteration 000600/002000] [loss: 0.00621556] [loss_bc: 0.00562716; loss_div: 0.00042264; loss_ff: 0.00016577] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  35%|███▍      | 698/2000 [00:51<01:35, 13.63it/s][Iteration 000700/002000] [loss: 0.00667751] [loss_bc: 0.00604724; loss_div: 0.00046033; loss_ff: 0.00016993] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  40%|███▉      | 798/2000 [00:59<01:27, 13.73it/s][Iteration 000800/002000] [loss: 0.00685725] [loss_bc: 0.00632448; loss_div: 0.00039014; loss_ff: 0.00014263] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  45%|████▍     | 898/2000 [01:06<01:22, 13.44it/s][Iteration 000900/002000] [loss: 0.00612834] [loss_bc: 0.00554060; loss_div: 0.00038869; loss_ff: 0.00019905] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  50%|████▉     | 998/2000 [01:14<01:13, 13.67it/s][Iteration 001000/002000] [loss: 0.00620551] [loss_bc: 0.00570272; loss_div: 0.00036210; loss_ff: 0.00014069] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  55%|█████▍    | 1098/2000 [01:21<01:05, 13.67it/s][Iteration 001100/002000] [loss: 0.00625568] [loss_bc: 0.00564964; loss_div: 0.00041699; loss_ff: 0.00018906] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  60%|█████▉    | 1198/2000 [01:29<00:59, 13.50it/s][Iteration 001200/002000] [loss: 0.00708814] [loss_bc: 0.00655175; loss_div: 0.00037771; loss_ff: 0.00015868] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  65%|██████▍   | 1298/2000 [01:36<00:51, 13.73it/s][Iteration 001300/002000] [loss: 0.00677762] [loss_bc: 0.00623845; loss_div: 0.00036538; loss_ff: 0.00017379] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  70%|██████▉   | 1398/2000 [01:43<00:44, 13.42it/s][Iteration 001400/002000] [loss: 0.00708686] [loss_bc: 0.00651648; loss_div: 0.00040933; loss_ff: 0.00016105] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  75%|███████▍  | 1498/2000 [01:51<00:37, 13.45it/s][Iteration 001500/002000] [loss: 0.00657007] [loss_bc: 0.00593497; loss_div: 0.00044077; loss_ff: 0.00019433] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  80%|███████▉  | 1598/2000 [01:58<00:29, 13.65it/s][Iteration 001600/002000] [loss: 0.00652554] [loss_bc: 0.00596294; loss_div: 0.00040936; loss_ff: 0.00015324] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  85%|████████▍ | 1698/2000 [02:06<00:22, 13.59it/s][Iteration 001700/002000] [loss: 0.00649123] [loss_bc: 0.00592164; loss_div: 0.00037416; loss_ff: 0.00019544] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  90%|████████▉ | 1798/2000 [02:13<00:14, 13.93it/s][Iteration 001800/002000] [loss: 0.00613306] [loss_bc: 0.00559122; loss_div: 0.00040187; loss_ff: 0.00013997] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  95%|█████████▍| 1898/2000 [02:20<00:07, 13.70it/s][Iteration 001900/002000] [loss: 0.00607417] [loss_bc: 0.00554781; loss_div: 0.00037820; loss_ff: 0.00014816] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training: 100%|█████████▉| 1998/2000 [02:28<00:00, 13.81it/s][Iteration 002000/002000] [loss: 0.00648522] [loss_bc: 0.00594136; loss_div: 0.00038666; loss_ff: 0.00015720] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training: 100%|██████████| 2000/2000 [02:28<00:00, 13.45it/s]\n",
      "[Iteration 002000/002000] [loss: 0.00648522] [loss_bc: 0.00594136; loss_div: 0.00038666; loss_ff: 0.00015720] [w_bc: 1.000000, LR: 0.000050]\n",
      "Runtime --> total: 148.82sec (2.98ms/iter.)\n",
      "Configuration:\n",
      "dim: 256, w_div: 1.000000, w_ff: 1.000000, decay_iterations: None, potential: True, vector_potential: False, \n",
      "Using device: cuda (gpus 1) ['NVIDIA RTX A6000']\n",
      "Potential Boundary: 100%|██████████| 1/1 [00:00<00:00,  1.06it/s]\n",
      "Loaded meta state: /userhome/jeon_mg/workspace/_data/NOAA12673/PINN/20170906_121200/model_final.pt\n",
      "Training:   0%|          | 0/2000 [00:00<?, ?it/s][Iteration 000000/002000] [loss: 0.00639240] [loss_bc: 0.00581672; loss_div: 0.00041325; loss_ff: 0.00016242] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:   5%|▍         | 98/2000 [00:07<02:20, 13.58it/s][Iteration 000100/002000] [loss: 0.00650541] [loss_bc: 0.00591411; loss_div: 0.00042485; loss_ff: 0.00016645] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  10%|▉         | 198/2000 [00:14<02:19, 12.95it/s][Iteration 000200/002000] [loss: 0.00638158] [loss_bc: 0.00573317; loss_div: 0.00045526; loss_ff: 0.00019315] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  15%|█▍        | 298/2000 [00:22<02:05, 13.59it/s][Iteration 000300/002000] [loss: 0.00619696] [loss_bc: 0.00570183; loss_div: 0.00033748; loss_ff: 0.00015765] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  20%|█▉        | 398/2000 [00:29<01:57, 13.64it/s][Iteration 000400/002000] [loss: 0.00728983] [loss_bc: 0.00668715; loss_div: 0.00043647; loss_ff: 0.00016620] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  25%|██▍       | 498/2000 [00:37<01:53, 13.21it/s][Iteration 000500/002000] [loss: 0.00680110] [loss_bc: 0.00617068; loss_div: 0.00044249; loss_ff: 0.00018792] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  30%|██▉       | 598/2000 [00:44<01:41, 13.76it/s][Iteration 000600/002000] [loss: 0.00665481] [loss_bc: 0.00598625; loss_div: 0.00050517; loss_ff: 0.00016339] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  35%|███▍      | 698/2000 [00:51<01:34, 13.78it/s][Iteration 000700/002000] [loss: 0.00717979] [loss_bc: 0.00661024; loss_div: 0.00042555; loss_ff: 0.00014401] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  40%|███▉      | 798/2000 [00:59<01:27, 13.68it/s][Iteration 000800/002000] [loss: 0.00636387] [loss_bc: 0.00577205; loss_div: 0.00043927; loss_ff: 0.00015255] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  45%|████▍     | 898/2000 [01:06<01:22, 13.35it/s][Iteration 000900/002000] [loss: 0.00620279] [loss_bc: 0.00563068; loss_div: 0.00040201; loss_ff: 0.00017010] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  50%|████▉     | 998/2000 [01:13<01:15, 13.24it/s][Iteration 001000/002000] [loss: 0.00627340] [loss_bc: 0.00560183; loss_div: 0.00047962; loss_ff: 0.00019195] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  55%|█████▍    | 1098/2000 [01:21<01:07, 13.38it/s][Iteration 001100/002000] [loss: 0.00624760] [loss_bc: 0.00558246; loss_div: 0.00045506; loss_ff: 0.00021008] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  60%|█████▉    | 1198/2000 [01:28<00:58, 13.72it/s][Iteration 001200/002000] [loss: 0.00621720] [loss_bc: 0.00562732; loss_div: 0.00044162; loss_ff: 0.00014826] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  65%|██████▍   | 1298/2000 [01:36<00:51, 13.57it/s][Iteration 001300/002000] [loss: 0.00627535] [loss_bc: 0.00561662; loss_div: 0.00046686; loss_ff: 0.00019187] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  70%|██████▉   | 1398/2000 [01:43<00:43, 13.72it/s][Iteration 001400/002000] [loss: 0.00660106] [loss_bc: 0.00590584; loss_div: 0.00045381; loss_ff: 0.00024141] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  75%|███████▍  | 1498/2000 [01:51<00:36, 13.61it/s][Iteration 001500/002000] [loss: 0.00612420] [loss_bc: 0.00544834; loss_div: 0.00049437; loss_ff: 0.00018150] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  80%|███████▉  | 1598/2000 [01:58<00:29, 13.51it/s][Iteration 001600/002000] [loss: 0.00633302] [loss_bc: 0.00555217; loss_div: 0.00058243; loss_ff: 0.00019842] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  85%|████████▍ | 1698/2000 [02:05<00:21, 13.73it/s][Iteration 001700/002000] [loss: 0.00713413] [loss_bc: 0.00650843; loss_div: 0.00047333; loss_ff: 0.00015237] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  90%|████████▉ | 1798/2000 [02:13<00:15, 13.25it/s][Iteration 001800/002000] [loss: 0.00612707] [loss_bc: 0.00559394; loss_div: 0.00037826; loss_ff: 0.00015486] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  95%|█████████▍| 1898/2000 [02:20<00:07, 13.48it/s][Iteration 001900/002000] [loss: 0.00628283] [loss_bc: 0.00559611; loss_div: 0.00046774; loss_ff: 0.00021898] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training: 100%|█████████▉| 1998/2000 [02:28<00:00, 13.71it/s][Iteration 002000/002000] [loss: 0.00599863] [loss_bc: 0.00545633; loss_div: 0.00038253; loss_ff: 0.00015977] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training: 100%|██████████| 2000/2000 [02:28<00:00, 13.48it/s]\n",
      "[Iteration 002000/002000] [loss: 0.00599863] [loss_bc: 0.00545633; loss_div: 0.00038253; loss_ff: 0.00015977] [w_bc: 1.000000, LR: 0.000050]\n",
      "Runtime --> total: 148.54sec (2.97ms/iter.)\n",
      "Configuration:\n",
      "dim: 256, w_div: 1.000000, w_ff: 1.000000, decay_iterations: None, potential: True, vector_potential: False, \n",
      "Using device: cuda (gpus 1) ['NVIDIA RTX A6000']\n",
      "Potential Boundary: 100%|██████████| 1/1 [00:00<00:00,  1.14it/s]\n",
      "Loaded meta state: /userhome/jeon_mg/workspace/_data/NOAA12673/PINN/20170906_122400/model_final.pt\n",
      "Training:   0%|          | 0/2000 [00:00<?, ?it/s][Iteration 000000/002000] [loss: 0.00618731] [loss_bc: 0.00558681; loss_div: 0.00042847; loss_ff: 0.00017204] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:   5%|▍         | 98/2000 [00:07<02:24, 13.18it/s][Iteration 000100/002000] [loss: 0.00616539] [loss_bc: 0.00548937; loss_div: 0.00047822; loss_ff: 0.00019780] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  10%|▉         | 198/2000 [00:14<02:12, 13.59it/s][Iteration 000200/002000] [loss: 0.00649589] [loss_bc: 0.00588451; loss_div: 0.00039409; loss_ff: 0.00021728] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  15%|█▍        | 298/2000 [00:21<02:02, 13.84it/s][Iteration 000300/002000] [loss: 0.00642104] [loss_bc: 0.00582100; loss_div: 0.00043599; loss_ff: 0.00016405] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  20%|█▉        | 398/2000 [00:29<01:56, 13.73it/s][Iteration 000400/002000] [loss: 0.00628486] [loss_bc: 0.00564413; loss_div: 0.00046032; loss_ff: 0.00018041] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  25%|██▍       | 498/2000 [00:36<01:49, 13.67it/s][Iteration 000500/002000] [loss: 0.00734740] [loss_bc: 0.00659420; loss_div: 0.00052900; loss_ff: 0.00022420] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  30%|██▉       | 598/2000 [00:44<01:42, 13.73it/s][Iteration 000600/002000] [loss: 0.00617984] [loss_bc: 0.00553808; loss_div: 0.00048339; loss_ff: 0.00015838] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  35%|███▍      | 698/2000 [00:51<01:37, 13.33it/s][Iteration 000700/002000] [loss: 0.00620912] [loss_bc: 0.00563481; loss_div: 0.00040494; loss_ff: 0.00016937] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  40%|███▉      | 798/2000 [00:58<01:26, 13.90it/s][Iteration 000800/002000] [loss: 0.00622325] [loss_bc: 0.00562292; loss_div: 0.00043706; loss_ff: 0.00016327] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  45%|████▍     | 898/2000 [01:06<01:19, 13.78it/s][Iteration 000900/002000] [loss: 0.00625577] [loss_bc: 0.00561684; loss_div: 0.00047337; loss_ff: 0.00016557] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  50%|████▉     | 998/2000 [01:13<01:13, 13.62it/s][Iteration 001000/002000] [loss: 0.00657172] [loss_bc: 0.00584615; loss_div: 0.00055205; loss_ff: 0.00017352] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  55%|█████▍    | 1098/2000 [01:21<01:06, 13.64it/s][Iteration 001100/002000] [loss: 0.00608805] [loss_bc: 0.00551095; loss_div: 0.00040194; loss_ff: 0.00017516] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  60%|█████▉    | 1198/2000 [01:28<01:00, 13.19it/s][Iteration 001200/002000] [loss: 0.00643084] [loss_bc: 0.00583589; loss_div: 0.00042650; loss_ff: 0.00016845] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  65%|██████▍   | 1298/2000 [01:36<00:51, 13.69it/s][Iteration 001300/002000] [loss: 0.00613743] [loss_bc: 0.00561420; loss_div: 0.00037603; loss_ff: 0.00014720] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  70%|██████▉   | 1398/2000 [01:43<00:45, 13.22it/s][Iteration 001400/002000] [loss: 0.00629928] [loss_bc: 0.00571347; loss_div: 0.00042500; loss_ff: 0.00016081] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  75%|███████▍  | 1498/2000 [01:50<00:36, 13.78it/s][Iteration 001500/002000] [loss: 0.00706905] [loss_bc: 0.00654372; loss_div: 0.00037577; loss_ff: 0.00014956] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  80%|███████▉  | 1598/2000 [01:58<00:29, 13.77it/s][Iteration 001600/002000] [loss: 0.00641232] [loss_bc: 0.00582674; loss_div: 0.00042755; loss_ff: 0.00015803] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  85%|████████▍ | 1698/2000 [02:05<00:22, 13.52it/s][Iteration 001700/002000] [loss: 0.00621267] [loss_bc: 0.00560284; loss_div: 0.00046089; loss_ff: 0.00014895] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  90%|████████▉ | 1798/2000 [02:12<00:14, 13.86it/s][Iteration 001800/002000] [loss: 0.00627574] [loss_bc: 0.00570464; loss_div: 0.00041422; loss_ff: 0.00015688] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  95%|█████████▍| 1898/2000 [02:20<00:07, 13.31it/s][Iteration 001900/002000] [loss: 0.00608519] [loss_bc: 0.00551152; loss_div: 0.00038380; loss_ff: 0.00018986] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training: 100%|█████████▉| 1998/2000 [02:27<00:00, 12.86it/s][Iteration 002000/002000] [loss: 0.00641300] [loss_bc: 0.00570329; loss_div: 0.00051523; loss_ff: 0.00019447] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training: 100%|██████████| 2000/2000 [02:28<00:00, 13.51it/s]\n",
      "[Iteration 002000/002000] [loss: 0.00641300] [loss_bc: 0.00570329; loss_div: 0.00051523; loss_ff: 0.00019447] [w_bc: 1.000000, LR: 0.000050]\n",
      "Runtime --> total: 148.24sec (2.96ms/iter.)\n",
      "Configuration:\n",
      "dim: 256, w_div: 1.000000, w_ff: 1.000000, decay_iterations: None, potential: True, vector_potential: False, \n",
      "Using device: cuda (gpus 1) ['NVIDIA RTX A6000']\n",
      "Potential Boundary: 100%|██████████| 1/1 [00:00<00:00,  1.14it/s]\n",
      "Loaded meta state: /userhome/jeon_mg/workspace/_data/NOAA12673/PINN/20170906_123600/model_final.pt\n",
      "Training:   0%|          | 0/2000 [00:00<?, ?it/s][Iteration 000000/002000] [loss: 0.00635009] [loss_bc: 0.00569266; loss_div: 0.00044997; loss_ff: 0.00020746] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:   5%|▍         | 98/2000 [00:07<02:18, 13.77it/s][Iteration 000100/002000] [loss: 0.00636537] [loss_bc: 0.00575257; loss_div: 0.00043091; loss_ff: 0.00018189] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  10%|▉         | 198/2000 [00:14<02:12, 13.64it/s][Iteration 000200/002000] [loss: 0.00654038] [loss_bc: 0.00595949; loss_div: 0.00042424; loss_ff: 0.00015665] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  15%|█▍        | 298/2000 [00:21<02:06, 13.44it/s][Iteration 000300/002000] [loss: 0.00662226] [loss_bc: 0.00600500; loss_div: 0.00045376; loss_ff: 0.00016350] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  20%|█▉        | 398/2000 [00:29<01:55, 13.85it/s][Iteration 000400/002000] [loss: 0.00659846] [loss_bc: 0.00592993; loss_div: 0.00046163; loss_ff: 0.00020690] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  25%|██▍       | 498/2000 [00:36<01:54, 13.10it/s][Iteration 000500/002000] [loss: 0.00612088] [loss_bc: 0.00555268; loss_div: 0.00039647; loss_ff: 0.00017173] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  30%|██▉       | 598/2000 [00:44<01:41, 13.87it/s][Iteration 000600/002000] [loss: 0.00657024] [loss_bc: 0.00597550; loss_div: 0.00044287; loss_ff: 0.00015188] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  35%|███▍      | 698/2000 [00:51<01:36, 13.54it/s][Iteration 000700/002000] [loss: 0.00661619] [loss_bc: 0.00598223; loss_div: 0.00042367; loss_ff: 0.00021029] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  40%|███▉      | 798/2000 [00:58<01:28, 13.61it/s][Iteration 000800/002000] [loss: 0.00650114] [loss_bc: 0.00591264; loss_div: 0.00042305; loss_ff: 0.00016545] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  45%|████▍     | 898/2000 [01:06<01:21, 13.49it/s][Iteration 000900/002000] [loss: 0.00658801] [loss_bc: 0.00592902; loss_div: 0.00049010; loss_ff: 0.00016889] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  50%|████▉     | 998/2000 [01:13<01:13, 13.64it/s][Iteration 001000/002000] [loss: 0.00660372] [loss_bc: 0.00597957; loss_div: 0.00043463; loss_ff: 0.00018953] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  55%|█████▍    | 1098/2000 [01:21<01:05, 13.73it/s][Iteration 001100/002000] [loss: 0.00615234] [loss_bc: 0.00554116; loss_div: 0.00044084; loss_ff: 0.00017034] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  60%|█████▉    | 1198/2000 [01:28<00:58, 13.73it/s][Iteration 001200/002000] [loss: 0.00624503] [loss_bc: 0.00561889; loss_div: 0.00046059; loss_ff: 0.00016554] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  65%|██████▍   | 1298/2000 [01:35<00:52, 13.39it/s][Iteration 001300/002000] [loss: 0.00654879] [loss_bc: 0.00589693; loss_div: 0.00048341; loss_ff: 0.00016844] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  70%|██████▉   | 1398/2000 [01:43<00:44, 13.65it/s][Iteration 001400/002000] [loss: 0.00643670] [loss_bc: 0.00591446; loss_div: 0.00040235; loss_ff: 0.00011989] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  75%|███████▍  | 1498/2000 [01:50<00:37, 13.45it/s][Iteration 001500/002000] [loss: 0.00613621] [loss_bc: 0.00553921; loss_div: 0.00041293; loss_ff: 0.00018407] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  80%|███████▉  | 1598/2000 [01:58<00:29, 13.82it/s][Iteration 001600/002000] [loss: 0.00648893] [loss_bc: 0.00591443; loss_div: 0.00041168; loss_ff: 0.00016281] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  85%|████████▍ | 1698/2000 [02:05<00:21, 13.74it/s][Iteration 001700/002000] [loss: 0.00662155] [loss_bc: 0.00593481; loss_div: 0.00048639; loss_ff: 0.00020034] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  90%|████████▉ | 1798/2000 [02:13<00:14, 13.75it/s][Iteration 001800/002000] [loss: 0.00656527] [loss_bc: 0.00590341; loss_div: 0.00048165; loss_ff: 0.00018021] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  95%|█████████▍| 1898/2000 [02:20<00:07, 13.72it/s][Iteration 001900/002000] [loss: 0.00623887] [loss_bc: 0.00560011; loss_div: 0.00044184; loss_ff: 0.00019692] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training: 100%|█████████▉| 1998/2000 [02:27<00:00, 13.45it/s][Iteration 002000/002000] [loss: 0.00651101] [loss_bc: 0.00590237; loss_div: 0.00045497; loss_ff: 0.00015367] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training: 100%|██████████| 2000/2000 [02:28<00:00, 13.50it/s]\n",
      "[Iteration 002000/002000] [loss: 0.00651101] [loss_bc: 0.00590237; loss_div: 0.00045497; loss_ff: 0.00015367] [w_bc: 1.000000, LR: 0.000050]\n",
      "Runtime --> total: 148.29sec (2.97ms/iter.)\n",
      "Configuration:\n",
      "dim: 256, w_div: 1.000000, w_ff: 1.000000, decay_iterations: None, potential: True, vector_potential: False, \n",
      "Using device: cuda (gpus 1) ['NVIDIA RTX A6000']\n",
      "Potential Boundary: 100%|██████████| 1/1 [00:01<00:00,  1.30s/it]\n",
      "Loaded meta state: /userhome/jeon_mg/workspace/_data/NOAA12673/PINN/20170906_124800/model_final.pt\n",
      "Training:   0%|          | 0/2000 [00:00<?, ?it/s][Iteration 000000/002000] [loss: 0.00707339] [loss_bc: 0.00653176; loss_div: 0.00038464; loss_ff: 0.00015699] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:   5%|▍         | 98/2000 [00:07<02:17, 13.86it/s][Iteration 000100/002000] [loss: 0.00652619] [loss_bc: 0.00585116; loss_div: 0.00046176; loss_ff: 0.00021328] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  10%|▉         | 198/2000 [00:14<02:13, 13.53it/s][Iteration 000200/002000] [loss: 0.00708785] [loss_bc: 0.00646683; loss_div: 0.00043822; loss_ff: 0.00018280] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  15%|█▍        | 298/2000 [00:22<02:03, 13.79it/s][Iteration 000300/002000] [loss: 0.00708616] [loss_bc: 0.00646975; loss_div: 0.00042696; loss_ff: 0.00018944] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  20%|█▉        | 398/2000 [00:29<01:58, 13.48it/s][Iteration 000400/002000] [loss: 0.00589282] [loss_bc: 0.00539104; loss_div: 0.00036985; loss_ff: 0.00013194] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  25%|██▍       | 498/2000 [00:36<01:49, 13.69it/s][Iteration 000500/002000] [loss: 0.00579318] [loss_bc: 0.00527354; loss_div: 0.00038232; loss_ff: 0.00013731] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  30%|██▉       | 598/2000 [00:44<01:44, 13.39it/s][Iteration 000600/002000] [loss: 0.00682147] [loss_bc: 0.00631714; loss_div: 0.00035526; loss_ff: 0.00014907] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  35%|███▍      | 698/2000 [00:51<01:34, 13.71it/s][Iteration 000700/002000] [loss: 0.00680194] [loss_bc: 0.00627259; loss_div: 0.00040656; loss_ff: 0.00012278] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  40%|███▉      | 798/2000 [00:59<01:26, 13.83it/s][Iteration 000800/002000] [loss: 0.00711408] [loss_bc: 0.00644408; loss_div: 0.00048302; loss_ff: 0.00018698] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  45%|████▍     | 898/2000 [01:06<01:19, 13.78it/s][Iteration 000900/002000] [loss: 0.00712202] [loss_bc: 0.00644976; loss_div: 0.00052099; loss_ff: 0.00015127] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  50%|████▉     | 998/2000 [01:14<01:15, 13.19it/s][Iteration 001000/002000] [loss: 0.00635041] [loss_bc: 0.00578471; loss_div: 0.00039185; loss_ff: 0.00017385] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  55%|█████▍    | 1098/2000 [01:21<01:06, 13.47it/s][Iteration 001100/002000] [loss: 0.00697977] [loss_bc: 0.00631260; loss_div: 0.00047164; loss_ff: 0.00019553] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  60%|█████▉    | 1198/2000 [01:29<01:00, 13.27it/s][Iteration 001200/002000] [loss: 0.00683680] [loss_bc: 0.00624668; loss_div: 0.00042209; loss_ff: 0.00016803] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  65%|██████▍   | 1298/2000 [01:36<00:51, 13.54it/s][Iteration 001300/002000] [loss: 0.00689832] [loss_bc: 0.00629344; loss_div: 0.00043323; loss_ff: 0.00017165] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  70%|██████▉   | 1398/2000 [01:43<00:44, 13.51it/s][Iteration 001400/002000] [loss: 0.00720848] [loss_bc: 0.00644290; loss_div: 0.00059135; loss_ff: 0.00017424] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  75%|███████▍  | 1498/2000 [01:51<00:37, 13.46it/s][Iteration 001500/002000] [loss: 0.00578553] [loss_bc: 0.00523906; loss_div: 0.00039463; loss_ff: 0.00015184] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  80%|███████▉  | 1598/2000 [01:58<00:29, 13.78it/s][Iteration 001600/002000] [loss: 0.00629884] [loss_bc: 0.00578717; loss_div: 0.00036288; loss_ff: 0.00014879] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  85%|████████▍ | 1698/2000 [02:06<00:22, 13.64it/s][Iteration 001700/002000] [loss: 0.00624465] [loss_bc: 0.00565347; loss_div: 0.00042882; loss_ff: 0.00016237] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  90%|████████▉ | 1798/2000 [02:13<00:14, 13.65it/s][Iteration 001800/002000] [loss: 0.00622659] [loss_bc: 0.00564197; loss_div: 0.00039031; loss_ff: 0.00019431] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training:  95%|█████████▍| 1898/2000 [02:21<00:07, 13.67it/s][Iteration 001900/002000] [loss: 0.00706025] [loss_bc: 0.00641237; loss_div: 0.00043981; loss_ff: 0.00020807] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training: 100%|█████████▉| 1998/2000 [02:28<00:00, 13.69it/s][Iteration 002000/002000] [loss: 0.00685818] [loss_bc: 0.00629516; loss_div: 0.00038863; loss_ff: 0.00017440] [w_bc: 1.000000, LR: 0.000050]\n",
      "Training: 100%|██████████| 2000/2000 [02:28<00:00, 13.44it/s]\n",
      "[Iteration 002000/002000] [loss: 0.00685818] [loss_bc: 0.00629516; loss_div: 0.00038863; loss_ff: 0.00017440] [w_bc: 1.000000, LR: 0.000050]\n",
      "Runtime --> total: 148.93sec (2.98ms/iter.)\n"
     ]
    }
   ],
   "source": [
    "meta_path = None\n",
    "\n",
    "for b_bottom_path in sorted(glob.glob(os.path.join(b_bottom_paths, '*.npy'))):\n",
    "    b_bottom_date = os.path.basename(b_bottom_path)[9:-4]\n",
    "    output_path = os.path.join(Path(b_bottom_path).parent.parent, f'PINN/{b_bottom_date}')\n",
    "    \n",
    "    with open(b_bottom_path, 'rb') as f:\n",
    "        b_bottom = np.load(f)\n",
    "\n",
    "    Nx, Ny, _ = b_bottom.shape\n",
    "    \n",
    "    final_model_path = os.path.join(output_path, 'model_final.pt')\n",
    "    if os.path.exists(final_model_path):\n",
    "        meta_path = final_model_path\n",
    "        continue\n",
    "    \n",
    "    if meta_path is None:\n",
    "        trainer = NF2Trainer(output_path, b_bottom, Nz, spatial_norm, b_norm,\n",
    "                             meta_path=None, dim=num_neurons, w_div=w_div, w_ff=w_ff,\n",
    "                             decay_iterations=decay_iterations)\n",
    "\n",
    "        start = time.time()\n",
    "        trainer.train(total_iterations, batch_size, log_interval, log_interval, num_workers=num_worker)\n",
    "        runtime = time.time() - start\n",
    "        trainer.logger.info(f'Runtime --> total: {runtime:.2f}sec ({(runtime/(total_iterations-1)*1000):.2f}ms/iter.)')\n",
    "        meta_path = os.path.join(output_path, 'model_final.pt')\n",
    "    else:\n",
    "        trainer = NF2Trainer(output_path, b_bottom, Nz, spatial_norm, b_norm,\n",
    "                             meta_path=meta_path, dim=num_neurons, w_div=w_div, w_ff=w_ff)\n",
    "\n",
    "        start = time.time()\n",
    "        trainer.train(series_iteration, batch_size, series_log_interval, series_log_interval, num_workers=num_worker)\n",
    "        runtime = time.time() - start\n",
    "        trainer.logger.info(f'Runtime --> total: {runtime:.2f}sec ({(runtime/(total_iterations-1)*1000):.2f}ms/iter.)')\n",
    "        meta_path = os.path.join(output_path, 'model_final.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
