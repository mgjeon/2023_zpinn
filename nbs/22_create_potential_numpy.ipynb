{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Potential Field"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load b_bottom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]= \"3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('config.json') as config:\n",
    "    info = json.load(config)\n",
    "\n",
    "nx = info['nx']\n",
    "ny = info['ny']\n",
    "nz = info['nz']\n",
    "b_norm = info['b_norm']\n",
    "spatial_norm = info['spatial_norm']\n",
    "\n",
    "input_path = info['input_path']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_original = os.path.join(input_path, 'original')\n",
    "b_bottom_original_path = os.path.join(input_original, \"b_bottom_original.pickle\")\n",
    "\n",
    "with open(b_bottom_original_path, \"rb\") as f:\n",
    "    b_bottom = pickle.load(f)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Potential Field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import numpy as np\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from zpinn.pinn_nf2_cleanup import PotentialModel, create_coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bottom_values = b_bottom.reshape(-1, 3)\n",
    "bottom_bounds = (0, nx-1, 0, ny-1, 0, 0)\n",
    "bottom_coords = create_coordinates(bottom_bounds).reshape(-1, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_bounds = (0, nx-1, 0, ny-1, nz-1, nz-1)\n",
    "lateral_bounds_1 = (0, 0, 0, ny-1, 0, nz-1)\n",
    "lateral_bounds_2 = (nx-1, nx-1, 0, ny-1, 0, nz-1)\n",
    "lateral_bounds_3 = (0, nx-1, 0, 0, 0, nz-1)\n",
    "lateral_bounds_4 = (0, nx-1, ny-1, ny-1, 0, nz-1)\n",
    "\n",
    "top_coords = create_coordinates(top_bounds)\n",
    "lateral_coords_1 = create_coordinates(lateral_bounds_1)\n",
    "lateral_coords_2 = create_coordinates(lateral_bounds_2)\n",
    "lateral_coords_3 = create_coordinates(lateral_bounds_3)\n",
    "lateral_coords_4 = create_coordinates(lateral_bounds_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_lateral_coordinates = [top_coords,\n",
    "                           lateral_coords_1,\n",
    "                           lateral_coords_2,\n",
    "                           lateral_coords_3,\n",
    "                           lateral_coords_4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_potential_boundary(b_n, height, batch_size=2048, **kwargs):\n",
    "    assert not np.any(np.isnan(b_n)), 'Invalid data value'\n",
    "\n",
    "    cube_shape = (*b_n.shape, height)\n",
    "\n",
    "    b_n = b_n.reshape((-1)).astype(np.float32)\n",
    "    coords = [np.stack(np.mgrid[:cube_shape[0], :cube_shape[1], cube_shape[2] - 2:cube_shape[2] + 1], -1),       #top\n",
    "              np.stack(np.mgrid[:cube_shape[0], -1:2, :cube_shape[2]], -1),                                      #y=0\n",
    "              np.stack(np.mgrid[:cube_shape[0], cube_shape[1] - 2:cube_shape[1] + 1, :cube_shape[2]], -1),       #y=max\n",
    "              np.stack(np.mgrid[-1:2, :cube_shape[1], :cube_shape[2]], -1),                                      #x=0\n",
    "              np.stack(np.mgrid[cube_shape[0] - 2:cube_shape[0] + 1, :cube_shape[1], :cube_shape[2]], -1), ]     #x=max\n",
    "    fields = _compute_fields(coords, cube_shape, b_n, batch_size=batch_size, **kwargs)\n",
    "\n",
    "    fields = [fields[0][:, :, 1],\n",
    "              fields[1][:, 1, :], fields[2][:, 1, :],\n",
    "              fields[3][1, :, :], fields[4][1, :, :]]\n",
    "    coords = [coords[0][:, :, 1],\n",
    "              coords[1][:, 1, :], coords[2][:, 1, :],\n",
    "              coords[3][1, :, :], coords[4][1, :, :]]\n",
    "    return coords, fields\n",
    "\n",
    "def _compute_fields(coords, cube_shape, b_n, batch_size=2048, progress=False):\n",
    "    coords_shape = [c.shape[:-1] for c in coords]\n",
    "    flat_coords = np.concatenate([c.reshape(((-1, 3))) for c in coords])\n",
    "\n",
    "    r_p = np.stack(np.mgrid[:cube_shape[0], :cube_shape[1], :1], -1).reshape((-1, 3))\n",
    "\n",
    "    # torch code\n",
    "    # r = (x * y, 3); coords = (x*y*z, 3), c = (1, 3)\n",
    "    # --> (x * y, x * y * z, 3) --> (x * y, x * y * z) --> (x * y * z)\n",
    "    device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "    with torch.no_grad():\n",
    "        b_n = torch.tensor(b_n, dtype=torch.float32, )\n",
    "        r_p = torch.tensor(r_p, dtype=torch.float32, )\n",
    "        model = nn.DataParallel(PotentialModel(b_n, r_p, )).to(device)\n",
    "\n",
    "        flat_coords = torch.tensor(flat_coords, dtype=torch.float32, )\n",
    "\n",
    "        potential = []\n",
    "        iter = DataLoader(TensorDataset(flat_coords), batch_size=batch_size, num_workers=2)\n",
    "        iter = iter if progress else tqdm(iter, desc='Potential Field')\n",
    "        for coord, in iter:\n",
    "            coord = coord.to(device)\n",
    "            p_batch = model(coord)\n",
    "            potential += [p_batch.cpu()]\n",
    "\n",
    "    potential = torch.cat(potential).numpy()\n",
    "    idx = 0\n",
    "    fields = []\n",
    "    for s in coords_shape:\n",
    "        p = potential[idx:idx + np.prod(s)].reshape(s)\n",
    "        b = - 1 * np.stack(np.gradient(p, axis=[0, 1, 2], edge_order=2), axis=-1)\n",
    "        fields += [b]\n",
    "        idx += np.prod(s)\n",
    "\n",
    "    return fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Potential Field: 100%|██████████| 480/480 [00:20<00:00, 23.94it/s]\n"
     ]
    }
   ],
   "source": [
    "coords, fields = get_potential_boundary(b_bottom[:, :, 2], nz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(coords)):\n",
    "    coords[i] = np.reshape(coords[i], (-1, 3))\n",
    "    fields[i] = np.reshape(fields[i], (-1, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_lateral_values = np.concatenate(fields) \n",
    "top_lateral_coords = np.concatenate(coords)\n",
    "\n",
    "boundary_values = np.concatenate([top_lateral_values, bottom_values])\n",
    "boundary_coords = np.concatenate([top_lateral_coords, bottom_coords])\n",
    "\n",
    "normalized_boundary_values = boundary_values / b_norm\n",
    "normalized_boundary_coords = boundary_coords / spatial_norm\n",
    "\n",
    "boundary_data = np.stack([normalized_boundary_coords, normalized_boundary_values], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bp_top = fields[0]\n",
    "bp_lateral_3 = fields[1]\n",
    "bp_lateral_4 = fields[2]\n",
    "bp_lateral_1 = fields[3]\n",
    "bp_lateral_2 = fields[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b_bottom = b_bottom / b_norm\n",
    "bp_top = bp_top / b_norm\n",
    "bp_lateral_1 = bp_lateral_1 / b_norm\n",
    "bp_lateral_2 = bp_lateral_2 / b_norm\n",
    "bp_lateral_3 = bp_lateral_3 / b_norm \n",
    "bp_lateral_4 = bp_lateral_4 / b_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b_bottom_path = os.path.join(input_path, \"b_bottom.pickle\")\n",
    "bp_top_path = os.path.join(input_path, \"bp_top.pickle\")\n",
    "bp_lateral_1_path = os.path.join(input_path, \"bp_lateral_1.pickle\")\n",
    "bp_lateral_2_path = os.path.join(input_path, \"bp_lateral_2.pickle\")\n",
    "bp_lateral_3_path = os.path.join(input_path, \"bp_lateral_3.pickle\")\n",
    "bp_lateral_4_path = os.path.join(input_path, \"bp_lateral_4.pickle\")\n",
    "boundary_data_path = os.path.join(input_path, \"boundary_data.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(b_bottom_path,\"wb\") as f:\n",
    "    pickle.dump(b_bottom, f)\n",
    "\n",
    "with open(bp_top_path,\"wb\") as f:\n",
    "    pickle.dump(bp_top, f)\n",
    "\n",
    "with open(bp_lateral_1_path,\"wb\") as f:\n",
    "    pickle.dump(bp_lateral_1, f)\n",
    "\n",
    "with open(bp_lateral_2_path,\"wb\") as f:\n",
    "    pickle.dump(bp_lateral_2, f)\n",
    "    \n",
    "with open(bp_lateral_3_path,\"wb\") as f:\n",
    "    pickle.dump(bp_lateral_3, f)\n",
    "\n",
    "with open(bp_lateral_4_path,\"wb\") as f:\n",
    "    pickle.dump(bp_lateral_4, f)\n",
    "\n",
    "with open(boundary_data_path,\"wb\") as f:\n",
    "    pickle.dump(boundary_data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
