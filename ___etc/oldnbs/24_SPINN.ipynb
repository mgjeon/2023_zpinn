{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SPINN"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-configure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import os\n",
    "import json\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('config.json') as config:\n",
    "    info = json.load(config)\n",
    "\n",
    "os.environ[\"XLA_PYTHON_CLIENT_PREALLOCATE\"] = info['jax_prealo']\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]= info['cuda_visible']\n",
    "\n",
    "nx = info['nx']\n",
    "ny = info['ny']\n",
    "nz = info['nz']\n",
    "b_norm = info['b_norm']\n",
    "\n",
    "input_path = info['input_path']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_original = os.path.join(input_path, 'original')\n",
    "\n",
    "b_bottom_path = os.path.join(input_path, \"b_bottom.pickle\")\n",
    "bp_top_path = os.path.join(input_path, \"bp_top.pickle\")\n",
    "bp_lateral_1_path = os.path.join(input_path, \"bp_lateral_1.pickle\")\n",
    "bp_lateral_2_path = os.path.join(input_path, \"bp_lateral_2.pickle\")\n",
    "bp_lateral_3_path = os.path.join(input_path, \"bp_lateral_3.pickle\")\n",
    "bp_lateral_4_path = os.path.join(input_path, \"bp_lateral_4.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(b_bottom_path,\"rb\") as f:\n",
    "    b_bottom = pickle.load(f)\n",
    "\n",
    "with open(bp_top_path,\"rb\") as f:\n",
    "    bp_top = pickle.load(f)\n",
    "\n",
    "with open(bp_lateral_1_path,\"rb\") as f:\n",
    "    bp_lateral_1 = pickle.load(f)\n",
    "\n",
    "with open(bp_lateral_2_path,\"rb\") as f:\n",
    "    bp_lateral_2 = pickle.load(f)\n",
    "\n",
    "with open(bp_lateral_3_path,\"rb\") as f:\n",
    "    bp_lateral_3 = pickle.load(f)\n",
    "\n",
    "with open(bp_lateral_4_path,\"rb\") as f:\n",
    "    bp_lateral_4 = pickle.load(f)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp spinn_cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import jax \n",
    "import jax.numpy as jnp\n",
    "from jax import jvp\n",
    "import optax\n",
    "from flax import linen as nn \n",
    "\n",
    "from typing import Sequence\n",
    "from functools import partial\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import time\n",
    "from tqdm import trange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def hvp_fwdfwd(f, primals, tangents, return_primals=False):\n",
    "    g = lambda primals: jvp(f, (primals,), tangents)[1]\n",
    "    primals_out, tangents_out = jvp(g, primals, tangents)\n",
    "    if return_primals:\n",
    "        return primals_out, tangents_out\n",
    "    else:\n",
    "        return tangents_out\n",
    "    \n",
    "@partial(jax.jit, static_argnums=(0,))\n",
    "def update_model(optim, gradient, params, state):\n",
    "    updates, state = optim.update(gradient, state)\n",
    "    params = optax.apply_updates(params, updates)\n",
    "    return params, state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class SPINN3d(nn.Module):\n",
    "    features: Sequence[int]\n",
    "    r: int\n",
    "    out_dim: int\n",
    "    pos_enc: int\n",
    "    mlp: str\n",
    "\n",
    "    @nn.compact\n",
    "    def __call__(self, x, y, z):\n",
    "        '''\n",
    "        inputs: input factorized coordinates\n",
    "        outputs: feature output of each body network\n",
    "        xy: intermediate tensor for feature merge btw. x and y axis\n",
    "        pred: final model prediction (e.g. for 2d output, pred=[u, v])\n",
    "        '''\n",
    "        if self.pos_enc != 0:\n",
    "            # positional encoding only to spatial coordinates\n",
    "            freq = jnp.expand_dims(jnp.arange(1, self.pos_enc+1, 1), 0)\n",
    "            y = jnp.concatenate((jnp.ones((y.shape[0], 1)), jnp.sin(y@freq), jnp.cos(y@freq)), 1)\n",
    "            z = jnp.concatenate((jnp.ones((z.shape[0], 1)), jnp.sin(z@freq), jnp.cos(z@freq)), 1)\n",
    "\n",
    "            # causal PINN version (also on time axis)\n",
    "            #  freq_x = jnp.expand_dims(jnp.power(10.0, jnp.arange(0, 3)), 0)\n",
    "            # x = x@freq_x\n",
    "            \n",
    "        inputs, outputs, xy, pred = [x, y, z], [], [], []\n",
    "        init = nn.initializers.glorot_normal()\n",
    "\n",
    "        if self.mlp == 'mlp':\n",
    "            for X in inputs:\n",
    "                for fs in self.features[:-1]:\n",
    "                    X = nn.Dense(fs, kernel_init=init)(X)\n",
    "                    X = nn.activation.tanh(X)\n",
    "                X = nn.Dense(self.r*self.out_dim, kernel_init=init)(X)\n",
    "                outputs += [jnp.transpose(X, (1, 0))]\n",
    "\n",
    "        elif self.mlp == 'modified_mlp':\n",
    "            for X in inputs:\n",
    "                U = nn.activation.tanh(nn.Dense(self.features[0], kernel_init=init)(X))\n",
    "                V = nn.activation.tanh(nn.Dense(self.features[0], kernel_init=init)(X))\n",
    "                H = nn.activation.tanh(nn.Dense(self.features[0], kernel_init=init)(X))\n",
    "                for fs in self.features[:-1]:\n",
    "                    Z = nn.Dense(fs, kernel_init=init)(H)\n",
    "                    Z = nn.activation.tanh(Z)\n",
    "                    H = (jnp.ones_like(Z)-Z)*U + Z*V\n",
    "                H = nn.Dense(self.r*self.out_dim, kernel_init=init)(H)\n",
    "                outputs += [jnp.transpose(H, (1, 0))]\n",
    "        \n",
    "        for i in range(self.out_dim):\n",
    "            xy += [jnp.einsum('fx, fy->fxy', outputs[0][self.r*i:self.r*(i+1)], outputs[1][self.r*i:self.r*(i+1)])]\n",
    "            pred += [jnp.einsum('fxy, fz->xyz', xy[i], outputs[-1][self.r*i:self.r*(i+1)])]\n",
    "\n",
    "        if len(pred) == 1:\n",
    "            # 1-dimensional output\n",
    "            return pred[0]\n",
    "        else:\n",
    "            # n-dimensional output\n",
    "            return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@partial(jax.jit, static_argnums=(0,1,2))\n",
    "def generate_train_data(nx, ny, nz, key):\n",
    "    # collocation points\n",
    "    \n",
    "    keys = jax.random.split(key, 4)\n",
    "    xc = jax.random.uniform(keys[1], (nx, 1), minval=0., maxval=2.)\n",
    "    yc = jax.random.uniform(keys[2], (ny, 1), minval=0., maxval=2.)\n",
    "    zc = jax.random.uniform(keys[3], (nz, 1), minval=0., maxval=2.)\n",
    "#     xc = jnp.linspace(0, 2, nx).reshape(nx, 1)\n",
    "#     yc = jnp.linspace(0, 2, ny).reshape(ny, 1)\n",
    "#     zc = jnp.linspace(0, 2, nz).reshape(nz, 1)\n",
    "\n",
    "    # # boundary points\n",
    "    xb = [jnp.linspace(0, 2, nx).reshape(nx, 1), # z=0   bottom\n",
    "          jnp.linspace(0, 2, nx).reshape(nx, 1), # z=2   top\n",
    "          jnp.array([[0.]]),                     # x=0   lateral_1\n",
    "          jnp.array([[2.]]),                     # x=2   lateral_2\n",
    "          jnp.linspace(0, 2, nx).reshape(nx, 1), # y=0   lateral_3\n",
    "          jnp.linspace(0, 2, nx).reshape(nx, 1)] # y=2   lateral_4\n",
    "\n",
    "    yb = [jnp.linspace(0, 2, ny).reshape(ny, 1), \n",
    "          jnp.linspace(0, 2, ny).reshape(ny, 1), \n",
    "          jnp.linspace(0, 2, ny).reshape(ny, 1), \n",
    "          jnp.linspace(0, 2, ny).reshape(ny, 1), \n",
    "          jnp.array([[0.]]), \n",
    "          jnp.array([[2.]])]\n",
    "\n",
    "    zb = [jnp.array([[0.]]), \n",
    "          jnp.array([[2.]]), \n",
    "          jnp.linspace(0, 2, nz).reshape(nz, 1), \n",
    "          jnp.linspace(0, 2, nz).reshape(nz, 1), \n",
    "          jnp.linspace(0, 2, nz).reshape(nz, 1), \n",
    "          jnp.linspace(0, 2, nz).reshape(nz, 1)]\n",
    "\n",
    "    return xc, yc, zc, xb, yb, zb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def curlx(apply_fn, params, x, y, z):\n",
    "    # curl vector w/ forward-mode AD\n",
    "    # w_x = uz_y - uy_z\n",
    "    vec_z = jnp.ones(z.shape)\n",
    "    vec_y = jnp.ones(y.shape)\n",
    "    uy_z = jvp(lambda z: apply_fn(params, x, y, z)[1], (z,), (vec_z,))[1]\n",
    "    uz_y = jvp(lambda y: apply_fn(params, x, y, z)[2], (y,), (vec_y,))[1]\n",
    "    wx = uz_y - uy_z\n",
    "    return wx\n",
    "\n",
    "\n",
    "def curly(apply_fn, params, x, y, z):\n",
    "    # curl vector w/ forward-mode AD\n",
    "    # w_y = ux_z - uz_x\n",
    "    vec_z = jnp.ones(z.shape)\n",
    "    vec_x = jnp.ones(x.shape)\n",
    "    ux_z = jvp(lambda z: apply_fn(params, x, y, z)[0], (z,), (vec_z,))[1]\n",
    "    uz_x = jvp(lambda x: apply_fn(params, x, y, z)[2], (x,), (vec_x,))[1]\n",
    "    wy = ux_z - uz_x\n",
    "    return wy\n",
    "\n",
    "def curlz(apply_fn, params, x, y, z):\n",
    "    # curl vector w/ forward-mode AD\n",
    "    # w_z = uy_x - ux_y\n",
    "    vec_y = jnp.ones(y.shape)\n",
    "    vec_x = jnp.ones(x.shape)\n",
    "    ux_y = jvp(lambda y: apply_fn(params, x, y, z)[0], (y,), (vec_y,))[1]\n",
    "    uy_x = jvp(lambda x: apply_fn(params, x, y, z)[1], (x,), (vec_x,))[1]\n",
    "    wz = uy_x - ux_y\n",
    "    return wz\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@partial(jax.jit, static_argnums=(0,))\n",
    "def apply_model_spinn(apply_fn, params, *train_data):\n",
    "    def residual_loss(params, x, y, z):\n",
    "        # calculate u\n",
    "        Bx, By, Bz = apply_fn(params, x, y, z)\n",
    "        B = jnp.stack([Bx, By, Bz], axis=-1)\n",
    "        \n",
    "        # calculate J\n",
    "        Jx = curlx(apply_fn, params, x, y, z)\n",
    "        Jy = curly(apply_fn, params, x, y, z)\n",
    "        Jz = curlz(apply_fn, params, x, y, z)\n",
    "        J = jnp.stack([Jx, Jy, Jz], axis=-1)\n",
    "\n",
    "        JxB = jnp.cross(J, B, axis=-1) \n",
    "\n",
    "        #-----------------------------------------------------------\n",
    "        loss_ff = jnp.sum(JxB**2, axis=-1) / (jnp.sum(B**2, axis=-1) + 1e-7)\n",
    "        loss_ff = jnp.mean(loss_ff)\n",
    "\n",
    "        # loss_ff = jnp.mean(JxB**2)\n",
    "\n",
    "        # loss_ff = jnp.sum(JxB**2, axis=-1)\n",
    "        # loss_ff = jnp.mean(loss_ff)\n",
    "        #-----------------------------------------------------------\n",
    "\n",
    "        # tangent vector dx/dx\n",
    "        # assumes x, y, z have same shape (very important)\n",
    "        vec_x = jnp.ones(x.shape)\n",
    "        vec_y = jnp.ones(y.shape)\n",
    "        vec_z = jnp.ones(z.shape)\n",
    "        \n",
    "        Bx_x = jvp(lambda x: apply_fn(params, x, y, z)[0], (x,), (vec_x,))[1]\n",
    "        # Bx_y = jvp(lambda y: apply_fn(params, x, y, z)[0], (y,), (vec,))[1]\n",
    "        # Bx_z = jvp(lambda z: apply_fn(params, x, y, z)[0], (z,), (vec,))[1]\n",
    "\n",
    "        # By_x = jvp(lambda x: apply_fn(params, x, y, z)[1], (x,), (vec,))[1]\n",
    "        By_y = jvp(lambda y: apply_fn(params, x, y, z)[1], (y,), (vec_y,))[1]\n",
    "        # By_z = jvp(lambda z: apply_fn(params, x, y, z)[1], (z,), (vec,))[1]\n",
    "\n",
    "        # Bz_x = jvp(lambda x: apply_fn(params, x, y, z)[2], (x,), (vec,))[1]\n",
    "        # Bz_y = jvp(lambda y: apply_fn(params, x, y, z)[2], (y,), (vec,))[1]\n",
    "        Bz_z = jvp(lambda z: apply_fn(params, x, y, z)[2], (z,), (vec_z,))[1]\n",
    "\n",
    "        divB = Bx_x + By_y + Bz_z\n",
    "        \n",
    "        #-----------------------------------------------------------\n",
    "        # loss_div = jnp.sum((divB)**2, axis=-1)\n",
    "        # loss_div = jnp.mean(loss_div)\n",
    "\n",
    "        loss_div = jnp.mean((divB)**2)\n",
    "        #-----------------------------------------------------------\n",
    "\n",
    "        loss = loss_ff + loss_div\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def boundary_loss(params, x, y, z):\n",
    "        \n",
    "        # loss = 0.\n",
    "        # for i in np.arange(4):\n",
    "        #     boundary_data_batched = boundary_batches[i, :, :, :]\n",
    "        #     xb = boundary_data_batched[:, 0, :][:, 0].reshape(-1, 1)\n",
    "        #     yb = boundary_data_batched[:, 0, :][:, 1].reshape(-1, 1)\n",
    "        #     zb = boundary_data_batched[:, 0, :][:, 2].reshape(-1, 1)\n",
    "\n",
    "        #     Bx, By, Bz = apply_fn(params, xb, yb, zb)\n",
    "        #     # Bx, By, Bz = Bx.reshape(-1, 1), By.reshape(-1, 1), Bz.reshape(-1, 1)\n",
    "\n",
    "        #     Bxb = boundary_data_batched[:, 1, :][:, 0].reshape(-1, 1)\n",
    "        #     Byb = boundary_data_batched[:, 1, :][:, 1].reshape(-1, 1)\n",
    "        #     Bzb = boundary_data_batched[:, 1, :][:, 2].reshape(-1, 1)\n",
    "\n",
    "        #     Bxb_mesh, Byb_mesh, Bzb_mesh = jnp.meshgrid(Bxb.ravel(), Byb.ravel(), Bzb.ravel(), indexing='ij')\n",
    "            \n",
    "        #     loss += jnp.mean((Bx - Bxb_mesh)**2) + jnp.mean((By - Byb_mesh)**2) + jnp.mean((Bz - Bzb_mesh)**2)\n",
    "\n",
    "        #0 z=0   bottom\n",
    "        #1 z=2   top                  -> Only normal(Bz), Bx=0, By=0\n",
    "        #2 x=0   lateral_1            -> Only tangential(By, Bz), Bx=0\n",
    "        #3 x=2   lateral_2            -> Only tangential(By, Bz), Bx=0\n",
    "        #4 y=0   lateral_3            -> Only tangential(Bx, Bz), By=0\n",
    "        #5 y=2   lateral_4            -> Only tangential(Bx, Bz), By=0\n",
    "        \n",
    "\n",
    "        loss = 0.\n",
    "        Bx, By, Bz = apply_fn(params,  x[0], y[0], z[0])\n",
    "        Bx, By, Bz = jnp.squeeze(Bx), jnp.squeeze(By), jnp.squeeze(Bz)\n",
    "        loss += (1/6)*jnp.mean((Bx - b_bottom[:, :, 0])**2) + jnp.mean((By - b_bottom[:, :, 1])**2) + jnp.mean((Bz - b_bottom[:, :, 2])**2)\n",
    "\n",
    "        # Bx, By, Bz = apply_fn(params,  x[1], y[1], z[1])\n",
    "        # Bx, By, Bz = jnp.squeeze(Bx), jnp.squeeze(By), jnp.squeeze(Bz)\n",
    "        # loss += jnp.mean(Bx**2) + jnp.mean(By**2)\n",
    "\n",
    "        # Bx, By, Bz = apply_fn(params,  x[2], y[2], z[2])\n",
    "        # Bx, By, Bz = jnp.squeeze(Bx), jnp.squeeze(By), jnp.squeeze(Bz)\n",
    "        # loss += jnp.mean(Bx**2)\n",
    "\n",
    "        # Bx, By, Bz = apply_fn(params,  x[3], y[3], z[3])\n",
    "        # Bx, By, Bz = jnp.squeeze(Bx), jnp.squeeze(By), jnp.squeeze(Bz)\n",
    "        # loss += jnp.mean(Bx**2)\n",
    "        \n",
    "        # Bx, By, Bz = apply_fn(params,  x[4], y[4], z[4])\n",
    "        # Bx, By, Bz = jnp.squeeze(Bx), jnp.squeeze(By), jnp.squeeze(Bz)\n",
    "        # loss += jnp.mean(By**2)\n",
    "\n",
    "        # Bx, By, Bz = apply_fn(params,  x[5], y[5], z[5])\n",
    "        # Bx, By, Bz = jnp.squeeze(Bx), jnp.squeeze(By), jnp.squeeze(Bz)\n",
    "        # loss += jnp.mean(By**2)\n",
    "\n",
    "        Bx, By, Bz = apply_fn(params,  x[1], y[1], z[1])\n",
    "        Bx, By, Bz = jnp.squeeze(Bx), jnp.squeeze(By), jnp.squeeze(Bz)\n",
    "        loss += (1/6)*jnp.mean((Bx - bp_top[:, :, 0])**2) + jnp.mean((By - bp_top[:, :, 1])**2) + jnp.mean((Bz - bp_top[:, :, 2])**2)\n",
    "\n",
    "        Bx, By, Bz = apply_fn(params,  x[2], y[2], z[2])\n",
    "        Bx, By, Bz = jnp.squeeze(Bx), jnp.squeeze(By), jnp.squeeze(Bz)\n",
    "        loss += (1/6)*jnp.mean((Bx - bp_lateral_1[:, :, 0])**2) + jnp.mean((By - bp_lateral_1[:, :, 1])**2) + jnp.mean((Bz - bp_lateral_1[:, :, 2])**2)\n",
    "\n",
    "        Bx, By, Bz = apply_fn(params,  x[3], y[3], z[3])\n",
    "        Bx, By, Bz = jnp.squeeze(Bx), jnp.squeeze(By), jnp.squeeze(Bz)\n",
    "        loss += (1/6)*jnp.mean((Bx - bp_lateral_2[:, :, 0])**2) + jnp.mean((By - bp_lateral_2[:, :, 1])**2) + jnp.mean((Bz - bp_lateral_2[:, :, 2])**2)\n",
    "\n",
    "        Bx, By, Bz = apply_fn(params,  x[4], y[4], z[4])\n",
    "        Bx, By, Bz = jnp.squeeze(Bx), jnp.squeeze(By), jnp.squeeze(Bz)\n",
    "        loss += (1/6)*jnp.mean((Bx - bp_lateral_3[:, :, 0])**2) + jnp.mean((By - bp_lateral_3[:, :, 1])**2) + jnp.mean((Bz - bp_lateral_3[:, :, 2])**2)\n",
    "\n",
    "        Bx, By, Bz = apply_fn(params,  x[5], y[5], z[5])\n",
    "        Bx, By, Bz = jnp.squeeze(Bx), jnp.squeeze(By), jnp.squeeze(Bz)\n",
    "        loss += (1/6)*jnp.mean((Bx - bp_lateral_4[:, :, 0])**2) + jnp.mean((By - bp_lateral_4[:, :, 1])**2) + jnp.mean((Bz - bp_lateral_4[:, :, 2])**2)\n",
    "\n",
    "        \n",
    "        return loss\n",
    "\n",
    "    # unpack data\n",
    "    xc, yc, zc, xb, yb, zb = train_data\n",
    "\n",
    "    # isolate loss func from redundant arguments\n",
    "    loss_fn = lambda params: residual_loss(params, xc, yc, zc) + boundary_loss(params, xb, yb, zb)\n",
    "\n",
    "    loss, gradient = jax.value_and_grad(loss_fn)(params)\n",
    "\n",
    "    return loss, gradient"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exporti\n",
    "seed = 111\n",
    "key = jax.random.PRNGKey(seed)\n",
    "key, subkey = jax.random.split(key, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exporti\n",
    "features = 256 # feature size of each layer\n",
    "n_layers = 8 # the number of layer\n",
    "feat_sizes = tuple([features for _ in range(n_layers)]) # feature sizes\n",
    "r = 128 # rank of a approximated tensor\n",
    "out_dim = 3 # size of model output\n",
    "\n",
    "lr = 5e-4 # learning rate\n",
    "\n",
    "epochs = 10000 #10000\n",
    "log_iter = 1000 #1000\n",
    "\n",
    "# Loss weight\n",
    "# lbda_c = 100\n",
    "# lbda_ic = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SPINN3d(feat_sizes, r, out_dim, pos_enc=0, mlp='modified_mlp')\n",
    "params = model.init(\n",
    "            subkey,\n",
    "            jnp.ones((nx, 1)),\n",
    "            jnp.ones((ny, 1)),\n",
    "            jnp.ones((nz, 1))\n",
    "        )\n",
    "apply_fn = jax.jit(model.apply)\n",
    "optim = optax.adam(learning_rate=lr)\n",
    "state = optim.init(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key, subkey = jax.random.split(key, 2)\n",
    "train_data = generate_train_data(nx, ny, nz, key)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Complie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, gradient = apply_model_spinn(apply_fn, params, *train_data)\n",
    "params, state = update_model(optim, gradient, params, state)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_path = info['output_spinn']\n",
    "os.makedirs(result_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/10000 [00:00<09:25, 17.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10000 --> total loss: 0.18075550\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 1004/10000 [00:42<06:17, 23.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1000/10000 --> total loss: 0.00120284\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 2005/10000 [01:24<05:39, 23.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2000/10000 --> total loss: 0.00083884\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 3002/10000 [02:06<04:59, 23.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3000/10000 --> total loss: 0.00082557\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 4003/10000 [02:48<04:30, 22.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4000/10000 --> total loss: 0.00056228\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 5004/10000 [03:29<03:32, 23.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5000/10000 --> total loss: 0.00058385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 6004/10000 [04:11<02:42, 24.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6000/10000 --> total loss: 0.00066298\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 7004/10000 [04:53<02:08, 23.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7000/10000 --> total loss: 0.00052826\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 8005/10000 [05:35<01:28, 22.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8000/10000 --> total loss: 0.00052175\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 9004/10000 [06:17<00:42, 23.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9000/10000 --> total loss: 0.00063197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [06:58<00:00, 23.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10000/10000 --> total loss: 0.00027216\n",
      "Runtime --> total: 418.31sec (41.83ms/iter.)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "for e in trange(1, epochs + 1):\n",
    "    \n",
    "    if e % 300 == 0:\n",
    "        # sample new input data\n",
    "        key, subkey = jax.random.split(key, 2)\n",
    "        train_data = generate_train_data(nx, ny, nz, subkey)\n",
    "\n",
    "    loss, gradient = apply_model_spinn(apply_fn, params, *train_data)\n",
    "    params, state = update_model(optim, gradient, params, state)\n",
    "    \n",
    "    if e % log_iter == 0 or e == 1:\n",
    "        print(f'Epoch: {e}/{epochs} --> total loss: {loss:.8f}')\n",
    "        params_path = os.path.join(result_path, f\"params_{e}.pickle\")\n",
    "        with open(params_path, \"wb\") as f:\n",
    "            pickle.dump(params, f)\n",
    "\n",
    "runtime = time.time() - start\n",
    "print(f'Runtime --> total: {runtime:.2f}sec ({(runtime/(epochs-1)*1000):.2f}ms/iter.)')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def load_spinn_mag(param_path, nx, ny, nz, b_norm):\n",
    "    nx, ny, nz, b_norm = int(nx), int(ny), int(nz), float(b_norm)\n",
    "    model = SPINN3d(feat_sizes, r, out_dim, pos_enc=0, mlp='modified_mlp')\n",
    "    params = model.init(\n",
    "                subkey,\n",
    "                jnp.ones((nx, 1)),\n",
    "                jnp.ones((ny, 1)),\n",
    "                jnp.ones((nz, 1))\n",
    "            )\n",
    "    apply_fn = jax.jit(model.apply)\n",
    "\n",
    "    with open(param_path, 'rb') as f:\n",
    "        params = pickle.load(f)\n",
    "    x = jnp.linspace(0, 2, nx).reshape(-1, 1)\n",
    "    y = jnp.linspace(0, 2, ny).reshape(-1, 1)\n",
    "    z = jnp.linspace(0, 2, nz).reshape(-1, 1)\n",
    "    x, y, z = jax.lax.stop_gradient(x), jax.lax.stop_gradient(y), jax.lax.stop_gradient(z)\n",
    "\n",
    "    Bx, By, Bz = apply_fn(params, x, y, z)\n",
    "    B = jnp.stack([Bx, By, Bz], axis=-1)*b_norm\n",
    "    return B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xx = jnp.linspace(0, 2, nx).reshape(-1, 1)\n",
    "# yy = jnp.linspace(0, 2, ny).reshape(-1, 1)\n",
    "# zz = jnp.linspace(0, 2, nz).reshape(-1, 1)\n",
    "# xx, yy, zz = jax.lax.stop_gradient(xx), jax.lax.stop_gradient(yy), jax.lax.stop_gradient(zz)\n",
    "\n",
    "# Bxx, Byy, Bzz = apply_fn(params, xx, yy, zz)\n",
    "# Bxx, Byy, Bzz = Bxx*b_norm, Byy*b_norm, Bzz*b_norm\n",
    "# Bb = jnp.stack([Bxx, Byy, Bzz], axis=-1)\n",
    "\n",
    "# Jxx = curlx(apply_fn, params, xx, yy, zz)\n",
    "# Jyy = curly(apply_fn, params, xx, yy, zz)\n",
    "# Jzz = curlz(apply_fn, params, xx, yy, zz)\n",
    "# Jj = jnp.stack([Jxx, Jyy, Jzz], axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# B_path = os.path.join(result_path, \"B.pickle\")\n",
    "\n",
    "# with open(B_path,\"wb\") as f:\n",
    "#     pickle.dump(np.array(Bb), f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
